id,chunk_id,label,statement,context,label_reason,subject_tags,chapter,chapter_title
100000,141,barely-true,Pairing ChromaDB vectors with hero attribute tables guarantees RAG will produce fully coherent narratives every time.,RAG using ChromaDB vectorized plot data and structured attributes,"Overreaches claim of guaranteed coherence; passage only describes capability and example, not assured perfect results.","data-prep,feature-engineering,rag",3,Prepping Data for AI
100001,141,FALSE,RAG cannot retrieve policy documents or technical manuals from vector stores.,pairing ChromaDB vectorized plot data with RAG retrieval,"Contradicts passage which explicitly states RAG can retrieve policy documents, manuals, and research articles.","data-prep,feature-engineering,rag",3,Prepping Data for AI
100002,141,half-true,Pairing ChromaDB vectors with structured hero attributes guarantees fully accurate RAG-based narratives.,pairing vectorized plot data in ChromaDB with structured hero attributes,Mixes truth and error: RAG with ChromaDB supports dynamic narratives but does not guarantee full accuracy or factual correctness.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
100003,135,TRUE,Transformer-based diffusion models can synthesize short videos from text prompts.,Transformer-based video diffusion model generating moving scenes,"Passage describes Transformer video diffusion models creating scenes from prompts, e.g., robot sandwich example.","generative-ai,diffusion,gans",7,Generative AI
100004,135,FALSE,Transformers cannot generate coherent sequences and fail at sequence-to-sequence tasks.,sequence-to-sequence Transformer architecture,"Contradicts passage evidence that seq2seq Transformers successfully convert input sequences into outputs and enable MusicLM, VideoCrafter2, and code generation.","generative-ai,diffusion,gans",7,Generative AI
100005,135,mostly-true,"Transformer-based generative models can synthesize music, code, and short videos from text prompts.",applications using Transformer-based video diffusion and seq2seq models,"Passage lists MusicLM, CodeGen, VideoCrafter2, and Phenaki as Transformer-based examples producing music, code, and video from text.","generative-ai,diffusion,gans",7,Generative AI
100006,90,barely-true,Feature engineering always guarantees significantly improved model performance across tasks.,feature engineering and dataset merging for predictive modeling,"Overreaches beyond passage; passage says features help but doesn’t claim guaranteed, universal improvement.","data-prep,feature-engineering,rag",3,Prepping Data for AI
100007,90,mostly-true,Well-engineered composite features generally improve model performance on complex prediction tasks.,feature engineering and dataset merging for RAG or predictive models,Supports claim that composite features and merged datasets boost model accuracy; omits cases where feature creation can overfit or be unnecessary.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
100008,90,TRUE,Well-engineered features improve model performance on complex prediction tasks.,feature engineering for datasets like customer profiles and purchasing history,Passage explains merging datasets and creating composite features boosts models' ability to handle complex questions and reliability.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
100009,123,half-true,"The agent sometimes classifies films differently than humans, misaligning genre judgment.","agent behavior, open source inspection and evaluation","Passage shows agent exercised judgment that didn’t match human criteria, mixing correct behavior and misaligned specifics.","ai,tool-chain,notebooks",2,AI Survival Kit
100010,123,pants-fire,The agent declared A Minecraft Movie a superhero film despite lacking human judgment.,agent behavior and open source inspectability,Direct contradiction: passage states the agent did not classify it as a superhero film and judged differently than humans.,"ai,tool-chain,notebooks",2,AI Survival Kit
100011,123,mostly-true,Open-source tools make agent behavior easier to inspect and adjust for safer decision-making.,open source tools for agent behavior inspection,"Supports passage claim that open source helps inspect, adjust, and improve agent behavior, minor nuance on limits omitted.","ai,tool-chain,notebooks",2,AI Survival Kit
100012,143,half-true,Agent behavior must always be fully reproducible in finance and healthcare deployments.,reproducibility for agentic AI in finance or healthcare,"Accurately notes reproducibility importance but overstates certainty; passage says it ""matters"" and requires tuning, not ""must always be fully reproducible."".","agentic-ai,planning,tools",12,Agentic AI
100013,143,TRUE,Reproducibility is important for agent behavior in finance and healthcare settings.,reproducibility for agentic AI in finance or healthcare,Passage states reproducibility matters in finance and healthcare and recommends tuning prompts and explanations to validate behavior.,"agentic-ai,planning,tools",12,Agentic AI
100014,143,TRUE,Reproducibility is crucial for agentic AI in domains like finance and healthcare.,"reproducibility, prompts, explain outcomes, agentic AI tools",Passage explicitly contrasts trivia variation with reproducibility needs and suggests tuning prompts and explanations.,"agentic-ai,planning,tools",12,Agentic AI
100015,122,half-true,The CrewAI agent autonomously fetched IMDb and Rotten Tomatoes scores and averaged them.,agent tool use involving IMDb and Rotten Tomatoes,Mixes correct autonomy and data sources with incorrect implication of full reliability and proper genre judgment.,"ai,tool-chain,notebooks",2,AI Survival Kit
100016,122,mostly-true,The CrewAI agent autonomously sourced IMDb and Rotten Tomatoes scores to compute average ratings.,tool-chain agent using IMDb and Rotten Tomatoes data,"Supported by passage: agent looked up IMDb/Rotten Tomatoes, inferred recent superhero films, and averaged scores; minor caveat about film classification omitted.","ai,tool-chain,notebooks",2,AI Survival Kit
100017,122,pants-fire,The CrewAI agent fabricated movie ratings and invented films to produce fake averages.,CrewAI agent retrieving IMDb and Rotten Tomatoes scores,"Agent claimed nonexistent or miscategorized titles and precise percentages, directly contradicting verifiable film data.","ai,tool-chain,notebooks",2,AI Survival Kit
100018,113,mostly-true,PyTorch's autograd automatically records operations to compute gradients during backpropagation when requires_grad is True.,automatic differentiation with PyTorch autograd and requires_grad,Accurately reflects autograd behavior; omits minor details like non-leaf tensors and grad retention options.,"deep-learning,frameworks,tensors",5,Deep Learning
100019,113,TRUE,PyTorch's autograd records operations when requires_grad=True to compute gradients automatically.,autograd tracking with requires_grad in PyTorch,Directly supported: passage explains autograd records operations when requires_grad=True and computes gradients during backpropagation.,"deep-learning,frameworks,tensors",5,Deep Learning
100020,113,pants-fire,Autograd in PyTorch never records any operations even with requires_grad=True.,autograd and requires_grad in PyTorch,Directly contradicts described behavior: requires_grad=True enables recording and backward gradient computation.,"deep-learning,frameworks,tensors",5,Deep Learning
100021,18,FALSE,Granite models are proprietary and unavailable on Hugging Face.,Granite foundation models and Hugging Face distribution,Contradicts passage detail stating Granite models are released under open-source licenses and available on Hugging Face.,"generative-ai,diffusion,gans",7,Generative AI
100022,18,barely-true,Granite models replace large commercial models in performance for enterprise code and language tasks.,Granite family foundation models on watsonx via Hugging Face,"Overstates performance claim; passage says Granite lags largest commercial models in raw scale, emphasizing transparency and flexibility instead.","generative-ai,diffusion,gans",7,Generative AI
100023,18,barely-true,Granite models deliver enterprise-grade explainability and privacy equivalent to commercial giants.,Granite family foundation models on watsonx platform,Overstates parity: passage notes built-in governance and privacy but says open-source lacks scale compared to largest commercial models.,"generative-ai,diffusion,gans",7,Generative AI
100024,129,TRUE,The Red Team must deliver reproducible adversarial test cases and prioritized fixes after a Day One sweep.,Day One security sweep agenda; reproducible test cases and CI/QA,"Passage explicitly lists reproducible prompts, executive summary, priority list, and CI test translations as deliverables.","security,red-team,guardrails",8,Breaking-Securing AI
100025,129,mostly-true,A red team should deliver reproducible adversarial prompts and prioritized fixes for developers.,"red team deliverables, reproducible test cases, CI/QA","Reflects passage guidance to provide reproducible prompts, priority list, and regression tests; omits potential coordination details.","security,red-team,guardrails",8,Breaking-Securing AI
100026,129,FALSE,Red Team outputs must be immediately useful and reproducible for developers.,"Day One Security Sweep deliverables, reproducible test cases and priority list","Contradicts passage specifics: passage requires exact prompts, one-page executive summary, and priority list.","security,red-team,guardrails",8,Breaking-Securing AI
100027,69,barely-true,A linear regression model trained on five budget points reliably predicts a $400M film's box office.,toolchain example using LinearRegression and budgets dataset,Model trained on only five points; extrapolating to $400M is largely unsupported and overreaching.,"ai,tool-chain,notebooks",2,AI Survival Kit
100028,69,TRUE,A linear regression model predicts box office revenue from production budgets.,Scikit-learn linear regression example with budgets and box_office arrays,"Training code fits LinearRegression on budget inputs to predict box_office outputs, then predicts $400M.","ai,tool-chain,notebooks",2,AI Survival Kit
100029,69,barely-true,The model accurately predicts real-world box office for a $400M movie using simple linear regression.,linear regression model predicting box_office from budgets in Colab,Overclaims accuracy: example fits a tiny synthetic dataset and omits validation or real-world factors.,"ai,tool-chain,notebooks",2,AI Survival Kit
100030,70,TRUE,The passage describes training LLM agents with LangChain and CrewAI.,agent training using LangChain and CrewAI tools,Directly supported by text listing LangChain and CrewAI for training LLM agents and building prompt templates.,"ai,open-source,builder",1,Introduction – The Gold Rush Paradox
100031,70,FALSE,Open-source contributors no longer influence AI development decisions.,open-source contribution influence on AI models,Contradicts passage emphasis on contributing and community impact; claims community influence vanishes.,"ai,open-source,builder",1,Introduction – The Gold Rush Paradox
100032,11,half-true,"Many leading AI models use PyTorch for research and open-source releases, but some stacks are undisclosed.","frameworks behind models (PyTorch, JAX, undisclosed stacks)",Passage shows PyTorch widely used yet several entries are explicitly marked undisclosed or mixed.,"deep-learning,frameworks,tensors",5,Deep Learning
100033,11,barely-true,Most popular deep-learning models run exclusively on JAX for all tasks.,"frameworks used by models like GPT, Gemini, Llama",List shows many models use PyTorch or undisclosed stacks; claiming exclusive JAX is largely unsupported.,"deep-learning,frameworks,tensors",5,Deep Learning
100034,11,half-true,Many top LLMs and vision models are implemented using PyTorch or JAX frameworks.,"frameworks behind popular AI programs (PyTorch, JAX, TPU)","Mixes correct examples (Llama 3, Stable Diffusion, Gemini) with unspecified/undisclosed stacks, so partially accurate.","deep-learning,frameworks,tensors",5,Deep Learning
100035,88,TRUE,Feature engineering turns raw data into meaningful signals for better model predictions.,feature engineering for dataset signal creation,Directly supported: passage defines feature engineering as transforming raw data into signals improving model predictions.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
100036,88,mostly-true,Feature engineering turns raw data into signals that improve model predictions and usefulness.,"feature engineering for datasets (customer churn, fairness analysis)",Passage explicitly defines feature engineering as transforming raw data into meaningful signals that enhance model predictions; minor caveat about fairness limitations omitted.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
100037,88,mostly-true,Feature engineering often improves prediction performance but can miss fairness issues with underrepresented groups.,feature engineering for a customer dataset and fairness analysis,Supports that engineered features boost model performance while noting underrepresentation can undermine fairness analysis.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
100038,180,TRUE,ReLU creates piecewise-linear regions by switching neurons off or on across input boundaries.,"activation functions (ReLU, sigmoid, tanh) partitioning input space",Directly supported: passage describes ReLU as a hinge producing on/off patterns and piecewise-linear boundaries.,"deep-learning,frameworks,tensors",5,Deep Learning
100039,180,half-true,ReLU creates discrete on/off neuron patterns that always produce piecewise-linear decision boundaries.,"activation functions (ReLU, sigmoid, tanh) and piecewise-linear boundaries",Accurately notes ReLU on/off patterns and piecewise-linear boundaries but overstates 'always' without noting network depth or other layers affect shape.,"deep-learning,frameworks,tensors",5,Deep Learning
100040,180,barely-true,ReLU makes neural networks universally approximate any function with a single hidden layer.,"activation functions, ReLU, piecewise-linear boundaries","Overreaches: ReLU enables piecewise-linear regions but universal approximation requires depth or wider architectures, not a single layer.","deep-learning,frameworks,tensors",5,Deep Learning
100041,71,half-true,A small T5 model can reliably translate English to French with default generation settings.,"T5 model usage for translation (t5-small, tokenizer, generate)","Model and code show translation setup, but reliability claim omits quality limits and tuning needs.","neural-networks,cnn,transformers",6,Neuron Building Blocks
100042,71,TRUE,T5-small can translate English sentences into French using sequence-to-sequence generation.,T5 model and tokenizer; translation task,"Code loads t5-small, encodes English prompt, and generates French output with beam search, directly supported by code.","neural-networks,cnn,transformers",6,Neuron Building Blocks
100043,71,FALSE,The T5-small model cannot perform English-to-French translation.,T5ForConditionalGeneration model usage and translation function,Contradicts shown code using T5-small to translate English to French via tokenizer and model.generate.,"neural-networks,cnn,transformers",6,Neuron Building Blocks
100044,106,half-true,Diffusion models are trained to reverse any arbitrary noise corruption to generate new outputs.,training process for diffusion models and noise reversal,"Correctly notes training to reverse noise, but overstates 'any arbitrary' noise and universality of capability.","generative-ai,diffusion,gans",7,Generative AI
100045,106,TRUE,A diffusion model learns to reverse noise by training on many corrupted examples.,diffusion model training on noisy examples,Passage explains training on thousands or millions of examples to recognize and reverse applied noise patterns.,"generative-ai,diffusion,gans",7,Generative AI
100046,106,half-true,A diffusion model learns to reverse noise and generate new outputs by training on many corrupted examples.,training diffusion models with noisy examples,Accurately describes learning-to-denoise mechanism but omits specifics like noise schedule and objective functions.,"generative-ai,diffusion,gans",7,Generative AI
100047,89,mostly-true,Feature engineering converts raw data into informative signals that improve model predictions and pattern detection.,feature engineering for datasets and merged customer profiles,"Broadly supported by passage: emphasizes reshaping datasets and merging context to boost model prediction, omitting implementation caveats.","data-prep,feature-engineering,rag",3,Prepping Data for AI
100048,89,TRUE,Feature engineering transforms raw data into meaningful signals that improve model predictions.,feature engineering; dataset and merged customer profiles,Passage defines feature engineering as converting raw data into signals and cites merging datasets to improve predictions.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
100049,89,half-true,Feature engineering always requires merging external datasets to improve model predictions.,feature engineering; dataset merging; customer profiles,Mixes correct idea that merges can help with the incorrect claim that merging is always required.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
100050,18,half-true,AI requires external tools to act autonomously on organized datasets in all cases.,"need for mechanisms to interact with data, reasoning and tool use","Accurately notes need for mechanisms, but passage doesn't claim external tools are always required.","agentic-ai,planning,tools",12,Agentic AI
100051,18,mostly-true,Agentic AI can analyze datasets and use tools to plan actions but requires reasoning mechanisms to act autonomously.,agentic AI planning with tools and datasets,Passage supports dataset analysis plus need for interaction and reasoning; minor overstates readiness for autonomous action.,"agentic-ai,planning,tools",12,Agentic AI
100052,18,half-true,Agentic AI can act autonomously once it has datasets and interaction mechanisms fully integrated.,agentic AI requiring datasets and interaction mechanisms,"Correct that datasets and mechanisms are needed, but overstates immediacy and completeness of autonomy capabilities.","agentic-ai,planning,tools",12,Agentic AI
100053,85,barely-true,"Equipping agents with web search tools guarantees consistently accurate, up-to-date answers.",tool-enabled agent using WebsiteSearchTool for web searches,Overstates reliability: web search access can improve information but does not ensure consistent accuracy or recency due to retrieval errors and source quality.,"agentic-ai,planning,tools",12,Agentic AI
100054,85,TRUE,Equipping agents with web search tools improves their decision-making and problem-solving abilities.,web search tool enabling external data access,"Passage states tools let agents access up-to-date information, enhancing decision-making and problem-solving.","agentic-ai,planning,tools",12,Agentic AI
100055,85,pants-fire,The agent autonomously controls real-world robots to perform physical tasks without human oversight.,agent tools and WebsiteSearchTool usage,Passage only describes web search tool and decision-making; no robot control or physical actuation capability exists.,"agentic-ai,planning,tools",12,Agentic AI
100056,23,TRUE,Audio fingerprinting extracts measurable features from raw audio to train listening models.,"audio fingerprint, feature extraction for models",Passage states raw audio is distilled into measurable features and used to teach AI to listen.,"media-forensics,voice-cloning,deepfake",9,Deepfake Defense
100057,23,half-true,Audio fingerprinting always enables AI models to fully distinguish real from synthetic speech.,"audio fingerprint, feature extraction for voice-cloning detection","Claims absolute discrimination though passage only describes extracting patterns and features, omitting limits and false positives.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
100058,23,half-true,Audio fingerprinting condenses raw sound into measurable features but may omit fine-grained signal details.,"audio fingerprint, feature extraction for models",Accurately notes feature extraction benefit while admitting omission of detailed raw signal information mentioned in passage.,"media-forensics,voice-cloning,deepfake",9,Deepfake Defense
100059,20,pants-fire,All models can be perfectly traced to individual data consent records for complete accountability.,data lineage and consent tracking in datasets,"Passage says lineage aids accountability, not that every model has perfect per-record consent; claims perfect traceability contradicts consent and collection reality.","ethics,governance,privacy",11,AI Ethics and Governance
100060,20,half-true,Data lineage guarantees full accountability and consent verification for all AI datasets.,data lineage and consent in transparency,"Accurately highlights data lineage importance but overstates guarantee; passage says it aids accountability and tracing, not ensures complete verification for all datasets.","ethics,governance,privacy",11,AI Ethics and Governance
100061,20,half-true,Data lineage claims full consent and provenance for all training datasets used by models.,transparency in data lineage and consent for datasets,Asserts complete consent/provenance which mixes correct emphasis on lineage with incorrect universality; passage promotes tracing but not guaranteed full consent.,"ethics,governance,privacy",11,AI Ethics and Governance
100062,25,half-true,The company exclusively partners only with cloud and hardware giants to provide all open models and training resources.,"integration with watsonx, NVIDIA, Google Cloud partnerships",Mixes correct partners and infrastructure involvement with incorrect exclusivity and completeness claims about open models and resources.,"open-source,community,ai",0,Foreword – Robo Interviews Clément Delangue
100063,25,barely-true,Clément Delangue claims the company’s partnerships fully ensure open-source AI remains community-controlled.,"integration with watsonx Granite models and partnerships (Google, NVIDIA, IBM)",Overstates evidence: passage cites collaborations and resources but not proof that community control is fully ensured.,"open-source,community,ai",0,Foreword – Robo Interviews Clément Delangue
100064,25,pants-fire,Delangue claims open-source AI partnerships secretly control global AI infrastructure and policymaking.,"enterprise AI partnerships with Google Cloud, NVIDIA, IBM, AWS",Allegation directly contradicts passage description of collaborative partnerships and openness; no evidence of secret global control.,"open-source,community,ai",0,Foreword – Robo Interviews Clément Delangue
100065,71,mostly-true,Enterprises prioritize trust and accountability over raw model performance when choosing AI systems.,"enterprise customers, trust and accountability, task-specific systems","Passage emphasizes enterprise preference for trust/accountability versus mere performance, minor nuance about task-specific tradeoffs omitted.","ethics,governance,privacy",11,AI Ethics and Governance
100066,71,TRUE,Enterprise customers prioritize trust and accountability over pure performance.,enterprise customers; trust and accountability,Passage states trust and accountability often tip the scale for enterprise customers compared to performance.,"ethics,governance,privacy",11,AI Ethics and Governance
100067,71,barely-true,Enterprise customers prioritize model performance over trust and accountability when choosing AI systems.,enterprise customers; trust and accountability vs performance,Contradicts passage emphasis that trust and accountability often tip the scale over mere performance.,"ethics,governance,privacy",11,AI Ethics and Governance
100068,102,mostly-true,Synthetic voices consistently leave identifiable acoustic traces that enable practical deepfake audio defenses.,voiceprint features and deepfake audio traces,"Passage indicates voiceprint-derived features reveal imitation traces, enabling defenses though methods are evolving.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
100069,102,barely-true,Synthetic voices always leave detectable traces that automated tools can reliably identify.,voiceprint features and deepfake audio detection,Overreaches by asserting always and reliable identification; passage only claims traces exist and defenses are developing.,"media-forensics,voice-cloning,deepfake",9,Deepfake Defense
100070,102,barely-true,Synthetic voices always leave detectable traces that allow reliable deepfake audio detection tools.,voiceprint features used for detection in deepfake audio,"Overreaches: passage says traces exist and can be modeled, but not that detection is always reliable.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
100071,125,barely-true,One-hot encoding of text with sparse_output=true always prevents data leakage in classification pipelines.,preprocessor using OneHotEncoder and train/test split with stratify,"Overstates protection: fitting encoder on training set prevents leakage, but sparse_output alone doesn't.","machine-learning,classification,evaluation",4,Classical Machine Learning
100072,125,barely-true,One-hot encoding text features and median imputation always prevent data leakage in train/test workflows.,preprocessor with OneHotEncoder and SimpleImputer,"Overstates protection: correct fit-on-training step helps, but those transforms can still leak via feature selection or improper handling.","machine-learning,classification,evaluation",4,Classical Machine Learning
100073,125,mostly-true,Stratified 80/20 train-test splitting and fitting preprocessing only on training data prevents label distribution shifts and leakage.,train_test_split with stratify and ColumnTransformer preprocessing,Approach preserves class ratios and avoids preprocessing leakage; minor caveat about other leakage sources.,"machine-learning,classification,evaluation",4,Classical Machine Learning
100074,109,TRUE,RAG improves model outputs by retrieving external documents to ground responses.,retrieval-augmented generation with LLMs and curated database,Passage states RAG queries external sources and provides retrieved snippets for LLMs to weave into grounded answers.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
100075,109,half-true,"RAG always guarantees accurate answers by retrieving perfect, up-to-date database snippets.",RAG using curated database and retrieved snippets with an LLM,"Mixes correct mechanism (retrieval into LLM) with incorrect certainty about perfect, up-to-date accuracy.","data-prep,feature-engineering,rag",3,Prepping Data for AI
100076,109,FALSE,RAG replaces large language models and functions without any generative model involvement.,RAG with LLMs and retrieved document snippets,"Contradicts passage: RAG is described as paired with LLMs, not replacing them; retrieved snippets feed a generative model.","data-prep,feature-engineering,rag",3,Prepping Data for AI
100077,75,TRUE,Batched inference with batch sizes around 32–64 provides a practical speed-efficiency sweet spot.,batched inference throughput and speedup for model inputs,"Observed >5× speedup at batch size 32 and diminishing marginal gains beyond, supporting 32–64.","mlops,scaling,deployment",10,AI At Scale
100078,75,barely-true,Batch size 128 provides the best balance of throughput and resource efficiency for the model.,"batched inference throughput and speedup, batch size 32–64",Contradicts reported sweet spot of 32–64; 128 overreaches beyond observed marginal gains.,"mlops,scaling,deployment",10,AI At Scale
100079,75,half-true,Batched inference with batch size 32 to 64 yields a practical 3–6× speedup over batch size 1 for this model.,"batched inference throughput and speedup, batch size 32–64","Passage reports over 5× speedup at batch 32 but omits exact 3–6× range, mixing accurate and inferred specifics.","mlops,scaling,deployment",10,AI At Scale
100080,105,barely-true,Human-in-the-loop sign-off checkpoints always prevent real-world consequences from autonomous actions.,HumanLayer with LangChain human approval checkpoint,Overreaches beyond passage: sign-off introduces review but doesn't guarantee prevention of real-world impacts.,"security,red-team,guardrails",8,Breaking-Securing AI
100081,105,barely-true,HumanLayer integration can enforce human approval checkpoints for critical model actions.,HumanLayer with LangChain approval checkpoint example,"Passage only gives a simplified, illustrative code snippet and notes complexity, so enforcement claim is overstated.","security,red-team,guardrails",8,Breaking-Securing AI
100082,105,FALSE,The passage claims human sign-off checkpoints are unnecessary for critical decisions.,human approval checkpoint using HumanLayer and LangChain,Contradicts passage instruction to introduce deliberate human sign-off; it actually advocates requiring approval.,"security,red-team,guardrails",8,Breaking-Securing AI
100083,59,TRUE,Decision trees provide transparent rule-based explanations for each classification decision.,interpretability of decision tree model in medical diagnosis and credit approval,"Passage explicitly highlights rule paths and transparency, citing regulators, doctors, and auditors needing explanations.","machine-learning,classification,evaluation",4,Classical Machine Learning
100084,59,barely-true,Decision trees always provide complete explanations of model decisions for regulators and auditors.,interpretability of decision trees in medical diagnosis and credit approval,"Overstates capabilities: decision trees offer transparency but may omit feature interactions, noise, or preprocessing steps.","machine-learning,classification,evaluation",4,Classical Machine Learning
100085,59,half-true,"Decision trees always provide fully transparent, easily interpretable classifications for regulated tasks.","decision trees, interpretability, credit approval","Accurate about rule paths but overstates universality; ignores complex trees, pruning, and feature interactions.","machine-learning,classification,evaluation",4,Classical Machine Learning
100086,61,mostly-true,The cheat sheet broadly helps users craft better prompts and design smarter agents.,agentic-ai prompt engineering and model tools,Passage endorses a cheat sheet as a practical game plan that improves prompt design and agent building.,"agentic-ai,planning,tools",12,Agentic AI
100087,61,TRUE,A cheat sheet summarizes prompts and models to help build smarter agents.,agentic-ai prompt and model cheat sheet,Directly supported: text says packaging prompts and models into a cheat sheet helps shape better prompts and smarter agents.,"agentic-ai,planning,tools",12,Agentic AI
100088,61,TRUE,The cheat sheet helps shape better prompts and build smarter agents.,"prompting and agent design; few-shot example, prompts, models","Passage explicitly frames a cheat sheet as a game plan to shape prompts and build smarter agents, improving odds.","agentic-ai,planning,tools",12,Agentic AI
100089,139,TRUE,Application-layer trust in LLM outputs causes the true security vulnerability in red-team exploits.,RAG pipeline and automation hook in downstream code,"Passage states exploits succeeded due to fragile downstream assumptions, not inherent model bugs.","security,red-team,guardrails",8,Breaking-Securing AI
100090,139,pants-fire,The application layer's RAG pipeline trust enabled successful red-team exploits.,RAG pipeline and downstream application logic,"Passage asserts exploits stem from fragile downstream assumptions, not the model itself.","security,red-team,guardrails",8,Breaking-Securing AI
100091,139,half-true,Red-team exploits often arise from fragile downstream application assumptions rather than model outputs alone.,RAG pipeline and automation hook in model deployment,Accurately notes downstream fragility but omits that model confidence and context also contribute vulnerability.,"security,red-team,guardrails",8,Breaking-Securing AI
100092,102,pants-fire,"Dropout permanently disables half the neurons during inference, reducing model capacity by 50%.",PyTorch nn.Dropout layer behavior during inference,Contradicts fact that dropout is inactive during inference; inference restores all neurons and scales outputs.,"deep-learning,frameworks,tensors",5,Deep Learning
100093,102,half-true,Dropout permanently removes individual neurons from the trained model to improve generalization.,dropout behavior in PyTorch neural network layers,Mixes correct goal (improves generalization) with incorrect mechanism: neurons are not permanently removed at inference.,"deep-learning,frameworks,tensors",5,Deep Learning
100094,102,mostly-true,Dropout is disabled during inference and outputs are scaled to match training behavior.,PyTorch nn.Dropout in model inference,"Passage states dropout is active only in training and restored during inference, with outputs scaled accordingly.","deep-learning,frameworks,tensors",5,Deep Learning
100095,85,barely-true,Fine-tuning SpeechT5 always produces indistinguishable clones of a target speaker's voice.,fine-tuning SpeechT5 on a prepared dataset,Overreaches beyond passage: fine-tuning specializes voice but does not guarantee indistinguishable cloning.,"media-forensics,voice-cloning,deepfake",9,Deepfake Defense
100096,85,TRUE,Fine-tuning SpeechT5 enables the model to replicate a specific speaker's voice.,fine-tuning SpeechT5 on a prepared dataset,Passage explicitly states SpeechT5 is fine-tuned on a dataset to replicate a speaker's rhythm and tone.,"media-forensics,voice-cloning,deepfake",9,Deepfake Defense
100097,85,mostly-true,Fine-tuning a SpeechT5 model customizes it to replicate a specific speaker's voice.,fine-tuning SpeechT5 on a prepared dataset for voice cloning,"Accurately reflects described process of adapting SpeechT5 to a speaker, omitting potential dataset limitations and exact hyperparameter effects.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
100098,36,barely-true,Ethics frameworks guarantee AI systems will prevent misuse and harm in all operational contexts.,ethical frameworks and human oversight in AI governance,Overreaches beyond passage: frameworks guide behavior but their impact depends on translation into practice.,"ethics,governance,privacy",11,AI Ethics and Governance
100099,36,FALSE,AI governance frameworks universally eliminate all misuse without need for human oversight.,governance frameworks and human oversight in AI ethics,Contradicts passage: governance depends on translation into practice and human oversight remains necessary to prevent misuse.,"ethics,governance,privacy",11,AI Ethics and Governance
100100,36,mostly-true,AI governance principles generally require human oversight to maintain control and mitigate misuse.,governance principles and human oversight in AI ethics,"Principles emphasize human oversight and guardrails, though practical impact depends on real-world implementation.","ethics,governance,privacy",11,AI Ethics and Governance
100101,29,TRUE,Agentic AI workflows can use external tool outputs and datasets to filter and analyze user sentiment.,FronkonGames/steam-games-dataset usage in an Agentic AI notebook,"Example shows loading dataset, extracting Positive review counts, and filtering for analysis and insights.","agentic-ai,planning,tools",12,Agentic AI
100102,29,mostly-true,The example demonstrates loading a Hugging Face dataset to list top Steam games by positive reviews.,FronkonGames/steam-games-dataset load and Pandas processing,"Code and output show dataset loading, conversion to DataFrame, and top-5 positive review listing.","agentic-ai,planning,tools",12,Agentic AI
100103,29,FALSE,The dataset shows Grand Theft Auto V has the most positive reviews on Steam.,FronkonGames/steam-games-dataset positive review counts,"Listed rankings show Counter-Strike: Global Offensive has the highest positive reviews, contradicting GTA V.","agentic-ai,planning,tools",12,Agentic AI
100104,176,barely-true,Synthetic data generation always preserves privacy while fully matching real data distributions.,synthetic data for sensitive datasets and model training,Overreaches: synthetic data can reduce disclosure risk but may still leak or fail to perfectly match real distributions.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
100105,176,FALSE,Synthetic data generation never preserves statistical patterns of real datasets.,synthetic data replicating sample data patterns,Contradicts passage: synthetic methods are described as replicating patterns to mimic real data for training.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
100106,176,half-true,Synthetic customer-service transcripts perfectly preserve all statistical properties of original data.,"synthetic data for sensitive datasets, e.g., customer service transcripts",Mixes correct idea of mimicry with incorrect absolute claim about perfectly preserving all statistical properties.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
100107,46,pants-fire,IBM secretly built a mass-surveillance facial recognition program despite public withdrawal claims.,"IBM facial recognition withdrawal, racial profiling and surveillance",Directly contradicts passage detail that IBM publicly withdrew from general-purpose facial recognition research citing surveillance concerns.,"ethics,governance,privacy",11,AI Ethics and Governance
100108,46,half-true,IBM ceased all facial recognition development permanently in 2020 due to racial profiling concerns.,ethical leadership example involving facial recognition research,Accurately notes IBM's 2020 withdrawal and racial profiling concerns but overstates permanence and scope of cessation.,"ethics,governance,privacy",11,AI Ethics and Governance
100109,46,half-true,IBM abandoned all facial recognition-related tools and datasets in 2020 due to mass surveillance concerns.,ethical leadership; facial recognition research and dataset stewardship,"Partly correct about IBM pausing general-purpose facial recognition research in 2020, but overstates abandoning all tools and datasets and omits nuance about research scope and policy motivations.","ethics,governance,privacy",11,AI Ethics and Governance
100110,101,pants-fire,Models trained with no logs or versioning are reproducible and transparent in production.,"model card, versioning, README.md on Hugging Face Hub",Contradicts described built-in versioning and logging; claims reproducibility without logs or versioning.,"mlops,scaling,deployment",10,AI At Scale
100111,101,half-true,Hugging Face model cards automatically capture every run's complete change log and bill of materials.,model card on Hugging Face Hub; versioning and README.md,"Correctly notes model cards and logs exist, but overstates automation and completeness of run-by-run BOM.","mlops,scaling,deployment",10,AI At Scale
100112,101,FALSE,Model versioning and visibility are absent from the described workflow.,model versioning and README.md model card on Hugging Face,"Passage explicitly states versioning and visibility are built in and model card added, contradicting absence claim.","mlops,scaling,deployment",10,AI At Scale
100113,108,barely-true,Gradients indicate how much each neural network weight contributed to the loss.,gradients and loss signal in deep learning,Accurately links gradients to parameter contribution but overstates determinism about exact magnitude and causality.,"deep-learning,frameworks,tensors",5,Deep Learning
100114,108,TRUE,Gradients indicate how much each network parameter contributed to the error.,gradients used to update model weights in deep learning,Directly supported: passage explains gradients show each parameter's contribution to the error for improvement.,"deep-learning,frameworks,tensors",5,Deep Learning
100115,108,half-true,Gradients tell exactly how much each neural network weight should be changed to fix error.,"gradients for model parameters (weights, biases) in deep learning","Correct that gradients indicate contribution and direction, but they don't give exact required magnitude due to learning rates, optimization dynamics, and nonlinearity.","deep-learning,frameworks,tensors",5,Deep Learning
100116,24,FALSE,Data preparation is optional because shortcuts reliably fix dataset problems before analysis.,data preparation and cleaning for datasets,Contradicts passage warning that shortcuts hide problems and early fixing is critical.,"ai,tool-chain,notebooks",2,AI Survival Kit
100117,24,half-true,Data preparation always prevents downstream model errors if done superficially.,"data preparation, dataset cleaning and formatting",Mixes a correct emphasis on data prep importance with incorrect claim that superficial fixes always prevent errors; shortcuts can hide problems.,"ai,tool-chain,notebooks",2,AI Survival Kit
100118,24,TRUE,"Data preparation involves cleaning datasets, converting formats, and addressing missing values and duplicates.",data preparation for datasets and features,"Describes cleaning, format conversion, missing values, duplicates, and feature adjustments as core tasks.","ai,tool-chain,notebooks",2,AI Survival Kit
100119,1,barely-true,AI systems often amplify societal biases and enable mass surveillance when deployed without safeguards.,ethical risks: biased algorithms and facial recognition surveillance,Overreach beyond passage specifics: passage cites risks and skepticism but lacks prevalence or inevitability claims.,"ethics,governance,privacy",11,AI Ethics and Governance
100120,1,mostly-true,"AI systems require ethics, transparency, and accountability to prevent harms like bias and surveillance.",ethical safeguards for models and facial recognition,"Broadly supported: passage emphasizes ethics, transparency, accountability and cites bias, facial recognition, surveillance as harms.","ethics,governance,privacy",11,AI Ethics and Governance
100121,1,half-true,AI systems often amplify societal biases unless designers ensure accountability mechanisms.,"ethical safeguards, transparency, accountability, biased algorithms",Mixes correct risk of bias amplification with overstated certainty about prevalence and causal role of accountability mechanisms.,"ethics,governance,privacy",11,AI Ethics and Governance
100122,146,half-true,AI chatbots with system access require both traditional IT safeguards and new generative-specific defenses.,deploying support chatbot with privileged API access,Combines correct advice about input sanitization and access control with vague claim about 'new generative-specific defenses' lacking concrete examples.,"security,red-team,guardrails",8,Breaking-Securing AI
100123,146,barely-true,AI chatbots require only the same traditional IT security measures as other APIs.,securing generative AI chatbots with access control and audit logs,Overreaches by implying no new risks; passage emphasizes generative AI breaks the mold.,"security,red-team,guardrails",8,Breaking-Securing AI
100124,146,mostly-true,AI systems require traditional IT security controls alongside new generative-specific safeguards.,securing generative AI models and privileged API access,"Passage endorses using existing controls like input sanitization and access control, while noting generative AI demands additional, model-specific safeguards.","security,red-team,guardrails",8,Breaking-Securing AI
100125,75,TRUE,Reducing 160 features to 60 components retained about 73% of the dataset's variance.,PCA dimensionality reduction on feature dataset,Directly supported by reported cumulative variance values showing 73% at 60 components.,"machine-learning,classification,evaluation",4,Classical Machine Learning
100126,75,FALSE,Retaining 60 principal components preserves over 90% of dataset variance in the example.,PCA variance explained for dimensionality reduction,"Contradicts reported numbers: 60 components retained about 73% variance, not over 90%.","machine-learning,classification,evaluation",4,Classical Machine Learning
100127,75,mostly-true,Using PCA to reduce 160 features to 60 preserves most signal while keeping data manageable.,PCA dimensionality reduction retaining ~73% cumulative variance at 60 components,"Empirical run shows 73% variance at 60 components, a substantial reduction with minor information loss.","machine-learning,classification,evaluation",4,Classical Machine Learning
100128,59,pants-fire,Z-score normalization makes Spider-Man weigh negative kilograms after scaling.,feature scaling example with z-score and hero dataset,"Claim contradicts numeric example: z-score maps to standard deviations, not negative physical kilograms; implausible conversion.","data-prep,feature-engineering,rag",3,Prepping Data for AI
100129,59,mostly-true,Z-score normalization generally makes different feature scales comparable for modeling.,feature scaling using z-score normalization in datasets,"Passage explains z-score converts values to standard deviations from mean, omitting edge cases and distribution assumptions.","data-prep,feature-engineering,rag",3,Prepping Data for AI
100130,59,pants-fire,Min-max scaling can make Spider-Man's height negative under typical hero ranges.,feature scaling on hero height using min-max normalization,Min-max yields 0.45 for Spider-Man given 122–244 cm; claiming negative contradicts provided min/max.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
100131,18,pants-fire,Big AI secretly prevents builders from using open tools or working with their own data.,builders using open tools and their own data,Passage states Big AI enables working with own data and open tools; claim directly contradicts that empowerment.,"ai,open-source,builder",1,Introduction – The Gold Rush Paradox
100132,18,TRUE,"Open tools let builders control, customize, and build models using their own data.",open tools and working with your own data,Directly supported: passage promises builders can use open tools to work with data and shape models.,"ai,open-source,builder",1,Introduction – The Gold Rush Paradox
100133,18,barely-true,Open tools enable builders to fully control and customize purpose-driven AI models without limitations.,using open tools and purpose-driven models,Overstates passage claim by implying 'fully' control and 'without limitations' despite only promising control and flexibility.,"ai,open-source,builder",1,Introduction – The Gold Rush Paradox
100134,45,mostly-true,The code includes a helper function that classifies audio as either Real Jerry or Not Real.,predict_new_wav helper function for voice-cloning authenticity,"Passage indicates a helper function (predict_new_wav) exists to decide Real Jerry versus Not Real, omitting implementation details.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
100135,45,FALSE,The helper function proves cloned voices can always be perfectly detected.,predict_new_wav helper function for voice-cloning detection,"Contradicts passage: helper function used for testing, not claimed infallible or perfect detection.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
100136,45,barely-true,The helper function can always determine with high confidence whether audio is Jerry's real voice.,predict_new_wav helper function for voice-cloning detection,"Overstates capability; passage only describes a helper function without claiming perfect, high-confidence decisions.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
100137,112,pants-fire,Diffusion models always output four identical images every run.,"diffusion model image generation, denoising steps, multiple variations",Contradicts passage detail that each run yields four slightly different images with natural variation.,"generative-ai,diffusion,gans",7,Generative AI
100138,112,TRUE,The diffusion model generates multiple varied images from pure noise through denoising steps.,diffusion model image generation using denoising steps,Passage explicitly describes starting from pure noise and producing four varied images via denoising iterations.,"generative-ai,diffusion,gans",7,Generative AI
100139,112,half-true,A diffusion model always generates exactly four distinct images per run.,"diffusion model image generation, denoising steps","Correct that diffusion models output multiple variations, but passage says each run yields four images sometimes, not always.","generative-ai,diffusion,gans",7,Generative AI
100140,93,barely-true,A cloned voice can perfectly replicate a speaker's warmth and timing from limited data.,"voice cloning, spectrogram, small dataset","Passage notes timing and warmth differences with smaller datasets, so perfect replication is largely unsupported.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
100141,93,TRUE,The cloned voice successfully reproduced Jerry's pacing and tone with minor timing and warmth differences.,"voice cloning, spectrogram for cloned audio",Passage explicitly reports pacing and tone matched while noting minor timing and warmth differences due to data/training.,"media-forensics,voice-cloning,deepfake",9,Deepfake Defense
100142,93,TRUE,The cloned voice closely matched Jerry's pacing and tone but had minor timing and warmth differences.,voice cloning spectrogram and training data quality,Passage notes close match in pacing and tone while citing timing and warmth differences due to dataset/training.,"media-forensics,voice-cloning,deepfake",9,Deepfake Defense
100143,135,barely-true,Models can rely solely on scoped IAM to prevent unauthorized document access in retrieval systems.,"access controls, scoped IAM, retrieval-side permissions",Overreaches: passage recommends HITL checkpoints or IAM but does not claim IAM alone suffices to prevent access breaches.,"security,red-team,guardrails",8,Breaking-Securing AI
100144,135,mostly-true,Models should enforce user-scoped access controls and HITL checkpoints for state-changing actions.,execution control with HITL and scoped IAM credentials,Passage advocates enforcing user-scoped retrieval and requiring HITL or scoped IAM for state changes; minor implementation caveats omitted.,"security,red-team,guardrails",8,Breaking-Securing AI
100145,135,half-true,Requiring scoped IAM and HITL fully prevents models from accessing unauthorized internal documents.,access controls and IAM for model retrieval and execution,Correctly cites scoped IAM and HITL but overstates outcome; measures reduce risk but don't fully prevent access.,"security,red-team,guardrails",8,Breaking-Securing AI
100146,13,half-true,Open-source contribution requires professional-level expertise in AI model training and governance.,"open-source contribution resources (First Timers Only, GitHub guide, Linux Foundation)",Mixes correct emphasis on governance and model training with incorrect claim that professional-level expertise is required; passage emphasizes beginners and non-expert roles.,"open-source,community,contribution",13,Commit to Contribute
100147,13,half-true,Open-source contribution requires advanced expertise in model training and governance to be meaningful.,"open-source contribution roles and guides (First Timers Only, GitHub Guide)",Mixes correct focus on model training/governance with contradicted guidance that beginners aren't required.,"open-source,community,contribution",13,Commit to Contribute
100148,13,barely-true,Anyone can meaningfully contribute to open-source AI projects without prior expertise.,"First Timers Only guide and contribution types (code, non-code, model training)",Passage lists many accessible roles but overstates ease and impact without addressing skill or review barriers.,"open-source,community,contribution",13,Commit to Contribute
100149,89,pants-fire,NIST's AI RMF mandates outlawing all facial recognition models worldwide immediately.,policy guidance for AI risk management (NIST AI RMF),Directly contradicts NIST AI RMF scope and recommendations; no global ban or immediate outlawing required.,"ethics,governance,privacy",11,AI Ethics and Governance
100150,89,mostly-true,AI governance frameworks like NIST's AI RMF broadly reduce organizational AI risks when implemented.,NIST AI RMF 1.0 risk management framework,"Framework provides structured practices and controls reducing risk, though implementation complexity and gaps remain.","ethics,governance,privacy",11,AI Ethics and Governance
100151,89,barely-true,NIST's AI RMF 1.0 mandates legal liability rules for all AI developers worldwide.,NIST AI RMF 1.0 risk management framework,"Overreaches: AI RMF provides voluntary risk-management guidance, not mandatory global liability rules.","ethics,governance,privacy",11,AI Ethics and Governance
100152,10,half-true,Scikit-learn was started in 2007 and is now the dominant toolkit for classical ML in Python.,scikit-learn history and community support,"Correct founding year and strong community, but overstates 'dominant' versus other frameworks like TensorFlow.","machine-learning,classification,evaluation",4,Classical Machine Learning
100153,10,half-true,Scikit-learn began as a 2007 Google Summer of Code project by David Cournapeau.,"scikit-learn origin and contributors (library, community)","Accurately names 2007 and David Cournapeau, but omits broader development timeline and community growth.","machine-learning,classification,evaluation",4,Classical Machine Learning
100154,10,half-true,Scikit-learn originated as a Google Summer of Code project started by David Cournapeau in 2007.,Scikit-learn origin and history in classical machine-learning toolkit,"Accurate origin and year, but overstates sole authorship and omits later major contributors and community growth.","machine-learning,classification,evaluation",4,Classical Machine Learning
100155,1,mostly-true,"The foreword asserts that open, collaborative human–AI partnerships produce powerful, trustworthy results.","foreword discussing openness, human–AI teaming, and projects","Supports openness and human–AI teaming claims, omits nuanced limits or required safeguards.","open-source,community,ai",0,Foreword – Robo Interviews Clément Delangue
100156,1,TRUE,"Delangue emphasizes open collaboration between humans and AI to build trustworthy, creative systems.","Foreword discussion of openness, trustworthy AI, human-AI collaboration",Passage explicitly praises human–AI teaming and states building trustworthy AI begins with openness.,"open-source,community,ai",0,Foreword – Robo Interviews Clément Delangue
100157,1,barely-true,The foreword claims open-source tools alone guarantee trustworthy AI collaborations.,foreword discussion of openness and trustworthy AI,Overstates support: passage emphasizes openness but not that open-source alone guarantees trustworthiness.,"open-source,community,ai",0,Foreword – Robo Interviews Clément Delangue
100158,162,half-true,Reinforcement learning agents always require no initial environment model to learn effective policies.,"reinforcement learning, policy, reward signal","Correct that many agents learn without models, but many methods use or benefit from initial models or simulators.","machine-learning,classification,evaluation",4,Classical Machine Learning
100159,162,half-true,Reinforcement learning agents learn optimal policies by trial-and-error using reward signals.,policy and reward signal in reinforcement learning,Accurately describes trial-and-error and reward feedback but overstates learning always reaching optimal policies.,"machine-learning,classification,evaluation",4,Classical Machine Learning
100160,162,half-true,The agent learns delivery routes by experimenting and receiving reward feedback during training.,reinforcement learning policy and reward signal,"Correctly states exploration and reward-driven learning, but overgeneralizes specifics about maps and training details.","machine-learning,classification,evaluation",4,Classical Machine Learning
100161,199,mostly-true,"A neural network for binary email spam classification can use word-count vectors, a two-neuron softmax output, and CrossEntropyLoss.",email spam classification using word-count vectors and Softmax output,"Passage describes converting emails to frequency vectors, two-neuron Softmax outputs, and using CrossEntropyLoss; minor caveat: alternatives like sigmoid/BCE could also apply.","deep-learning,frameworks,tensors",5,Deep Learning
100162,199,mostly-true,A neural network can classify emails as spam or not spam using word-count vectors and CrossEntropyLoss.,spam detection using word-frequency vectors and Softmax output,"Supported by passage: uses word-frequency vectors, two-output Softmax, and CrossEntropyLoss for classification.","deep-learning,frameworks,tensors",5,Deep Learning
100163,199,half-true,Softmax with two output neurons is required for binary email spam classification using CrossEntropyLoss.,binary classification output layer and CrossEntropyLoss in deep-learning,"Correct that two outputs with Softmax and CrossEntropyLoss work, but unnecessary: single-logit with BCEWithLogitsLoss is common and more efficient.","deep-learning,frameworks,tensors",5,Deep Learning
100164,15,pants-fire,OpenCV was secretly created to enable voice-cloning deepfakes for covert surveillance worldwide.,OpenCV framework for video and computer vision,"Directly contradicts origin and stated uses: created inside Intel for real-time CPU image processing, not voice-cloning or covert deepfake surveillance.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
100165,15,mostly-true,OpenCV evolved from Intel research into a widely used framework for computer vision and AI applications.,"OpenCV framework, image processing and video tools","Supported by history and examples like real-time panoramic video, omits some specific growth timelines and domains.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
100166,15,FALSE,OpenCV was originally developed for GPU-based real-time image processing.,tool origin and compute platform in OpenCV research,"Contradicts passage detail: OpenCV initially targeted CPU-heavy image processing, not GPU.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
100167,55,half-true,A single abstraction layer completely eliminates need for provider-specific API changes.,model swapping and vendor independence abstraction layer,"Overstates guarantees: passage says abstraction minimizes provider-specific reliance and enables swapping, not that it entirely eliminates API changes.","agentic-ai,planning,tools",12,Agentic AI
100168,55,TRUE,An abstraction layer enables switching models without changing application logic.,model swapping and input/output standardization in tool abstractions,Directly stated: abstraction layer allows model swapping and consistent input/output without code changes.,"agentic-ai,planning,tools",12,Agentic AI
100169,55,FALSE,An abstraction layer forces developers to rewrite application logic when changing AI models.,model swapping abstraction layer,Contradicts passage detail that the abstraction layer enables model swapping without modifying application logic.,"agentic-ai,planning,tools",12,Agentic AI
100170,12,half-true,Jerry authored multiple Think-series books and co-wrote blockchain and automation titles.,author biography mentioning Think Blockchain and Blockchain for Business,Accurately cites Think-series and coauthorship but implies multiple coauthored works beyond those listed.,"ai,open-source,builder",1,Introduction – The Gold Rush Paradox
100171,12,TRUE,Jerry authored books on blockchain and artificial intelligence.,author of Think Blockchain and Think Artificial Intelligence,Directly supported by named works listed; both Think Blockchain and Think Artificial Intelligence noted.,"ai,open-source,builder",1,Introduction – The Gold Rush Paradox
100172,11,barely-true,Voice-cloning defenses reliably detect most deepfake audio across diverse datasets.,voice-cloning defenses in media-forensics toolkit,"Overreaches: passage emphasizes privacy, consent, toolkit components but gives no evidence that defenses reliably detect deepfakes.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
100173,11,FALSE,Deepfake voice-cloning systems reliably preserve speaker privacy by default.,voice-cloning privacy and consent in media-forensics toolkit,"Contradicts passage emphasis on privacy, consent, and integrity needing active handling and safeguards.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
100174,11,mostly-true,Deepfake defenses should combine technical detection with privacy and consent safeguards to reduce bias.,media toolkit for deepfake detection and privacy,"Combines supported points about privacy, consent, integrity and bias with implied need to integrate technical defenses; minor implementation details omitted.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
100175,125,mostly-true,SHAP provides interpretable explanations for individual model predictions in high-stakes domains.,"transparency tool SHAP for hiring, healthcare, credit decisions","Passage endorses SHAP as illuminating individual predictions for sensitive uses, minor implementation caveats omitted.","ai,tool-chain,notebooks",2,AI Survival Kit
100176,125,TRUE,SHAP helps explain individual model predictions used in high-stakes domains.,"transparency and SHAP tool for hiring, healthcare, or credit decisions",Passage explicitly cites SHAP as a tool that breaks down how individual predictions are made.,"ai,tool-chain,notebooks",2,AI Survival Kit
100177,125,half-true,SHAP fully reveals how complex models make every individual prediction in high-stakes domains.,"transparency tool SHAP for hiring, healthcare, credit decisions","Accurate that SHAP explains contributions, but overstates completeness and ability to fully reveal complex model internals.","ai,tool-chain,notebooks",2,AI Survival Kit
100178,68,FALSE,Linear regression predicts superhero movie revenue from production budget using Scikit-learn.,Linear Regression with Scikit-learn (ML) on budget and revenue,"Contradicts passage emphasis: the passage frames this as a warm-up example, not a definitive predictive claim.","ai,tool-chain,notebooks",2,AI Survival Kit
100179,68,barely-true,Linear regression on Scikit-learn reliably predicts superhero movie revenue from budget.,Linear Regression with Scikit-learn predicting box office revenue,"Overstates reliability; passage only describes a quick warm-up example, not validation or performance.","ai,tool-chain,notebooks",2,AI Survival Kit
100180,68,pants-fire,The passage asserts AI will imminently achieve human-level general intelligence across all tasks.,"tool-chain and AI Survival Kit overview, mentioning Scikit-learn linear regression","Claim contradicts passage specifics: only a simple linear regression example predicting movie revenue is described, not AGI across tasks.","ai,tool-chain,notebooks",2,AI Survival Kit
100181,160,barely-true,"A Transformer-guided diffusion pipeline reliably produces long, high-resolution videos from short text prompts.",text-to-video generator using Transformer encoder and diffusion model,"Overstates capabilities: passage shows short animated clips and 25-step diffusion, not long high-resolution videos.","generative-ai,diffusion,gans",7,Generative AI
100182,160,barely-true,A Transformer encoder plus diffusion model reliably converts prompts into accurate animated videos.,Transformer text encoder and diffusion-based video generator,Overstates reliability and accuracy; passage shows a demo using transformer and diffusion but not robustness or fidelity.,"generative-ai,diffusion,gans",7,Generative AI
100183,160,half-true,A Transformer text encoder paired with a diffusion video generator reliably converts prompts into short animated videos.,Transformer-based text encoder and diffusion-based video generator,Mixes correct architecture pairing with overconfident claim about reliability and fidelity of outputs.,"generative-ai,diffusion,gans",7,Generative AI
100184,126,TRUE,The passage advises serving models via simple apps or APIs for usability.,deployment with Hugging Face Spaces or Gradio,"Directly states sharing through apps/APIs (Hugging Face Spaces, Gradio) makes models usable and testable.","mlops,scaling,deployment",10,AI At Scale
100185,126,mostly-true,"Developers typically validate and serve models using from_pretrained, the Hub, and simple apps or APIs.","operationalizing strategy; from_pretrained, Hugging Face Hub, Spaces, Gradio","Passage describes validating with from_pretrained and sharing via Hub, Spaces or Gradio; minor caveat about additional deployment steps omitted.","mlops,scaling,deployment",10,AI At Scale
100186,126,TRUE,Model serving via Hugging Face Spaces or Gradio makes trained models usable and testable by others.,serving models with Hugging Face Spaces or Gradio,Text explicitly recommends sharing through Hugging Face Spaces or Gradio to make models usable and testable by others.,"mlops,scaling,deployment",10,AI At Scale
100187,67,barely-true,Principal component analysis always reduces datasets to two components for easier interpretation.,dimensionality reduction using principal components (PCA),"Overreaches: PCA can use any number of components; passage says one or two often suffice, not always.","machine-learning,classification,evaluation",4,Classical Machine Learning
100188,67,TRUE,Principal components are ranked by how much dataset variance they capture.,PCA variance explanation in dimensionality reduction,Describes ranking by explained variance directly stated; aligns with PCA component ordering and purpose.,"machine-learning,classification,evaluation",4,Classical Machine Learning
100189,67,half-true,PCA always captures most signal with just two components for any dataset.,principal component analysis (PCA) dimensionality reduction,"Correct that two components can capture most signal for simple datasets, but incorrect for complex datasets needing more components.","machine-learning,classification,evaluation",4,Classical Machine Learning
100190,123,mostly-true,"Agentic AI agents can decompose tasks, plan tool use, and reach coordinated decisions in live executions.",multi-agent reasoning with tools and planning,"Passage demonstrates agents processing, reasoning, and arriving at a final decision, omitting scalability caveats.","agentic-ai,planning,tools",12,Agentic AI
100191,123,FALSE,The agents unanimously relied on a single pretrained model without tool use.,live game execution showing agent decisions and tools,"Contradicts passage detail: agents processed information and used reasoning/tools, not one pretrained model.","agentic-ai,planning,tools",12,Agentic AI
100192,123,half-true,An agent produced a recent nonpolitical trivia question and answer during live game execution.,live game output showing agent processing and Game Master task,"Mixes correct live-game format with uncertain claim about recency and training-data novelty, lacking verification.","agentic-ai,planning,tools",12,Agentic AI
100193,132,half-true,Model accuracy can be misleading when class imbalance lowers F1 despite parameter-free improvements.,classification metric evaluation using F1 and accuracy on imbalanced dataset,Mixes correct point about imbalanced F1 with overstated claim that accuracy is misleading despite genuine parameter-free improvement.,"machine-learning,classification,evaluation",4,Classical Machine Learning
100194,132,TRUE,Class imbalance lowered F1 scores despite improved accuracy.,model evaluation using F1 and accuracy metrics,"Text states imbalance pulls down F1 while accuracy can be misleading, matching improvement caveat.","machine-learning,classification,evaluation",4,Classical Machine Learning
100195,132,mostly-true,Addressing class imbalance improved F1 scores and enabled further fine-tuning for both classes.,classification evaluation (F1 score) and class imbalance,"Passage notes imbalance reduced F1, improvement occurred without parameter changes and allows fine-tuning next.","machine-learning,classification,evaluation",4,Classical Machine Learning
100196,121,pants-fire,Sniffer always converges instantly regardless of learning rate or slope conditions.,learning rate and slope in optimization,"Directly contradicts described behavior: learning rate and slope affect step sizes and convergence, causing overshoot if too high.","deep-learning,frameworks,tensors",5,Deep Learning
100197,121,barely-true,Sniffer's learning rate always ensures convergence by adjusting step sizes based on slope.,learning rate and slope in optimization,"Overreaches: passage says learning rate affects step size and overshooting risk, not guaranteed convergence.","deep-learning,frameworks,tensors",5,Deep Learning
100198,121,half-true,The learning rate always causes overshooting when set too high in neural network training.,learning rate effect on gradient descent steps,Mixes correct concept (high learning rates can overshoot) with absolute claim ('always') not supported by passage.,"deep-learning,frameworks,tensors",5,Deep Learning
100199,121,barely-true,Red teams should capture exact malicious prompts and transcripts verbatim for reproducibility.,red-team note-takers and transcripts,Passage emphasizes verbatim capture but overstates necessity; practical constraints or redaction needs often prevent exact preservation.,"security,red-team,guardrails",8,Breaking-Securing AI
100200,121,FALSE,Red teams should avoid recording exact malicious prompts and model transcripts during exercises.,red-team note-takers and transcripts,Contradicts passage guidance: note-takers must capture exact malicious prompts and transcripts verbatim.,"security,red-team,guardrails",8,Breaking-Securing AI
100201,121,TRUE,Red-team exercises capture exact malicious prompts and model transcripts for reproducible failures.,note-takers capturing model transcripts during red-team exercises,Passage explicitly states note-takers record verbatim prompts and transcripts to reproduce failures later.,"security,red-team,guardrails",8,Breaking-Securing AI
100202,22,pants-fire,ResNet50 memorizes the entire rock-paper-scissors dataset perfectly after one forward pass.,ResNet50 pretrained on ImageNet evaluating rock_paper_scissors dataset,"Claim contradicts passage: model makes general, not perfect, predictions; no training or memorization described.","neural-networks,cnn,transformers",6,Neuron Building Blocks
100203,22,barely-true,ResNet50 pretrained on ImageNet reliably classifies rock-paper-scissors images without fine-tuning.,transfer learning with ResNet50 and ImageNet pretrained weights,"Overreaches: passage shows a few example predictions and says performance is surprisingly good, but provides no systematic accuracy or reliability evidence.","neural-networks,cnn,transformers",6,Neuron Building Blocks
100204,22,half-true,ResNet50 pretrained on ImageNet can often classify Rock-Paper-Scissors images reasonably well without fine-tuning.,ResNet50 pretrained on ImageNet using TensorFlow and tfds 'rock_paper_scissors',Mixes correct generalization ability with omission of domain mismatch and lack of reported accuracy or fine-tuning details.,"neural-networks,cnn,transformers",6,Neuron Building Blocks
100205,10,barely-true,Early convolutional layers only detect simple edges and never respond to textures or shape components.,CNN feature maps and layer hierarchy,"Overreaches relative to passage: early layers detect lines/corners, later layers capture textures and shapes.","neural-networks,cnn,transformers",6,Neuron Building Blocks
100206,10,mostly-true,Convolutional filters detect simple features in early layers and complex object parts in later layers.,"CNN feature maps, ReLU activation, pooling layers","Matches passage description: filters produce feature maps, early layers detect lines/corners, later layers capture shapes and parts; minor caveat about other architectures omitted.","neural-networks,cnn,transformers",6,Neuron Building Blocks
100207,10,FALSE,Pooling layers expand feature map spatial dimensions to increase resolution.,CNN architecture—pooling layers and feature maps,"Contradicts passage detail: pooling layers shrink data, not increase spatial resolution.","neural-networks,cnn,transformers",6,Neuron Building Blocks
100208,98,barely-true,The Kryptonian and tech-heavy cluster shows the strongest internal similarity among groups.,"cluster similarity scores (Kryptonian, tech-heavy, cosmic, mystical, Human/Mutant)","Passage reports a 0.49 internal similarity for the Kryptonian/tech cluster, highest among listed clusters.","machine-learning,classification,evaluation",4,Classical Machine Learning
100209,98,barely-true,Kryptonian and tech-heavy heroes show the highest internal similarity among clusters.,cluster similarity metric (pairwise similarity scores),Supported by passage numbers but overstates generality; specific score 0.49 is highest among provided clusters.,"machine-learning,classification,evaluation",4,Classical Machine Learning
100210,98,TRUE,The Kryptonian and tech-heavy cluster shows the highest internal similarity among clusters.,"cluster similarity scores (Kryptonian, tech-heavy)","Passage gives numeric internal similarities and reports the Kryptonian/tech-heavy cluster at 0.49, highest among listed clusters.","machine-learning,classification,evaluation",4,Classical Machine Learning
100211,132,pants-fire,The passage claims AI models can autonomously rebuild human civilization from scratch.,agentic AI and model orchestration with LangChain,"Extremely implausible given described tools (Pandas, Scikit-learn, Stable Diffusion); contradicts capabilities of agentic AI and pretrained models.","ai,tool-chain,notebooks",2,AI Survival Kit
100212,132,half-true,The passage claims Colab taught production-ready model deployment using LangChain and Hugging Face.,tool-chain and deployment with LangChain and Hugging Face,Mixes correct tool coverage with incorrect implication of production-readiness and deployment depth.,"ai,tool-chain,notebooks",2,AI Survival Kit
100213,45,TRUE,CrossEntropyLoss is used as the training loss function for classification.,training loop code snippet using nn.CrossEntropyLoss and optimizer.zero_grad,"Code shows loss_fn = nn.CrossEntropyLoss() and a training loop setup, directly supporting the claim.","deep-learning,frameworks,tensors",5,Deep Learning
100214,45,TRUE,The training loop resets gradients before each optimization step using optimizer.zero_grad().,training loop snippet with CrossEntropyLoss and optimizer.zero_grad(),"Code shows optimizer.zero_grad() called inside data loop, matching reset-of-gradients before each step.","deep-learning,frameworks,tensors",5,Deep Learning
100215,45,TRUE,The code uses CrossEntropyLoss as the loss function for training the model.,training loop snippet using nn.CrossEntropyLoss and optimizer.zero_grad,Loss function is explicitly instantiated as nn.CrossEntropyLoss and used within the training loop.,"deep-learning,frameworks,tensors",5,Deep Learning
100216,105,mostly-true,Mean squared error is generally suitable for continuous prediction but not ideal for categorical classification.,loss function discussion; mean squared error (MSE) for digit recognition,"Passage explains MSE squares prediction errors and notes it's better for continuous values, not categories.","deep-learning,frameworks,tensors",5,Deep Learning
100217,105,barely-true,MSE always performs poorly for digit recognition compared to other losses.,"loss functions for digit recognition, MSE vs categorical losses",Overreaches beyond passage: passage says MSE is not ideal for categories but doesn't claim it always performs poorly.,"deep-learning,frameworks,tensors",5,Deep Learning
100218,105,mostly-true,Mean squared error is broadly appropriate but suboptimal for categorical tasks like digit recognition.,loss function; mean squared error (MSE) for digit recognition,Passage says MSE measures squared prediction errors and is less ideal for categorical labels like digits.,"deep-learning,frameworks,tensors",5,Deep Learning
100219,63,pants-fire,The model always ignores conversation history and retrieval context when generating responses.,conversation history and retrieval data guidance,Directly contradicts guidance that conversation history and retrieval context should be used; claims absolute ignoring.,"security,red-team,guardrails",8,Breaking-Securing AI
100220,63,FALSE,Retrieval data should be ignored when generating model responses.,conversation history and retrieval data in the supply chain,Contradicts passage guidance that retrieval data and conversation history must be used to reduce contradictions.,"security,red-team,guardrails",8,Breaking-Securing AI
100221,63,FALSE,Conversation history should be ignored to prevent contradictions in responses.,using conversation history for retrieval data and context,Contradicts passage which advises using conversation history to reduce contradictions and improve relevance.,"security,red-team,guardrails",8,Breaking-Securing AI
100222,118,mostly-true,"A red lead should document attacks on RAG systems using prompt injection, hallucination, and execution control.",team roles in red-team exercises for RAG systems,"Passage explicitly assigns Red Lead to break RAG systems and document Prompt Injection, Hallucination, and Execution Control.","security,red-team,guardrails",8,Breaking-Securing AI
100223,118,barely-true,Red Lead primarily focuses on breaking RAG systems rather than documenting defenses or mitigations.,team roles; Red Lead; RAG systems,"Passage says Red Lead's primary objective is to break and document how, not to prioritize defenses, so claim overstates role.","security,red-team,guardrails",8,Breaking-Securing AI
100224,118,half-true,A red lead should both exploit RAG weaknesses and directly create the corresponding defenses.,team roles for red-team testing of RAG systems,Mixes correct role alignment with incorrect claim that the red lead must also build defenses; passage assigns testing and documentation duties only.,"security,red-team,guardrails",8,Breaking-Securing AI
100225,58,TRUE,Applying targeted training tweaks can raise model accuracy from about 52% to the mid-80s.,model training with Scikit-learn and open-source frameworks,Passage states accuracy climbs from 52% to 77% then 84% through smart tweaks during training.,"ai,open-source,builder",1,Introduction – The Gold Rush Paradox
100226,58,mostly-true,Open-source frameworks and transparent training raise model accuracy and trust through careful design.,training with modern open-source frameworks and Scikit-learn,"Passage describes improving accuracy from 52% to 84% and links transparent design to explainable, trustworthy models.","ai,open-source,builder",1,Introduction – The Gold Rush Paradox
100227,58,half-true,Model accuracy improves from about 52% to the mid-80s after applying practical training tweaks.,training with Scikit-learn and open-source frameworks,Mixes correct reported accuracy gains with vague cause: specific tweaks and methods not fully detailed.,"ai,open-source,builder",1,Introduction – The Gold Rush Paradox
100228,206,TRUE,"The reader has practiced tensors, training loops, optimizers, and loss functions.",deep learning foundations; tensors and training loops,"Passage explicitly lists tensors, training loops, optimizers, and loss functions as hands-on topics the reader tackled.","deep-learning,frameworks,tensors",5,Deep Learning
100229,206,pants-fire,All deep learning frameworks are obsolete and replaced by a single universal tool.,deep-learning frameworks and tensors tools,"Contradicts passage emphasis on tensors, training loops, optimizers and important tools; claims impossible universality.","deep-learning,frameworks,tensors",5,Deep Learning
100230,206,TRUE,The reader has learned core deep learning mechanics including tensors and training loops.,"foundational concepts: tensors, training loops, optimizers","Passage directly states the reader tackled core mechanics and worked with tensors, training loops, optimizers.","deep-learning,frameworks,tensors",5,Deep Learning
100231,2,barely-true,Guardrails make chatbots completely unable to generate banned content under any prompt.,guardrails reprocessing prompts in ChatGPT,Overstates effectiveness; passage notes reprocessing and refusals but not absolute or universal prevention.,"security,red-team,guardrails",8,Breaking-Securing AI
100232,2,barely-true,ChatGPT reliably rejects ethically or legally disallowed prompt requests using guardrails.,guardrails reprocessing prompts in AI chatbots,"Overstates reliability; passage says chatbots reprocess and sometimes refuse, not that rejection is consistent or foolproof.","security,red-team,guardrails",8,Breaking-Securing AI
100233,2,half-true,Chatbot guardrails sometimes reject prompts but can be bypassed with careful rephrasing.,guardrails reprocessing prompts in ChatGPT-style systems,Passage confirms guardrails reject boundary-crossing prompts but omits evidence about bypassability.,"security,red-team,guardrails",8,Breaking-Securing AI
100234,10,FALSE,The passage asserts that synthetic news data is unsuitable for benchmarking model accuracy.,fake news detector dataset and generated statements,"Passage describes synthetic/generated statements as a helpful testbed, directly contradicting unsuitability.","mlops,scaling,deployment",10,AI At Scale
100235,10,TRUE,The passage describes using generated statements as a testbed for fake-news detection models.,benchmarking with generated statements for fake news detector,Explicitly mentions curated generated statements and using them to test fake-news detection and model accuracy.,"mlops,scaling,deployment",10,AI At Scale
100236,131,TRUE,Open-source AI tools can enable voice analysis and multimedia deepfake detection.,"voice analysis, detection models, DeepSafe framework","Passage explicitly cites open-source AI enabling voice analysis, transcription, and detection using frameworks like DeepSafe.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
100237,131,barely-true,Open-source detection frameworks completely prevent voice-cloning deepfakes in multimedia workflows.,DeepSafe and Deepstar detection frameworks,"Overstates capabilities; passage cites validation and scans but notes concerns and uncertainty, not complete prevention.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
100238,131,half-true,Deepfake detection frameworks reliably validate cloned-voice samples using confidence scores and logs.,DeepSafe/Deepstar detection models and confidence scores,"Mixes correct features (validation, logs, confidence scores) with overstated reliability of detection frameworks.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
100239,92,barely-true,TF-IDF was designed specifically to predict superhero gender using Naïve Bayes.,TF-IDF (Scikit-learn) text vectorization for gender prediction,"Passage only mentions TF-IDF used that way as an example, not as its original or exclusive design purpose.","open-source,community,contribution",13,Commit to Contribute
100240,92,barely-true,TF-IDF is a Scikit-learn feature used to predict superhero gender with Naïve Bayes.,TF-IDF (Scikit-learn) dataset for gender prediction,"Passage mentions TF-IDF used to vectorize superhero descriptions for Naïve Bayes gender prediction, but attribution to Scikit-learn as the dataset/tool is overstated.","open-source,community,contribution",13,Commit to Contribute
100241,92,half-true,TF-IDF in scikit-learn is primarily used to create features for Naïve Bayes gender prediction tasks.,tool: TF-IDF (Scikit-learn) for text vectorization,"Correct that TF-IDF creates features and was used for superhero gender prediction, but overstates primacy and scope for Naïve Bayes tasks.","open-source,community,contribution",13,Commit to Contribute
100242,26,barely-true,CNNs alone can reliably detect all visual features in diverse datasets without additional preprocessing.,"CNNs, YOLO, visual feature extraction in image datasets","Overstates CNN capabilities; passage notes spatial preservation but omits need for preprocessing, architectures, or limits.","neural-networks,cnn,transformers",6,Neuron Building Blocks
100243,26,half-true,"Convolutional neural networks preserve pixel spatial relationships to detect edges, shapes, and contextual features.",CNNs and YOLO for visual feature extraction in images and video frames,Accurately states CNN spatial preservation and edge detection but omits limits and implementation specifics.,"neural-networks,cnn,transformers",6,Neuron Building Blocks
100244,26,barely-true,CNNs always fully understand visual context in images from single pixels to whole scenes.,convolutional neural networks (CNNs) and spatial relationships,Overstates capability: passage credits improved context but omits limits and failure modes.,"neural-networks,cnn,transformers",6,Neuron Building Blocks
100245,4,mostly-true,Generative models learn patterns from large datasets to produce diverse outputs like text and images.,"generative models, deep learning, training data","Accurately reflects passage claim that models learn from large datasets and mimic patterns to generate text and images, omitting minor specifics about architectures.","generative-ai,diffusion,gans",7,Generative AI
100246,4,pants-fire,Generative AI models always generate completely original content never seen in training data.,generative models and training datasets,Directly contradicts statement that models learn and mimic training data patterns; claims total novelty impossible.,"generative-ai,diffusion,gans",7,Generative AI
100247,4,half-true,Generative models primarily generate new content by memorizing training examples and returning them unchanged.,"generative models, training data, deep learning","Mixes correct idea (training data influences outputs) with incorrect claim that models mainly memorize and output exact training examples, omitting pattern learning and synthesis.","generative-ai,diffusion,gans",7,Generative AI
100248,17,FALSE,Amazon's hiring tool fairly evaluated résumés without gender bias.,Amazon automated hiring tool example,"Contradicts described detail that the tool downgraded résumés containing “women’s,” indicating learned gender bias.","ethics,governance,privacy",11,AI Ethics and Governance
100249,17,barely-true,Amazon's hiring tool intentionally penalized résumés containing 'women's'.,automated hiring tool trained on biased dataset,"Overstates intent: passage attributes downgrading to biased training, not deliberate penalization.","ethics,governance,privacy",11,AI Ethics and Governance
100250,17,mostly-true,Biased training data can cause AI systems to produce discriminatory outcomes like downgraded résumés.,biased datasets and Amazon automated hiring tool,"Passage cites Amazon hiring tool example showing biased training data led to résumé downgrading, a minor broader generalization.","ethics,governance,privacy",11,AI Ethics and Governance
100251,34,TRUE,"A simple, interpretable model is used for binary classification of Real Jerry versus Not Real Jerry.",fingerprinting function and train/test split for voice-cloning detection,"Passage explicitly describes an efficient, interpretable two-class model using fingerprinted audio and balanced train/test sets.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
100252,34,TRUE,The model uses binary classification to decide whether a voice is Real Jerry or not.,binary classification on Real Jerry vs Not Real Jerry dataset,Passage explicitly describes a two-class binary model trained on Real Jerry and Not Real Jerry clips using fingerprinting.,"media-forensics,voice-cloning,deepfake",9,Deepfake Defense
100253,34,half-true,The model uses fingerprinting features to classify audio clips as Real Jerry or Not Real Jerry.,binary classification using fingerprinting features,"Accurate about fingerprinting and binary labels, but overstates certainty about model performance and calibration.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
100254,25,half-true,The passage argues that smaller transparent systems are always preferable to Big AI.,tradeoff between Big AI and smaller transparent systems; data as fuel,Mixes correct point about valuing transparent systems with incorrect absolutist claim 'always preferable'.,"ai,open-source,builder",1,Introduction – The Gold Rush Paradox
100255,25,mostly-true,The passage endorses using both large AI and smaller transparent systems when appropriate.,choice between Big AI and smaller transparent systems (data as fuel),Supports dual approach recommendation; omits specific criteria for choosing systems and data-protection tactics.,"ai,open-source,builder",1,Introduction – The Gold Rush Paradox
100256,25,half-true,Author claims smaller transparent systems are preferable sometimes despite Big AI's power.,tradeoff between Big AI and transparent systems; data-as-fuel concept,Accurately notes mixed recommendation but omits specifics about when to choose each and data-ownership guidance.,"ai,open-source,builder",1,Introduction – The Gold Rush Paradox
100257,179,mostly-true,Classical machine learning is often preferable for structured data when transparency and limited compute matter.,model selection for structured dataset and transparency,"Passage endorses classical ML for structured data, limited compute, and transparency; omits edge cases.","machine-learning,classification,evaluation",4,Classical Machine Learning
100258,179,barely-true,"Classical ML is typically inferior to deep learning for raw text, images, or audio tasks.","model suitability for unstructured data (text, images, audio)","Passage says classical ML is less suitable for messy unstructured inputs, overstating inferiority without nuance.","machine-learning,classification,evaluation",4,Classical Machine Learning
100259,179,barely-true,Classical machine learning always outperforms deep learning on structured datasets with limited compute.,model selection for structured data and compute-constrained environments,"Overstates certainty: passage says classical ML is often best in such settings, not always.","machine-learning,classification,evaluation",4,Classical Machine Learning
100260,2,pants-fire,The passage claims AI systems always fabricate outputs intentionally to deceive users.,model behavior and trust in scalable AI systems,"Directly contradicts passage which discusses spotting faking and building reliable, trustworthy systems.","mlops,scaling,deployment",10,AI At Scale
100261,2,TRUE,"Scaling, benchmarking, tuning, and measuring model performance enables reliable, trustworthy AI systems.",model performance benchmarking and tuning in MLOps,"Passage explicitly lists Benchmark, Scale, Tune, Measure and emphasizes building reliable, trustworthy systems.","mlops,scaling,deployment",10,AI At Scale
100262,2,mostly-true,"AI systems scaled with benchmarking, tuning, and measurement generally produce more reliable performance.","scaling workflow: Benchmark, Tune, Measure (MLOps tools and metrics)","Broadly supported by emphasis on benchmark, scale, tune, measure, though omits implementation caveats.","mlops,scaling,deployment",10,AI At Scale
100263,70,half-true,SpeechT5 plus HiFi-GAN can synthesize realistic cloned voices but setup may be unstable.,"SpeechT5 model, SpeechT5HifiGan vocoder, GPU setup",Combines correct components for voice cloning yet notes installation compatibility issues and instability.,"media-forensics,voice-cloning,deepfake",9,Deepfake Defense
100264,70,mostly-true,SpeechT5 combined with a HiFi-GAN vocoder enables high-quality text-to-speech synthesis using GPU acceleration.,"model pipeline: SpeechT5 processor, SpeechT5ForTextToSpeech, SpeechT5HifiGan vocoder",Code shows SpeechT5 plus HiFi-GAN producing waveforms on GPU; caveat about install compatibility omitted.,"media-forensics,voice-cloning,deepfake",9,Deepfake Defense
100265,70,half-true,The example uses SpeechT5 with HiFi-GAN to synthesize speech but omits detailed training or dataset specifics.,text-to-speech model setup using SpeechT5 and HiFi-GAN,"Code shows model+vocoder and device setup but lacks training data, fine-tuning, and evaluation details.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
100266,73,mostly-true,"Generative AI commentary broadly aligns with hero PCA power scores, but may miss nuanced reliability caveats.",GenAI commentary on PCA power scores for heroes,Matches passage: GenAI often aligns with scores yet authors note coincidence and limited reliability.,"machine-learning,classification,evaluation",4,Classical Machine Learning
100267,73,TRUE,Generative AI commentary can provide useful sanity checks on PCA power scores for characters.,GenAI commentary on PCA power scores and model outputs,"Examples show model noting score-character alignment, and passage endorses its use for occasional sanity checks.","machine-learning,classification,evaluation",4,Classical Machine Learning
100268,73,mostly-true,Generative AI can provide reasonable sanity-check commentary on PCA power scores for characters.,GenAI commentary on PCA power scores for heroes,"Broadly supported by passage: models often note score-character alignment, though reliability is limited.","machine-learning,classification,evaluation",4,Classical Machine Learning
100269,144,half-true,Hyperparameter tuning always finds the single best model configuration for deployment.,hyperparameter tuning of model recipes and agents,"Correct that tuning evaluates configurations, but incorrect to claim it always finds a single best due to search limits and variability.","deep-learning,frameworks,tensors",5,Deep Learning
100270,144,half-true,The passage claims hyperparameter tuning always finds the most efficient model configuration.,"hyperparameter tuning of models (hyperparameter ""recipes"")","Correct that tuning evaluates combinations, but overstated: tuning may not always find optimal or most efficient configuration.","deep-learning,frameworks,tensors",5,Deep Learning
100271,144,mostly-true,Hyperparameter search systems run many training experiments to evaluate and optimize model recipes.,hyperparameter search for model training and evaluation,"Describes testing different hyperparameter ""recipes"" and repeated training/evaluation; minor nuance about orchestration tools omitted.","deep-learning,frameworks,tensors",5,Deep Learning
100272,151,FALSE,Pseudonymization alone guarantees irreversible anonymization of datasets for AI use.,privacy and security practices mentioning pseudonymization,"Contradicts passage: pseudonymization is listed alongside other techniques, not claimed as irreversible anonymization.","data-prep,feature-engineering,rag",3,Prepping Data for AI
100273,151,TRUE,"Pseudonymization, masking, differential privacy, and encryption protect user data in AI systems.","data privacy and security; pseudonymization, masking, differential privacy, encryption",Lists specific techniques presented as foundational security measures that preserve user trust and privacy.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
100274,151,mostly-true,"Pseudonymization, masking, and differential privacy help maintain user trust in AI systems.","Data privacy and security practices (pseudonymization, masking, differential privacy)",Practices listed are standard trust-building measures; minor caveat: implementation and limits affect effectiveness.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
100275,122,half-true,Sniffer's learning rate must be tuned because its loss landscape has many bumps and dips.,training hyperparameter (learning rate) in deep learning optimization,Mixes correct intuition about tuning with an overstated necessity and vague mechanism details.,"deep-learning,frameworks,tensors",5,Deep Learning
100276,122,mostly-true,Appropriate learning rates help gradient-based optimizers converge without overshooting or stalling.,optimization learning rate in deep learning loss landscape,Passage explains high rates cause overshoot and low rates slow progress; omits specific optimizer behaviors and tuning methods.,"deep-learning,frameworks,tensors",5,Deep Learning
100277,122,barely-true,The optimizer's learning rate often causes overshooting or very slow progress on complex loss landscapes.,optimizer learning rate affecting loss landscape navigation,Accurately echoes described overshoot and slow progress but overgeneralizes frequency and universality.,"deep-learning,frameworks,tensors",5,Deep Learning
100278,42,half-true,Dot product and cosine similarity always yield identical rankings of superhero power alignment.,tool: cosine similarity and dot product comparison in vector assessment,Mixes correct idea (both measure alignment) with incorrect specific claim (they can differ when vector magnitudes vary).,"ai,tool-chain,notebooks",2,AI Survival Kit
100279,42,half-true,Cosine similarity always gives a more useful comparison of superhero powers than dot product.,Dot product and cosine similarity in power-alignment comparisons,Mixes correct idea that cosine removes magnitude with incorrect absolute claim that it's always more useful.,"ai,tool-chain,notebooks",2,AI Survival Kit
100280,42,half-true,Dot product and cosine similarity always determine superhero power alignment accurately.,Dot Products and Superhero Power Similarity example,Mixes correct use of dot product/cosine with overstatement that they always provide accurate alignment; ignores scale and semantic nuances.,"ai,tool-chain,notebooks",2,AI Survival Kit
100281,21,mostly-true,"A neuron computes a weighted sum of inputs, adds a bias, then applies an activation function.","simple neuron diagram using weights, bias, and activation functions (ReLU, Sigmoid, Tanh)",Directly reflects described computation sequence; omits minor implementation details like vectorization or batching.,"deep-learning,frameworks,tensors",5,Deep Learning
100282,21,TRUE,"A neuron multiplies inputs by weights, sums them, adds a bias, then applies an activation.","simple neuron computation with ReLU, Sigmoid, Tanh activation","Describes exactly the passage's computation flow: weighted inputs summed, bias added, activation applied.","deep-learning,frameworks,tensors",5,Deep Learning
100283,21,pants-fire,"Deep learning neurons multiply inputs by weights, sum them, ignore biases entirely, and skip activation functions.","simple neuron, weights, bias, activation function",Contradicts passage detail that neurons add a bias term and pass summed result through an activation function; claim omits bias and activations.,"deep-learning,frameworks,tensors",5,Deep Learning
100284,88,half-true,The cluster mostly contains Kryptonians and Androids but includes some other species.,clustering by Species and power levels,Mixes correct dominance of Kryptonians/Androids with inaccurate claim of 'mostly' implying clear separation.,"machine-learning,classification,evaluation",4,Classical Machine Learning
100285,88,pants-fire,Kryptonians are actually weaker than humans across all power metrics.,species clustering by Species and power levels,Directly contradicts passage detail that Kryptonians dominate power profiles and cluster apart from humans.,"machine-learning,classification,evaluation",4,Classical Machine Learning
100286,88,mostly-true,Cluster profiling shows Kryptonians and Androids predominantly define the group's power signature.,cluster profiling by Species and power levels,"Profiles and species counts show Kryptonians and Androids dominate, though clusters aren't perfectly separated.","machine-learning,classification,evaluation",4,Classical Machine Learning
100287,68,mostly-true,Hugging Face Accelerate generally simplifies scaling by managing device placement and precision for distributed runs.,"tool: Hugging Face Accelerate for CPUs, GPUs, TPUs","Passage directly states Accelerate manages device placement, precision, and distributed runs, minor omission of specific limits.","mlops,scaling,deployment",10,AI At Scale
100288,68,TRUE,Hugging Face Accelerate simplifies scaling by managing device placement and precision for distributed runs.,tool: Hugging Face Accelerate for device placement and distributed runs,"Directly supported: passage says Accelerate manages device placement, precision, and distributed runs across CPUs, GPUs, or TPUs.","mlops,scaling,deployment",10,AI At Scale
100289,68,half-true,"Hugging Face Accelerate always handles device placement, precision, and distributed runs across CPUs, GPUs, or TPUs automatically.",tool: Hugging Face Accelerate for scaling and device management,Accurate features listed but overstates automation and universality; tuning and config still often required.,"mlops,scaling,deployment",10,AI At Scale
100290,18,FALSE,Unsupervised learning always requires labeled data to form clusters or features.,"unsupervised learning, clustering, dimensionality reduction",Contradicts unsupervised learning; passage states it operates without labels and finds patterns independently.,"machine-learning,classification,evaluation",4,Classical Machine Learning
100291,18,barely-true,Unsupervised clustering always finds meaningful customer segments without any human validation.,unsupervised learning clustering on customer purchasing data,Overreaches beyond passage: unsupervised methods find patterns but require validation and interpretation.,"machine-learning,classification,evaluation",4,Classical Machine Learning
100292,18,half-true,Unsupervised clustering always uncovers true customer segments without any human input.,unsupervised learning clustering on customer purchasing dataset,"Correct that clustering groups customers, but incorrect to assert it always finds true segments without validation.","machine-learning,classification,evaluation",4,Classical Machine Learning
100293,61,half-true,AI systems sometimes exhibit discrimination because they learn from biased training data.,fairness and biased data in AI training,"Mixes correct causal link with implication that learning is primary cause, omitting other design or deployment factors.","ethics,governance,privacy",11,AI Ethics and Governance
100294,61,FALSE,AI systems rarely exhibit any discrimination when trained on biased data.,fairness and bias in training data,Contradicts passage: biased training data can cause discrimination even without intentional design.,"ethics,governance,privacy",11,AI Ethics and Governance
100295,61,half-true,AI systems can appear fair yet still discriminate due to biased training data.,fairness and biased data in AI,Acknowledges correct mechanism (biased data causing discrimination) but simplifies causes and mitigation complexities.,"ethics,governance,privacy",11,AI Ethics and Governance
100296,148,FALSE,Human-in-the-Loop design is unnecessary for safety with generative AI systems.,Human-in-the-Loop design for generative AI safety,"Contradicts passage's claim that Human-in-the-Loop provides pause, scrutiny, and accountability essential for safety.","security,red-team,guardrails",8,Breaking-Securing AI
100297,148,barely-true,Human-in-the-loop design is unnecessary for ensuring safety with generative AI systems.,Human-in-the-Loop design for generative AI safety,"Contradicts passage emphasis that human oversight provides pause, scrutiny, and accountability for risky outputs.","security,red-team,guardrails",8,Breaking-Securing AI
100298,148,barely-true,Human-in-the-loop design completely prevents AI-generated misinformation in deployed systems.,Human-in-the-Loop design for generative AI safety,Overstates effectiveness; passage says HITL creates pause and scrutiny but not complete prevention.,"security,red-team,guardrails",8,Breaking-Securing AI
100299,84,mostly-true,A sequence-classification model can be trained to distinguish safe versus injected prompts using a pre-trained tokenizer.,pre-trained tokenizer and sequence classification model for safe vs. injected labels,"Procedure lists tokenization, padding, truncation, and loading a two-label sequence classification model, omitting dataset size or robustness caveats.","security,red-team,guardrails",8,Breaking-Securing AI
100300,84,half-true,The passage recommends training a sequence-classification model to detect prompt injection with two labels.,pre-trained tokenizer and sequence classification model,"Accurate about two-label setup and tokenizer use, but overstates explicit goal as 'detect prompt injection' not directly specified.","security,red-team,guardrails",8,Breaking-Securing AI
100301,84,half-true,A binary classifier using accuracy alone reliably detects prompt-injection attacks during training.,pre-trained model for sequence classification with two output labels,"Partially correct: binary label setup is valid, but relying solely on accuracy omits nuanced metrics and attack variability.","security,red-team,guardrails",8,Breaking-Securing AI
100302,103,TRUE,Deep learning models use loss functions to guide learning during training.,loss functions and evaluation metrics in deep learning,Passage states loss functions are used to measure performance and guide learning step by step during training.,"deep-learning,frameworks,tensors",5,Deep Learning
100303,103,half-true,The text claims deep learning models use loss functions to guide learning step by step during training.,loss functions in deep learning models,Accurately states passage idea but omits specifics about which loss functions or optimization details.,"deep-learning,frameworks,tensors",5,Deep Learning
100304,103,TRUE,Deep learning models use loss functions to guide learning step by step.,loss functions in deep learning models,Passage states loss functions measure performance and guide learning step by step at the network output.,"deep-learning,frameworks,tensors",5,Deep Learning
100305,51,half-true,Francesca won a prestigious IBM award for an AI master's thesis in 1986 in Italy.,award recognition for AI thesis (IBM Best Thesis),"Combines correct award claim with ambiguous prestige and scope; lacks verification of award name, selection criteria, or IBM's national involvement.","ethics,governance,privacy",11,AI Ethics and Governance
100306,51,barely-true,Francesca received IBM's Best Thesis in AI award in 1986 for her master's thesis.,award recognition for AI thesis (IBM Best Thesis in AI),"Passage asserts the IBM award claim, but external verification or broader context of award program is missing.","ethics,governance,privacy",11,AI Ethics and Governance
100307,51,mostly-true,Francesca received an IBM Best Thesis in AI award for her master's thesis in 1986.,award recognition in AI history,Claim aligns with her stated award and year; minor omission of award scope or ceremony details.,"ethics,governance,privacy",11,AI Ethics and Governance
100308,76,pants-fire,Freezing early generator layers makes models unable to learn any new task-specific structure.,"selective fine-tuning, generator layers, requires_grad in PyTorch",Contradicts described trade-off: freezing preserves foundational features and stabilizes fine-tuning rather than preventing all new structure learning.,"generative-ai,diffusion,gans",7,Generative AI
100309,76,barely-true,Freezing early generator layers always prevents catastrophic forgetting in GAN fine-tuning.,"selective fine-tuning, generator layer freezing",Overreaches beyond passage: freezing can stabilize but does not guarantee preventing catastrophic forgetting.,"generative-ai,diffusion,gans",7,Generative AI
100310,76,TRUE,Freezing early generator layers preserves foundational features while fine-tuning higher layers.,selective fine-tuning; generator layers; requires_grad in PyTorch,Passage explains freezing early layers retains edge/lighting structure and lets higher layers adapt.,"generative-ai,diffusion,gans",7,Generative AI
100311,1,pants-fire,Robby’s first open-source contribution single-handedly rebuilt the Linux kernel from scratch.,"open-source contribution, Robby’s First Contribution","Claim contradicts passage scale and plausibility: passage describes a small, symbolic contribution and tips, not rewriting Linux kernel.","open-source,community,contribution",13,Commit to Contribute
100312,1,half-true,An AI-assembled glossary and tips partly prepare newcomers for open-source contributions but omit practical mentorship details.,open-source glossary and tips assembled by AI agents,"Accurate about AI glossary and tips but misses specifics like mentorship, hands-on project leads, and onboarding steps.","open-source,community,contribution",13,Commit to Contribute
100313,1,barely-true,"Robby’s open-source contribution immediately sparked a large, active community around the project.","Robby’s first contribution; open-source contribution, glossary, AI agents","Passage only mentions a small streamed audience and resources, not immediate large community growth.","open-source,community,contribution",13,Commit to Contribute
100314,117,mostly-true,The passage shows creating a sequential Crew that runs defined agents and ordered tasks.,"Crew construct with agents, tasks, Process.sequential",Directly follows example code where a Crew lists agents and ordered tasks using Process.sequential.,"agentic-ai,planning,tools",12,Agentic AI
100315,117,pants-fire,The Crew will autonomously override human operators and take full control of systems.,agentic AI Crew orchestrating agents and Process.sequential,"Claim contradicts passage: Crew runs defined agents sequentially, not autonomously seizing control.","agentic-ai,planning,tools",12,Agentic AI
100316,117,barely-true,The Crew setup guarantees tasks run sequentially across all four agents without errors.,Crew setup with Process.sequential and four agents,"Asserts guaranteed error-free execution, but passage only shows a clean setup example, not reliability or error handling.","agentic-ai,planning,tools",12,Agentic AI
100317,90,TRUE,The trained voice-cloning model converts text into synthesized speech for final evaluation.,steps 4 & 5: testing and synthesizing speech in voice-cloning,"Passage describes turning text into sound after training, combining data, embeddings, and model for evaluation.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
100318,90,half-true,"The passage claims a tuned voice-cloning model can trade off speed, stability, and quality when synthesizing speech.","voice-cloning model tuning, embeddings, testing and synthesizing speech","Accurate about tuning trade-offs and final synthesis steps, but overstates ability without naming datasets, metrics, or quantified limits.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
100319,90,half-true,"The tuned values always guarantee optimal speed, stability, and audio quality for cloned speech.",voice cloning model tuning and synthesis steps,"Overstates guarantees: passage says values can be tuned to balance those factors, not always guarantee optimal outcomes.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
100320,12,TRUE,Prompt injection is a common vulnerability for public-facing chatbots and training pipelines.,prompt injection in public-facing chatbot systems,"Passage explicitly names prompt injection as a primary, quick-win vulnerability across chatbots and pipelines.","security,red-team,guardrails",8,Breaking-Securing AI
100321,12,TRUE,Prompt injection attacks are common initial vulnerabilities to test in deployed AI systems.,public-facing chatbots and training pipelines; prompt injection,Passage identifies prompt injection as a primary quick-win pressure point across chatbots and pipelines.,"security,red-team,guardrails",8,Breaking-Securing AI
100322,12,mostly-true,Prompt injection is a primary and easy-to-exploit attack surface against deployed AI systems.,public-facing chatbots and prompt injection concept,Passage emphasizes prompt injection as the recommended first stress-test and common real-world pressure point.,"security,red-team,guardrails",8,Breaking-Securing AI
100323,120,half-true,Splitting agents into Crews isolates information so Judges can fairly score players.,multi-agent Crew design with Game Master and Judge roles,"Correct about separating roles and info flow, but overstates inevitability of fairness without evaluation.","agentic-ai,planning,tools",12,Agentic AI
100324,120,half-true,An agentic system separated roles so the Judge received both player answers plus the correct answer.,agentic AI role separation; Judge receives correct answer and player responses,Accurately describes role split but overstates universality and omits coordination limitations.,"agentic-ai,planning,tools",12,Agentic AI
100325,120,half-true,Splitting agents into Crews restricted each agent to only the information necessary for its role.,"agentic-ai Crew design with Game Master, Player, Judge roles",Accurately reflects passage but omits potential coordination or information leakage risks.,"agentic-ai,planning,tools",12,Agentic AI
100326,72,half-true,DVC enables full reproducibility of AI training pipelines by tracking every dataset and model change.,DVC dataset and model version control tool,"Accurate that DVC tracks datasets and models, but overstates 'full reproducibility'—workflow integration and external dependencies often required.","open-source,community,contribution",13,Commit to Contribute
100327,72,mostly-true,Open-source tools like DVC and Hugging Face datasets broadly improve reproducibility in AI workflows.,datasets library and DVC data version control tools,"Matches passage support: DVC traces data lineage and HF hosts curated datasets, minor caveat about scope.","open-source,community,contribution",13,Commit to Contribute
100328,72,half-true,Hugging Face's Datasets Library exclusively hosts only NLP datasets for model training and reproducibility.,Datasets Library (Hugging Face) hub of curated datasets,"Accurate that Datasets Library aids reproducibility and model training, but it also includes vision and multimodal datasets, so exclusivity claim is incorrect.","open-source,community,contribution",13,Commit to Contribute
100329,53,TRUE,Logistic regression achieved about 76% accuracy on the superhero species classification task.,superhero Species classification; LogisticRegression model; accuracy metric,"Reported accuracy is 0.759, supporting the claim that logistic regression correctly predicted roughly three-quarters of cases.","machine-learning,classification,evaluation",4,Classical Machine Learning
100330,53,pants-fire,"The model completely fails to identify Cyborgs, predicting none correctly.","Species classification on SUPERHEROES_POWERS dataset, precision/recall table","Performance table shows 0.00 precision and recall for Cyborg class, indicating total failure.","machine-learning,classification,evaluation",4,Classical Machine Learning
100331,53,barely-true,The models completely failed to detect Cyborgs despite reasonable overall accuracy.,superhero Species classification; metric: precision/recall for Cyborg class,Mostly unsupported phrasing overstates 'completely failed' as overreach; passage shows zero precision and recall but accuracy remains moderate.,"machine-learning,classification,evaluation",4,Classical Machine Learning
100332,60,mostly-true,"AI systems should be aligned to human values to ensure fair, ethical, and transparent recommendations.",value alignment and bias in AI decision-making,"Broadly supported by passage emphasizing bias, value alignment, fairness, ethics, and transparency; minor implementation caveats omitted.","ethics,governance,privacy",11,AI Ethics and Governance
100333,60,mostly-true,AI decision-making systems should be aligned to human values to ensure fairness and transparency.,value alignment and bias in AI decision systems,"Broadly supported by discussion of bias and value alignment, minor caveat about implementation specifics omitted.","ethics,governance,privacy",11,AI Ethics and Governance
100334,60,FALSE,AI systems inherently reflect human values when making decisions.,value alignment and bias in AI recommendations,Contradicts passage by asserting inherent reflection; passage warns value alignment is a concern needing assurance.,"ethics,governance,privacy",11,AI Ethics and Governance
100335,170,half-true,Fernet encryption alone guarantees complete protection of sensitive healthcare datasets in applications.,data encryption using Fernet from the Python cryptography library,"Accurately notes Fernet provides strong symmetric encryption, but overstates guarantee and ignores key management and access controls.","data-prep,feature-engineering,rag",3,Prepping Data for AI
100336,170,barely-true,Fernet encryption completely eliminates security risks for healthcare datasets.,data encryption using Fernet from the Python cryptography library,Overstates protection: Fernet reduces exposure but does not fully eliminate risks like key compromise or implementation errors.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
100337,170,mostly-true,Fernet symmetric encryption is suitable for protecting sensitive healthcare datasets in applications.,data encryption with Fernet from the Python cryptography library,"Passage endorses Fernet for securing healthcare records, omitting deployment caveats like key management.","data-prep,feature-engineering,rag",3,Prepping Data for AI
100338,74,FALSE,Batch size 32 yields lower throughput than batch size 1 on the GPU.,throughput and latency for batch sizes in GPU performance,Contradicts passage saying batch size 32 gives over 5× speedup and stabilizes throughput when GPU is fully utilized.,"mlops,scaling,deployment",10,AI At Scale
100339,74,mostly-true,Batch size 32 achieves over fivefold speedup while keeping latency below 0.01 seconds.,throughput and latency for GPU batching,"Performance data shows latency drops under 0.01s and speedup exceeds 5× at batch size 32, omitting minor variability.","mlops,scaling,deployment",10,AI At Scale
100340,74,barely-true,Batch size 32 always achieves over 5× speedup with negligible latency for all GPU models.,throughput and latency for batch size experiments on GPU,"Overreaches passage: only reports >5× at batch 32 for a specific run, omits different GPUs and workloads.","mlops,scaling,deployment",10,AI At Scale
100341,117,pants-fire,Deploying any model as a hosted API always eliminates all installation and compatibility needs.,"deploying model as a service, hosted endpoint, CPU tier",Passage states hosted endpoints reduce installation for many uses; claiming elimination of all compatibility needs is extreme and incorrect.,"mlops,scaling,deployment",10,AI At Scale
100342,117,half-true,Deploying a model as a hosted service always lets teams scale seamlessly from free tiers to high-demand production.,"deploying model as a service, hosted endpoint, free CPU tier",Claim mixes correct scalability potential with incorrect certainty; passage says scaling is possible but doesn't guarantee seamlessness or 'always' availability.,"mlops,scaling,deployment",10,AI At Scale
100343,117,barely-true,Deploying a hosted model endpoint always eliminates the need for any local installations.,deploying as a service; hosted endpoint; lightweight apps,"Overreaches beyond passage: it suggests hosting always removes local installs, which passage only says it can help and integrate without installing.","mlops,scaling,deployment",10,AI At Scale
100344,22,barely-true,Classic statistical AI is the only viable approach for most builders today.,opportunity for builders using classic statistical AI,"Overreaches the passage: it notes opportunity in classic AI but explicitly denies Big AI exclusivity, not exclusivity claim.","ai,open-source,builder",1,Introduction – The Gold Rush Paradox
100345,22,barely-true,Classic statistical AI remains a major opportunity for builders over Big AI hype.,opportunity for builders; classic statistical AI vs Big AI,"Overstates prominence and opportunity; passage only says classic AI 'still has a lot to offer', not that it 'remains a major opportunity'.","ai,open-source,builder",1,Introduction – The Gold Rush Paradox
100346,22,TRUE,Classic statistical AI remains a valuable opportunity for builders alongside large AI models.,opportunity for builders in classic statistical AI,Passage explicitly contrasts Big AI with classic statistical AI and calls it a huge opportunity for builders.,"ai,open-source,builder",1,Introduction – The Gold Rush Paradox
100347,134,half-true,Deepfake risks can be mitigated primarily through user knowledge and understanding of the software.,defense strategy using knowledge and tools in deepfake media-forensics,Mixes correct emphasis on education with incorrect claim that knowledge alone is the primary mitigation.,"media-forensics,voice-cloning,deepfake",9,Deepfake Defense
100348,134,barely-true,Deepfake risks are mostly solved by increasing user knowledge about the tools.,"deepfake defense, knowledge-driven mitigation and tool understanding",Overstates effectiveness: passage promotes understanding but doesn't claim knowledge alone solves deepfake risks.,"media-forensics,voice-cloning,deepfake",9,Deepfake Defense
100349,134,half-true,Deepfake risks are best managed by improving public and practitioner knowledge about the tools.,deepfake defense via understanding software tools,Mixes correct emphasis on knowledge with overstated universality; ignores technical measures and evaluation datasets.,"media-forensics,voice-cloning,deepfake",9,Deepfake Defense
100350,69,barely-true,PCA always preserves essential information when reducing many features to a single score.,PCA dimensionality reduction for power features,Overstates PCA capabilities; passage notes reducing 160 powers to one score loses detail and is only a handy shortcut.,"machine-learning,classification,evaluation",4,Classical Machine Learning
100351,69,half-true,PCA condenses many power features into a single composite score for clustering.,PCA dimensionality reduction of power features before clustering,"Mixes correct PCA use for reduction with incorrect claim that it yields one composite score, losing nuance.","machine-learning,classification,evaluation",4,Classical Machine Learning
100352,69,TRUE,PCA is used to reduce dimensionality of power features before clustering.,dimensionality reduction using PCA on power features,Passage explicitly states PCA will be used to reduce dimensionality of the power features prior to clustering.,"machine-learning,classification,evaluation",4,Classical Machine Learning
100353,30,half-true,The dataset lets an agentic AI reliably plan multi-step game recommendation actions without human oversight.,structured game dataset with positive reviews and genres,"Dataset supports filtering and recommendations but omits planning affordances, tool interfaces, and autonomy guarantees.","agentic-ai,planning,tools",12,Agentic AI
100354,30,FALSE,Counter-Strike: Global Offensive has fewer positive reviews than Dota 2.,Table 11-1 dataset of positive reviews for games,"Contradicts given review counts: CS:GO 5,764,420 vs Dota 2 1,477,153, so CS:GO has more.","agentic-ai,planning,tools",12,Agentic AI
100355,30,TRUE,AI can filter and analyze game data by review sentiment and genres for recommendations.,structured dataset of games with positive reviews and genres,"Dataset explicitly supports filtering by sentiment, analyzing engagement across genres, and generating recommendations.","agentic-ai,planning,tools",12,Agentic AI
100356,91,barely-true,Stable Diffusion image generation requires GPUs to run at all practical speeds.,Generating Images with Stable Diffusion in Colab using GPU,"Passage only says GPUs speed up generation from minutes to seconds, not strictly required for practical use.","ai,tool-chain,notebooks",2,AI Survival Kit
100357,91,TRUE,Stable Diffusion image generation runs much faster on a GPU in Colab environments.,Generating Images with Stable Diffusion; Colab GPU support,Passage explicitly states GPU support in Colab dramatically speeds image generation from minutes to seconds.,"ai,tool-chain,notebooks",2,AI Survival Kit
100358,91,pants-fire,Stable Diffusion on Colab always runs without GPUs and never speeds up image generation.,Generating Images with Stable Diffusion in Colab notebook,Directly contradicts passage claiming GPU support can dramatically speed up Stable Diffusion image generation.,"ai,tool-chain,notebooks",2,AI Survival Kit
100359,113,TRUE,"Vector databases store embeddings to enable fast, accurate retrieval for RAG applications.",vector database storing embeddings for retrieval-augmented generation (RAG),Passage explains vector databases store numerical embeddings used to find matching information for RAG.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
100360,113,TRUE,Vector databases store embeddings that enable fast semantic retrieval for RAG systems.,vector database storing embeddings for retrieval,"Directly supported: passage explains vector databases store embeddings enabling fast, accurate matching for RAG.","data-prep,feature-engineering,rag",3,Prepping Data for AI
100361,113,mostly-true,"Vector databases store embeddings to enable fast, meaning-based retrieval for RAG systems.",vector database storing embeddings for RAG retrieval,Describes embedding storage and fast retrieval for RAG; omits implementation caveats and performance tradeoffs.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
100362,208,TRUE,"PyTorch is an imperative-style, high-performance deep learning library.",PyTorch paper (NeurIPS 2019) describing deep learning framework,Directly matches paper title asserting PyTorch's imperative style and high-performance qualities.,"deep-learning,frameworks,tensors",5,Deep Learning
100363,208,barely-true,PyTorch exclusively uses static computation graphs for all tensor operations and models.,"PyTorch deep-learning framework, tensors, imperative style",Contradicts PyTorch's documented imperative/dynamic graph approach; overstates implementation detail.,"deep-learning,frameworks,tensors",5,Deep Learning
100364,208,half-true,PyTorch originally focused primarily on CPU-bound tensor operations before adding GPU support.,PyTorch deep-learning library and tensors,"Partly true: PyTorch supported CPU tensors early, but GPU (CUDA) support was integral and emphasized from initial releases.","deep-learning,frameworks,tensors",5,Deep Learning
100365,133,barely-true,"Open-source tools alone guarantee responsible, unbiased AI deployments in production.","tool-chain and ethics with Hugging Face, LangChain, bias mitigation",Overreaches beyond passage: mentions ethics and bias mitigation but passage warns responsibility and change management.,"ai,tool-chain,notebooks",2,AI Survival Kit
100366,133,pants-fire,Open-source tools make AI models infallible and never require oversight or ethics.,tool-chain and open-source software for model deployment,"Passage emphasizes responsibility, ethics, and oversight; claim contradicts need for bias mitigation and change management.","ai,tool-chain,notebooks",2,AI Survival Kit
100367,133,FALSE,All agentic AI systems require proprietary software to function in production environments.,tool-chain and Hugging Face/LangChain deployment,Contradicts passage assertion that agentic systems were built with open-source tools like Hugging Face and LangChain.,"ai,tool-chain,notebooks",2,AI Survival Kit
100368,126,barely-true,The baseline majority-class classifier achieves about 65% accuracy on the Marvel vs. DC task.,baseline accuracy on dataset with Marvel vs. DC classes,Accuracy claim matches reported result but omits details about dataset size and class balance.,"machine-learning,classification,evaluation",4,Classical Machine Learning
100369,126,TRUE,The baseline majority-class classifier achieved 65% accuracy on the Marvel vs. DC task.,baseline accuracy on training/test split with majority_class predictor,Directly reported result from running the baseline majority-class predictor on the dataset.,"machine-learning,classification,evaluation",4,Classical Machine Learning
100370,126,TRUE,A majority-class baseline yields a 65% accuracy for the Marvel vs. DC binary task.,baseline accuracy on training labels using majority_class,Baseline accuracy reported as 65% after limiting task to Marvel vs. DC and using majority-class prediction.,"machine-learning,classification,evaluation",4,Classical Machine Learning
100371,41,mostly-true,The model's voice-classification improved when training used ten 10-second samples per speaker rather than five.,dataset: ten 10-second samples per speaker audio clips,"Testing showed performance stabilized with ten samples versus inconsistent results using five, indicating improved reliability.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
100372,41,mostly-true,Model performance improved when training used ten audio samples per speaker rather than five.,dataset of 10-second audio clips with Jerry and other speakers,Experimentation showed five samples produced inconsistent results while ten-per-class stabilized performance and recognition.,"media-forensics,voice-cloning,deepfake",9,Deepfake Defense
100373,41,barely-true,Ten training examples per speaker always guarantee stable voice-clone detection performance.,training dataset size for voice-cloning model,Overreaches the passage: ten examples stabilized results in their tests but does not guarantee stability universally.,"media-forensics,voice-cloning,deepfake",9,Deepfake Defense
100374,47,mostly-true,AI deployment at scale typically requires MLOps practices to ensure reliable model serving and monitoring.,model deployment and MLOps practices for scaling,"Broadly supported by discussion of training, serving, and datasets; minor operational specifics omitted.","mlops,scaling,deployment",10,AI At Scale
100375,47,mostly-true,"AI deployment at scale requires robust MLOps, automation, and monitoring to maintain model performance.",MLops and deployment practices for large models,"Broadly supported by emphasis on training, tooling, and dataset-management, though specific costs and tooling trade-offs omitted.","mlops,scaling,deployment",10,AI At Scale
100376,143,mostly-true,RAG workflows use curated datasets and vector stores to enhance retrieval during generation.,vector store from plot texts and OpenAIEmbeddings in RAG,Demonstrates Chroma vector store and embeddings for retrieval-augmented generation; minor implementation details omitted.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
100377,143,barely-true,RAG reliably generates faithful superhero stories solely from small curated plot datasets.,RAG with Chroma vector store and OpenAIEmbeddings,Overstates reliability and faithfulness; example shows RAG using one retrieved plot but omits hallucination risks and dataset limits.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
100378,143,barely-true,RAG guarantees retrieval of perfectly relevant plot details for every user query.,vector store similarity_search on plot dataset with OpenAIEmbeddings,"Overstates capability: retrieval often returns approximate matches and depends on embeddings, k, and curated data quality.","data-prep,feature-engineering,rag",3,Prepping Data for AI
100379,128,barely-true,Agentic AI planners cannot reliably attribute long-term goals to tool-using models.,agentic-ai planners and tool use,Claim overreaches: passage discusses planning and tools but offers no evidence about reliable long-term goal attribution.,"agentic-ai,planning,tools",12,Agentic AI
100380,128,barely-true,The judge incorrectly claimed Kilauea's eruption began in 2021 rather than late 2020.,evaluation prompt involving Kilauea eruption dates and Judge tool,Passage shows judge's justification stating 2021 error; claim overstates judge's certainty about dates.,"agentic-ai,planning,tools",12,Agentic AI
100381,128,half-true,An automated judge incorrectly claimed Kīlauea's eruption began in 2021 instead of late 2020.,evaluating answers; eruption start date and lava fountain heights,"Mixes correct eruption details (ongoing, high lava fountains) with incorrect start-year attribution, creating a factual blend.","agentic-ai,planning,tools",12,Agentic AI
100382,87,TRUE,Cluster 2 groups Kryptonian and tech-enhanced characters together.,cluster analysis of character embeddings,"Passage explicitly lists General Zod, Cyborg Superman, and Firestorm as Cluster 2 members.","machine-learning,classification,evaluation",4,Classical Machine Learning
100383,87,mostly-true,Clustering grouped overwhelmingly powerful and Kryptonian/tech-enhanced characters into separate small clusters.,"clustering output for character power types (Kryptonian, tech-enhanced, Deities)","Cluster description supports grouping by power and technology, but omits clustering method and full dataset details.","machine-learning,classification,evaluation",4,Classical Machine Learning
100384,87,mostly-true,Clustering groups powerful supernatural and Kryptonian/tech-enhanced characters together.,"clustering of characters (Kryptonian, Deities/Eternals, tech-enhanced)",Passage shows Cluster 1 holds Deities/Eternals and Cluster 2 skews toward Kryptonian and tech-enhanced characters.,"machine-learning,classification,evaluation",4,Classical Machine Learning
100385,98,pants-fire,ReLU always preserves negative gradient flow during backpropagation through tensors.,activation functions like ReLU in deep-learning tensors,"Contradicts ReLU behavior: ReLU zeroes negatives, blocking gradient flow for negative pre-activations.","deep-learning,frameworks,tensors",5,Deep Learning
100386,98,mostly-true,Activation functions such as ReLU and Sigmoid introduce nonlinearity and control neuron activity in neural networks.,"activation functions (ReLU, Sigmoid) in deep learning layers","Supported by passage: ReLU, Sigmoid, and Tanh apply nonlinear transforms to pre-activation values, controlling neuron outputs.","deep-learning,frameworks,tensors",5,Deep Learning
100387,98,mostly-true,"Activation functions like ReLU, Sigmoid, and Tanh introduce nonlinearity and control neuron activation.","activation functions (ReLU, Sigmoid, Tanh) in neural network layers","Directly described: passage explains ReLU, Sigmoid roles and states they introduce non-linearity and control activation.","deep-learning,frameworks,tensors",5,Deep Learning
100388,145,mostly-true,Ymir saves his sister but loses his temporal powers after defeating Siren.,"plot summary of protagonist, antagonist Siren, and Dr. Chronos","Supported by passage: he rescues sister and sacrifices abilities, omitting minor emotional aftermath details.","data-prep,feature-engineering,rag",3,Prepping Data for AI
100389,145,barely-true,Ymir sacrifices his powers and becomes a quiet city hero after saving his sister.,plot summary of Ymir confronting Siren and Neo-Chronos,"Mostly supported: passage states he saves sister and Neo-Chronos and sacrifices abilities, but 'quiet city hero' is inferred beyond explicit phrasing.","data-prep,feature-engineering,rag",3,Prepping Data for AI
100390,145,mostly-true,"Ymir defeats Siren and saves his sister but loses his powers, becoming a city hero.",narrative plot summary of protagonist Ymir and time-manipulator Siren,Plot describes rescue and sacrifice; minor omitted nuance about Neo-Chronos role and training.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
100391,41,pants-fire,All open-source projects in the reference architecture are proprietary and closed-source.,reference architecture of open-source tools,"Direct contradiction: reference explicitly lists open-source tools and links to repositories, so claim is implausible.","open-source,community,contribution",13,Commit to Contribute
100392,41,barely-true,All project names in the reference architecture link to their live repositories and homepages.,reference architecture of open-source tools by category,"Partially unsupported: passage says each project name links out, but live repository presence not confirmed.","open-source,community,contribution",13,Commit to Contribute
100393,41,mostly-true,"The reference groups open-source AI tools by lifecycle role, linking each project to its repository.",reference architecture of open-source tools by category,Accurately reflects grouping and links; omits minor details about interactive live version and figure numbering.,"open-source,community,contribution",13,Commit to Contribute
100394,165,TRUE,"The agent learns thruster timing, angle stabilization, and descent control through repeated simulated episodes.",reinforcement learning agent training on lander simulation dataset,"Simulation repeatedly updates policy from state, action, reward sequences, directly supporting learning mechanisms described.","machine-learning,classification,evaluation",4,Classical Machine Learning
100395,165,barely-true,"The agent learns entirely without any instructions, solely from trial-and-error experience.",reinforcement learning agent on lunar lander simulation,Overstates learning: passage says agent improves from attempts but omits potential engineered rewards or algorithmic guidance.,"machine-learning,classification,evaluation",4,Classical Machine Learning
100396,165,mostly-true,The agent generally learns to stabilize angle and control descent by repeated trial-and-error in the environment.,"reinforcement learning agent training, rewards, and actions","Description aligns with passage: agent improves thruster timing and descent control through repeated episodes, omitting minor RL details.","machine-learning,classification,evaluation",4,Classical Machine Learning
100397,36,pants-fire,Hugging Face controls every open-source AI contribution globally.,"Hugging Face ecosystem (Transformers, Datasets, Spaces, Model Cards)","Claim impossibly overstates influence; passage notes high mentions and ecosystem, not global control of contributions.","open-source,community,contribution",13,Commit to Contribute
100398,36,FALSE,Hugging Face was rarely mentioned and offered no tooling for model hosting or evaluation.,Hugging Face ecosystem and Datasets/Spaces tools,"Contradicts passage stating Hugging Face had 10 mentions and provided hosting, evaluation, and sharing tools.","open-source,community,contribution",13,Commit to Contribute
100399,76,mostly-true,Data representation choices can subtly bias model outputs in superhero analysis tasks.,dataset composition and sensitive category representation,Supports that representation of sensitive categories like gender influences results; omits specific mitigation steps.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
100400,76,mostly-true,Dataset composition can shape model outputs for sensitive categories like gender in superhero portrayals.,"dataset composition for sensitive categories (gender, moral alignment)",Aligns with passage emphasizing dataset alignment with questions; minor caveat about broader modeling factors omitted.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
100401,76,barely-true,Dataset alignment with research questions always ensures fair representation of sensitive categories.,"dataset alignment for sensitive categories (gender, moral alignment)","Overreaches by claiming guaranteed fairness; passage only advises pausing and aligning datasets, not ensuring fairness.","data-prep,feature-engineering,rag",3,Prepping Data for AI
100402,98,mostly-true,"Embedded AI tools enable agentic systems that plan, call tools, and act autonomously.","using tools like Hugging Face Hub, LangChain, CrewAI for embedded AI","Passage describes embedded AI and those tools enabling agentic capabilities, minor implementation caveats omitted.","ai,tool-chain,notebooks",2,AI Survival Kit
100403,98,half-true,Embedded AI enables agentic systems that can fully act autonomously across complex real-world tasks.,"tools such as Hugging Face Hub, LangChain, and CrewAI","Passage claims agentic AI can plan, call tools, and act autonomously but overstates scope and real-world completeness.","ai,tool-chain,notebooks",2,AI Survival Kit
100404,98,mostly-true,"Embedded AI enables agentic systems that plan tasks, call tools, and act autonomously.","tool use with Hugging Face Hub, LangChain, and CrewAI","Passage presents agentic AI via embedded models and tools, omitting implementation limitations.","ai,tool-chain,notebooks",2,AI Survival Kit
100405,72,half-true,The pipeline uses SpeechT5 features and HiFi-GAN but requires additional dataset preparation steps.,text-to-speech pipeline using SpeechT5 and HiFi-GAN,Partially correct: passage names SpeechT5 and HiFi-GAN but omits exact dataset requirements and setup specifics.,"media-forensics,voice-cloning,deepfake",9,Deepfake Defense
100406,72,mostly-true,SpeechT5 and HiFi-GAN together enable text-to-speech by converting text to waveform audio.,voice-generation pipeline using SpeechT5 and HiFi-GAN,Passage explicitly names SpeechT5 mapping text to features and HiFi-GAN producing waveform; minor implementation details omitted.,"media-forensics,voice-cloning,deepfake",9,Deepfake Defense
100407,72,half-true,SpeechT5 always converts text directly into final audible waveforms without intermediate steps.,voice-generation pipeline using SpeechT5 and HiFi-GAN,"Partially correct about SpeechT5 role but contradicts passage: SpeechT5 produces intermediate features, HiFi-GAN makes waveforms.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
100408,86,pants-fire,The passage claims a deployed pipeline can fully prevent all prompt-injection attacks.,tool pipeline using transformers text-classification model,Directly contradicts excerpt: pipeline setup loads model/tokenizer but offers no guarantee of preventing prompt-injection attacks.,"security,red-team,guardrails",8,Breaking-Securing AI
100409,86,barely-true,The example shows using a Hugging Face text-classification pipeline with a preloaded model and tokenizer.,code snippet using transformers.pipeline for text-classification,Mostly accurate but overstates: passage only shows pipeline call without explicit model/tokenizer loaded.,"security,red-team,guardrails",8,Breaking-Securing AI
100410,86,TRUE,The code initializes a Hugging Face text-classification pipeline for inference.,transformers pipeline using model and tokenizer,"Passage shows pipeline('text-classification') with model and tokenizer arguments, enabling inference.","security,red-team,guardrails",8,Breaking-Securing AI
100411,75,half-true,CrewAI combines open-source flexibility with a paid enterprise edition offering commercial support.,multi-agent AI framework; integration with LangChain and structured task delegation,Mixes correct dual-distribution claim with unspecified enterprise features and level of support.,"agentic-ai,planning,tools",12,Agentic AI
100412,75,half-true,CrewAI both offers an open-source framework and a commercially supported enterprise edition.,"multi-agent AI frameworks; CrewAI, LangChain integration",Accurate dual offering but implies equal feature parity and support level without evidence.,"agentic-ai,planning,tools",12,Agentic AI
100413,75,mostly-true,CrewAI combines an open-source framework with an enterprise edition offering commercial support and added features.,multi-agent AI frameworks; integration with LangChain and structured task delegation,"Passage explicitly states dual open-source and enterprise editions, with integration and delegation benefits; minor unspecified enterprise features omitted.","agentic-ai,planning,tools",12,Agentic AI
100414,32,barely-true,Red teamers exploit overtrusted AI-generated code to insert polymorphic payloads and bypass lazy reviews.,tool usage: GenAI for polymorphic payloads and fake pull requests,"Passage describes using GenAI to create polymorphic payloads and fake PRs that pass cursory review, showing exploitation of overtrust.","security,red-team,guardrails",8,Breaking-Securing AI
100415,32,half-true,AI-generated code is often overtrusted and used to create polished malicious payloads without review.,use of GenAI for polymorphic payloads and fake pull requests,"Accurately notes overtrust and malicious use, but implies frequency and reviewer laziness without precise evidence.","security,red-team,guardrails",8,Breaking-Securing AI
100416,32,barely-true,Attackers often rely on unreviewed AI-generated code to sneak polymorphic payloads past lazy reviewers.,"AI-generated code, polymorphic payloads, fake pull requests",Matches passage's claim but overstates frequency and attacker intent without evidence.,"security,red-team,guardrails",8,Breaking-Securing AI
100417,1,TRUE,Some builders prefer to use preexisting AI instead of creating their own systems.,developer attitudes toward AI builders and prebuilt models,"Passage explicitly contrasts people content with given AI versus those who build their own, supporting claim.","ai,open-source,builder",1,Introduction – The Gold Rush Paradox
100418,1,half-true,Some builders wrongly accept any supplied AI as sufficient without scrutiny.,developer attitude toward AI tools and open-source models,Mixes correct criticism of passive trust with exaggerated universality about builders' behavior.,"ai,open-source,builder",1,Introduction – The Gold Rush Paradox
100419,1,barely-true,Builders prefer customizing open-source AI rather than passively using prepackaged models.,preference contrast between builders and users; open-source AI,Overstates passage: passage praises builders but doesn't claim broad preference for open-source customization.,"ai,open-source,builder",1,Introduction – The Gold Rush Paradox
100420,54,TRUE,The decision tree achieves about 73% accuracy while providing inspectable rules.,decision tree model accuracy and visualization,Passage states the decision tree has ~73% accuracy and highlights rule inspection when visualized.,"machine-learning,classification,evaluation",4,Classical Machine Learning
100421,54,barely-true,The decision tree perfectly detects all Cyborgs in the dataset.,decision tree model performance on Cyborg class,Contradicts passage: decision tree fails on Cyborgs while boosting Human recall to 91%.,"machine-learning,classification,evaluation",4,Classical Machine Learning
100422,54,TRUE,Both models achieved about 75% overall accuracy on the hero classification task.,decision tree and neural model accuracy on hero dataset,"Passage reports both models were correct about three-quarters of the time, roughly 73% accuracy.","machine-learning,classification,evaluation",4,Classical Machine Learning
100423,123,half-true,Advanced optimizers always find the global minimum in deep learning loss landscapes.,optimizer behavior on loss landscape with local minima and saddle points,"Overstates optimizer capabilities: passage praises optimizers but only implies they help navigate traps, not guarantee global minima.","deep-learning,frameworks,tensors",5,Deep Learning
100424,123,half-true,Advanced optimizers always find the global minimum in neural network training.,optimizer behavior on loss landscape and training loop,Overstates optimizer capability; passage says they help navigate traps but not guarantee finding global minimum.,"deep-learning,frameworks,tensors",5,Deep Learning
100425,123,FALSE,Advanced optimizers always guarantee finding the global minimum for neural network loss landscapes.,optimizer behavior in deep learning loss landscapes,Passage says advanced optimizers help navigate traps but does not claim they always find the global minimum; contradicts optimization reality.,"deep-learning,frameworks,tensors",5,Deep Learning
100426,126,half-true,Red-teamers should run short reconnaissance then longer focused attacks against RAG and execution control filters.,"reconnaissance, RAG connections, prompt injection","Partly correct sequence and targets, but overstates necessity and exact timing for every red-team engagement.","security,red-team,guardrails",8,Breaking-Securing AI
100427,126,TRUE,"Red teams should probe prompt injection, hallucination, and execution control vulnerabilities.",reconnaissance and focused attacks on RAG-connected AI assistant,"Passage instructs systematic probing of prompt injection, hallucination, and execution control vectors.","security,red-team,guardrails",8,Breaking-Securing AI
100428,126,pants-fire,The passage claims the AI's core defensive filters are permanently inseparable from the pipeline.,defensive filters wired into pipeline for RAG and assistant,Contradicts passage timing: filters checked during reconnaissance and may be temporary or reconfigured.,"security,red-team,guardrails",8,Breaking-Securing AI
100429,145,mostly-true,Varying learning rate and batch size helps find more effective agent plans.,"hyperparameter tuning for agent planning (learning rate, batch size)","Passage describes testing different learning rates (0.01 vs 0.001) and batch sizes to identify the best plan, omitting potential trade-offs or other hyperparameters.","deep-learning,frameworks,tensors",5,Deep Learning
100430,145,barely-true,Using a 0.01 learning rate always produces the most efficient agent plans.,learning rate hyperparameter in training experiments,"Overreaches beyond passage's examples; passage only presents 0.01 and 0.001 as tested options, not a universal best.","deep-learning,frameworks,tensors",5,Deep Learning
100431,145,FALSE,Increasing batch size always improves deep learning model generalization.,training hyperparameters: batch size and learning rate,Contradicts passage: batch size affects training but not guaranteed to improve generalization.,"deep-learning,frameworks,tensors",5,Deep Learning
100432,63,TRUE,AI-generated content can spread misinformation widely and harm public trust.,misinformation risk from AI-generated content,"Passage explains AI-produced content enables convincing, scalable falsehoods that undermine trust and credibility.","ethics,governance,privacy",11,AI Ethics and Governance
100433,63,half-true,AI-generated content often spreads because recipients unknowingly share inaccurate material.,misinformation spreading via AI-generated content,Mixes correct concern about scale with implied frequency and intent details not specified in passage.,"ethics,governance,privacy",11,AI Ethics and Governance
100434,63,half-true,AI-generated content frequently causes widespread misinformation and undermines public trust in institutions.,misinformation risk from AI-generated content,Accurately notes misinformation risk but overstates frequency and scope without evidence of scale.,"ethics,governance,privacy",11,AI Ethics and Governance
100435,3,barely-true,An agentic AI always decomposes goals into fixed step-by-step plans before acting.,agentic AI planning and step decomposition,"Overreaches: passage says agents often break goals into steps and adapt, not always use fixed step-by-step plans.","agentic-ai,planning,tools",12,Agentic AI
100436,3,pants-fire,Agentic AI always invents plans by breaking goals into steps and never uses direct answers.,agentic AI planning and goal decomposition,"Contradicts passage: planning often breaks goals into steps, but passage doesn't claim agents never use direct answers.","agentic-ai,planning,tools",12,Agentic AI
100437,3,FALSE,Agentic AI always jumps straight to final answers without stepwise planning.,agentic AI planning and stepwise reasoning,Contradicts passage detail that agentic AI breaks goals into manageable steps and adapts while planning.,"agentic-ai,planning,tools",12,Agentic AI
100438,5,FALSE,AI guardrails cannot prevent all data exfiltration by malicious prompts or bots.,"hacker perspective, prompt injection and unchecked autonomy in models",Contradicts passage which explains guardrail weakness but not total ineffectiveness; overstates inevitability.,"security,red-team,guardrails",8,Breaking-Securing AI
100439,5,TRUE,"AI systems can fail via prompt injection, data poisoning, brittle models, and unchecked autonomy.",hacker perspective on guardrails and model failures,"Passage explicitly lists prompt injection, data poisoning, brittle models, and unchecked autonomy as failure modes when guardrails are weak.","security,red-team,guardrails",8,Breaking-Securing AI
100440,5,FALSE,AI systems never experience prompt injection or data poisoning failures.,hacker’s perspective; prompt injection and data poisoning,Contradicts passage listing prompt injection and data poisoning as explicit failure modes.,"security,red-team,guardrails",8,Breaking-Securing AI
100441,119,half-true,The example AR model perfectly prevents exploding gradients during training on the flights dataset.,"normalization to [0,1] on flights dataset for autoregressive model",Mixes correct benefit of normalization with overclaim that it guarantees preventing exploding gradients.,"generative-ai,diffusion,gans",7,Generative AI
100442,119,half-true,The code trains a simple autoregressive neural network to predict the next month's normalized passenger value.,autoregression with SEQ_LEN=12 on the flights dataset,Mixes correct model and sequence usage with unsupported claim that training guarantees smoother convergence and avoids exploding gradients.,"generative-ai,diffusion,gans",7,Generative AI
100443,119,pants-fire,The autoregressive model learns to generate photorealistic images from random noise using GAN-style adversarial training.,generative-ai model claim involving GANs and diffusion,"Directly contradicts passage: code shows an autoregressive regression model forecasting passengers, not GAN or diffusion image generation.","generative-ai,diffusion,gans",7,Generative AI
100444,157,pants-fire,The DataLoader alone trains deep learning models end-to-end without any model code or optimizers.,DataLoader utility in deep-learning frameworks like PyTorch,"Contradicts passage: DataLoader only prepares and serves data; it does not implement models, training loops, or optimizers.","deep-learning,frameworks,tensors",5,Deep Learning
100445,157,pants-fire,PyTorch DataLoader automatically converts model tensors to GPU-specific bfloat16 format.,DataLoader usage in PyTorch framework,Contradicts passage which says DataLoader organizes batches and transforms; no GPU bfloat16 conversion claim.,"deep-learning,frameworks,tensors",5,Deep Learning
100446,157,FALSE,DataLoaders inherently convert image tensors from 0-255 to 0.0-1.0 automatically.,DataLoader behavior in PyTorch frameworks,"Contradicts passage: pixel scaling is separate transformation, not an inherent DataLoader function.","deep-learning,frameworks,tensors",5,Deep Learning
100447,15,TRUE,"Open-source AI promotes transparency and public scrutiny, aiding more trustworthy models.","open-source AI, transparency, data biases","Passage explicitly states open-source AI invites transparency and public scrutiny, supporting trustworthiness.","ethics,governance,privacy",11,AI Ethics and Governance
100448,15,half-true,Open-source AI increases transparency but cannot by itself ensure sustained ethical impact.,"open-source AI, transparency, data bias","Acknowledges transparency benefit yet notes enforcement, measurement, and data-bias challenges left unresolved.","ethics,governance,privacy",11,AI Ethics and Governance
100449,15,TRUE,"Open-source AI fosters transparency and public scrutiny that supports more trustworthy, ethically grounded models.",open-source AI transparency and advisory boards,"Passage states open-source invites transparency and scrutiny, encouraging more trustworthy, ethically grounded models.","ethics,governance,privacy",11,AI Ethics and Governance
100450,150,pants-fire,Agentic AI autonomously replaces all human planners across industries within months.,agentic-ai planning and tools capability claim,"Extremely implausible given agentic AI limits; contradicts planning, tool-use complexity and gradual deployment timelines.","agentic-ai,planning,tools",12,Agentic AI
100451,150,mostly-true,Agentic AI systems plan and use external tools to pursue goals with limited human guidance.,agentic-ai planning and tools usage,"Passage emphasizes planning, tool use, and pursuit of goals; omits caveats about oversight and failure modes.","agentic-ai,planning,tools",12,Agentic AI
100452,150,pants-fire,Agentic AI autonomously overthrows human institutions within weeks using self-improving planning tools.,agentic-ai planning and tools discussion,Extreme claim contradicts passage content and tags; no evidence of rapid institutional overthrow or timeline.,"agentic-ai,planning,tools",12,Agentic AI
100453,84,half-true,Victoria’s ray gun compresses inputs into a latent code and injects randomness like a VAE.,variational autoencoder (VAE) latent representation in neural-networks,Matches passage analogy but overgeneralizes mechanism; passage likens ray gun to a VAE without technical specifics.,"neural-networks,cnn,transformers",6,Neuron Building Blocks
100454,84,half-true,The passage claims Victoria's ray gun compresses data into a latent space and adds randomness like a VAE.,variational autoencoder (VAE) analogy in neural-networks,"Mixes correct VAE compression/randomness idea with fictional ray gun analogy, blending fact and fiction.","neural-networks,cnn,transformers",6,Neuron Building Blocks
100455,84,pants-fire,The passage claims a ray gun literally implements a variational autoencoder in hardware.,VAE analogy to Victoria’s ray gun in neural-networks concept,"Asserts physical hardware implementation of a VAE, contradicting text which uses a metaphorical analogy.","neural-networks,cnn,transformers",6,Neuron Building Blocks
100456,132,FALSE,Transformers rely mainly on recurrent layers rather than self-attention for sequence modeling.,"model architecture, self-attention vs recurrent layers","Contradicts passage detail that Transformers use self-attention, not recurrent layers, to model sequences.","generative-ai,diffusion,gans",7,Generative AI
100457,132,half-true,"Transformers use self-attention to weigh all words simultaneously, enabling faster parallel training and scalability.",self-attention mechanism in models like GPT or BERT,"Accurate on self-attention and parallelism, but overstates that it alone guarantees greater scalability and training speed improvements.","generative-ai,diffusion,gans",7,Generative AI
100458,132,TRUE,Transformers use self-attention to weigh other words' importance when processing each token.,"self-attention mechanism in Transformer models (e.g., GPT, BERT)",Directly supported: passage explains self-attention lets models weigh all other words when generating or interpreting each word.,"generative-ai,diffusion,gans",7,Generative AI
100459,94,TRUE,Cosine similarity is better for detecting relative profile patterns than measuring absolute strength.,cosine_similarity metric on hero dataset,Passage explicitly states cosine similarity spots relative-profile patterns and is not for absolute strength measurement.,"machine-learning,classification,evaluation",4,Classical Machine Learning
100460,94,TRUE,Cosine similarity is best for detecting relative profile patterns rather than absolute strength.,cosine_similarity metric on hero dataset,"Passage explicitly says cosine similarity spots relative profiles, not measuring absolute strength.","machine-learning,classification,evaluation",4,Classical Machine Learning
100461,94,half-true,Cosine similarity is useful for comparing relative profile patterns but not for measuring absolute feature magnitudes.,cosine_similarity metric on hero dataset clusters,Matches passage: cosine captures relative patterns (similarity within/across clusters) but not absolute strength; mixes correct scope and omission.,"machine-learning,classification,evaluation",4,Classical Machine Learning
100462,17,mostly-true,Pip can install and manage Python libraries directly from a notebook cell.,tool: pip in notebook cells,Describes pip's notebook installation capability directly mentioned; omits minor setup or environment caveats.,"ai,tool-chain,notebooks",2,AI Survival Kit
100463,17,TRUE,Pip is used to install and manage Python libraries directly within a notebook cell.,pip usage in notebook cells,Passage states pip lets users install and manage libraries directly from a notebook cell and shows running a pip command.,"ai,tool-chain,notebooks",2,AI Survival Kit
100464,17,barely-true,Pip cannot install Python libraries from within a notebook cell.,using pip in a notebook cell,Contradicts passage which states pip lets you install and manage libraries directly from a notebook cell.,"ai,tool-chain,notebooks",2,AI Survival Kit
100465,1,barely-true,The passage claims a tiny curated dataset suffices to build a trustworthy AI foundation.,small curated dataset example in Colab (Listing 2-15),"Overreaches by implying a tiny dataset alone ensures trustworthy, adaptable AI; lacks evidence about scale, validation, or preprocessing.","data-prep,feature-engineering,rag",3,Prepping Data for AI
100466,1,half-true,"A tiny curated dataset alone guarantees trustworthy, adaptable AI system foundations.",data preparation using a small curated dataset in Colab example,Mixes correct practice (curated dataset helps) with incorrect claim of guarantee and sole sufficiency.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
100467,1,TRUE,"Data preparation identifies duplicates, placeholders, inconsistent formats, and outliers.",data-prep example using a curated dataset and Colab notebook,Directly supported by passage listing those specific red flags and demonstrating with a curated dataset.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
100468,98,FALSE,A verifier LLM always detects hallucinations from a creative generator model.,LYNX-style fact check using reviewer_llm and chatbot_llm,Contradicts passage: reviewer_llm simulates checking but example shows generator can still produce confident hallucinations.,"security,red-team,guardrails",8,Breaking-Securing AI
100469,98,FALSE,A single LLM can both generate answers and reliably fact-check its own hallucinations.,LYNX-style verification using reviewer_llm and chatbot_llm,Contradicts passage: example shows separate models used and fact-checking can still miss hallucinations.,"security,red-team,guardrails",8,Breaking-Securing AI
100470,98,FALSE,The reviewer LLM always corrects hallucinations generated by the chatbot LLM.,LYNX-style verification chain using reviewer_llm,Contradicts described example: reviewer simulated fact-checker may still allow confident but imprecise chatbot hallucinations.,"security,red-team,guardrails",8,Breaking-Securing AI
100471,73,half-true,Larger batch sizes always yield proportionally higher throughput for all models in production.,"batch size throughput chart, model efficiency",Chart shows rising throughput up to batch 32 but omits model variation and diminishing returns.,"mlops,scaling,deployment",10,AI At Scale
100472,73,TRUE,Increasing batch size substantially raises model throughput for inference.,batch size and throughput measurement (inference performance),"Chart shows throughput rising from ~20 sps at batch size 1 to over 99 sps at batch size 32, directly supporting claim.","mlops,scaling,deployment",10,AI At Scale
100473,73,barely-true,Batching always makes models significantly more efficient at all batch sizes in production.,"inference throughput and batching (batch size, samples/sec)",Overreaches beyond passage: chart shows efficiency gains up to batch 32 but not proven 'always' or across production constraints.,"mlops,scaling,deployment",10,AI At Scale
100474,33,TRUE,Pandas DataFrames simplify calculating dataset missing-value percentages with NumPy-backed functions.,data-prep using Pandas DataFrames and NumPy,Directly supported: passage explains Pandas and NumPy functions compute missing-field percentages efficiently.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
100475,33,TRUE,Pandas DataFrames efficiently quantify and clean missing data using NumPy-backed operations.,data cleaning with Pandas DataFrame and NumPy functions,"Directly supported: passage describes replacing placeholders, dropping columns, and computing missing-field percentages using Pandas and NumPy.","data-prep,feature-engineering,rag",3,Prepping Data for AI
100476,33,mostly-true,Pandas DataFrames efficiently quantify missing data and clean large datasets with concise code.,data cleaning with Pandas DataFrame and NumPy-backed functions,"Passage describes using Pandas to replace placeholders, drop columns, and calculate missing-field percentages, omitting edge cases or alternatives.","data-prep,feature-engineering,rag",3,Prepping Data for AI
100477,137,mostly-true,An encoder–decoder model encodes input meaning and the decoder generates output sequentially.,encoder-decoder architecture for summarization and sequence generation,Matches passage description: encoder creates internal representation and decoder produces response word-by-word; no major caveat.,"generative-ai,diffusion,gans",7,Generative AI
100478,137,mostly-true,Encoder–decoder models typically encode input meaning then decode it into output tokens sequentially.,"encoder–decoder architecture, encoder, decoder, summarization","Describes core mechanism supported by passage; omits caveats about attention, bidirectional encoders, or parallel decoding methods.","generative-ai,diffusion,gans",7,Generative AI
100479,137,mostly-true,Encoder-decoder models broadly capture meaning in an encoder and generate outputs token-by-token with a decoder.,encoder-decoder architecture for summarization and sequence generation,"Accurately reflects encoder producing representations and decoder generating word-by-word, omitting model variants and subtleties.","generative-ai,diffusion,gans",7,Generative AI
100480,23,barely-true,Open-source video models already match the image quality of top commercial video systems.,open-source text-to-video diffusion models like AnimateDiff and VideoCrafter2,Overstates capabilities; passage says open-source quality and resolution still trail leading commercial models.,"generative-ai,diffusion,gans",7,Generative AI
100481,23,pants-fire,Open-source video models already surpass commercial models in output quality and resolution.,open-source text-to-video diffusion models like AnimateDiff and ModelScope T2V,"Contradicts passage: open-source outputs explicitly described as trailing Runway Gen-2, Sora, and Pika in quality and resolution.","generative-ai,diffusion,gans",7,Generative AI
100482,23,mostly-true,Open-source video diffusion models broadly approach commercial quality but lag slightly in resolution.,"open-source text-to-video diffusion models (AnimateDiff, ModelScope T2V, VideoCrafter2)","Community models are accessible and modular yet still yield lower output quality and resolution than Runway Gen-2, Sora, and Pika.","generative-ai,diffusion,gans",7,Generative AI
100483,17,barely-true,Agentic AI always makes strategic decisions when given structured data and clear prompts.,agentic-ai using structured datasets and clear prompts,"Overstates reliability: passage says it thrives and can be strategic, not that it always makes strategic decisions.","agentic-ai,planning,tools",12,Agentic AI
100484,17,TRUE,"Agentic AI performs best with structured datasets, clear prompts, and decision-capable models.",structured dataset and prompt-guided agentic models,"Passage directly states structured data, clear prompts, and capable models enable strategic agentic decision-making.","agentic-ai,planning,tools",12,Agentic AI
100485,17,barely-true,Agentic AI always makes strategic decisions when given any structured dataset and clear prompts.,agent-based AI using structured datasets and prompts,Overstates reliability: passage says it thrives and can be strategic but not that it always succeeds given any dataset or prompt.,"agentic-ai,planning,tools",12,Agentic AI
100486,0,FALSE,Diffusion models were fully explained and implemented in the passage.,generative-ai diffusion models,"Passage contains only a dialog about meta-awareness and does not explain or implement diffusion models, contradicting the claim.","generative-ai,diffusion,gans",7,Generative AI
100487,114,barely-true,The Judge task must see both answers and declare a winner in the competition flow.,Task definition for Judge using {substitution variables},Passage only suggests Judge sees answers and declares winner; overstates mandatory requirement and specifics.,"agentic-ai,planning,tools",12,Agentic AI
100488,114,mostly-true,The Judge task receives both contestants' answers and declares a winner in the evaluation setup.,task design for Judge role using substitution variables,Passage specifies Judge sees both answers and declares winner; omits details on tie-breaking or scoring.,"agentic-ai,planning,tools",12,Agentic AI
100489,114,TRUE,The Judge role receives both contestants' answers to declare a winner.,Task assigned to the Judge; substitution variables,Passage explicitly states the Judge should see both answers and declare a winner; Judge task emphasized.,"agentic-ai,planning,tools",12,Agentic AI
100490,139,FALSE,Confusion matrices always require equal class counts to be valid for model evaluation.,confusion_matrix from sklearn.metrics comparing true vs predicted publishers,Contradicts passage guidance: confusion matrices show misclassifications regardless of class counts; class imbalance noted as a separate issue to address.,"machine-learning,classification,evaluation",4,Classical Machine Learning
100491,139,mostly-true,Confusion matrices help identify misclassification patterns to guide dataset and threshold fixes.,confusion_matrix and ConfusionMatrixDisplay from sklearn.metrics,"Supports that confusion matrices reveal misclassifications and suggest remedies like more data, class weights, thresholds.","machine-learning,classification,evaluation",4,Classical Machine Learning
100492,139,half-true,Confusion matrices reveal specific misclassified publisher pairs but overstate fixes like class-weight tuning alone.,confusion_matrix and ConfusionMatrixDisplay for publisher classification,Correct that matrices show misclassified publisher pairs; overstated because fixes often require more than class-weight tuning or thresholding alone.,"machine-learning,classification,evaluation",4,Classical Machine Learning
100493,103,mostly-true,HumanLayer enables inserting human review points into AI workflows to manage uncertain outcomes.,HumanLayer SDK integration with LangChain or orchestration layers,Passage describes HumanLayer as an open-source SDK that adds decision points and human approval for uncertain outcomes.,"security,red-team,guardrails",8,Breaking-Securing AI
100494,103,TRUE,HumanLayer enables human-in-the-loop oversight by pausing or escalating uncertain AI outputs.,HumanLayer SDK integration with LangChain or orchestration layers,"Passage explicitly states HumanLayer pauses execution, escalates uncertainty, and sends tasks to humans for approval.","security,red-team,guardrails",8,Breaking-Securing AI
100495,103,TRUE,HumanLayer provides modular human-in-the-loop controls to pause and escalate uncertain AI outputs.,HumanLayer SDK integration with LangChain orchestration,"Text explicitly describes HumanLayer as an open-source SDK that adds decision points to pause, escalate, or send tasks to humans.","security,red-team,guardrails",8,Breaking-Securing AI
100496,83,barely-true,Using averages to impute missing height and weight preserves natural variation in datasets.,feature engineering for Height and Weight imputation,"Contradicts passage noting averages can smooth out and reduce natural variation, so claim is largely unsupported.","data-prep,feature-engineering,rag",3,Prepping Data for AI
100497,83,half-true,The dataset's gender field oversimplifies identity while height and weight are moderately imbalanced.,"dataset bias analysis: gender, height, weight features",Mixes correct dataset imbalance claims with an overstated linkage to imputation smoothing and implied cause-effect.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
100498,83,half-true,The dataset's gender and species labels are simplified and often misrepresent non-human diversity.,"dataset imbalance, species and gender labels, missing-value imputation",Mixes correct observation about simplified gender and species bias with unspecified quantification and imputation effects.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
100499,52,half-true,The provided chain reliably extracts single-word superhero species from text using regex.,prompt → ChatHuggingFace LLM chain with StrOutputParser and regex,"Correctly describes chain and regex use, but overstating reliability and single-word constraint.","data-prep,feature-engineering,rag",3,Prepping Data for AI
100500,52,half-true,The chain reliably extracts one-word superhero species using a regex on LLM output.,"code snippet using ChatHuggingFace, ChatPromptTemplate, StrOutputParser, regex",Method mixes correct regex extraction with risky assumptions about LLM consistency and single-word outputs.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
100501,52,half-true,The code reliably extracts a single-word superhero species from dataset entries using regex.,prompted LLM chain with Hugging Face endpoint and regex extraction,"Correct about regex extraction and LLM prompt, but overstates reliability and ignores parsing and model errors.","data-prep,feature-engineering,rag",3,Prepping Data for AI
100502,65,barely-true,LYNX reliably prevents all AI hallucinations when deployed in production systems.,hallucination evaluation model LYNX for reasoning and detection,"Overstates capability; passage says LYNX detects hallucination moments, not guarantees complete prevention.","security,red-team,guardrails",8,Breaking-Securing AI
100503,65,mostly-true,LYNX is an effective open-source tool for detecting when models begin to hallucinate.,hallucination evaluation model LYNX for model reasoning,"Passage describes LYNX as trained for real-world reasoning and designed to detect hallucinations, supporting effectiveness though implementation details are omitted.","security,red-team,guardrails",8,Breaking-Securing AI
100504,65,mostly-true,LYNX is an open-source model designed to detect when other models start hallucinating.,hallucination evaluation model LYNX,"Passage states LYNX is open-source, trained for reasoning, and designed to detect hallucinations, omitting evaluation limits.","security,red-team,guardrails",8,Breaking-Securing AI
100505,147,barely-true,Agentic systems typically operate fully autonomously without human collaboration in most real-world deployments.,agentic AI and prompt engineering for multi-step tools,Contradicts passage emphasis on collaborative agents; overstates prevalence of fully autonomous deployments.,"agentic-ai,planning,tools",12,Agentic AI
100506,147,FALSE,Agentic AI systems generally operate fully autonomously without human collaboration.,agentic-ai and prompt engineering in interactive agents,Contradicts passage that emphasizes agents usually collaborate with humans and require prompt iteration.,"agentic-ai,planning,tools",12,Agentic AI
100507,147,TRUE,Most practically useful autonomous agents collaborate with humans rather than operate independently.,"agentic AI, autonomous agents, prompt engineering",Passage states fully autonomous agents are rare and most useful ones collaborate with humans.,"agentic-ai,planning,tools",12,Agentic AI
100508,45,half-true,Cosine similarity always detects identical user preferences with perfect accuracy.,cosine similarity in recommender systems,"Mixes correct claim about detecting similar profiles with incorrect implication of perfect, universal accuracy.","ai,tool-chain,notebooks",2,AI Survival Kit
100509,45,barely-true,Cosine similarity always perfectly identifies user preferences in recommender systems.,"use in recommender systems, cosine similarity metric",Overreaches by claiming perfect identification; passage says cosine similarity finds similar items but not perfection.,"ai,tool-chain,notebooks",2,AI Survival Kit
100510,45,TRUE,Cosine similarity values near 1 indicate nearly identical profiles.,cosine similarity in recommender systems,Passage defines near 1 as almost identical and cites use in search and recommender systems.,"ai,tool-chain,notebooks",2,AI Survival Kit
100511,57,half-true,Chatbots sometimes fabricate plausible-seeming citations and dates when asked for sources.,model hallucination when retrieving citations or URLs,"Accurately notes fabrication tendency but omits that frequency, triggers, and specific conditions vary widely.","security,red-team,guardrails",8,Breaking-Securing AI
100512,57,TRUE,"Chatbots can fabricate citations, dates, and URLs when asked for sources.",model outputs and hallucination of citations,"Passage explicitly states models invent dates, citations, and URLs, producing believable but false sources.","security,red-team,guardrails",8,Breaking-Securing AI
100513,57,half-true,"Chatbots frequently fabricate dates, citations, and URLs when no verification is available.",model hallucination of citations and URLs,Accurately notes fabrication behavior but overstates frequency and certainty without empirical rate.,"security,red-team,guardrails",8,Breaking-Securing AI
100514,6,half-true,Classical ML models are always more interpretable than deep learning models.,model interpretability in classical machine learning,"Passage praises interpretability but overgeneralizes; interpretability varies by model and task, so claim mixes correct intuition with incorrect absolutism.","machine-learning,classification,evaluation",4,Classical Machine Learning
100515,6,half-true,Classical machine learning models never require heavy computing compared to deep learning models.,model efficiency and computational cost for classical ML,Overstates requirement: classical methods are generally efficient but some models or large datasets still need substantial compute.,"machine-learning,classification,evaluation",4,Classical Machine Learning
100516,6,TRUE,"Classical machine learning methods remain useful for classification, forecasting, and grouping tasks.","classical machine learning methods and tasks (classification, forecasting, grouping)","Passage explicitly states these techniques support forecasting, grouping, and classification and remain useful due to simplicity and efficiency.","machine-learning,classification,evaluation",4,Classical Machine Learning
100517,79,mostly-true,Autoencoders compress high-dimensional data into lower-dimensional codes and can reconstruct the input with reasonable fidelity.,autoencoder encoder-decoder bottleneck representation,"Passage describes encoder, bottleneck compression, and decoding to rebuild inputs, omitting limits like loss or imperfect reconstruction.","neural-networks,cnn,transformers",6,Neuron Building Blocks
100518,79,TRUE,Autoencoders compress high-dimensional data into a lower-dimensional bottleneck and reconstruct the input.,"autoencoders, encoder–decoder bottleneck representation","Directly supported by passage describing encoder, bottleneck compression, and decoder reconstruction of inputs.","neural-networks,cnn,transformers",6,Neuron Building Blocks
100519,79,half-true,Autoencoders compress high-dimensional input into a bottleneck and reconstruct approximations of the original.,"autoencoders, encoder-decoder bottleneck representation","Accurately describes encoder, bottleneck, and reconstruction but omits limits on perfect fidelity and compression trade-offs.","neural-networks,cnn,transformers",6,Neuron Building Blocks
100520,91,TRUE,Scaling input values to small numeric ranges helps mitigate exploding and vanishing gradients during training.,input scaling for deep learning tensors,"Directly supported by passage stating scaling inputs to ranges like [0.0,1.0] keeps gradients manageable during backpropagation.","deep-learning,frameworks,tensors",5,Deep Learning
100521,91,half-true,"Scaling input pixel values to [0,1] prevents both exploding and vanishing gradients during training.",input normalization for tensors and image preprocessing,Partly true: scaling helps mitigate gradient issues but does not guarantee prevention; other factors like activations and initialization matter.,"deep-learning,frameworks,tensors",5,Deep Learning
100522,91,FALSE,"Scaling inputs to larger numerical ranges like [0, 255] prevents exploding and vanishing gradients during backpropagation.",input scaling for tensors or images,"Contradicts passage: larger ranges worsen gradients; passage advocates smaller ranges like [0.0,1.0] to mitigate instability.","deep-learning,frameworks,tensors",5,Deep Learning
100523,55,half-true,Using Tanh in the generator and LeakyReLU in the discriminator guarantees stable GAN training and convergence.,activation functions in GAN Generator and Discriminator,Mixes correct best-practice recommendations with an unwarranted guarantee of stability and convergence.,"generative-ai,diffusion,gans",7,Generative AI
100524,55,half-true,Using Tanh in generators and LeakyReLU in discriminators stabilizes and improves GAN training convergence.,activation functions in GAN generator and discriminator,Mixes correct best-practice guidance with overstated certainty about universal stabilization and convergence benefits.,"generative-ai,diffusion,gans",7,Generative AI
100525,55,TRUE,Using Tanh in the Generator helps match generator outputs to normalized data ranges.,activation choices for GAN Generator and Discriminator,"Passage states Tanh ensures outputs match normalized range (typically −1 to 1), aiding alignment.","generative-ai,diffusion,gans",7,Generative AI
100526,40,half-true,The model achieved perfect accuracy on a small four-clip test identifying Jerry's real voice.,small demonstration workflow using audio features for voice-cloning detection,"Correctly notes reported perfect results, but overgeneralizes performance beyond tiny four-clip evaluation and sensitive data dependence.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
100527,40,FALSE,The model failed to identify any real Jerry audio clips correctly.,test clips classification using chosen features,Contradicts passage evidence showing perfect accuracy: real Jerry labeled correctly in all four clips.,"media-forensics,voice-cloning,deepfake",9,Deepfake Defense
100528,40,barely-true,The model reliably detects any voice clone as Not Real Jerry across diverse datasets.,"voice-cloning detection workflow, test clips and features",Claims overreach beyond small demonstration; evaluation was perfect only on four clips and sensitivity to data was noted.,"media-forensics,voice-cloning,deepfake",9,Deepfake Defense
100529,137,half-true,"The Liar, Liar dataset combines labeled short statements with speaker metadata for fake-news research.","dataset: Liar, Liar short statements with speaker metadata","Dataset indeed pairs short claims with speaker attributes, but description omits specific label schema and size details.","mlops,scaling,deployment",10,AI At Scale
100530,137,FALSE,The dataset contains multimodal articles with images and audio for fake news detection tasks.,"Liar, Liar Pants on Fire dataset for fake news detection",Dataset is text-based short statements from 2017 paper; no images or audio modalities included.,"mlops,scaling,deployment",10,AI At Scale
100531,137,barely-true,The dataset claims to reliably detect fake news using simple linguistic features.,"Liar, Liar Pants on Fire dataset for fake news detection",Dataset actually contains short political statements and labels; simple linguistic features alone are insufficient and overclaimed.,"mlops,scaling,deployment",10,AI At Scale
100532,30,half-true,Community-contributed examples in training data can be deliberately seeded to manipulate model behavior.,"community-contributed examples, forums, GitHub gists",Accurately notes deliberate seeding claim but overstates certainty about prevalence and impact on final model.,"security,red-team,guardrails",8,Breaking-Securing AI
100533,30,TRUE,Community-contributed examples can be seeded to influence model behavior.,"community-contributed examples, forums and GitHub gists",Passage explicitly states models learn from community examples and that attackers can seed those sources.,"security,red-team,guardrails",8,Breaking-Securing AI
100534,30,mostly-true,Community-contributed examples are easily seeded to influence model behavior.,"community-contributed examples, forums and GitHub gists","Passage says much model learning comes from community examples and admits they can be seeded, a minor nuance about scale omitted.","security,red-team,guardrails",8,Breaking-Securing AI
100535,53,TRUE,APIs for different AI models often require different request formats and response structures.,"model APIs, request format and response structure","Passage explicitly lists differing request formats and response structures across model APIs, requiring adaptation.","agentic-ai,planning,tools",12,Agentic AI
100536,53,pants-fire,Agentic AI models always require complete application rewrites when switching between APIs.,API differences in request format and response structure,Contradicts text stating model abstraction prevents rewrites; overstates inevitability of complete rewrites.,"agentic-ai,planning,tools",12,Agentic AI
100537,53,pants-fire,All agentic AI APIs use identical JSON request formats and authentication methods.,API differences in request format and authentication,Contradicts passage detail: it states APIs vary in request format and authentication methods.,"agentic-ai,planning,tools",12,Agentic AI
100538,60,TRUE,Machine learning systems improve their performance as they receive more data to learn from.,data-driven learning and Scikit-learn tools,Passage explicitly states ML systems improve with more data and cites Scikit-learn enabling practical use.,"ai,tool-chain,notebooks",2,AI Survival Kit
100539,60,pants-fire,AI models always become infallible with more data and never make mistakes.,machine learning data scaling and algorithms (Scikit-learn),Contradicts passage: more data improves models but does not make them infallible; assumption is implausible.,"ai,tool-chain,notebooks",2,AI Survival Kit
100540,60,TRUE,Machine learning models improve with more data and automated learning algorithms.,open-source tools like Scikit-learn and growing digital data,Directly supported: passage states ML improves with more data and uses algorithms that learn automatically.,"ai,tool-chain,notebooks",2,AI Survival Kit
100541,147,half-true,The model uses PCA-derived latent components alongside individual power features during classification.,"PCA components (PC13, PC34, PC7, PC35) in feature importance",Mixes correct observation of PCA component usage with unclear extent and impact on classification performance.,"machine-learning,classification,evaluation",4,Classical Machine Learning
100542,147,barely-true,The model primarily relies on single power features rather than combined PCA components.,PCA components and powers used by the model,"Passage indicates multiple PCA components appear in top features, so claiming primary reliance on single features overstates facts.","machine-learning,classification,evaluation",4,Classical Machine Learning
100543,147,pants-fire,The model secretly uses telepathic signals beyond PCA and behavioral cues.,latent PCA components and Alignment_bad signal,Asserts implausible telepathy contradicting stated latent component and directional signal mechanisms.,"machine-learning,classification,evaluation",4,Classical Machine Learning
100544,43,barely-true,Delangue overstated open-source AI community unity and impact to advance his platform.,"open-source AI community, LinkedIn post by Clément Delangue","Claim mostly unsupported by cited excerpts; references show matched quotes and summary, not broad unity or impact.","open-source,community,ai",0,Foreword – Robo Interviews Clément Delangue
100545,43,half-true,Delangue praises open-source AI while overstating its immediate community benefits and readiness.,LinkedIn post about open-source AI and community,Mixes accurate support for open-source with exaggerated claims about near-term community readiness and benefits.,"open-source,community,ai",0,Foreword – Robo Interviews Clément Delangue
100546,43,pants-fire,He claims open-source AI destroys all community collaboration and eliminates every contributor forever.,open-source AI and community statement on LinkedIn,Direct contradiction: passage promotes open-source AI cooperation; claim falsely asserts total eradication of contributors.,"open-source,community,ai",0,Foreword – Robo Interviews Clément Delangue
100547,103,half-true,Publicly hosting models simplifies remote testing but can expose sensitive context and provenance gaps.,"public inference, model repository, transparency",Correctly notes ease of remote testing but mixes in unmentioned risks about provenance and sensitive context.,"mlops,scaling,deployment",10,AI At Scale
100548,103,FALSE,Public inference makes model decision-making fully accountable to all users.,public inference for sharing models,"Contradicts passage: public testing enables access but passage says transparency helps accountability, not full accountability.","mlops,scaling,deployment",10,AI At Scale
100549,103,FALSE,Public inference always guarantees accountable model decisions in production deployments.,public inference for sharing models,"Contradicts passage: transparency helps accountability, but public inference alone does not guarantee accountability or grounded decisions.","mlops,scaling,deployment",10,AI At Scale
100550,28,mostly-true,Forward propagation produces a prediction whose loss measures how far the network's output is from the correct answer.,forward propagation / loss in deep learning,Directly reflects passage: forward pass yields a prediction and loss quantifies deviation from correct answer.,"deep-learning,frameworks,tensors",5,Deep Learning
100551,28,barely-true,Forward propagation computes loss directly without needing backpropagation or weight updates.,forward propagation / loss computation in neural networks,"Overreaches: forward pass produces outputs and loss but does not perform weight updates, which require backpropagation.","deep-learning,frameworks,tensors",5,Deep Learning
100552,28,barely-true,Forward propagation always guarantees lower loss after a single forward pass through the network.,"forward propagation, loss, prediction","Contradicts training dynamics: forward pass just computes prediction and loss, not weight updates to reduce loss.","deep-learning,frameworks,tensors",5,Deep Learning
100553,122,half-true,Neural Duel's agents' internal reasoning traces were captured during a live trivia round.,Neural Duel live game execution with Crew verbose=True,"Passage shows verbose=True produced detailed agent reasoning, but extent of trace completeness is uncertain.","agentic-ai,planning,tools",12,Agentic AI
100554,122,barely-true,"Neural Duel's live run produced detailed, verbatim agent reasoning transcripts for all agents.",live game execution with verbose=True in Crew definitions,"Passage notes verbose=True captured more detailed breakdowns, but not full verbatim transcripts.","agentic-ai,planning,tools",12,Agentic AI
100555,122,mostly-true,Neural Duel demonstrated agents' step-by-step reasoning during a live trivia round when verbose logging was enabled.,live game execution with verbose=True in Crew agent definitions,"Execution output shows detailed agent reasoning for a real trivia round, omitting evaluation metrics.","agentic-ai,planning,tools",12,Agentic AI
100556,62,TRUE,Authors improved prompt effectiveness using iterative refinement with Steam gameplay data.,prompt design for AI agents using Steam gameplay data,Passage describes iterating prompts around Steam gameplay data and landing on an effective version.,"agentic-ai,planning,tools",12,Agentic AI
100557,62,half-true,The authors used iterative prompts on Steam gameplay data to refine an AI agent's behavior.,prompt engineering with Steam gameplay dataset,Mixes correct iterative prompt refinement with overstated claim that agents' behavior was fully refined.,"agentic-ai,planning,tools",12,Agentic AI
100558,170,mostly-true,CLIP enables broadly transferable visual representations through natural language supervision.,learning transferable visual models from natural language supervision (CLIP),"Paper demonstrates CLIP's wide transferability across datasets and tasks, omitting some task-specific fine-tuning caveats.","generative-ai,diffusion,gans",7,Generative AI
100559,170,TRUE,Contrastive language–image pretraining enables transferable visual representations for downstream tasks.,CLIP model and contrastive image–text pretraining,Paper demonstrates CLIP learns transferable visual features via contrastive image–text supervision for many downstream tasks.,"generative-ai,diffusion,gans",7,Generative AI
100560,170,TRUE,Contrastive pretraining on image–text pairs produces transferable visual representations.,CLIP image–text contrastive pretraining on web dataset,Paper demonstrates CLIP uses contrastive learning on image-text pairs to yield representations transferable to many vision tasks.,"generative-ai,diffusion,gans",7,Generative AI
100561,44,mostly-true,Librosa-based pitch and tempo augmentation broadly improves deepfake audio detection training data.,data augmentation with Librosa for speaker identification and deepfake detection,"Augmentation using Librosa features is affirmed as expanding example variety, though specific performance gains omitted.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
100562,44,barely-true,Librosa-based pitch and tempo shifts reliably identify deepfake voice forgeries across varied datasets.,feature extraction using Librosa for deepfake detection,"Overstates reliability and generalization; passage only claims Librosa aids feature extraction and augmentation, not guaranteed cross-dataset detection.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
100563,44,half-true,Librosa-based pitch and tempo shifts reliably create diverse training examples for deepfake detection models.,data augmentation with Librosa for speaker identification and deepfake detection,"Accurate that Librosa can augment data, but 'reliably' overstates effectiveness and model impact.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
100564,33,half-true,AI deepfakes using GAN-based techniques facilitated a £20 million bank fraud in 2024.,AI-generated voice and video deepfake incident involving GANs,Mixes correct incident and GAN involvement with uncertain claim about specific GAN usage.,"generative-ai,diffusion,gans",7,Generative AI
100565,33,FALSE,Generative AI was not involved in the Hong Kong bank £20 million fraud case.,deepfake video and GANs in fraud report,Contradicts passage statement that fraudsters used AI-generated deepfake voice and video likely powered by GANs.,"generative-ai,diffusion,gans",7,Generative AI
100566,33,mostly-true,Generative AI deepfakes likely enabled a 2024 £20 million fraud by impersonating executives in a video call.,AI-generated voice and video deepfake using GANs,Supports incident description; minor uncertainty remains about exact models and full attribution to GANs.,"generative-ai,diffusion,gans",7,Generative AI
100567,34,mostly-true,Using train/test splits with test_size=0.2 and random_state=42 helps evaluate generalization reliably.,"train/test split, test_size=0.2, random_state=42",Accurately reflects guidance: 20% test set checks overfitting and fixed seed ensures repeatable splits.,"machine-learning,classification,evaluation",4,Classical Machine Learning
100568,34,mostly-true,Holding out 20% of data as a test set helps evaluate model generalization and detect overfitting.,"train/test split, test_size=0.2, random_state parameter","Matches passage guidance that reserving 20% tests generalization and reveals overfitting, minor nuance about exact split choice omitted.","machine-learning,classification,evaluation",4,Classical Machine Learning
100569,34,pants-fire,Setting random_state=42 guarantees model generalization to unseen heroes across all splits.,train/test split parameter random_state=42,"Contradicts passage: random_state fixes the split reproducibly, it does not guarantee generalization to unseen data.","machine-learning,classification,evaluation",4,Classical Machine Learning
100570,97,barely-true,Average cosine similarity is substantially higher for same-cluster pairs than cross-cluster pairs.,cosine similarity between cluster pairs on similarity matrix S,"Reported means 0.09 within versus -0.11 between, but magnitude is small and effect size unclear.","machine-learning,classification,evaluation",4,Classical Machine Learning
100571,97,TRUE,Within-cluster cosine similarity is higher than between-cluster similarity for the heroes dataset.,cosine similarity S and cluster labels array labs,"Reported means: within mean 0.09 versus between −0.11, showing clusters capture real commonalities.","machine-learning,classification,evaluation",4,Classical Machine Learning
100572,97,half-true,Average within-cluster cosine similarity is higher than between-cluster similarity by about 0.20.,cosine_similarity scores comparing within and between cluster pairs,Matches reported means (0.09 vs −0.11) but implies exact significance and robustness without statistical test.,"machine-learning,classification,evaluation",4,Classical Machine Learning
100573,20,barely-true,A classifier trained on geography will always produce useful customer segments for buying behavior.,supervised learning; classification; customer clustering,"Overstates usefulness: passage warns geographic clusters can be technically valid but not helpful for buying behavior, so claim is largely unsupported.","machine-learning,classification,evaluation",4,Classical Machine Learning
100574,20,FALSE,Supervised learning exclusively uses clustering to assign categories to data points.,supervised learning and classification,"Contradicts passage: supervised learning uses classification and regression, not clustering for category assignment.","machine-learning,classification,evaluation",4,Classical Machine Learning
100575,20,TRUE,Supervised learning splits into regression for continuous targets and classification for categorical labels.,supervised learning techniques; regression and classification,Text explicitly states supervised learning has two branches: regression predicts continuous values and classification assigns categories.,"machine-learning,classification,evaluation",4,Classical Machine Learning
100576,66,mostly-true,LYNX largely prevents hallucinations by detecting when models start fabricating information.,LYNX model and HaluBench hallucination evaluation,"Passage says LYNX is designed to detect hallucination moments and HaluBench evaluates mitigation, minor effectiveness caveat omitted.","security,red-team,guardrails",8,Breaking-Securing AI
100577,66,TRUE,LYNX is designed to detect when a model begins hallucinating.,HaluBench hallucination benchmark for grounded evaluation,Describes design claim directly supported by passage stating LYNX detects model hallucinations during reasoning.,"security,red-team,guardrails",8,Breaking-Securing AI
100578,66,TRUE,LYNX detects when a model begins producing hallucinated information.,HaluBench hallucination evaluation benchmark,"Passage states LYNX is designed to detect when a model starts making things up, supported by HaluBench.","security,red-team,guardrails",8,Breaking-Securing AI
100579,14,half-true,Contributing non-code work is as valuable as code contributions for open-source projects.,"community contribution, documentation, tutorials, UI improvements",Passage lists non-code work alongside code work but implies value without quantifying equality.,"open-source,community,contribution",13,Commit to Contribute
100580,14,barely-true,Anyone can start contributing without expert-level knowledge in open-source AI projects.,community contributions and non-code work in open-source,"Passage explicitly encourages non-experts to contribute, but overstates ease and scope of barriers.","open-source,community,contribution",13,Commit to Contribute
100581,14,TRUE,Contributing to open-source projects helps people improve skills regardless of expertise level.,open-source contribution suggestions and roles,Lists varied contribution types and emphasizes ‘‘You don’t have to be an expert. The best way to get good is to contribute.’’.,"open-source,community,contribution",13,Commit to Contribute
100582,86,barely-true,Foundation models typically perform excellently on diverse tasks without any fine-tuning.,"foundation models, fine-tune, pre-trained model","Overstates performance: passage says they 'often' work well out of the box, not 'typically excel' on diverse tasks without tuning.","ai,tool-chain,notebooks",2,AI Survival Kit
100583,86,half-true,Foundation models always perform well out of the box without any fine-tuning for domain tasks.,"foundation models, fine-tune, GenAI",Passage says models often work without fine-tuning but also supports fine-tuning; absolute claim mixes correct and incorrect specifics.,"ai,tool-chain,notebooks",2,AI Survival Kit
100584,86,mostly-true,Foundation models generalize across tasks and often perform well without fine-tuning.,"foundation models, pre-trained on large text and image datasets","Passage states models learn general patterns and frequently work well out of the box, minor caveat about fine-tuning benefits omitted.","ai,tool-chain,notebooks",2,AI Survival Kit
100585,160,mostly-true,Reinforcement learning focuses on learning how to act rather than uncovering data structure or predictions.,"reinforcement learning, structure-driven learning, supervised/unsupervised split","Passage emphasizes RL's action-focused learning versus structure/prediction, omitting some RL predictive aspects.","machine-learning,classification,evaluation",4,Classical Machine Learning
100586,160,FALSE,Reinforcement learning is primarily about uncovering structure and making predictions.,"reinforcement learning, structure-driven learning, supervised/unsupervised split","Contradicts passage: RL is described as learning how to act, not focused on uncovering structure or predictions.","machine-learning,classification,evaluation",4,Classical Machine Learning
100587,160,half-true,Reinforcement learning focuses on learning actions rather than predicting structures.,reinforcement learning concept in machine-learning,Mixes correct focus on actions with incorrect exclusion of prediction roles and overlap with deep networks.,"machine-learning,classification,evaluation",4,Classical Machine Learning
100588,86,mostly-true,"Agent tasks framed as prompt-shaped assignments yield more consistent, reliable agent behavior.",task definition for agents; prompt-shaped task description,"Passage says prompts structure tasks and improve consistency and reliability, omitting potential edge-case limits.","agentic-ai,planning,tools",12,Agentic AI
100589,86,FALSE,Tasks are optional suggestions that agents can ignore without affecting outcomes.,task attributes and agent prompts,Passage states tasks give clear direction and shape agent behavior; claiming optional ignores that requirement.,"agentic-ai,planning,tools",12,Agentic AI
100590,86,barely-true,"Agent tasks reliably guarantee correct execution of complex, open-ended goals without further oversight.",task attributes and prompts for agent definitions,Overstates guarantees: passage says tasks provide direction and consistency but not assured correct execution or removal of oversight.,"agentic-ai,planning,tools",12,Agentic AI
100591,154,mostly-true,Designing workflows can embed privacy and security from the start in data preparation for AI.,data sensitivity and workflow design for datasets,Supports that privacy/security are integrated into workflows; omits specifics on techniques or tools for implementation.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
100592,154,half-true,"Designing workflows can embed privacy and security, preventing all identification risks from datasets.",data sensitivity and dataset preparation for RAG,Mixes correct idea of embedding privacy with incorrect absolute claim that all identification risks are prevented.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
100593,154,barely-true,All personally identifying data always must be removed before preparing datasets for AI models.,data sensitivity in dataset preparation,Overreaches passage: it defines sensitive data but doesn't require absolute removal in every workflow.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
100594,0,mostly-true,"Convolutional neural networks excel at detecting edges, corners, and shapes in images.",CNNs as pattern detectors in vision,"Passage explicitly describes CNNs spotting edges, corners, and shapes; minor nuance about other vision tasks omitted.","neural-networks,cnn,transformers",6,Neuron Building Blocks
100595,0,mostly-true,Transformers broadly outperform RNNs on language tasks by capturing long-range context more effectively.,transformers and RNNs in neural-networks and transformers,"Passage highlights transformers as context-aware and revolutionary, omitting specific benchmarks and task nuances.","neural-networks,cnn,transformers",6,Neuron Building Blocks
100596,0,barely-true,CNNs alone can fully understand sentence context in language tasks.,Transformers and CNNs in neural network architectures,"Overreaches beyond passage: transformers, not CNNs, are described as revolutionizing language context.","neural-networks,cnn,transformers",6,Neuron Building Blocks
100597,136,mostly-true,Requiring scoped IAM credentials and documenting third-party models in an AI BOM improves defense transparency.,scoped IAM credentials and AI BOM for third-party models,Supports mandating limited IAM credentials and AI BOM entries; minor omission about enforcement specifics.,"security,red-team,guardrails",8,Breaking-Securing AI
100598,136,TRUE,Scoped IAM credentials should be required and verified before allowing model-executed commands.,"IAM credentials, AI BOM, third-party model documentation",Passage explicitly mandates requiring scoped IAM credentials and blocking commands lacking proof.,"security,red-team,guardrails",8,Breaking-Securing AI
100599,136,pants-fire,The passage claims enforcing scoped IAM credentials alone can make models fully secure from all attacks.,IAM credentials and AI Bill of Materials for third-party models,"Overstates security: contradicts passage which recommends IAM plus documentation, not sole complete protection.","security,red-team,guardrails",8,Breaking-Securing AI
100600,43,FALSE,"The model's predictions and actual future data are displayed on separate, non-overlapping timelines.",timeline visualization of training data and model predictions,"Visualization text says training, predictions, and actual future data are plotted together on the same timeline, not separately.","neural-networks,cnn,transformers",6,Neuron Building Blocks
100601,43,FALSE,The model's training period is always hidden and never shown alongside predictions.,"timeline visualization showing training, actual future data, and predictions",Contradicts passage detail that training period is explicitly plotted together with predictions and actuals.,"neural-networks,cnn,transformers",6,Neuron Building Blocks
100602,43,barely-true,"The visualization overlays training, prediction, and future real data on a single timeline for model evaluation.","timeline plot of training, predictions, and future data","Accurate that timelines are overlaid, but overstates ease of evaluating model generalization and pattern capture.","neural-networks,cnn,transformers",6,Neuron Building Blocks
100603,122,half-true,Red teams should run adversarial tests only in a sandboxed environment isolated from production.,test harness (sandbox) for red-team security testing,Correctly emphasizes sandbox isolation but overstates absolutism; passage allows scoped non-production testing rather than 'only' sandbox use.,"security,red-team,guardrails",8,Breaking-Securing AI
100604,122,half-true,Red teams should never test against live production environments during adversarial model evaluations.,test harness sandbox for chat interface and automation hook,Passage forbids running tests in production but overgeneralizes by implying absolute prohibition in every scenario.,"security,red-team,guardrails",8,Breaking-Securing AI
100605,122,pants-fire,Red teams should run adversarial tests directly against live production systems to maximize realism.,red-team sandbox and test harness guidance,Contradicts explicit sandbox requirement and warning to never use live production environments for tests.,"security,red-team,guardrails",8,Breaking-Securing AI
100606,118,pants-fire,Model will achieve perfect classification accuracy distinguishing Marvel and DC superheroes.,"dataset with numeric PCA features, text fields, and LabelEncoder",Claim contradicts realistic expectations; dataset preprocessing and baseline accuracy won’t guarantee perfect accuracy.,"machine-learning,classification,evaluation",4,Classical Machine Learning
100607,118,barely-true,A baseline classifier trained on simple numeric and text features will reliably achieve high accuracy distinguishing Marvel versus DC.,"superhero dataset; features: Alignment, Species, Gender, PCA numeric columns",Passage only shows feature selection and baseline setup; no evidence baseline yields reliably high accuracy.,"machine-learning,classification,evaluation",4,Classical Machine Learning
100608,118,barely-true,Baseline accuracy immediately reflects final classifier performance without further tuning.,baseline accuracy from train/test split metric,"Overreaches: baseline is a simple benchmark from 80/20 split, not final tuned performance.","machine-learning,classification,evaluation",4,Classical Machine Learning
100609,121,mostly-true,The simple 12-dimensional model generally predicts next-month passenger counts accurately with MSE training.,sequence prediction on airline passenger dataset using mean squared error,"Model effectiveness is supported for strong temporal patterns, though caveats about dataset variability are omitted.","generative-ai,diffusion,gans",7,Generative AI
100610,121,half-true,The described model always outputs a single next-month passenger count from a 12-dimensional input.,sequence prediction model using mean squared error on airline travel data,"Partially correct: model uses 12-dimensional input and MSE, but 'always' and 'single' omit possible multi-output or design variations.","generative-ai,diffusion,gans",7,Generative AI
100611,121,TRUE,A minimalist sequence model predicts next-month airline passenger counts using a 12-dimensional input vector.,sequence prediction model with mean squared error metric,Passage states model takes a 12-dimensional vector to output next month's passenger count and is trained with MSE.,"generative-ai,diffusion,gans",7,Generative AI
100612,27,mostly-true,"DataFrames greatly simplify cleaning, reshaping, and transforming structured data for AI workflows.",tool: DataFrame operations in notebooks and AI tool-chains,"Passage emphasizes DataFrame strengths—speed, flexibility, filtering, aggregation—omitting minor scalability caveats.","ai,tool-chain,notebooks",2,AI Survival Kit
100613,27,barely-true,DataFrames always replace spreadsheets for all structured data tasks in AI workflows.,"DataFrame tools for reshaping, filtering, aggregation",Overreaches passage: it praises DataFrames' flexibility but doesn't claim they universally replace spreadsheets for every task.,"ai,tool-chain,notebooks",2,AI Survival Kit
100614,27,half-true,DataFrames vastly outperform traditional spreadsheets for all data-cleaning tasks at scale.,DataFrame operations and structured data handling,Mixes true advantages with overgeneralization; passage praises speed/flexibility but not universal superiority.,"ai,tool-chain,notebooks",2,AI Survival Kit
100615,97,FALSE,The passage asserts that differential privacy is universally unnecessary for model governance.,privacy best practices for model governance,"Contradicts passage: passage critiques organization and tone, never claims differential privacy unnecessary.","ethics,governance,privacy",11,AI Ethics and Governance
100616,97,mostly-true,AI governance guidance often lists many projects and best practices but lacks concise organization.,organizational best-practices table for governance projects,"Broadly reflected by critique: numerous projects listed without summarized table or organized categories, minor omission of specific reorganization suggestions.","ethics,governance,privacy",11,AI Ethics and Governance
100617,97,barely-true,The passage claims numerous best-practice projects are essential for AI governance.,organize categories and projects; best practice table,Overstates support: passage lists projects and recommends a summary table but does not call them essential.,"ethics,governance,privacy",11,AI Ethics and Governance
100618,42,FALSE,LangChain and MLflow are listed in the Data Layer alongside Pandas and NumPy.,"tool organization across layered architecture, Data Layer and Agents & Operations","Passage places LangChain and MLflow under Agents & Operations, not the Data Layer, contradicting placement.","open-source,community,contribution",13,Commit to Contribute
100619,42,half-true,The passage lists Pandas and NumPy as examples in the Data Layer alongside LangChain and MLflow.,"tool roles grouping (Data Layer, Agents & Operations, Vector Stores)","Accurately names Pandas/NumPy and LangChain/MLflow, but implies they were exhaustively listed.","open-source,community,contribution",13,Commit to Contribute
100620,42,pants-fire,The passage claims Pandas and NumPy are irrelevant to data preparation in open-source projects.,"Data Layer tools (Pandas, NumPy) in open-source contribution",Directly contradicts passage naming Pandas and NumPy as familiar Data Layer tools used for data preparation.,"open-source,community,contribution",13,Commit to Contribute
100621,109,half-true,An assistant created four agents with distinct roles including a Judge and tool-enabled capabilities.,agent definitions with tools and Judge agent,"Accurately reports four agents and a Judge, but overstates tool-enabled capabilities not fully detailed.","agentic-ai,planning,tools",12,Agentic AI
100622,109,TRUE,The system added four agents with distinct roles including a Judge agent.,agent definitions with tools and role assignments,"Passage explicitly describes four agents (Game Master, Player 1, Player 2, Judge) and updated definitions.","agentic-ai,planning,tools",12,Agentic AI
100623,109,mostly-true,The assistant implemented four specialized agents including a Judge to evaluate outcomes.,"agent definitions with tools, LLM assignments, and a Judge agent",Matches passage describing four agents and added Judge; omits minor implementation detail specifics.,"agentic-ai,planning,tools",12,Agentic AI
100624,40,mostly-true,"DeepSeek-V3 performs competitively among top conversational models on MT-Bench, with minor ranking gaps.",MT-Bench leaderboard for conversational model evaluation,"Leaderboard shows DeepSeek-V3 tied sixth with a strong Arena Score, omitting small rank and score differences.","mlops,scaling,deployment",10,AI At Scale
100625,40,barely-true,DeepSeek-V3 is among the top conversational models but notably lags behind the leading proprietary systems.,MT-Bench leaderboard ranking for conversational models,Leaderboard shows DeepSeek-V3 tied sixth with lower Arena Score than top proprietary models like Gemini-2.5 and GPT-4.5.,"mlops,scaling,deployment",10,AI At Scale
100626,40,pants-fire,DeepSeek-V3 completely outperforms all major commercial models on MT-Bench without exception.,MT-Bench leaderboard comparing models like Gemini-2.5 and GPT-4.5,"Leaderboard shows DeepSeek-V3 tied sixth with lower Arena Score, contradicting claim of complete outperformance.","mlops,scaling,deployment",10,AI At Scale
100627,24,FALSE,The RAG backend never allows access to sensitive VIP client escalation notes.,RAG backend enforcing user context in customer support scenario,Contradicts passage which warns RAG backends can leak VIP escalation notes if not enforcing user context.,"security,red-team,guardrails",8,Breaking-Securing AI
100628,24,TRUE,Human-in-the-loop design prevents unauthorized exposure from RAG backends in sensitive queries.,RAG backend handling VIP client outage escalation notes,Passage explicitly recommends human-in-the-loop to stop RAG backends leaking sensitive escalation notes.,"security,red-team,guardrails",8,Breaking-Securing AI
100629,24,barely-true,"RAG backends often fail to enforce user context, risking exposure of sensitive customer notes.",RAG backend enforcing user context in customer support,Passage warns RAG backend can leak VIP client outage notes; claim overgeneralizes frequency and inevitability.,"security,red-team,guardrails",8,Breaking-Securing AI
100630,63,TRUE,Unsupervised learning discovers hidden patterns and structures without predefined labels.,"unsupervised learning techniques, datasets without labels",Directly supported by passage stating unsupervised methods analyze data without predefined labels to find hidden patterns.,"machine-learning,classification,evaluation",4,Classical Machine Learning
100631,63,mostly-true,Unsupervised learning uncovers hidden patterns in datasets without using predefined labels.,"unsupervised learning techniques, patterns, datasets",Accurately reflects passage description; omits nuance about specific methods or limitations.,"machine-learning,classification,evaluation",4,Classical Machine Learning
100632,63,barely-true,Unsupervised learning always outperforms supervised methods on unlabeled datasets.,"unsupervised learning techniques, unlabeled datasets",Overreaches by claiming superiority; passage only states unsupervised finds patterns without claiming better performance.,"machine-learning,classification,evaluation",4,Classical Machine Learning
100633,41,half-true,A rising generator loss can indicate improving sample realism in GAN training.,GAN generator loss interpretation,"Mixes correct interpretation with incorrect generalization: rising loss may reflect discriminator strength, not always realism.","generative-ai,diffusion,gans",7,Generative AI
100634,41,FALSE,Higher generator loss indicates the generator is performing worse at producing realistic images.,generator loss in GAN training,Contradicts passage which says higher G loss can signal more convincing samples; reverses that relationship.,"generative-ai,diffusion,gans",7,Generative AI
100635,41,TRUE,Rising generator loss can indicate the generator produces more convincing samples.,GAN generator loss interpretation,"Explained by the passage: higher, gradually rising G loss signals more convincing generated images; example given.","generative-ai,diffusion,gans",7,Generative AI
100636,38,barely-true,Classification should be used whenever regression metrics are poor for continuous outcomes.,model selection involving logistic regression and decision trees,"Overreaches: passage suggests classification when linear relation absent, not for continuous targets.","machine-learning,classification,evaluation",4,Classical Machine Learning
100637,38,barely-true,Classification always fixes unreliable predictions when linear models fail.,"classification algorithms (Logistic Regression, Decision Trees)","Overreaches: classification may help but does not guarantee fixes; dataset, feature, or model issues can persist.","machine-learning,classification,evaluation",4,Classical Machine Learning
100638,38,half-true,Classification methods like logistic regression and decision trees help when linear relationships fail.,model selection for metrics and linear relationship assumptions,Mixes correct idea (use classification when linear fit fails) with imprecise claim about logistic regression applicability.,"machine-learning,classification,evaluation",4,Classical Machine Learning
100639,80,half-true,The framework fully automates the training loop while allowing custom loss functions.,training loop and loss functions in deep learning,"Correct that automation and loss tweaking are mentioned, but overstates 'fully automates' and 'framework' specifics not given.","deep-learning,frameworks,tensors",5,Deep Learning
100640,80,FALSE,The framework fully automates loss function design and prevents user modifications.,training loop and loss functions in deep-learning framework,"Contradicts passage: user is invited to tweak the loss function, not prevented from changing it.","deep-learning,frameworks,tensors",5,Deep Learning
100641,80,mostly-true,The framework handles the training loop while users customize the loss function.,training loop and loss function in deep-learning flow,Passage explicitly says training loop is handled and users can tweak loss functions; minor omission of other components.,"deep-learning,frameworks,tensors",5,Deep Learning
100642,5,pants-fire,Python is fundamentally unnecessary for any AI development or tool-chain work.,AI toolkit; Python in survival kit; tool-chain,Directly contradicts passage claim that Python is the first item in the AI survival kit and central to tool-chain.,"ai,tool-chain,notebooks",2,AI Survival Kit
100643,5,TRUE,Python is presented as the primary programming language for an AI toolkit.,guidance on tools and concepts; Python as foundational skill,Directly supported: passage explicitly names Python as the first item in the AI survival kit.,"ai,tool-chain,notebooks",2,AI Survival Kit
100644,5,pants-fire,Python guarantees autonomous AGI development without additional tools or expertise.,"AI toolkit, Python in survival kit",Passage only presents Python as a foundational tool; claim contradicts reality by asserting full AGI development capability.,"ai,tool-chain,notebooks",2,AI Survival Kit
100645,167,pants-fire,Reinforcement learning always outperforms supervised learning on all classification tasks.,"reinforcement learning, Gymnasium, stable-baselines3 usage",Directly contradicts passage emphasis on sequential decisions and trial-and-error; classification uses labeled examples.,"machine-learning,classification,evaluation",4,Classical Machine Learning
100646,167,TRUE,Reinforcement learning suits problems with sequential decisions and feedback.,"reinforcement learning, Gymnasium, stable-baselines3",Passage recommends RL for sequential decision tasks and cites tools like Gymnasium and stable-baselines3.,"machine-learning,classification,evaluation",4,Classical Machine Learning
100647,167,pants-fire,Reinforcement learning never worked for any real-world scheduling or recommendation problem.,"reinforcement learning applications, Gymnasium and stable-baselines3 tools",Passage explicitly cites elevator scheduling and recommendation systems as early successful uses; contradicts those examples.,"machine-learning,classification,evaluation",4,Classical Machine Learning
100648,25,half-true,GAN discriminators always receive only final generated samples to judge authenticity.,discriminator evaluating generated images in GAN training,"Correct that discriminators judge real versus generated samples, but many architectures use intermediate features or auxiliary inputs omitted.","generative-ai,diffusion,gans",7,Generative AI
100649,25,mostly-true,A GAN trains a generator against a discriminator to produce realistic synthetic data through adversarial feedback.,GAN training with generator and discriminator on synthetic images,"Matches passage description of generator producing data and discriminator distinguishing real versus fake, omitting training instability caveats.","generative-ai,diffusion,gans",7,Generative AI
100650,25,half-true,A GAN’s discriminator reliably detects fake outputs versus real training data during training.,discriminator role in GAN training,"Correct that discriminator distinguishes real versus fake, but reliability varies and detection is imperfect.","generative-ai,diffusion,gans",7,Generative AI
100651,124,mostly-true,DeepSafe and Deepstar are research-grade open-source frameworks for detecting manipulated media.,"open-source frameworks (DeepSafe, Deepstar) for manipulated media detection",Passage names DeepSafe and Deepstar as research-grade detection frameworks but notes they need extensive setup and large datasets.,"media-forensics,voice-cloning,deepfake",9,Deepfake Defense
100652,124,FALSE,DeepSafe and Deepstar are lightweight tools suitable for quick hands-on deepfake demos.,open-source frameworks DeepSafe and Deepstar for manipulated media detection,Contradicts passage: both are described as research-grade requiring extensive setup and large datasets.,"media-forensics,voice-cloning,deepfake",9,Deepfake Defense
100653,124,barely-true,"DeepSafe and Deepstar are simple, ready-to-run tools usable by nonexperts for detecting deepfakes.",open-source frameworks DeepSafe and Deepstar mentioned in deepfake defense,"Passage says both are research-grade requiring extensive setup and large datasets, so claim overreaches.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
100654,54,half-true,GAN training often requires extensive compute and meticulous hyperparameter tuning for high-resolution outputs.,"training GANs, Generator and Discriminator design for high-resolution data",Accurately notes compute and tuning needs but overstates universality for all resolutions and models.,"generative-ai,diffusion,gans",7,Generative AI
100655,54,half-true,GAN training often requires extensive compute and careful tuning but reliably produces high-resolution realistic images.,training GANs; Generator and Discriminator design,"Partly true: passage cites heavy compute and tuning, but overstates guaranteed high-resolution realism.","generative-ai,diffusion,gans",7,Generative AI
100656,54,mostly-true,"GAN training is resource-intensive but often yields versatile, realistic synthetic data for many applications.",training GANs for high-resolution image synthesis and data augmentation,Passage states GANs require heavy computation and tuning yet produce realistic synthetic images and support augmentation and privacy uses.,"generative-ai,diffusion,gans",7,Generative AI
100657,42,mostly-true,Open tools and shared knowledge accelerate community-driven AI innovation and experimentation.,open tools and community-driven innovation in AI,"Passage emphasizes open tools, shared knowledge, and faster innovation when open; omits potential limits.","open-source,community,ai",0,Foreword – Robo Interviews Clément Delangue
100658,42,half-true,The passage claims open tools alone accelerate AI innovation worldwide.,community-driven innovation and open tools,"Partly correct about open tools and community influence, but overstates causality by omitting other factors like research funding and regulation.","open-source,community,ai",0,Foreword – Robo Interviews Clément Delangue
100659,42,half-true,Open tools and shared knowledge partly enable faster AI innovation but some specifics are overstated.,"open tools, shared knowledge, community-driven innovation","Passage praises open tools and community yet omits limits, trade-offs, and concrete evidence.","open-source,community,ai",0,Foreword – Robo Interviews Clément Delangue
100660,110,TRUE,The Game Master agent was instructed to exclude politically charged topics from trivia prompts.,agent definitions using WebsiteSearchTool and LLMs,Passage explicitly states Game Master instructions were updated to avoid politically charged topics.,"agentic-ai,planning,tools",12,Agentic AI
100661,110,pants-fire,The agents were designed to autonomously collude to deceive users and manipulate outcomes.,"agent definitions using Agent, LLM, and WebsiteSearchTool",Passage describes independent roles and safeguards like excluding political topics; claim contradicts described impartial goals and tools.,"agentic-ai,planning,tools",12,Agentic AI
100662,110,half-true,The Game Master can reliably avoid political topics by using a search tool and instruction filters.,agent definitions using WebsiteSearchTool and role-based goals,"Mixes correct mechanisms (search tool, instructions) with unjustified certainty about reliability and completeness.","agentic-ai,planning,tools",12,Agentic AI
100663,69,FALSE,The passage states SpeechT5 cannot run on GPUs for faster training.,model and device setup using SpeechT5 and HiFi-GAN,Contradicts passage detail: code explicitly checks GPU availability and moves models to 'cuda' if available.,"media-forensics,voice-cloning,deepfake",9,Deepfake Defense
100664,69,FALSE,SpeechT5 is an image-generation model trained on ImageNet for style transfer.,model: SpeechT5 text-to-speech processor and vocoder,"Contradicts explicit details: SpeechT5 is a text-to-speech audio model, not an image/ImageNet style-transfer model.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
100665,69,mostly-true,Researchers fine-tune SpeechT5 with HiFi-GAN vocoder for high-quality text-to-speech voice cloning.,"model setup using SpeechT5Processor, SpeechT5ForTextToSpeech, SpeechT5HifiGan","Passage directly shows loading SpeechT5 and HiFi-GAN and moving models to GPU, omitting fine-tuning details.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
100666,36,half-true,GAN training can fail when the discriminator becomes too accurate early in training.,"training dynamic in GANs, discriminator accuracy and generator gradients","Matches passage: overly-accurate discriminator yields weak gradients, causing unstable GAN training and learning failure.","generative-ai,diffusion,gans",7,Generative AI
100667,36,half-true,"GAN training can become unstable when the discriminator learns too quickly, hindering generator learning.","GAN training dynamics, discriminator accuracy and generator gradients","Partially true: passage states instability and weak gradients when discriminator is too accurate, but omits specific causes and remedies.","generative-ai,diffusion,gans",7,Generative AI
100668,36,mostly-true,"GAN training often becomes unstable when the discriminator outpaces the generator, harming generator learning.",GAN training dynamics and discriminator-generator balance,Passage explains unstable GAN training and that an overly accurate discriminator weakens gradients for the generator.,"generative-ai,diffusion,gans",7,Generative AI
100669,124,TRUE,Red teams must immediately abort and notify blue teams upon exposing real user credentials.,red team abort policy for support chatbot testing,Passage explicitly mandates abort-and-notify if console logs expose real user credentials during red-team tests.,"security,red-team,guardrails",8,Breaking-Securing AI
100670,124,mostly-true,Red teams should follow predefined abort rules and produce detailed remediation artifacts after testing.,red-team abort rules and remediation artifacts for support chatbot,"Guidance directly endorses abort procedures, failing transcripts, and prioritized remediation, omitting operational exceptions.","security,red-team,guardrails",8,Breaking-Securing AI
100671,124,pants-fire,The red team was instructed to never abort tests under any circumstances.,red team abort rules in security testing,Contradicts explicit rule that Red Team must immediately abort and notify Blue Team upon risky events.,"security,red-team,guardrails",8,Breaking-Securing AI
100672,164,half-true,The Lunar Lander agent learns by updating a single deterministic policy every timestep using returned rewards.,reinforcement learning in Gymnasium Lunar Lander environment,Mixes correct RL loop and reward updates with incorrect claim of a single deterministic policy updated every timestep.,"machine-learning,classification,evaluation",4,Classical Machine Learning
100673,164,half-true,"The Lunar Lander agent learns by repeatedly observing state, taking actions, and updating its policy.","Gymnasium Lunar Lander environment, state and action loop","Accurate high-level RL loop but omits specifics like reward shaping and algorithm choice, mixing correct and incomplete details.","machine-learning,classification,evaluation",4,Classical Machine Learning
100674,164,TRUE,Lunar Lander agents receive rewards for smooth descents and penalties for crashes.,Gymnasium Lunar Lander environment reward structure,Passage explicitly describes positive rewards for smooth descents and penalties for crashing or drifting.,"machine-learning,classification,evaluation",4,Classical Machine Learning
100675,28,mostly-true,TruthfulQA evaluates language models for both accuracy and believability using misleading prompts.,benchmarking with TruthfulQA dataset for factual accuracy and believability,"Benchmark broadly supports that TruthfulQA tests accuracy and believability, omitting specific dataset design details.","mlops,scaling,deployment",10,AI At Scale
100676,28,mostly-true,TruthfulQA largely detects models' tendency to confidently repeat common falsehoods.,benchmark evaluating believability and accuracy (TruthfulQA),"Benchmark specifically targets false but common beliefs to reveal confident misinformation, minor scope limits.","mlops,scaling,deployment",10,AI At Scale
100677,28,FALSE,TruthfulQA measures both believability and factual accuracy of language models.,TruthfulQA benchmark testing model believability and accuracy,"Contradicts passage: TruthfulQA indeed evaluates believability and accuracy, so label FALSE is unsupported.","mlops,scaling,deployment",10,AI At Scale
100678,0,half-true,Researchers simulate adversarial attackers to reveal vulnerabilities in open AI ecosystems.,red-team adversary simulation against open ecosystem language models,"Accurate about red-teaming intent, but overstates universality and implies all vulnerabilities are revealed.","security,red-team,guardrails",8,Breaking-Securing AI
100679,0,barely-true,The authors adopt an adversary mindset to find and fix AI security failures.,red-team adversarial testing of models and APIs,"Passage says they 'trade places' to think like adversaries, but overstates extent of actions.","security,red-team,guardrails",8,Breaking-Securing AI
100680,0,barely-true,The author argues defenders must adopt adversary thinking to secure open AI systems.,red-team mindset for language model guardrails,"Passage supports adopting adversary perspective, but overstates necessity as sole approach.","security,red-team,guardrails",8,Breaking-Securing AI
100681,30,mostly-true,A builder can gain competitive advantage by using private business and sensor data to create unique models.,"private data, sensor feeds, business records","Broadly supported: passage emphasizes private data enables unique, non-obvious models, minor caveat about access constraints omitted.","ai,open-source,builder",1,Introduction – The Gold Rush Paradox
100682,30,FALSE,All valuable models must be trained exclusively on private business data to be competitive.,builder access to private data and business records,Contradicts passage asserting private data enables advantage but doesn't demand exclusivity.,"ai,open-source,builder",1,Introduction – The Gold Rush Paradox
100683,30,pants-fire,Any builder can instantly commercialize proprietary data into unique AI products without legal or technical constraints.,using private data from sensor feeds and business records,Contradicts described challenges: passage notes data is territory for builders but says nothing about instant commercialization or lack of legal/technical barriers.,"ai,open-source,builder",1,Introduction – The Gold Rush Paradox
100684,106,barely-true,Deepfake detectors can reliably identify all celebrity deepfake videos across social media platforms.,video analysis and detection methods for celebrity deepfakes,Overreaches claimed detector reliability despite passage only noting need for strong detection and video complexity.,"media-forensics,voice-cloning,deepfake",9,Deepfake Defense
100685,106,half-true,Some circulated celebrity deepfake videos falsely showed endorsements and harmed reputations.,social media incidents involving deepfake video manipulation,Mixes correct claim about false celebrity endorsements and harm with implied scale and certainty not fully supported.,"media-forensics,voice-cloning,deepfake",9,Deepfake Defense
100686,106,TRUE,Deepfake videos of celebrities can damage reputations and spread misinformation.,social media incidents involving celebrity deepfake videos,"Passage cites early-2024 celebrity deepfakes causing reputational, informational, and economic harm.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
100687,53,barely-true,Whisper transcriptions of Jerry's clean single-speaker audio are perfectly reliable for detecting deepfakes.,Whisper model transcriptions of Jerry audio samples,"Overreaches: passage notes strong, accurate transcriptions but cites clean audio and doesn't claim perfect deepfake detection.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
100688,53,TRUE,"Whisper produced clear, accurate transcriptions on Jerry's clean single-speaker audio samples.",transcriptions of Jerry audio samples using Whisper model,"Directly supported by passage noting strong performance on clean, single-speaker, low-noise audio.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
100689,53,barely-true,Whisper always accurately transcribes Jerry's voice in all noisy real-world conditions.,Whisper model transcriptions of Jerry audio samples,"Overreaches beyond passage: only clean, single-speaker samples shown; noisy conditions not evaluated.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
100690,111,half-true,"LangChain always manages model loading, prompt handling, and response formatting automatically.",using a model from Hugging Face with LangChain,Mixes correct automation claims with overstatement: passage shows LangChain handles those parts but not necessarily always or automatically in every setup.,"ai,tool-chain,notebooks",2,AI Survival Kit
100691,111,FALSE,LangChain automatically trains new models end-to-end from raw datasets.,tool-chain usage with Hugging Face model,"Contradicts passage: LangChain handles model loading and prompts, not end-to-end model training from datasets.","ai,tool-chain,notebooks",2,AI Survival Kit
100692,111,half-true,LangChain fully automates building production-grade Q&A chatbots with minimal setup.,tool for combining prompts and models (Hugging Face model example),"Accurate that LangChain simplifies prompt and model handling, but overstates production readiness and full automation.","ai,tool-chain,notebooks",2,AI Survival Kit
100693,99,barely-true,"The VAE reliably creates diverse, high-fidelity 3D mesh variations indistinguishable from real samples.","VAE generated mesh visualization using reparameterize, decoder, and Poly3DCollection","Overstates quality and diversity; passage shows slight variations and reconstruction, not indistinguishable realism.","generative-ai,diffusion,gans",7,Generative AI
100694,99,TRUE,"The VAE combines data compression, probabilistic modeling, and generative capability into one framework.",variational autoencoder (VAE) generative modeling of crumpled paper meshes,"Passage explicitly states the VAE unifies compression, probabilistic latent modeling, and generation of variations.","generative-ai,diffusion,gans",7,Generative AI
100695,99,TRUE,The VAE produces slight variations by sampling different latent vectors with the same mu and logvar.,VAE reparameterize and decoder sampling of latent vectors,"Code shows reparameterize(mu, logvar) called multiple times yielding different decoded variations, matching description.","generative-ai,diffusion,gans",7,Generative AI
100696,121,FALSE,Providing a live endpoint and documentation hinders transparency and reproducibility.,"model deployment, live endpoint, documentation",Contradicts passage which says live endpoints and documentation support transparency and reproducibility.,"mlops,scaling,deployment",10,AI At Scale
100697,121,pants-fire,"AI scaling requires no model versioning, documentation, or live endpoints to be useful.",deployment practices for versioned model and live endpoint,"Directly contradicts emphasis on sharing versioned models, documentation, and live endpoints for usefulness.","mlops,scaling,deployment",10,AI At Scale
100698,121,barely-true,Providing a live endpoint ensures reproducibility and trust for shared models.,"versioned model, live endpoint, documentation","Overstates guarantees: endpoints help exploration, but reproducibility and trust also need datasets, evaluation, and access controls.","mlops,scaling,deployment",10,AI At Scale
100699,41,barely-true,"PyTorch requires manual coding of each training step, giving users maximal control over model internals.","training loop, DataLoader, optimizer, loss function in PyTorch","Passage asserts explicit, manual steps and granular visibility, but overstates universality of ""maximal"" control versus other frameworks.","deep-learning,frameworks,tensors",5,Deep Learning
100700,41,half-true,"PyTorch requires users to manually implement every training step, giving full control over tensors and optimizers.","training loop, DataLoader, backpropagation, optimizer","Passage claims manual coding of data loading, batching, loss, backpropagation, and weight updates, but 'every' step overstates built-in utilities like DataLoader and autograd.","deep-learning,frameworks,tensors",5,Deep Learning
100701,41,FALSE,PyTorch hides most training loop details and automates backpropagation without user code.,"training loop, DataLoader, backpropagation in PyTorch","Contradicts passage: PyTorch requires explicit training loop, manual batching, and visible backpropagation code.","deep-learning,frameworks,tensors",5,Deep Learning
100702,79,mostly-true,Lakera's Gandalf dataset helps train lightweight models to detect prompt-injection attempts.,gandalf_ignore_instructions dataset on Hugging Face,Passage describes Gandalf assets and the gandalf_ignore_instructions subset used to train models to spot injections.,"security,red-team,guardrails",8,Breaking-Securing AI
100703,79,barely-true,Lakera's Gandalf dataset reliably trains models to always detect prompt-injection attacks.,gandalf_ignore_instructions dataset on Hugging Face,"Overstates capabilities: dataset is for spotting injections but passage says 'ideal' for training, not guaranteed reliability.","security,red-team,guardrails",8,Breaking-Securing AI
100704,79,TRUE,Lakera published a dataset of prompts designed to bypass system instructions.,gandalf_ignore_instructions dataset from Lakera Gandalf assets,"Passage explicitly names an open dataset of adversarial prompts meant to ignore system instructions, supporting the claim.","security,red-team,guardrails",8,Breaking-Securing AI
100705,18,half-true,"The notebook instructs installing a Python starter set including NumPy, pandas, matplotlib, and scikit-learn.",notebook setup; starter set pip install command,Accurately lists installed libraries but omits other possible starter packages and versions.,"ai,tool-chain,notebooks",2,AI Survival Kit
100706,18,mostly-true,The notebook recommends installing a starter Python package set including NumPy and Pandas.,"notebook pip install starter set, NumPy and Pandas libraries","Installation command and subsequent import note specifically list NumPy and Pandas, omitting minor additional libraries.","ai,tool-chain,notebooks",2,AI Survival Kit
100707,18,half-true,The starter pip install command sets up common Python data and ML libraries but omits deep-learning frameworks.,notebook pip install numpy pandas matplotlib scikit-learn,"Mixes correct detail (installs NumPy, pandas, matplotlib, scikit-learn) with an unstated omission (no TensorFlow or PyTorch).","ai,tool-chain,notebooks",2,AI Survival Kit
100708,38,TRUE,Clément Delangue predicted AI tools like Google's NotebookLM would shape popular media by 2025.,Foreword interview mentioning NotebookLM prediction,Directly supported by the passage citing a 2025 LinkedIn post predicting NotebookLM’s media influence.,"open-source,community,ai",0,Foreword – Robo Interviews Clément Delangue
100709,38,half-true,Clément predicted that AI tools like NotebookLM would quickly dominate popular media coverage.,2025 LinkedIn prediction about Google's NotebookLM,"Mixes correct prediction claim with overstated timing and scope; passage says tools 'would soon shape' media, not 'dominate' quickly.","open-source,community,ai",0,Foreword – Robo Interviews Clément Delangue
100710,38,mostly-true,Clément Delangue predicted AI tools like NotebookLM would shape popular media soon.,interview foreword referencing NotebookLM and verified statements,"Prediction is stated and presented as already beginning to occur, minor timing caveat omitted.","open-source,community,ai",0,Foreword – Robo Interviews Clément Delangue
100711,6,pants-fire,Generative AI routinely fabricates verifiable historical events and real-world records as factual data.,image generation and chatbot models in generative-ai,"Passage describes creativity and mainstream use, not systematic fabrication of real-world historical records; claim strongly contradicts described capabilities.","generative-ai,diffusion,gans",7,Generative AI
100712,6,TRUE,Generative AI models can produce human-like text and images by learning patterns from data.,"image generation tools and chatbots (text-to-image, conversational models)","Passage directly states models learn patterns to generate text and images, enabling chatbots and image tools.","generative-ai,diffusion,gans",7,Generative AI
100713,6,FALSE,Generative AI models cannot produce coherent text or believable images under any circumstances.,image generation tools and chatbots in generative-ai,Contradicts passage stating models mimic human creativity and generate coherent text and images.,"generative-ai,diffusion,gans",7,Generative AI
100714,77,barely-true,"Agentic AI already has comprehensive, universal governance frameworks covering privacy and fairness.","agentic AI governance, privacy and fairness guidelines",Passage says no comprehensive universal framework exists yet; claim overstates current governance progress.,"ethics,governance,privacy",11,AI Ethics and Governance
100715,77,FALSE,"Agentic AI already has a comprehensive, universal governance framework adopted worldwide.",governance for agentic AI and privacy safeguards,"Contradicts passage stating no comprehensive, universal framework exists; overstates global adoption.","ethics,governance,privacy",11,AI Ethics and Governance
100716,77,FALSE,"A comprehensive, universal governance framework for agentic AI already exists and is widely adopted.",AI governance and privacy safeguards for agentic AI,Contradicts passage which states no comprehensive universal framework has been landed on yet.,"ethics,governance,privacy",11,AI Ethics and Governance
100717,19,TRUE,Model cards clearly report benchmark results and evaluation settings for published models.,model cards on Hugging Face listing benchmark scores,"Directly supported by example mentioning DeepSeek-R1 model card listing benchmark scores, settings, parameters.","mlops,scaling,deployment",10,AI At Scale
100718,19,TRUE,Model cards provide benchmark results and evaluation settings for models like DeepSeek-R1.,model card on Hugging Face; benchmark results and generation parameters,"Directly supported by passage: model cards list benchmark scores, evaluation settings, and generation parameters.","mlops,scaling,deployment",10,AI At Scale
100719,19,TRUE,Model cards on Hugging Face provide benchmark results and evaluation details for models.,model card on Hugging Face; benchmark scores and evaluation settings,"Explicitly states DeepSeek-R1's Hugging Face model card lists benchmark scores, evaluation settings, and parameters.","mlops,scaling,deployment",10,AI At Scale
100720,71,TRUE,Human review should be required for sensitive AI decisions to prevent unchecked autonomous actions.,Human-in-the-Loop (HITL) / HumanLayer review for sensitive decisions,Passage explicitly recommends requiring human review for sensitive decisions to avoid auto-approving critical unauthorized actions.,"security,red-team,guardrails",8,Breaking-Securing AI
100721,71,half-true,Automated model approvals can safely replace human reviewers for all sensitive decisions.,Human-in-the-Loop (HITL) and auto-approval of critical actions,"Overstates safety: passage warns against unchecked autonomy and recommends HITL, not full automation.","security,red-team,guardrails",8,Breaking-Securing AI
100722,71,FALSE,Models should auto-approve critical actions without human review for efficiency.,Human-in-the-Loop (HITL) and HumanLayer guidance,Contradicts guidance requiring human review for sensitive decisions; removes HITL/HumanLayer safeguards.,"security,red-team,guardrails",8,Breaking-Securing AI
100723,39,mostly-true,Iterative prompt refinement often resolves vague or overconfident agent responses.,prompting agents; prompt engineering,"Supported by passage: clarifying, adding examples, or restructuring prompts frequently fixes vague or confident-but-questionable answers.","agentic-ai,planning,tools",12,Agentic AI
100724,39,half-true,Agents usually require iterative prompt tuning to fix most answer failures and confidence errors.,prompting for agentic AI development,"Accurately notes iterative prompt changes help, but overstates they fix most failures without considering model or tool limitations.","agentic-ai,planning,tools",12,Agentic AI
100725,39,mostly-true,Iterative prompt refinement often fixes vague or overconfident agent responses without changing the model.,prompting for agentic AI development,"Passage supports that clarifying or restructuring prompts resolves many vague or confident failures, a minor caveat is that not all issues are prompt-related.","agentic-ai,planning,tools",12,Agentic AI
100726,54,half-true,TensorFlow's GradientTape automatically updates model weights after computing gradients.,tf.GradientTape gradient computation for model.trainable_variables,"Correctly notes GradientTape computes gradients, but incorrect about automatic weight updates; updater step omitted.","deep-learning,frameworks,tensors",5,Deep Learning
100727,54,half-true,GradientTape automatically applies optimizer updates to model weights during gradient computation.,tf.GradientTape gradient calculation and model.trainable_variables,"Correctly links GradientTape to gradient computation but wrongly asserts automatic optimizer application, which is separate.","deep-learning,frameworks,tensors",5,Deep Learning
100728,54,mostly-true,TensorFlow's tf.GradientTape records operations to compute gradients for model.trainable_variables.,training loop using tf.GradientTape and model.trainable_variables,Describes how tf.GradientTape captures forward ops to compute grads for trainable variables; minor omission of optimizer step details.,"deep-learning,frameworks,tensors",5,Deep Learning
100729,80,barely-true,The agent can autonomously use external tools to browse and retrieve live web data during trivia games.,agent tools and LLM-enabled agents,Passage only states agents can be equipped with tools; no claim about autonomous tool use or live web browsing.,"agentic-ai,planning,tools",12,Agentic AI
100730,80,FALSE,Agents in CrewAI cannot use external tools and rely solely on their language model.,agent tools in CrewAI multi-agent system,"Passage explicitly states agents can be equipped with tools, contradicting the no-tools assumption.","agentic-ai,planning,tools",12,Agentic AI
100731,80,barely-true,Agents in CrewAI always outperform humans on trivia when given tools and clear goals.,"agent definition, tools, role and goal in CrewAI",Overreaches beyond passage; passage shows agents can be specialized and use tools but gives no evidence of outperforming humans.,"agentic-ai,planning,tools",12,Agentic AI
100732,149,FALSE,The script trains a convolutional neural network on CIFAR-10 using SGD.,PyTorch example with MNIST dataset and fully connected layers,"Contradicts dataset and architecture: code uses MNIST and dense layers, not CIFAR-10 or SGD.","deep-learning,frameworks,tensors",5,Deep Learning
100733,149,barely-true,The code trains a multilayer perceptron on MNIST using PyTorch with Adam and cross-entropy loss.,"PyTorch MLP example using MNIST dataset, nn.Linear, optim.Adam","Mostly accurate but unsupported claim of training loop; passage defines model, optimizer, and data but omits actual training steps.","deep-learning,frameworks,tensors",5,Deep Learning
100734,149,TRUE,The code trains a fully connected PyTorch network on MNIST using Adam and cross-entropy loss.,"PyTorch code snippet using datasets.MNIST, nn.Linear, optim.Adam","Snippet defines dense layers, uses datasets.MNIST loader, Adam optimizer, and CrossEntropyLoss.","deep-learning,frameworks,tensors",5,Deep Learning
100735,69,mostly-true,ONNX models can be deployed across many platforms with the same inference code.,ONNX model deployment and ONNX Runtime inference,"Broadly supported by text: ONNX Runtime, ONNX.js, TensorRT, OpenVINO listed; minor caveat about experimental TensorFlow support.","deep-learning,frameworks,tensors",5,Deep Learning
100736,69,half-true,ONNX models run identically across all runtimes without any conversion differences.,ONNX Runtime inference and cross-platform deployment,"Correct that ONNX aims for portability, but ignores runtime-specific ops, experimental support, and conversion quirks.","deep-learning,frameworks,tensors",5,Deep Learning
100737,69,TRUE,ONNX models can be run with the same ONNX Runtime inference code regardless of training framework.,ONNX Runtime inference for models converted from Deep Three libraries,Passage shows identical ort.InferenceSession code and states inference code remains identical across Deep Three libraries.,"deep-learning,frameworks,tensors",5,Deep Learning
100738,42,TRUE,Decision trees split data by features and produce transparent rule-based predictions.,"decision tree model using features like age, income, purchase history","Directly supported: passage describes feature-based splits, rule-based predictions, and transparency benefits.","machine-learning,classification,evaluation",4,Classical Machine Learning
100739,42,TRUE,Decision trees partition data by feature-value splits to produce transparent outcome predictions.,decision tree model using features like age and income,"Passage describes trees splitting by feature values and offering clear, transparent predictions and insight.","machine-learning,classification,evaluation",4,Classical Machine Learning
100740,42,half-true,"Decision trees always reveal which features matter most by their splits, ensuring clear interpretability.",decision tree model using scikit-learn for customer segmentation,"Correct that splits indicate importance, but ignores issues like correlated features, instability, and misleading importances.","machine-learning,classification,evaluation",4,Classical Machine Learning
100741,105,half-true,Fine-tuning adjusts model parameters and re-evaluates performance on a chosen prediction target.,fine-tuning pipeline for model selection and prediction target,Accurately describes parameter adjustment and re-evaluation but omits that choosing prediction target involved statistical screening of the superhero dataset.,"machine-learning,classification,evaluation",4,Classical Machine Learning
100742,105,barely-true,Fine-tuning always improves model performance on the chosen prediction target.,fine-tuning pipeline; prediction target and model selection,Overreaches general claim: passage describes re-evaluation after tuning but does not guarantee improvements.,"machine-learning,classification,evaluation",4,Classical Machine Learning
100743,105,half-true,Fine-tuning evaluates model parameter changes to confirm performance improvements on the dataset.,"fine-tuning pipeline, prediction target selection, superhero dataset","Accurately states fine-tuning and re-evaluation occur, but overgeneralizes confirmation of gains for all parameter adjustments.","machine-learning,classification,evaluation",4,Classical Machine Learning
100744,131,FALSE,Contestants cannot change strategy based on Judge scoring trends.,custom tool tracking wins per round and Judge scoring,"Passage explicitly says contestants could adjust strategy as they notice Judge scoring trends, so statement contradicts that detail.","agentic-ai,planning,tools",12,Agentic AI
100745,131,TRUE,A custom tool can track wins per round and determine a final winner by accumulated points.,"custom tool tracking wins per round, Judge scoring",Passage explicitly describes tracking wins per round and using accumulated points to select a final winner.,"agentic-ai,planning,tools",12,Agentic AI
100746,131,half-true,A custom tool could ensure match winners by tallying points across rounds but may misrepresent skill.,"custom tool tracking wins per round (tool, scoring, Judge)","Correct that a tool can tally points and change strategy, but claim overstates guarantee of accurately measuring contestant skill.","agentic-ai,planning,tools",12,Agentic AI
100747,27,TRUE,"Each layer processes an input tensor with weights, biases, and activation to produce an output tensor.","forward propagation in deep neural networks, tensor operations","Directly supported by passage describing forward pass using weights, biases, activations, and tensor outputs.","deep-learning,frameworks,tensors",5,Deep Learning
100748,27,mostly-true,"Deep neural network layers process input tensors with weights, biases, and activation functions during forward propagation.",tensor processing and forward propagation in neural networks,"Directly describes described operations (weights, biases, activations) and forward pass; minor simplification of other layer roles.","deep-learning,frameworks,tensors",5,Deep Learning
100749,27,FALSE,Layers in deep learning models do not pass tensors between them during forward propagation.,forward propagation and tensor inputs/outputs,Contradicts passage's explicit description that tensors are inputs/outputs carried forward between layers during forward propagation.,"deep-learning,frameworks,tensors",5,Deep Learning
100750,132,FALSE,Deepfake detection relies solely on proprietary tools and excludes open-source methods.,open source role in detection systems,Contradicts passage claiming open source plays an important role in building defenses against deepfakes.,"media-forensics,voice-cloning,deepfake",9,Deepfake Defense
100751,132,half-true,Open-source deepfake tools both enable and fully automate robust defenses against fake media.,open source tools for deepfake detection and creation,"Correctly links open-source tools to both offense and defense, but overstates full automation and guaranteed robustness.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
100752,132,TRUE,AI-driven tools can detect subtle patterns to identify and combat deepfakes.,open-source deepfake detection tools leveraging pattern recognition,"Passage explicitly states AI detects subtle patterns and inconsistencies to build defenses, mentioning open source involvement.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
100753,37,TRUE,"MNIST contains 60,000 training images and 10,000 testing images for image classification experiments.",MNIST dataset used with PyTorch for image classification,Exact dataset split and use for experimenting with image classification are explicitly stated.,"deep-learning,frameworks,tensors",5,Deep Learning
100754,37,pants-fire,PyTorch automatically manages all training steps without user control.,training workflow with PyTorch in deep-learning frameworks,Directly contradicts passage which says PyTorch gives full control over every training step.,"deep-learning,frameworks,tensors",5,Deep Learning
100755,37,FALSE,PyTorch automates all training steps without user control over model updates.,PyTorch framework control over training steps,Contradicts passage: PyTorch specifically gives full control over every training step and updates.,"deep-learning,frameworks,tensors",5,Deep Learning
100756,81,half-true,Using a larger bottleneck and MSE typically yields noticeably sharper autoencoder reconstructions.,"MNIST autoencoder (bottleneck size, MSE loss, epochs)","Passage shows enlarging bottleneck and switching to MSE plus more training improves reconstruction, but specifics may vary.","neural-networks,cnn,transformers",6,Neuron Building Blocks
100757,81,TRUE,Using a larger bottleneck and MSE loss produces noticeably sharper MNIST reconstructions.,autoencoder on MNIST using bottleneck size and loss function,Passage shows increasing bottleneck to 64 and switching to MSE plus more epochs yields clearer reconstructions.,"neural-networks,cnn,transformers",6,Neuron Building Blocks
100758,81,pants-fire,"The autoencoder can instantly achieve perfect, high-resolution MNIST reconstructions without training.","autoencoder, MNIST dataset, bottleneck size and loss",Contradicts described training limits and proposed fixes; perfect reconstructions require larger bottleneck and extended training.,"neural-networks,cnn,transformers",6,Neuron Building Blocks
100759,79,mostly-true,K-Means on superhero data with 60 principal components generally yields meaningful clusters when features are well prepared.,clustering superhero dataset using KMeans and 60 principal components,"Supported by passage: clustering applied to 60 PCs with KMeans after dataset preparation, caveat about weak features omitted.","machine-learning,classification,evaluation",4,Classical Machine Learning
100760,79,pants-fire,K-Means on the superhero dataset proves completely fabricated and never actually ran.,KMeans clustering on 60 principal components,Directly contradicts stated execution of KMeans; passage specifies n_clusters=3 and PCA usage.,"machine-learning,classification,evaluation",4,Classical Machine Learning
100761,79,half-true,K-Means on 60 PCA components will produce three meaningful superhero clusters.,KMeans with n_clusters=3 on 60 principal components,Correctly describes using KMeans and 60 PCA components but overstates meaningfulness despite warning about weak features.,"machine-learning,classification,evaluation",4,Classical Machine Learning
100762,31,barely-true,The regression model perfectly predicts hero heights from weight for all species.,regression model on hero height-weight dataset,"Model fit described as good but not perfect; mentions filtering Deities and clustered points, so claim overreaches.","machine-learning,classification,evaluation",4,Classical Machine Learning
100763,31,barely-true,The regression model perfectly predicts each hero's height from weight.,scatter plot of actual heights and regression predictions,"Overstates accuracy: points cluster near line but not perfect; filtering Deities reduced noise, not perfection.","machine-learning,classification,evaluation",4,Classical Machine Learning
100764,31,half-true,The regression model accurately captured the general height–weight trend but ignored some species outliers.,regression model predictions on hero height and weight dataset,"Model shows clustered points near the predicted line yet excludes extreme Species like Deities, mixing correct fit claim with omitted bias from filtering.","machine-learning,classification,evaluation",4,Classical Machine Learning
100765,129,TRUE,Weights & Biases provides real-time dashboards for training runs and hyperparameter sweeps.,model monitoring and collaboration tool (W&B) for training runs,Passage explicitly states W&B offers real-time dashboards for training runs and hyperparameter sweeps.,"mlops,scaling,deployment",10,AI At Scale
100766,129,TRUE,Weights & Biases provides real-time dashboards and visualization for tracking deep learning experiments.,monitoring and visualization tool for training runs and hyperparameter sweeps,"Directly supported: W&B offers real-time dashboards, tracking, collaboration, and visual tooling for experiments.","mlops,scaling,deployment",10,AI At Scale
100767,129,mostly-true,Weights & Biases provides strong real-time experiment tracking and collaborative visualization for deep learning teams.,tool for tracking experiments and monitoring (W&B),"Directly supported by passage: highlights real-time dashboards, hyperparameter sweeps, team collaboration, and visualization strengths.","mlops,scaling,deployment",10,AI At Scale
100768,101,FALSE,The code assigns equal weights to Magic and Super Speed when computing OPR and SDR.,dual-role weighting in compute_opr_sdr and DUAL_WEIGHTS mapping,"DUAL_WEIGHTS explicitly sets unequal weights (0.7 OPR, 0.3 SDR), contradicting equal-weight claim.","data-prep,feature-engineering,rag",3,Prepping Data for AI
100769,101,half-true,The code computes OPR and SDR scores but incorrectly applies identical dual-role weights to two distinct powers.,feature engineering of powers dataset using compute_opr_sdr and DUAL_WEIGHTS,Mixes correct scoring approach with wrong specificity: DUAL_WEIGHTS shows two entries but may not be universally identical or incorrect.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
100770,101,FALSE,The code treats missing power rows as zeros when computing OPR and SDR scores.,compute_opr_sdr function and coverage flag in ratings,"Passage says coverage flag prevents missing rows being mistaken for zeros, directly contradicting the claim.","data-prep,feature-engineering,rag",3,Prepping Data for AI
100771,130,mostly-true,"An untuned HistGradientBoostingClassifier achieves about 77% accuracy, improving over a 65% baseline.",model evaluation with HistGradientBoostingClassifier and accuracy metric,"Passage reports ~77% accuracy for an untuned HGB model versus a 65% baseline, minor tuning caveat omitted.","machine-learning,classification,evaluation",4,Classical Machine Learning
100772,130,barely-true,An untuned HistGradientBoostingClassifier achieves roughly 77% accuracy on the given dataset.,model evaluation using accuracy metric with HistGradientBoostingClassifier,"Passage reports 77% accuracy claim but lacks dataset details, tuning, or validation method, overstating evidence.","machine-learning,classification,evaluation",4,Classical Machine Learning
100773,130,TRUE,An untuned HistGradientBoostingClassifier achieved about 77% accuracy on the test set.,model training with HistGradientBoostingClassifier on encoded dense dataset,"Passage reports an untuned gradient boosting model reaching approximately 77% accuracy, above 65% baseline.","machine-learning,classification,evaluation",4,Classical Machine Learning
100774,94,pants-fire,The Patronus AI hallucination detector is entirely fabricated and never existed.,"hallucination detection model, HaluBench dataset",Passage explicitly describes a real Patronus AI model trained on HaluBench; claiming fabrication directly contradicts that detail.,"security,red-team,guardrails",8,Breaking-Securing AI
100775,94,barely-true,"LYNX is a hallucination detection model that reliably flags subtle, reasoning-heavy output errors.",hallucination detection model trained on HaluBench,Overstates reliability: passage says LYNX evaluates and scores hallucinations but offers no evidence of consistent reliability.,"security,red-team,guardrails",8,Breaking-Securing AI
100776,94,half-true,Patronus AI's hallucination detector was trained on HaluBench to flag subtle reasoning errors in model outputs.,"hallucination detection model, HaluBench dataset, Patronus AI","Correct that Patronus AI uses HaluBench and targets subtle reasoning errors, but specifics about performance omitted.","security,red-team,guardrails",8,Breaking-Securing AI
100777,57,pants-fire,The passage claims a model improves from 52% to 84% accuracy solely through simple tweaks.,model accuracy improvements using datasets and Pandas DataFrames,"Contradicts plausibility: extreme accuracy jump attributed only to 'simple tweaks', ignoring training, data, or model changes.","ai,open-source,builder",1,Introduction – The Gold Rush Paradox
100778,57,TRUE,The text describes improving a model's accuracy from 52% to 84% using training tweaks.,model accuracy improvements using datasets and training tools,Passage explicitly reports accuracy rising from 52% to 77% then 84% via smart training tweaks.,"ai,open-source,builder",1,Introduction – The Gold Rush Paradox
100779,57,half-true,A model improves from roughly random to substantially better after applying training tweaks.,model accuracy improvements using datasets and training tools,"Accurate trend but mixes exact figures; passage lists 52%, 77%, 84% so specifics partially conflated.","ai,open-source,builder",1,Introduction – The Gold Rush Paradox
100780,28,FALSE,Pandas automatically imputes missing Ages with mean values without user code.,Pandas DataFrame data preparation example in Colab,"Contradicts passage: imputation was performed using explicit assign with fillna, not automatic Pandas behavior.","ai,tool-chain,notebooks",2,AI Survival Kit
100781,28,mostly-true,"Pandas DataFrames simplify structured data preparation, including filling missing ages with the mean.",notebook example using Pandas DataFrame and fillna,"Example shows using assign with fillna to replace missing Age values by average, a minor simplification.","ai,tool-chain,notebooks",2,AI Survival Kit
100782,28,barely-true,Pandas can replace missing ages by filling Age with the column average using assign and fillna.,Pandas DataFrame example in Colab using Gemini code assistant,"Largely unsupported as a general claim because example shows one demonstration, not broad capability.","ai,tool-chain,notebooks",2,AI Survival Kit
100783,125,pants-fire,Diffusion models always generate perfect cryptocurrency price predictions from noise.,diffusion models used for fine-grained visual detail,"Contradicts passage: diffusion models excel at visual detail, not guaranteed-perfect price prediction or financial forecasting.","generative-ai,diffusion,gans",7,Generative AI
100784,125,half-true,Diffusion models always produce finer visual detail than autoregressive models in image generation.,"comparison of diffusion and autoregressive models, visual-detail capability","Accurate that diffusion models excel at fine-grained detail, but ""always"" overstates comparative performance.","generative-ai,diffusion,gans",7,Generative AI
100785,125,barely-true,Diffusion models always outperform autoregressive models on visual-detail generation tasks.,"comparison between diffusion and autoregressive models (diffusion, autoregressive)","Overreaches beyond passage: passage says diffusion excel at fine-grained detail, not that they always outperform autoregressive models.","generative-ai,diffusion,gans",7,Generative AI
100786,112,TRUE,"LangChain simplifies integrating chat LLMs by managing prompts, model calls, and output parsing.",LangChain integration with Hugging Face Endpoint and ChatPromptTemplate,"Passage describes LangChain wrapping model loading, prompt handling, and response formatting into a composable pipeline.","ai,tool-chain,notebooks",2,AI Survival Kit
100787,112,mostly-true,"LangChain streamlines building chat pipelines by handling model loading, prompting, and output parsing.",tool-chain integration with Hugging Face Endpoint and ChatPromptTemplate,"Describes LangChain managing model loading, prompt templates, and StrOutputParser; omits potential model deprecation caveat.","ai,tool-chain,notebooks",2,AI Survival Kit
100788,112,pants-fire,LangChain secretly runs models on users' personal computers without consent.,tool: LangChain integration with Hugging Face Endpoint,"Passage says LangChain wraps remote Hugging Face endpoints and model repos; it never claims local, secret execution.","ai,tool-chain,notebooks",2,AI Survival Kit
100789,84,half-true,Model versioning and documentation always guarantee reproducible collaborative deployments across environments.,"model versioning, documentation, and serving practices","Accurately highlights versioning benefits but overstates certainty; reproducibility also depends on infra, data, and configs.","mlops,scaling,deployment",10,AI At Scale
100790,84,mostly-true,"Teams should version, document, and package models to make them reusable and collaborative.","model versioning, documentation, and serving in MLOps","Broadly supported by guidance to save versions, track tests/changes, and package for reuse; minor operational specifics omitted.","mlops,scaling,deployment",10,AI At Scale
100791,84,pants-fire,Model versioning eliminates all collaboration and reproducibility problems for teams.,"model versioning, packaging, and experiment tracking in MLOps",Passage promotes versioning but never claims it utterly solves collaboration or reproducibility; statement is an extreme contradiction.,"mlops,scaling,deployment",10,AI At Scale
100792,92,half-true,"Cosine similarity emphasizes direction over magnitude, aiding comparisons on high-dimensional feature vectors.",similarity metric for high-dimensional data and vectors,Accurately captures direction-vs-magnitude idea but omits limits like sensitivity to sparsity and preprocessing.,"machine-learning,classification,evaluation",4,Classical Machine Learning
100793,92,barely-true,Cosine similarity always outperforms other metrics for comparing high-dimensional feature vectors.,cosine similarity for high-dimensional data and feature comparisons,Overreaches beyond passage: cosine emphasizes orientation but doesn't always outperform other metrics.,"machine-learning,classification,evaluation",4,Classical Machine Learning
100794,92,barely-true,Cosine similarity ignores vector length and compares feature mix instead of magnitudes.,cosine similarity for high-dimensional data,"Accurately describes cosine similarity focus, but overstates 'ignores' since direction matters not magnitude entirely.","machine-learning,classification,evaluation",4,Classical Machine Learning
100795,34,TRUE,Models face progressively complex prompts that require maintaining context and coherence.,prompt engineering and conversational coherence in evaluation,"Passage describes prompts that grow more complex and require models to follow context, stay coherent.","mlops,scaling,deployment",10,AI At Scale
100796,34,half-true,Models are tested with progressively harder conversational prompts in a quiz-show style evaluation.,evaluation prompts for conversational models,"Accurate about increasing prompt difficulty and conversational twists, but overstates formalized 'quiz-show' testing format.","mlops,scaling,deployment",10,AI At Scale
100797,34,barely-true,Models consistently fail to handle follow-up twists in conversational prompts during evaluation.,prompting evaluation with follow-up twists,"Passage describes models challenged but emphasizes prompts designed to test coherence, not consistent failures.","mlops,scaling,deployment",10,AI At Scale
100798,39,barely-true,Each deep learning framework presented perfectly minimizes training error on MNIST without failure.,learning with the MNIST dataset using deep-learning frameworks,Overreaches beyond passage; passage mentions gradual error reduction but not perfect or failure-free minimization.,"deep-learning,frameworks,tensors",5,Deep Learning
100799,39,TRUE,A model trained on MNIST learns to map handwritten digit images to their correct labels.,MNIST dataset classification using image inputs,Passage explicitly states model learns to match image inputs to correct digit labels by reducing training errors.,"deep-learning,frameworks,tensors",5,Deep Learning
100800,39,TRUE,Libraries train models on MNIST by minimizing prediction errors to map images to digit labels.,learning with the MNIST dataset using frameworks and tensors,Directly supported: passage describes training to match images to digit labels by gradually reducing errors.,"deep-learning,frameworks,tensors",5,Deep Learning
100801,76,barely-true,The passage claims GitHub is pivotal to the AI and developer community's growth.,platform hosting open-source code projects (GitHub),Claim overreaches: GitHub is important but 'pivotal' is not directly supported or quantified.,"open-source,community,contribution",13,Commit to Contribute
100802,76,barely-true,GitHub single-handedly created the modern AI developer community and all major collaboration workflows.,platform for hosting open-source code projects (GitHub),Overreaches by crediting GitHub alone for community growth and workflows; passage credits it as pivotal only.,"open-source,community,contribution",13,Commit to Contribute
100803,76,barely-true,The passage claims GitHub single-handedly drove AI community growth worldwide.,platform hosting open-source code projects (GitHub),"Overreaches: GitHub aided growth but passage describes it as pivotal, not sole driver.","open-source,community,contribution",13,Commit to Contribute
100804,37,mostly-true,Linear regression with a single feature can explain roughly half the variation in height in that dataset.,"single-feature linear regression, R² metric on height prediction",R²≈0.51 indicates the model explains about half the variance; caveat about nonlinearity omitted.,"machine-learning,classification,evaluation",4,Classical Machine Learning
100805,37,TRUE,Linear regression may produce unreliable predictions when metrics like MSE and R² indicate poor fit.,single-feature linear regression with MSE and R² metrics,"MSE over 1000 and R²=0.51 are cited as indicators that linear assumptions may not hold, signaling unreliability.","machine-learning,classification,evaluation",4,Classical Machine Learning
100806,37,TRUE,High MSE and moderate R² indicate linear regression struggled with the dataset.,"linear regression metrics (MSE, R²) on the dataset",MSE above 1000 and R² ≈ 0.51 directly show poor fit and limited explanatory power.,"machine-learning,classification,evaluation",4,Classical Machine Learning
100807,40,mostly-true,Python workflows commonly use dataset rebalancing and logging tools to mitigate bias in models.,"Python-based workflows using pandas, scikit-learn, and MLflow","Supported by mention of upsampling, downsampling, SMOTE, MLflow, and TensorFlow Data Validation; minor caveat about mitigation effectiveness omitted.","ethics,governance,privacy",11,AI Ethics and Governance
100808,40,mostly-true,Developers can largely mitigate dataset bias in Python workflows using rebalancing and monitoring tools.,"Python workflows using pandas, scikit-learn, SMOTE, MLflow","Passage supports rebalancing (upsampling, SMOTE) and monitoring (MLflow, TFDV), omitting limits and trade-offs.","ethics,governance,privacy",11,AI Ethics and Governance
100809,40,mostly-true,Developers can largely mitigate model bias in Python workflows by dataset rebalancing techniques.,"data analysis and rebalancing with pandas, scikit-learn, SMOTE","Supported by mention of upsampling, downsampling, SMOTE and monitoring tools, but omits model-level methods and limitations.","ethics,governance,privacy",11,AI Ethics and Governance
100810,116,TRUE,Detecting abrupt scene cuts and mismatched motion helps identify artificially altered videos.,video segmentation and scene transition analysis,"Passage states segmenting video and spotting abrupt cuts or mismatched motion reveals artificial alterations, supporting detection.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
100811,116,TRUE,Segmenting video by scene transitions helps detect subtle deepfake inconsistencies.,video segmentation focusing on scene transitions and content shifts,"Passage states segmenting video and analyzing transitions reveals lighting, motion, and cut inconsistencies useful for deepfake defense.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
100812,116,half-true,Analyzing scene transitions reliably detects most deepfakes by exposing lighting and motion inconsistencies.,video segmentation focusing on scene transitions and content shifts,"Mixes correct cues (lighting, motion, cuts) with overstated reliability; passage suggests potential, not guaranteed success.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
100813,126,half-true,Autoregressive models always preserve fine-grained visual detail better than diffusion or GAN models.,"model comparison: autoregressive vs diffusion, GANs",Mixes correct claim about autoregressive order with incorrect visual-detail superiority versus diffusion/GANs.,"generative-ai,diffusion,gans",7,Generative AI
100814,126,TRUE,Diffusion models excel at tasks requiring fine-grained visual detail.,comparison between diffusion and autoregressive models,Passage explicitly notes superior performance on fine-grained visual detail for diffusion models versus autoregressive approaches.,"generative-ai,diffusion,gans",7,Generative AI
100815,126,mostly-true,Diffusion models generally produce finer visual detail than autoregressive models in image tasks.,comparison between diffusion and autoregressive models for visual detail,"Passage states diffusion excels at fine-grained visual detail while autoregressive models favor sequence order, a minor generalization omitted.","generative-ai,diffusion,gans",7,Generative AI
100816,4,TRUE,"Scaling AI involves increasing trust, reliability, and performance together.",AI Builder generative AI scaling of trust and reliability,"Passage explicitly ties scaling to trust, reliability, and performance when using generative AI.","mlops,scaling,deployment",10,AI At Scale
100817,4,half-true,AI builders can scale trust and reliability as effectively as raw performance when deploying generative models.,scaling trust and reliability in generative AI deployment,Mixes correct emphasis on trust with unsupported claim that trust scales equally to performance in deployments.,"mlops,scaling,deployment",10,AI At Scale
100818,4,mostly-true,"Scaling focuses on performance, trust, and reliability when deploying generative AI systems.",MLOps deployment and reliability for generative AI builders,Passage emphasizes scaling includes trust and reliability alongside performance; minor implementation caveats omitted.,"mlops,scaling,deployment",10,AI At Scale
100819,112,half-true,Publisher identification is as difficult as detecting fraud among many legitimate examples.,"dataset loading and encoding; publisher classification, fraudulent transactions",Accurately likens publisher identification to fraud detection but overstates equivalence of challenges and methods.,"machine-learning,classification,evaluation",4,Classical Machine Learning
100820,112,mostly-true,Encoding and tuning progressively reveal subtle signals that differentiate publishers within overlapping traits.,dataset loading and encoding for publisher classification,"Broadly supported by analogy to needle-in-haystack and tuning steps, omits specifics about features or methods.","machine-learning,classification,evaluation",4,Classical Machine Learning
100821,112,half-true,Publisher identification resembles detecting fraud hidden among many legitimate examples.,publisher identification task; dataset loading and encoding,Mixes correct analogy to fraud detection with overgeneralized equivalence of publisher identification specifics.,"machine-learning,classification,evaluation",4,Classical Machine Learning
100822,178,TRUE,Open-source tools enable full classical ML workflows on a laptop.,"tools like Scikit-learn, Pandas, and Matplotlib","Passage states those tools let individuals build, test, and deploy entire ML workflows.","machine-learning,classification,evaluation",4,Classical Machine Learning
100823,178,FALSE,Open-source tools make advanced deep neural network training trivial on a laptop.,tools like Scikit-learn and SHAP for model workflows,"Contradicts passage: it highlights classical ML tools, not deep neural network training or trivial laptop-scale training.","machine-learning,classification,evaluation",4,Classical Machine Learning
100824,178,FALSE,Open source tools eliminate any need for statistical feature selection in classification tasks.,Scikit-learn workflows and SHAP explainability,Contradicts passage: tools enable workflows and explainability but do not remove need for feature selection or statistical methods.,"machine-learning,classification,evaluation",4,Classical Machine Learning
100825,172,pants-fire,The example guarantees encrypted data is unrecoverable without the key forever.,Fernet encryption example for sensitive dataset,Contradicts code showing decryption with same key; assumes permanent irrecoverability despite explicit decrypt operation.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
100826,172,half-true,The example encrypts a sample dataset with Fernet but does not securely store the encryption key.,encrypting sensitive data example using Fernet and key generation,"Mixes correct detail (Fernet encryption) with omission (no key storage/rotation guidance), creating a half-true claim.","data-prep,feature-engineering,rag",3,Prepping Data for AI
100827,172,TRUE,The example encrypts sensitive patient data using Fernet symmetric encryption.,encrypting sensitive data with Fernet cipher suite,"Code shows Fernet.generate_key(), cipher usage, and encryption/decryption of patient dataset, directly supported.","data-prep,feature-engineering,rag",3,Prepping Data for AI
100828,2,half-true,Builders are portrayed as transformative AI innovators who convert openness into powerful tools.,audience guidance for builders using AI and open-source practices,Accurately reflects praise for builders and openness but overstates 'transformative' scale without evidence.,"ai,open-source,builder",1,Introduction – The Gold Rush Paradox
100829,2,TRUE,"Builders are the new AI superheroes, transforming curiosity into creation and openness into power.",introductory claim about builders and openness,Directly supported by passage praising builders and stating they turn curiosity and openness into power.,"ai,open-source,builder",1,Introduction – The Gold Rush Paradox
100830,2,mostly-true,The passage praises builders as essential drivers turning openness into AI power.,builders and openness in AI,Affirms builders as key agents converting openness into practical AI impact; minor nuance about trust and usage omitted.,"ai,open-source,builder",1,Introduction – The Gold Rush Paradox
100831,60,half-true,Inference time scales linearly with input token count in the synthetic prompt experiments.,measuring inference time vs. input length using synthetic prompts (LIAR replaced),"Experiment used repeated synthetic prompts, so linear scaling claim mixes plausible trend with unverified exactness.","mlops,scaling,deployment",10,AI At Scale
100832,60,TRUE,Inference time increases as input token length grows in the described experiments.,measuring inference time vs. input length using synthetic prompts and token counts,Experiment explicitly varied input token counts and measured how inference time changed with input length.,"mlops,scaling,deployment",10,AI At Scale
100833,60,half-true,The experiment used synthetic prompts that repeat a short sentence to test inference time scaling.,"measuring inference time vs. input length; synthetic prompts, token counts","Accurately describes method but omits that prompts replace LIAR dataset statements and target specific token counts, mixing detail levels.","mlops,scaling,deployment",10,AI At Scale
100834,133,half-true,Most scaling gains come from tooling and data packaging rather than model tuning alone.,"operationalizing with model cards, checkpoints, and logging","Correctly credits tooling and data packaging, but overstates by implying tuning is unimportant.","mlops,scaling,deployment",10,AI At Scale
100835,133,half-true,Packaging data and tooling changes alone can deliver most scaling improvements without model changes.,"operationalizing with checkpoints, logs, model cards, and data packaging",Mixes accurate emphasis on tooling and data with incorrect absolute claim that most scaling needs no model changes.,"mlops,scaling,deployment",10,AI At Scale
100836,133,TRUE,"Operational practices like packaging data, logging, and checkpoints enable significant scaling improvements.","operationalizing with checkpoints, logs, and model cards","Passage explicitly credits packaging data, tools, checkpoints, and logging with delivering substantial scaling and performance gains.","mlops,scaling,deployment",10,AI At Scale
100837,93,mostly-true,Normalizing inputs to zero mean and unit scale speeds up neural network learning.,transforms.Normalize mean and std for tensors,"Normalization centers inputs (e.g., subtract 0.5) and rescales by std, improving gradients and training speed.","deep-learning,frameworks,tensors",5,Deep Learning
100838,93,mostly-true,Normalizing inputs by subtracting the mean and dividing by std generally speeds neural network training.,transforms.Normalize mean and std for input tensors,Supported by explanation that centering around zero and scaling by std improves learning speed and gradient flow.,"deep-learning,frameworks,tensors",5,Deep Learning
100839,93,barely-true,Dividing by standard deviation always ensures gradients flow evenly during backpropagation.,data normalization using transforms.Normalize and std scaling,Overreaches the passage: std scaling helps but does not guarantee even gradient flow across architectures or layers.,"deep-learning,frameworks,tensors",5,Deep Learning
100840,23,half-true,Robby asserts open innovation should be repaid by continuous contributions to shared AI resources.,open-source contributors and shared AI resources,Mixes correct value alignment with an unsupported universal prescription that contributions must be continuous.,"open-source,community,contribution",13,Commit to Contribute
100841,23,TRUE,Robby believes sharing contributions keeps open innovation alive.,open-source contribution and community memory,Directly supported: passage states Robby recalled shared human contributions and wanted to keep that loop alive.,"open-source,community,contribution",13,Commit to Contribute
100842,23,TRUE,Robby credits open-source contributors for enabling today's AI advancements.,open innovation and contributors in AI landscape,Passage states Robby recalled open innovation and credited human contributors for enabling AI benefits.,"open-source,community,contribution",13,Commit to Contribute
100843,101,mostly-true,A voiceprint-based detector reliably distinguishes cloned speech from an authentic speaker in tests.,model predictions on cloned and authentic audio samples (voiceprint features),"Results show two cloned samples flagged while an authentic Jerry clip verified, minor generalization caveat.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
100844,101,pants-fire,The model always detects any voice clone with perfect certainty in every scenario.,voice cloning detection model predictions on cloned and authentic audio,"Claim contradicts reported scores and scope; experiments show high detection on two samples only, not universal guarantee.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
100845,101,mostly-true,Detection features can reliably differentiate cloned from authentic voices with minor caveats.,audio forensics using voiceprint features and model predictions,"Model results show cloned clips flagged and authentic clip verified, though thresholds and dataset generality omitted.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
100846,152,barely-true,Torchvision is required to run all PyTorch tensor operations and neural network modules.,"torch, torch.nn, torchvision packages and tensors","Overreaches: core torch provides tensor ops and torch.nn supplies modules; torchvision only adds datasets/transforms, not required for tensors.","deep-learning,frameworks,tensors",5,Deep Learning
100847,152,FALSE,Torchvision implements core tensor operations instead of torch.,torch and torchvision libraries for tensors and datasets,"Contradicts passage detail: core tensor ops provided by torch, torchvision supplies datasets/transformations.","deep-learning,frameworks,tensors",5,Deep Learning
100848,152,mostly-true,"PyTorch separates core tensor ops, neural network modules, optimizers, and vision datasets into distinct packages.","torch core, torch.nn, torch.optim, torchvision","Passage states tensor ops in core, nn for modules, optim for optimizers, torchvision for datasets; minor nuance about F omitted.","deep-learning,frameworks,tensors",5,Deep Learning
100849,149,mostly-true,Open-source frameworks give developers visibility into agentic AI reasoning and planning.,open-source frameworks like LangChain and CrewAI,"Frameworks explicitly enable insight into agent reasoning and planning, minor caveat about completeness.","agentic-ai,planning,tools",12,Agentic AI
100850,149,FALSE,Open-source frameworks always make agent reasoning fully understandable to users.,open-source frameworks like LangChain and CrewAI,Contradicts passage: frameworks increase visibility but do not guarantee full understandability or trust.,"agentic-ai,planning,tools",12,Agentic AI
100851,149,FALSE,Open-source frameworks completely eliminate opacity in agent reasoning and decision-making.,open-source frameworks like LangChain and CrewAI,Contradicts passage which says frameworks provide visibility but not complete elimination of opacity in agentic reasoning.,"agentic-ai,planning,tools",12,Agentic AI
100852,107,pants-fire,The Game Master autonomously used a web search API to control contestants' answers in real time.,web search tool access for Game Master,"Contradicts passage: Game Master could look up events, but contestants remained independent; no control or API-driven answer manipulation described.","agentic-ai,planning,tools",12,Agentic AI
100853,107,TRUE,Granting the Game Master a web search tool expanded external information access for the role.,tool access for Game Master (web search),"Passage states the Game Master could look up current events via a web search tool, enabling external information.","agentic-ai,planning,tools",12,Agentic AI
100854,107,mostly-true,Granting an agent web search access improves its performance but gives competitors less advantage.,Game Master web search tool and prompt design,"Passage indicates web search aided the Game Master while contestants relied on internal knowledge, minor nuance omitted.","agentic-ai,planning,tools",12,Agentic AI
100855,4,mostly-true,The passage encourages builders to create trustworthy AI by understanding how every component works.,audience: AI builders who understand model components,"Broadly supported: emphasizes builders' confidence and understanding of every part, minor nuance about risk reduction omitted.","ai,open-source,builder",1,Introduction – The Gold Rush Paradox
100856,4,mostly-true,"The passage endorses builders creating trustworthy, well-understood AI systems.",audience guidance for AI builders and trustworthy AI,"Supports encouragement for builders to create trustworthy, understandable AI; omits specific methods or tools.","ai,open-source,builder",1,Introduction – The Gold Rush Paradox
100857,48,mostly-true,Language models are useful for low-stakes data fill-in tasks like generating categorical features.,feature engineering for dataset augmentation using language models,Supports using LMs to auto-fill features with low risk; notes hallucination risk omitted as caveat.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
100858,48,barely-true,Language models reliably provide accurate factual data for high-stakes dataset fields.,using a language model; dataset field like Species,"Overstates reliability; passage warns models can hallucinate and are suited only for low-risk, noncritical fields.","data-prep,feature-engineering,rag",3,Prepping Data for AI
100859,48,half-true,A language model reliably fills low-stakes dataset fields by emulating web search summaries.,using LLMs for dataset feature completion (Species field),Mixes correct low-stakes suitability with incorrect certainty about reliability and web-search equivalence.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
100860,147,half-true,The example trains a full neural network on the MNIST dataset using a framework like PyTorch.,MNIST dataset and PyTorch framework,Accurately notes MNIST and PyTorch but overstates 'full' network specifics and training details omitted.,"deep-learning,frameworks,tensors",5,Deep Learning
100861,147,mostly-true,PyTorch can be used to train a neural network to recognize handwritten digits from MNIST.,training example using PyTorch and the MNIST dataset,Example explicitly uses PyTorch and MNIST to demonstrate implementing models and training workflows.,"deep-learning,frameworks,tensors",5,Deep Learning
100862,147,mostly-true,PyTorch can be used to implement and train neural networks for MNIST digit recognition.,example using PyTorch and the MNIST dataset,"Passage explicitly mentions frameworks like PyTorch and an example training a network on MNIST, omitting minor setup details.","deep-learning,frameworks,tensors",5,Deep Learning
100863,93,FALSE,LYNX is an open-source hallucination detection tool provided freely by Nature.,hallucination detection model LYNX from Patronus AI,"Contradicts passage detail: LYNX is from Patronus AI, not published by Nature or described as open-source; Nature referenced a different study.","security,red-team,guardrails",8,Breaking-Securing AI
100864,93,half-true,LYNX reliably detects all hallucinations in novel questions produced by large language models.,hallucination detection model LYNX from Patronus AI,"Overstates LYNX capabilities: passage describes LYNX giving likelihood scores but not perfect, universal detection.","security,red-team,guardrails",8,Breaking-Securing AI
100865,93,TRUE,LYNX detects hallucinations by scoring outputs' factuality with entropy-based uncertainty methods.,hallucination detection model LYNX and entropy-based estimators,Passage states LYNX evaluates factuality and mentions entropy-based uncertainty estimators for detecting confabulations.,"security,red-team,guardrails",8,Breaking-Securing AI
100866,66,half-true,Model responsiveness often degrades with longer inputs when GPU acceleration is unavailable.,"T5 inference latency by input length and device (input size, hardware)","Accurate about input length and missing GPU causing slowdown, but omits cache/bandwidth and parallelism nuances.","mlops,scaling,deployment",10,AI At Scale
100867,66,half-true,Model inference slows significantly with longer inputs when GPU acceleration is unavailable.,inference time by input length and device; T5 model,"Partly correct about input length and GPU absence, but overstates universality without hardware specifics.","mlops,scaling,deployment",10,AI At Scale
100868,66,half-true,Model responsiveness can degrade significantly with larger inputs when GPU acceleration is absent.,T5 inference time by input length and device; GPU acceleration,Accurately notes slower performance without GPUs but overstates inevitability and magnitude across all setups.,"mlops,scaling,deployment",10,AI At Scale
100869,77,barely-true,Fine-tuning a GAN often causes it to forget previously learned shapes like circles.,catastrophic forgetting in GAN fine-tuning,Describes forgetting example in passage; overgeneralizes frequency and severity across all multi-class scenarios.,"generative-ai,diffusion,gans",7,Generative AI
100870,77,half-true,Fine-tuning a GAN can cause it to lose earlier learned patterns like circles.,"catastrophic forgetting in GAN fine-tuning, generator behavior",Describes correct phenomenon but omits conditions and extent; mixes generalization with a specific circle example.,"generative-ai,diffusion,gans",7,Generative AI
100871,77,pants-fire,"GAN fine-tuning always erases all previously learned classes, making models useless for any prior tasks.",catastrophic forgetting in GAN fine-tuning for multi-class image generation,"Passage describes forgetting of some patterns (circles to slashes) but not that fine-tuning invariably erases all classes; claim is an extreme, implausible contradiction.","generative-ai,diffusion,gans",7,Generative AI
100872,24,half-true,Relying on opaque Big AI reduces user ownership of data and explainability while offering convenience.,choosing AI tools; opaque systems versus transparent smaller models,Mixes accurate tradeoff claim with implied universality; omits specific exceptions and quantification.,"ai,open-source,builder",1,Introduction – The Gold Rush Paradox
100873,24,barely-true,"Builders should always prefer transparent, small AI systems over opaque Big AI for all tasks.",choice between Big AI and smaller transparent systems,"Overreaches passage guidance; passage recommends choosing per task, not always preferring small transparent models.","ai,open-source,builder",1,Introduction – The Gold Rush Paradox
100874,24,half-true,Relying on opaque big AI reduces user control over data and methods.,tradeoff between Big AI and transparent systems in AI model selection,"Matches passage claim that opaque systems diminish ownership of data, methods, and explainability.","ai,open-source,builder",1,Introduction – The Gold Rush Paradox
100875,78,mostly-true,AI ethics frameworks for agentic systems will be developed rapidly through collaborative industry efforts.,framework for agentic AI; ethics governance,"Optimism backed by past decade learning supports collaborative, faster framework development, minor timing caveat.","ethics,governance,privacy",11,AI Ethics and Governance
100876,78,barely-true,IBM is developing a robust framework for agentic AI entirely on its own.,collaboration with Microsoft or Google; agentic AI framework,Contradicts passage implication of external collaboration; passage questions isolation versus collaboration.,"ethics,governance,privacy",11,AI Ethics and Governance
100877,78,FALSE,IBM is developing agentic AI ethics frameworks entirely alone without any external collaboration.,collaboration with companies like Microsoft or Google,Directly contradicts mention of collaboration queries; passage indicates collaboration with other companies is discussed.,"ethics,governance,privacy",11,AI Ethics and Governance
100878,128,barely-true,Gradient boosting always outperforms a majority-class baseline on classification tasks.,HistGradientBoostingClassifier baseline model evaluation,"Overreaches: passage only uses gradient boosting as a first real model without tuning, not proving consistent outperformance.","machine-learning,classification,evaluation",4,Classical Machine Learning
100879,128,half-true,The initial model is an untuned HistGradientBoostingClassifier that slightly outperforms a majority-class baseline.,training a HistGradientBoostingClassifier model against majority-class baseline,"Correct that the model is untuned and compared to a majority baseline, but no performance evidence provided.","machine-learning,classification,evaluation",4,Classical Machine Learning
100880,128,half-true,The HistGradientBoostingClassifier will always outperform the majority-class baseline without hyperparameter tuning.,training a HistGradientBoostingClassifier on a dataset baseline,"Partly true: boosting typically beats majority baselines, but no-tuning performance can match or underperform depending on data and defaults.","machine-learning,classification,evaluation",4,Classical Machine Learning
100881,171,barely-true,The example claims encrypted healthcare data becomes irrecoverable if the Fernet key is lost.,Fernet encryption of a sample healthcare dataset,Overreaches by implying irreversible loss universally; passage notes real apps require proper key management and recovery practices.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
100882,171,mostly-true,Encrypting healthcare data before storage secures it provided encryption keys are properly managed.,Fernet encryption of a sample healthcare dataset,"Demonstrated encryption protects data but example omits key management, risking irrecoverability.","data-prep,feature-engineering,rag",3,Prepping Data for AI
100883,171,barely-true,Encrypting healthcare datasets with Fernet guarantees data recovery even without key management.,example using Fernet encryption on a healthcare dataset,"Contradicts passage: example explicitly warns lost keys prevent recovery, so recovery isn't guaranteed.","data-prep,feature-engineering,rag",3,Prepping Data for AI
100884,79,barely-true,Elastic Weight Consolidation fully prevents catastrophic forgetting in generative models.,"catastrophic forgetting, replay buffers, Elastic Weight Consolidation (EWC)",Overstates effectiveness: passage lists EWC as a potential solution but calls methods limited and not detailed.,"generative-ai,diffusion,gans",7,Generative AI
100885,79,barely-true,Generative diffusion models avoid catastrophic forgetting without replay buffers or EWC.,"catastrophic forgetting, replay buffers, Elastic Weight Consolidation (EWC)","Overreaches: passage lists replay buffers and EWC as solutions, so claim that diffusion models avoid forgetting contradicts recommended remedies.","generative-ai,diffusion,gans",7,Generative AI
100886,79,TRUE,Replay buffers and Elastic Weight Consolidation help mitigate catastrophic forgetting in continual training.,"catastrophic forgetting mitigation methods (replay buffers, EWC)","Passage explicitly lists replay buffers, EWC, and mixed-data continual training as potential solutions to forgetting.","generative-ai,diffusion,gans",7,Generative AI
100887,126,pants-fire,Kilauea's 2021 eruption produced lava fountains over 300 feet high.,volcanic eruption report mentioning Kilauea and lava fountain heights,Contradicts known eruption details: 2021 Kilauea did not produce reliably 300+ foot fountains; overstates observed heights.,"agentic-ai,planning,tools",12,Agentic AI
100888,126,half-true,The passage claims Kilauea erupted in 2021 with lava fountains over 300 feet high.,"final answer about a volcanic eruption (Kilauea, lava fountains)",Combines correct volcano name with incorrect year and unverified fountain height; mixed accurate and wrong specifics.,"agentic-ai,planning,tools",12,Agentic AI
100889,126,half-true,The passage correctly identifies Kilauea as an active volcano linked to high lava fountains.,natural event; Kilauea volcano; eruption year,"Mixes correct volcano identification with incorrect eruption timing—Kilauea fountains peaked in earlier eruptions, not specifically 2021.","agentic-ai,planning,tools",12,Agentic AI
100890,43,pants-fire,Decision trees always perfectly memorize every superhero dataset instance without error.,decision tree model on superhero dataset,"Asserts perfect memorization always occurs, contradicting passage which warns trees can overfit but not inevitably always memorize.","machine-learning,classification,evaluation",4,Classical Machine Learning
100891,43,barely-true,Decision trees always provide more transparency than logistic regression for every dataset.,model comparison between decision trees and logistic regression,Overstates universality: passage praises tree transparency but notes tradeoffs like overfitting and dataset dependence.,"machine-learning,classification,evaluation",4,Classical Machine Learning
100892,43,half-true,Decision trees often sacrifice accuracy for transparency on complex datasets.,decision tree model on superhero dataset,"Accurate that trees offer transparency, but overstates general accuracy loss versus alternatives like logistic regression.","machine-learning,classification,evaluation",4,Classical Machine Learning
100893,58,barely-true,The code uses a Dense layer with ten output neurons for classification tasks.,Dense(10) layer in TensorFlow Keras model,"Partly supported: Dense(10) exists, but passage omits activation, dataset, and classification specifics, overstating purpose.","deep-learning,frameworks,tensors",5,Deep Learning
100894,58,mostly-true,The example compiles a Keras model using SGD optimizer and sparse categorical crossentropy loss.,Keras model.compile with optimizer 'sgd' and SparseCategoricalCrossentropy,"Example shows model.compile configured with optimizer='sgd' and SparseCategoricalCrossentropy(from_logits=True), omitting dataset or training details.","deep-learning,frameworks,tensors",5,Deep Learning
100895,58,FALSE,The model uses a convolutional layer as its first layer.,Keras Sequential model with Flatten and Dense layers,Passage shows Flatten then Dense layers; no convolutional (Conv2D) layer is present.,"deep-learning,frameworks,tensors",5,Deep Learning
100896,118,half-true,The YOLOv5 detection pipeline always outputs perfectly accurate bounding boxes and confidence scores for every frame.,object detection using YOLOv5 on Jerry-Jose-SampleVideo01.mp4,"Passage describes YOLOv5 annotations and adjustable parameters, but claims of perfect accuracy are unsupported.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
100897,118,barely-true,The YOLOv5 model reliably detects and labels all objects in the sample video without errors.,object detection using YOLOv5 on Jerry-Jose-SampleVideo01.mp4,"Passage only describes detection and annotation; claiming flawless, complete detection overreaches given noted adjustable parameters.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
100898,118,TRUE,The video frames were processed with YOLOv5 to detect objects and produce an annotated output file.,object detection on Jerry-Jose-SampleVideo01.mp4 using YOLOv5,Passage explicitly describes running YOLOv5 on each frame and creating an annotated video with bounding boxes and labels.,"media-forensics,voice-cloning,deepfake",9,Deepfake Defense
100899,40,barely-true,The passage claims missing Height and Weight are filled with species-specific averages without rescaling.,data-prep: missing value imputation for dataset fields Height and Weight,Largely unsupported because using species averages ignores distributional bias and uncertainty estimates.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
100900,40,barely-true,The passage claims species averages reliably fill missing Height and Weight without rescaling.,"dataset missing values, Species, Height and Weight fields",Overreaches: averaging ignores potential within-species variance and uncertainty; notable estimation assumptions omitted.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
100901,40,mostly-true,Imputing missing height and weight by species averages reduces missingness while preserving units.,"dataset preprocessing, missing value imputation for Height and Weight fields",Approach is supported: averaging per species fills gaps and units remain consistent; omits potential bias or variance issues.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
100902,136,barely-true,Adam always outperforms SGD on all deep learning tasks due to per-parameter adaptive step sizes.,optimizer behavior for gradients (Adam vs SGD),Overstates claim: passage describes adaptive advantages but provides no evidence of universal superiority across tasks.,"deep-learning,frameworks,tensors",5,Deep Learning
100903,136,TRUE,Adam adaptively adjusts per-parameter step sizes using gradient history.,optimizer behavior with adaptive learning rates (Adam vs SGD),Passage explains Adam tracks recent gradient directions and past update scales to set individual step sizes.,"deep-learning,frameworks,tensors",5,Deep Learning
100904,136,pants-fire,Adam always finds the global minimum for every neural network training problem.,optimization algorithm Adam in deep-learning,Contradicts known limitations: Adam adapts per-parameter steps but does not guarantee global minima for nonconvex neural network loss landscapes.,"deep-learning,frameworks,tensors",5,Deep Learning
100905,38,barely-true,PyTorch cannot perform high-level training abstractions like Keras and only supports manual training loops.,"training APIs and GradientTape, Keras, .backward(), optimizer.step()","Overreaches: passage says PyTorch offers manual control but contrasts TensorFlow+Keras high-level options, not claiming PyTorch lacks any abstractions.","deep-learning,frameworks,tensors",5,Deep Learning
100906,38,half-true,PyTorch requires manual gradient calls while TensorFlow cannot perform manual gradient control.,training loops with .backward() and GradientTape,Mixes correct PyTorch detail with incorrect TensorFlow claim; TensorFlow also supports manual GradientTape.,"deep-learning,frameworks,tensors",5,Deep Learning
100907,38,barely-true,PyTorch requires manual gradient computation and weight updates for all training workflows.,training loop and .backward() in PyTorch examples,Overstates requirement: passage shows PyTorch gives control but not that all workflows must be manual; contrasts TensorFlow's high-level Keras.,"deep-learning,frameworks,tensors",5,Deep Learning
100908,29,pants-fire,RNNs always outperform transformers on all language tasks by capturing sequence dependencies better.,RNNs for sequences in language modeling,"Contradicts established results: transformers generally outperform RNNs on many language tasks, especially large-scale modeling and long-range dependencies.","neural-networks,cnn,transformers",6,Neuron Building Blocks
100909,29,half-true,Recurrent neural networks are ideal for all sequence tasks including language and music generation.,"RNNs for sequences, language modeling and music generation",Accurately notes RNNs suit sequential data but overstates 'all' sequence tasks versus newer models like Transformers.,"neural-networks,cnn,transformers",6,Neuron Building Blocks
100910,29,TRUE,Recurrent neural networks are well-suited to modeling sequential data where later elements depend on earlier ones.,"RNNs for sequence modeling (language, next-word prediction)","Passage explicitly states RNNs are designed for sequences and ideal when next depends on previous, mentioning language and next-word prediction.","neural-networks,cnn,transformers",6,Neuron Building Blocks
100911,164,mostly-true,Transformer language embeddings can drive diffusion-based video synthesis in real time.,video synthesis pipeline using Transformer embeddings and diffusion models,Describes supported mechanism: Transformers produce embeddings that steer diffusion models for frame-by-frame video generation; minor caveat about implementation details omitted.,"generative-ai,diffusion,gans",7,Generative AI
100912,164,half-true,Transformer text embeddings drive diffusion synthesis to produce coherent video frames during iterations.,video synthesis using diffusion models and Transformer embeddings,"Accurately captures cross-modal use of Transformer embeddings with diffusion, but overstates that embeddings alone fully 'drive' synthesis without noting sanitation and compilation steps.","generative-ai,diffusion,gans",7,Generative AI
100913,164,half-true,The described system mixes diffusion and Transformer embeddings to synthesize video frames from text.,video synthesis using diffusion and Transformer language embeddings,"Accurate about combining diffusion and Transformers, but omits specifics about sanitation and MP4 encoding steps.","generative-ai,diffusion,gans",7,Generative AI
100914,39,half-true,"The interview claims AI-curated, verified statements fully replace human editorial judgment.",AI-curated verified statements in interview on generative tools,Mixes correct elements (AI curation and verification mentioned) with incorrect absolute claim about replacing human judgment.,"open-source,community,ai",0,Foreword – Robo Interviews Clément Delangue
100915,39,half-true,The interview claims AI-curated verified statements fully replace human editorial judgment.,AI curation of verified statements in generative tools,Combines correct claim of AI curation with incorrect assertion that it fully replaces human editorial judgment.,"open-source,community,ai",0,Foreword – Robo Interviews Clément Delangue
100916,39,half-true,The interview claims AI-curated verified statements can extend but not replace human thought.,AI-curated verified statements in generative tools,Mixes correct idea of augmenting human thought with an overclaim that curation guarantees verification and non-replacement without caveats.,"open-source,community,ai",0,Foreword – Robo Interviews Clément Delangue
100917,30,half-true,The passage claims visual inspection alone suffices to fully prepare a dataset for model training.,"data cleaning, dataset (superheroes_info), visual inspection",Mixes correct emphasis on visual inspection with incorrect claim that no further data-driven cleaning is needed.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
100918,30,barely-true,Intuition and visual inspection are sufficient to fully clean datasets before modeling.,"analyzing the dataset for cleaning, superheroes_info dataset, data-driven analysis","Overreaches: passage recommends intuition first then transition to data-driven methods, not sole reliance.","data-prep,feature-engineering,rag",3,Prepping Data for AI
100919,30,half-true,The author claims visual inspection alone suffices to fully prepare datasets for model-ready feature engineering.,"dataset cleaning, visual inspection, superheroes_info",Correctly emphasizes visual inspection but incorrectly implies it fully replaces data-driven analysis and imputation.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
100920,2,half-true,High-fidelity audio recordings today can be indistinguishable from authentic live performances to many listeners.,audio authenticity and voice-cloning in media-forensics,"Correctly notes modern fidelity and listener confusion, but overstates indistinguishability without evidence or metrics.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
100921,2,mostly-true,Advances in AI have shifted authenticity concerns from fidelity to whether media is genuine.,audio/video authenticity and Memorex-era fidelity example,Passage links AI progress to changing focus from high-fidelity reproduction to assessing media authenticity; minor nuance about specific techniques omitted.,"media-forensics,voice-cloning,deepfake",9,Deepfake Defense
100922,2,TRUE,Deepfake detection focuses on verifying whether audio or video media are genuinely authentic.,"audio and video authenticity, Memorex analogy and media-forensics","Passage draws analogy between Memorex fidelity and modern need to determine media authenticity, supporting detection focus.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
100923,74,TRUE,Varying PCA component count reveals cumulative variance increases progressively.,"PCA cumulative variance for principal components (10,20,40,60,80)","Numeric cumulative variance examples (26%,40%,59%,73%,83%) directly support progressive increase.","machine-learning,classification,evaluation",4,Classical Machine Learning
100924,74,half-true,Preserving 80 principal components retains about 83% of cumulative variance in the example.,principal components cumulative variance (PCA) on dataset,Example numbers mix correct trend with specific dataset values; claim matches reported 80→83% but may not generalize.,"machine-learning,classification,evaluation",4,Classical Machine Learning
100925,74,pants-fire,PCA always preserves over 90% variance with 80 components on all datasets.,principal components cumulative variance in PCA analysis,"Claim directly contradicts provided variances (83% at 80 components), unrealistic universal guarantee across datasets.","machine-learning,classification,evaluation",4,Classical Machine Learning
100926,191,TRUE,Setting model.eval() switches a deep learning model to evaluation mode before testing.,evaluation mode and test dataset using model.eval(),Directly supported by passage stating evaluation occurs on unseen test data and model.eval() sets evaluation mode.,"deep-learning,frameworks,tensors",5,Deep Learning
100927,191,pants-fire,Model.eval() trains the deep neural network during testing to further adjust parameters.,evaluation mode and model.eval() during test dataset evaluation,Directly contradicts passage which says eval() sets evaluation mode and training loop adjusts parameters.,"deep-learning,frameworks,tensors",5,Deep Learning
100928,191,TRUE,Model evaluation uses a held-out test dataset and model.eval() to assess performance.,evaluating accuracy on test dataset and model.eval(),Passage states evaluation occurs on a test dataset unseen during training and calls model.eval() for evaluation mode.,"deep-learning,frameworks,tensors",5,Deep Learning
100929,74,mostly-true,Layered defenses using open-source guardrails help mitigate prompt-injection vulnerabilities in chatbots.,Gandalf-Style Guardrails for prompt injection testing,"Passage endorses layered defenses and Gandalf-style guardrails, but omits limits and residual risks.","security,red-team,guardrails",8,Breaking-Securing AI
100930,74,half-true,Gandalf-Style Guardrails alone can fully prevent prompt injection and unsafe tool actions.,Gandalf-Style Guardrails open-source tool for prompt injection testing,"Passage endorses layered defenses and Gandalf for stress-testing, not sole, complete prevention.","security,red-team,guardrails",8,Breaking-Securing AI
100931,74,mostly-true,A layered defense using open-source guardrails helps mitigate prompt injection vulnerabilities in chatbots.,Gandalf-Style Guardrails for prompt injection testing,Passage endorses layered defenses and Gandalf-Style Guardrails but omits deployment complexity and limits.,"security,red-team,guardrails",8,Breaking-Securing AI
100932,0,half-true,AI systems sometimes produce inaccurate or misleading outputs despite their power.,AI ethics and governance discussion about AI outputs,"Passage explicitly notes AI generates inaccurate or misleading outputs while stressing responsibility, mixing correct and general claim details.","ethics,governance,privacy",11,AI Ethics and Governance
100933,0,half-true,AI systems frequently generate misleading outputs and therefore require governance frameworks.,"AI ethics and governance, model outputs and responsibility",Acknowledges documented tendency for inaccurate outputs but overstates frequency and presumes specific governance solutions.,"ethics,governance,privacy",11,AI Ethics and Governance
100934,0,half-true,AI systems frequently produce inaccurate or misleading outputs without proper governance.,AI ethics and governance; model outputs and responsibility,Passage notes AI can generate inaccurate or misleading outputs but omits frequency and scale specifics.,"ethics,governance,privacy",11,AI Ethics and Governance
100935,67,barely-true,The cloned voice sample usually fools the logistic-regression detector identifying Jerry.,voice cloning evaluation using logistic-regression model,Passage only describes generating and comparing samples; it gives no evidence that the detector is usually fooled.,"media-forensics,voice-cloning,deepfake",9,Deepfake Defense
100936,67,mostly-true,The fine-tuned model can synthesize cloned speech evaluated against originals using a logistic-regression model.,voice cloning pipeline using fine-tuned model and logistic-regression detector,"Procedure describes generating cloned samples and comparing with a logistic-regression identity model, omitting evaluation metrics.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
100937,67,mostly-true,Fine-tuned voice models can produce cloned speech that largely matches the original speaker's voice.,voice-cloning fine-tuned model and logistic-regression model,"Procedure describes synthesizing speech with a fine-tuned model and testing with logistic-regression, supporting close but not perfect matches.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
100938,86,FALSE,A diffusion model's encoder deterministically maps images to a single fixed latent vector.,latent space and encoder in diffusion models,"Passage describes a probabilistic latent space and distributional encoding, contradicting deterministic mapping.","generative-ai,diffusion,gans",7,Generative AI
100939,86,TRUE,A variational autoencoder encodes images into a probabilistic latent space of latent variables.,encoder-decoder using probabilistic latent space (latent variables),Passage states encoder compresses images into a probabilistic latent space using latent variables representing distributions.,"generative-ai,diffusion,gans",7,Generative AI
100940,86,barely-true,The encoder compresses images into a low-dimensional probabilistic latent space of a few numbers.,encoder compressing images into probabilistic latent space (latent variables),"Passage describes encoder mapping images to a probabilistic latent space, but 'few numbers' overstates dimensionality specifics.","generative-ai,diffusion,gans",7,Generative AI
100941,119,barely-true,Models can always scale to any production use case using the same tools.,deployment and MLOps for hosted API and local scripts,Overreaches claim: passage says tools carry forward but doesn't guarantee unlimited scaling or suitability.,"mlops,scaling,deployment",10,AI At Scale
100942,119,TRUE,Operationalizing a model by exposing it via scripts or a hosted API enables real-world use and testing.,model deployment via hosted API or local scripts,Passage explicitly says exposing models through scripts or hosted APIs moves them into real environments for testing and use.,"mlops,scaling,deployment",10,AI At Scale
100943,119,pants-fire,The passage claims models deployed via local scripts or hosted APIs will always scale indefinitely without limits.,deployment via hosted API or local scripts (model operationalizing),"Contradicts scalability realities: resource limits, infrastructure, and use-case constraints prevent indefinite scaling.","mlops,scaling,deployment",10,AI At Scale
100944,127,mostly-true,The baseline classifier's macro-F1 was low and dominated by the majority class.,"baseline model evaluation, macro-F1 metric on dataset","Passage reports a 0.39 macro-F1 and notes heavy majority-class bias, a minor caveat omitted.","machine-learning,classification,evaluation",4,Classical Machine Learning
100945,127,TRUE,The baseline classifier achieved about 50% accuracy and a macro-F1 of 0.39.,"evaluation metrics for baseline model (macro-F1, accuracy)",Directly supported by passage reporting ~50% accuracy and macro-F1 = 0.39 indicating majority-class bias.,"machine-learning,classification,evaluation",4,Classical Machine Learning
100946,127,TRUE,The baseline classifier achieved approximately 50% accuracy and a macro-F1 of 0.39.,baseline model evaluation on dataset using macro-F1 metric,"Reported numbers indicate near-chance accuracy (~50%) and a low macro-F1 (0.39), showing majority-class bias.","machine-learning,classification,evaluation",4,Classical Machine Learning
100947,120,half-true,OneHotEncoder always produces exactly three new columns for categorical features.,feature preprocessing with OneHotEncoder and Alignment column,"Correct about OneHotEncoder creating indicator columns, but wrong to claim it always makes three columns; depends on categories present.","machine-learning,classification,evaluation",4,Classical Machine Learning
100948,120,pants-fire,The dataset contains entirely fabricated numeric and text features with no real-world basis.,feature preparation for OneHotEncoder and SimpleImputer,Asserting features are fabricated wildly contradicts described real preprocessing steps like median imputation and category encoding.,"machine-learning,classification,evaluation",4,Classical Machine Learning
100949,120,mostly-true,OneHotEncoder and median imputation are used to preprocess categorical and numeric features respectively.,"feature preparation for model training (OneHotEncoder, SimpleImputer, median)",Describes exact preprocessing steps mentioned; minor caveat omitted about handling unseen categories or scaling.,"machine-learning,classification,evaluation",4,Classical Machine Learning
100950,19,half-true,"Hugging Face claims broad adoption of its open-source tools across diverse organizations, but specifics are overstated.",community adoption of Transformers and Spaces tools,"Passage cites adoption by researchers, indie devs, big organizations, governments, and institutions but gives no detailed evidence or numbers, mixing accurate community growth with vague, overstated scope.","open-source,community,ai",0,Foreword – Robo Interviews Clément Delangue
100951,19,TRUE,Hugging Face champions open-source tools and a collaborative community around AI models.,"Hugging Face ecosystem: Spaces, Transformers, evaluation benchmarks","Passage cites Spaces and Transformers adoption and emphasizes community collaboration and tooling, directly supporting this claim.","open-source,community,ai",0,Foreword – Robo Interviews Clément Delangue
100952,19,barely-true,Hugging Face's open-source tools have become the dominant choice for most developers working with LLMs.,Transformers library and Spaces deployment tools in the ecosystem,"Passage claims wide adoption and de facto status for Transformers, but dominance for most developers is overstated.","open-source,community,ai",0,Foreword – Robo Interviews Clément Delangue
100953,109,half-true,The design fully prevents data poisoning and bias across all training datasets and components.,Training & Source Data and Supply Chain (AI BOMs),Mixes correct intent—preemptive elimination efforts—with an overstated guarantee; passage notes mitigation not absolute.,"security,red-team,guardrails",8,Breaking-Securing AI
100954,109,TRUE,"Human-in-the-loop sign-off is required for critical, high-risk AI functions.",HumanLayer execution control and HITL sign-off,"Passage explicitly mandates human sign-off on critical, high-risk functions like HumanLayer.","security,red-team,guardrails",8,Breaking-Securing AI
100955,109,half-true,Human-in-the-loop sign-off always prevents high-risk AI failures during real-world actions.,HumanLayer HITL sign-off for critical real-world actions,"Accurate that HITL requires sign-off, but overstates guarantee; human approval reduces risk without ensuring prevention.","security,red-team,guardrails",8,Breaking-Securing AI
100956,115,TRUE,The model can adapt its responses to different languages when instructed.,language adaptation example using system prompt and Spanish output,Spanish reply shown demonstrates prompt-driven multilingual adaptation and successful language switching.,"ai,tool-chain,notebooks",2,AI Survival Kit
100957,115,half-true,The model reliably answers factual questions correctly after switching system language instructions.,instruction prompt switching (system message) and multilingual response,"Model adapts to language but may still produce incorrect facts, so accuracy isn't guaranteed.","ai,tool-chain,notebooks",2,AI Survival Kit
100958,115,half-true,The model reliably produces accurate factual answers when asked to switch languages.,multilingual prompt handling in model responses,Mixes correct multilingual adaptation with incorrect claim of reliable factual accuracy; example shows adaptation but not verification.,"ai,tool-chain,notebooks",2,AI Survival Kit
100959,23,barely-true,"A pretrained ResNet50 will reliably identify hand gestures like rock, paper, and scissors without fine-tuning.",ResNet50 pretrained on ImageNet applied to rock_paper_scissors dataset,Overstates performance: passage notes surprising good predictions but not guaranteed reliability or absence of fine-tuning.,"neural-networks,cnn,transformers",6,Neuron Building Blocks
100960,23,mostly-true,Pretrained ResNet50 can generalize to classify rock–paper–scissors images with reasonable accuracy.,transfer learning with ResNet50 on Rock-Paper-Scissors dataset,"Model's ImageNet-trained features support good predictions, omitting dataset-specific fine-tuning details.","neural-networks,cnn,transformers",6,Neuron Building Blocks
100961,23,barely-true,"A ResNet50 pretrained on ImageNet will reliably recognize rock, paper, and scissors gestures without fine-tuning.",ResNet50 pretrained on ImageNet applied to rock_paper_scissors dataset,Overstates capability: pretrained ResNet50 may help but lacks dataset-specific fine-tuning for reliable gesture recognition.,"neural-networks,cnn,transformers",6,Neuron Building Blocks
100962,23,FALSE,RAG always exposes sensitive documents regardless of access controls.,RAG retrieval layer lacking robust access checks,"Contradicts passage stating exposure occurs when access checks are absent, not always.","security,red-team,guardrails",8,Breaking-Securing AI
100963,23,TRUE,RAG systems can expose sensitive internal documents when retrieval lacks access checks.,RAG retrieval from internal document stores or customer knowledge bases,Passage describes RAG crawling internal stores and returning documents if backend access controls are missing.,"security,red-team,guardrails",8,Breaking-Securing AI
100964,23,TRUE,A RAG system can expose sensitive internal documents when retrieval lacks access controls.,RAG retrieval from internal document stores or customer knowledge bases,"Passage explicitly describes RAG returning documents without robust access checks, enabling unauthorized data exposure.","security,red-team,guardrails",8,Breaking-Securing AI
100965,29,FALSE,Hugging Face excludes community contributions and restricts AI tools to internal teams.,Hugging Face community and tools for AI builders,Passage emphasizes openness and 7 million AI builders contributing; claim directly contradicts inclusivity and public tooling.,"open-source,community,ai",0,Foreword – Robo Interviews Clément Delangue
100966,29,TRUE,Hugging Face prioritizes open community tools enabling millions of AI builders to contribute.,Hugging Face platform and community (7 million AI builders),Passage states Hugging Face provides tools and counts 7 million AI builders contributing to community efforts.,"open-source,community,ai",0,Foreword – Robo Interviews Clément Delangue
100967,29,mostly-true,Hugging Face enables millions of open-source AI builders to contribute through shared tools and collaboration.,community and open-source tools at Hugging Face,"Broadly supported by the passage claiming 7 million AI builders and emphasis on tools, transparency, and collaboration, though exact impact details are omitted.","open-source,community,ai",0,Foreword – Robo Interviews Clément Delangue
100968,19,half-true,Open-source image generation is dominated by diffusion and GAN architectures.,model types: Diffusion Models and Generative Adversarial Networks (GANs),Accurately reflects passage but omits nuance about commercial scale and other image approaches.,"generative-ai,diffusion,gans",7,Generative AI
100969,19,mostly-true,Open-source generative models prioritize transparency and community-driven innovation over raw scale.,"open-source models, Diffusion models and GANs in image generation","Passage emphasizes transparency, flexibility, and community innovation while acknowledging smaller scale compared to commercial models.","generative-ai,diffusion,gans",7,Generative AI
100970,19,FALSE,Diffusion models are rarely used for image generation in open-source projects.,image generation and Diffusion models,"Contradicts passage stating image generation is dominated by Diffusion and GAN architectures, so claim is false.","generative-ai,diffusion,gans",7,Generative AI
100971,119,half-true,Sharing a single Crew can leak Judge-only answers into player contexts during execution.,"execution space with Game Master, Players, and Judge",Accurately notes context leak mechanism but overstates inevitability and ignores mitigations.,"agentic-ai,planning,tools",12,Agentic AI
100972,119,barely-true,The shared Crew allowed players to access the Judge's secret answer through context leakage.,execution space / Crew setup causing context leak,Overstates certainty and impact; passage says leakage occurred but not that players accessed Judge's secret universally.,"agentic-ai,planning,tools",12,Agentic AI
100973,119,half-true,Placing all agents in one Crew always causes confidential answers to leak into players' contexts.,multi-agent Crew execution space with Judge and Players,"Correctly links single execution space to leaks, but overgeneralizes 'always' and omits mitigation possibilities.","agentic-ai,planning,tools",12,Agentic AI
100974,49,half-true,Whisper's small model reliably transcribes speech into text for downstream voice synthesis tasks.,Whisper small model transcription to feed voice synthesis,"Accurately notes transcription and use with synthesis, but overstates reliability and excludes model limits and errors.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
100975,49,half-true,Whisper's small model reliably produces punctuation and translations from audio for voice-cloning workflows.,Whisper small model transcription for voice synthesis and comparison,Accurately notes punctuation and translation abilities but overstates reliability and workflow sufficiency.,"media-forensics,voice-cloning,deepfake",9,Deepfake Defense
100976,49,mostly-true,Whisper's smaller model can transcribe speech into text for later voice-synthesis tasks.,Whisper smaller model transcription for voice synthesis pipeline,Supported by passage: describes using Whisper's smaller model to transcribe audio into text for subsequent synthesis and comparison exercises.,"media-forensics,voice-cloning,deepfake",9,Deepfake Defense
100977,28,FALSE,The project used proprietary closed-source tools rather than open-source frameworks.,glossary compilation using open-source CrewAI agents,Contradicts passage detail: CrewAI and other projects described as open-source tools.,"open-source,community,contribution",13,Commit to Contribute
100978,28,half-true,The authors used autonomous agents with CrewAI to compile a glossary of open-source projects.,glossary compilation using CrewAI autonomous agents,"Accurate that a squad of agents using CrewAI was used, but implies sole method and excludes manual or other tooling.","open-source,community,contribution",13,Commit to Contribute
100979,28,FALSE,The authors assembled the glossary entirely by hand without any AI assistance.,glossary creation using CrewAI and open-source agents,Contradicts passage detail that CrewAI autonomous agents and open-source AI handled glossary compilation.,"open-source,community,contribution",13,Commit to Contribute
100980,2,barely-true,Clément Delangue single-handedly built Hugging Face into the world's primary open-source AI platform.,Hugging Face open-source AI platform,"Greatly overstates individual credit; passage credits Delangue but omits community, scientists, developers, and contributors.","open-source,community,ai",0,Foreword – Robo Interviews Clément Delangue
100981,2,mostly-true,"Clément Delangue helped move AI toward an open, collaborative platform through Hugging Face.",Hugging Face open-source AI platform and community,"Passage credits Delangue and Hugging Face for making AI accessible and collaborative, omitting specific metrics or examples.","open-source,community,ai",0,Foreword – Robo Interviews Clément Delangue
100982,2,half-true,Clément Delangue overstated Hugging Face's role in moving AI into a shared open-source space.,Hugging Face open-source AI platform and community,Mixes accurate praise of community openness with implied exaggeration about singular influence.,"open-source,community,ai",0,Foreword – Robo Interviews Clément Delangue
100983,153,TRUE,AI poses real risks but also has effective countermeasures available.,"breaking-securing AI, red-team and guardrails discussion","Passage explicitly acknowledges real threats while affirming countermeasures exist, no panic urged.","security,red-team,guardrails",8,Breaking-Securing AI
100984,153,TRUE,AI security risks are real but effective countermeasures also exist.,"security, red-team, guardrails discussion",Passage affirms real threats from red-team-style attacks while stating countermeasures are available.,"security,red-team,guardrails",8,Breaking-Securing AI
100985,153,TRUE,AI risks are real but mitigatable through countermeasures and defensive practices.,"security, red-team guardrails and countermeasures",Passage affirms real risks from hacking mindset while asserting countermeasures can address threats.,"security,red-team,guardrails",8,Breaking-Securing AI
100986,117,mostly-true,A disciplined red-team framework lets teams test and plan AI assistant remediation efficiently in one day.,red team framework for AI assistant testing,"Fits passage claiming formalized process enables testing, documentation, and remediation planning within a single day; minor caveat about variability in real-world complexity.","security,red-team,guardrails",8,Breaking-Securing AI
100987,117,TRUE,Red Team exercises must formalize processes so findings lead directly to engineering remediation.,red-team framework for AI assistant testing,Passage states formalizing the red-team process ensures findings are helpful and drive engineering remediation.,"security,red-team,guardrails",8,Breaking-Securing AI
100988,117,barely-true,"A red-team exercise can always test, document, and plan AI remediation within a single day.",red-team framework and team roles for AI assistant testing,"Overreaches timeline: passage says framework enables single-day work, but claiming it always can is largely unsupported and optimistic.","security,red-team,guardrails",8,Breaking-Securing AI
100989,53,half-true,The training loop manually selects batches and uses GradientTape to compute gradients for updates.,training loop with tf.GradientTape and x_train batching,"Correct about manual batching and GradientTape use, but omits optimizer apply/parameter update details.","deep-learning,frameworks,tensors",5,Deep Learning
100990,53,half-true,The training loop processes one epoch with manual 64-size batching and automatic gradients.,Training loop using GradientTape and x_train batches,"Accurately notes one epoch and 64-size manual batching, but implies full automatic optimization details omitted.","deep-learning,frameworks,tensors",5,Deep Learning
100991,53,TRUE,The code uses TensorFlow's GradientTape to record operations for automatic differentiation during training.,training loop using tf.GradientTape and batched x_train,Passage explicitly shows with tf.GradientTape recording operations during a training loop with batched x_train.,"deep-learning,frameworks,tensors",5,Deep Learning
100992,24,half-true,LangChain lets users run multiple LLMs together but requires significant custom wiring to coordinate them.,toolkit for mixing models and workflow automation (LangChain),Passage correctly notes multi-LLM capability but omits complexity and engineering needed to coordinate models.,"agentic-ai,planning,tools",12,Agentic AI
100993,24,TRUE,LangChain enables integrating multiple AI models and external data sources without rewriting code.,"toolkit for integrating models, prompts, and workflow automation","Passage explicitly states LangChain mixes prompts, swaps models, and integrates external data sources seamlessly.","agentic-ai,planning,tools",12,Agentic AI
100994,24,barely-true,LangChain can always combine multiple LLMs and data sources without any code changes.,toolkit for integrating models and external data (LangChain),Passage claims easy model/data mixing but overstates universality; some code or config changes often required.,"agentic-ai,planning,tools",12,Agentic AI
100995,148,barely-true,FLAN-T5 is primarily a diffusion model used for image generation tasks.,"model description: flan-t5-large (T5, instruction-tuned)","Contradicts model class: passage describes T5/FLAN-T5 as text-to-text transformer, not a diffusion image model.","generative-ai,diffusion,gans",7,Generative AI
100996,148,barely-true,FLAN-T5-large is essentially a compact ChatGPT-style conversational model for many tasks.,"model flan-t5-large, instruction-tuned T5 architecture",Overstates equivalence to ChatGPT; passage says compact version and strong instruction following but not full parity.,"generative-ai,diffusion,gans",7,Generative AI
100997,148,pants-fire,The passage claims FLAN-T5-large is a diffusion model used for image generation.,model description mentioning flan-t5-large (T5 text-to-text transformer),"Contradicts model type: T5/FLAN-T5 are text-to-text transformers, not diffusion image-generation models.","generative-ai,diffusion,gans",7,Generative AI
100998,53,half-true,The passage mixes correct ML concepts with overstated immediacy about practical model training.,"math concepts, gradients, Colab, and model training","Combines accurate building blocks (dot products, gradients) with an overstated claim that practical training follows immediately.","ai,tool-chain,notebooks",2,AI Survival Kit
100999,53,half-true,Dot products and gradients partly explain how machine learning models learn but omit training details.,math-oriented examples using dot products and gradients,"Accurately notes core concepts but omits specifics about optimization, datasets, and model training procedures.","ai,tool-chain,notebooks",2,AI Survival Kit
101000,53,TRUE,"Dot products, gradients, and probabilities form foundational building blocks for machine learning.",math-oriented examples in AI and Colab notebooks,"Passage explicitly lists dot products, gradients, and probabilities as building blocks for ML and model training.","ai,tool-chain,notebooks",2,AI Survival Kit
101001,44,mostly-true,Differential privacy libraries like Opacus enable privacy-preserving model training by adding calibrated noise.,"differential privacy, Opacus library, privacy-preserving training","Passage states Opacus implements differential privacy via calibrated noise for privacy-preserving training, matching claim.","ethics,governance,privacy",11,AI Ethics and Governance
101002,44,half-true,Differential privacy libraries like Opacus always prevent any personal data leakage during model training.,"differential privacy, Opacus, privacy-preserving training","Overstates guarantees: Opacus injects noise but implementation, calibration, and side channels can still allow leakage.","ethics,governance,privacy",11,AI Ethics and Governance
101003,44,TRUE,Differential privacy can be implemented using libraries such as Opacus for privacy-preserving training.,privacy tool Opacus for differential privacy,Passage explicitly names Opacus and describes injecting calibrated noise to enable privacy-preserving training.,"ethics,governance,privacy",11,AI Ethics and Governance
101004,23,mostly-true,Open-source models generally allow independent audits that reveal lineage issues and bias more easily.,"open-source models, independent audits, dataset lineage","Passage states open-source visibility enables audits and lineage tracking uncovers bias, minor caveat omitted.","ethics,governance,privacy",11,AI Ethics and Governance
101005,23,TRUE,Open-source models enable independent audits that help detect and address bias and unintended behaviors.,open-source models; tracking lineage and dataset changes,Passage explicitly says open-source visibility allows independent audits and lineage tracking uncovers bias.,"ethics,governance,privacy",11,AI Ethics and Governance
101006,23,FALSE,Open-source models inherently eliminate bias and guarantee fair outcomes for all users.,"open-source models, audits, dataset lineage",Contradicts passage noting lineage and tweaks can still create unnoticed bias and unpredictable outcomes.,"ethics,governance,privacy",11,AI Ethics and Governance
101007,72,pants-fire,CrewAI autonomously replaces all human developers across software engineering tasks.,open-source framework CrewAI for orchestrating AI agents,Passage only describes orchestration and collaboration; claim wildly contradicts scope and timing of CrewAI.,"agentic-ai,planning,tools",12,Agentic AI
101008,72,half-true,CrewAI coordinates multiple AI agents to execute shared goals but lacks proven real-time adaptation claims.,"open-source agent framework CrewAI, multi-step reasoning and orchestration",Correct that CrewAI orchestrates agents and shared goals; overstates unproven real-time adaptation and evaluation.,"agentic-ai,planning,tools",12,Agentic AI
101009,72,half-true,CrewAI coordinates semi-autonomous agents to pursue shared goals with real-time collaboration features.,open-source agent framework (CrewAI) for multi-step reasoning and orchestration,"Accurately notes coordination and collaboration, but overstates real-time features and implementation specifics.","agentic-ai,planning,tools",12,Agentic AI
101010,3,barely-true,"Convolutional filters slide over images to detect edges, textures, and other local patterns.",convolution filters (kernels) in CNN feature extraction,Supported concept but overstates generality; omits that deeper layers and architectures capture more abstract features beyond simple local patterns.,"neural-networks,cnn,transformers",6,Neuron Building Blocks
101011,3,half-true,Convolutional filters always detect global image objects rather than local patterns.,convolution filters (kernels) in CNNs detecting features,Mixes correct idea of filters detecting patterns with incorrect claim about global object detection; filters are local.,"neural-networks,cnn,transformers",6,Neuron Building Blocks
101012,3,FALSE,"Convolutional filters process images by treating them as flat, unstructured pixel walls.",convolutional filters and kernels in CNNs,"Contradicts passage: filters slide across images to detect features, not treat pixels as a flat wall.","neural-networks,cnn,transformers",6,Neuron Building Blocks
101013,52,half-true,Open tools sometimes boost creativity but can introduce reuse and security trade-offs.,open tools unlocking creativity in AI builder framework,Acknowledges passage claim that open tools unlock creativity while adding incorrect certainty about reuse/security trade-offs not specified.,"ai,open-source,builder",1,Introduction – The Gold Rush Paradox
101014,52,TRUE,Open tools and transparency enable creativity and trust for thoughtful AI builders.,open tools and transparency in AI builder framework,Passage explicitly links open tools to creativity and transparency to improved trust within the AI builder framework.,"ai,open-source,builder",1,Introduction – The Gold Rush Paradox
101015,52,TRUE,Open tools and transparency help AI builders unlock creativity and build trust.,open tools and transparency in AI builder framework,Passage explicitly links open tools to creativity and transparency to improved trust in AI projects.,"ai,open-source,builder",1,Introduction – The Gold Rush Paradox
101016,10,barely-true,Jerry co-invented the “Someone is typing…” messaging feature used by billions worldwide.,patents and messaging feature in open-source and IBM projects,Claim overreaches: passage credits Jerry with that patent but offers no evidence of billions of users or sole invention.,"ai,open-source,builder",1,Introduction – The Gold Rush Paradox
101017,10,mostly-true,Jerry was an early WebSphere creator and longstanding open-source proponent with influential patents.,"WebSphere software, open-source advocacy, U.S. patents","Supported by passage noting original WebSphere role, championing open-source, and 100+ patents including a widely used feature.","ai,open-source,builder",1,Introduction – The Gold Rush Paradox
101018,10,mostly-true,Jerry helped create WebSphere and championed open-source approaches while holding many patents.,"professional contributions at IBM, WebSphere, open-source, patent portfolio","Supported by passage: lists WebSphere creation, open-source advocacy, and over 100 U.S. patents including a messaging feature.","ai,open-source,builder",1,Introduction – The Gold Rush Paradox
101019,133,half-true,Neural Duel demonstrates agents can both collaborate and compete to evaluate generated content.,agentic-ai evaluation framework with Judge agent,"Correct that agents compete and a Judge evaluates, but overstates proven generalization beyond the toy Neural Duel setup.","agentic-ai,planning,tools",12,Agentic AI
101020,133,TRUE,Agents can generate and a separate Judge agent evaluate outputs using clear criteria.,Neural Duel framework comparing model-generated content and Judge agent,Passage describes models creating content and a Judge agent selecting best outputs based on clear criteria.,"agentic-ai,planning,tools",12,Agentic AI
101021,133,half-true,Neural Duel reliably evaluates competing agent proposals using a separate Judge agent.,agent framework comparing model-generated content with a Judge evaluator,"Partly correct: passage describes a Judge comparing agents, but omits limits on reliability and scope.","agentic-ai,planning,tools",12,Agentic AI
101022,45,barely-true,Federated learning guarantees personal data never leaves its origin during model training.,federated learning frameworks like PySyft and TensorFlow Federated,"Overreaches: passage claims frameworks allow training without data leaving, but guarantees omit practical exceptions.","ethics,governance,privacy",11,AI Ethics and Governance
101023,45,barely-true,Federated learning frameworks alone guarantee full regulatory compliance for AI deployments.,federated learning frameworks like PySyft and TensorFlow Federated,Overstates toolkit capabilities; passage says frameworks help but do not by themselves ensure compliance.,"ethics,governance,privacy",11,AI Ethics and Governance
101024,45,half-true,Federated learning guarantees personal data never leaves user devices during model training.,federated learning frameworks like PySyft and TFF,Accurate premise about federated learning but overstates guarantee; implementations and integrations can leak data.,"ethics,governance,privacy",11,AI Ethics and Governance
101025,58,TRUE,Unverified AI outputs can mislead users into taking harmful actions based on hallucinations.,AI hallucinations and fabricated citations or APIs,"Passage describes models fabricating citations, policies, and APIs and users acting on unchecked outputs.","security,red-team,guardrails",8,Breaking-Securing AI
101026,58,TRUE,Unverified AI outputs frequently produce fabricated citations and policies that users may act on.,hallucinations producing fake journal citations and return policies,"Directly supported by passage stating models create fake citations, fabricate policies, and suggest nonexistent APIs.","security,red-team,guardrails",8,Breaking-Securing AI
101027,58,barely-true,The passage claims AI hallucinations frequently produce fabricated citations and nonexistent APIs.,"model hallucinations, fabricated citations and APIs","Largely unsupported as ""frequently"" overstates; passage gives examples but not frequency evidence.","security,red-team,guardrails",8,Breaking-Securing AI
101028,51,FALSE,The Sequential model described automatically performs data normalization during training.,model definition using Sequential and MNIST data preprocessing,"Contradicts passage: normalization is done explicitly by reshaping and dividing by 255, not by the Sequential model.","deep-learning,frameworks,tensors",5,Deep Learning
101029,51,mostly-true,The MNIST images are reshaped to 784-dimensional vectors and normalized to 0–1 values.,data preprocessing for MNIST using reshape and scaling,"Passage explicitly shows reshaping to 28*28=784 and dividing by 255, matching normalization claim.","deep-learning,frameworks,tensors",5,Deep Learning
101030,51,FALSE,The model processes MNIST images as 28x28 tensors without normalization.,data loading and preprocessing for MNIST dataset,"Contradicts passage which reshapes to 784-vector and scales pixels to 0–1, not kept as 28x28 tensors.","deep-learning,frameworks,tensors",5,Deep Learning
101031,21,TRUE,The text recommends scanning leaderboards and companion papers before choosing a model.,model selection using leaderboards and companion papers,"Directly supported: passage advises scanning leaderboards, reproducibility notes, companion papers to choose models.","mlops,scaling,deployment",10,AI At Scale
101032,21,barely-true,Model cards always fully capture all performance nuances after tuning.,model card documentation for model tuning and evaluation,Overreaches: passage recommends documenting tuning but does not claim model cards capture every nuance.,"mlops,scaling,deployment",10,AI At Scale
101033,21,half-true,Model cards always include complete performance tuning results and reproducibility notes.,"model card, leaderboards, reproducibility notes","Passage encourages documenting tuning and scanning reproducibility, but doesn't claim model cards always contain complete results.","mlops,scaling,deployment",10,AI At Scale
101034,124,half-true,Autoregressive models can be easily deployed for practical forecasting but may need advanced architectures for complex patterns.,time-series forecasting with autoregressive models and LSTM/Transformer,"Correctly notes easy deployment and need for LSTM/Transformer for complex volatility, but mixes simplicity claim with potentially understated data/feature engineering challenges.","generative-ai,diffusion,gans",7,Generative AI
101035,124,mostly-true,Autoregressive models can be readily deployed for practical forecasting tasks like electricity demand and stock prices.,time-series forecasting with autoregressive models and LSTMs,Passage supports deployability for electricity demand and stocks but omits limitations and model complexity.,"generative-ai,diffusion,gans",7,Generative AI
101036,124,FALSE,Diffusion models are the primary method used for time series forecasting in finance.,time series forecasting with autoregressive models and LSTMs,"Contradicts passage: forecasting uses autoregressive models, LSTMs, Transformers; diffusion models not mentioned.","generative-ai,diffusion,gans",7,Generative AI
101037,79,half-true,The preprocessing pipeline removes audio file_path and filters texts longer than 200 tokens.,data preprocessing pipeline with remove_columns and filter_long_texts,"Mixes correct steps (remove_columns, <200 token filter) but implies both always applied and sufficient for stability.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
101038,79,pants-fire,The dataset enables undetectable deepfake voice cloning of any speaker with perfect accuracy.,speaker embeddings extraction from audio dataset,"Passage describes tokenization and filtering, not making cloning undetectable; claim contradicts dataset scope and feasibility.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
101039,79,barely-true,The passage claims removing file_path prevents audio extraction errors during embedding computation.,data preprocessing step using remove_columns and speaker embeddings,"Overreaches: remove_columns drops file path but passage only logs tokenization and embedding mapping, not explicit error prevention.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
101040,52,mostly-true,Enabling GPU acceleration typically speeds up training as sequence length and batch size increase.,training performance with GPU acceleration and dataset preparation for T5,Passage notes GPU support clearly improves training with longer sequences and larger batches; minor caveat about exact speedups omitted.,"mlops,scaling,deployment",10,AI At Scale
101041,52,FALSE,Enabling GPU acceleration is unnecessary for training longer sequences and larger batches.,"GPU acceleration for training, sequence length and batch size",Passage states GPU support makes a clear difference during training for longer sequences and larger batches.,"mlops,scaling,deployment",10,AI At Scale
101042,52,half-true,Enabling GPU acceleration always yields large training speedups for T5 on merged LIAR and BYOAI datasets.,"training setup with GPU acceleration, T5 model, LIAR and BYOAI datasets","GPU helps with longer sequences and bigger batches, but ""always"" and ""large"" speedups depend on model size and I/O or batch constraints.","mlops,scaling,deployment",10,AI At Scale
101043,66,mostly-true,Fine-tuning SpeechT5 with speaker embeddings generally preserves a speaker's vocal signature for synthesis.,process for voice cloning using SpeechT5 and speaker embedding,"Supports fine-tuning and conditioning on speaker embeddings, but omits limits like dataset size or quality.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
101044,66,barely-true,Fine-tuning SpeechT5 always perfectly reproduces a speaker's unique vocal signature.,Fine-Tune SpeechT5 on paired dataset with speaker embedding,"Overreaches beyond passage: it describes training steps but omits limits, evaluation, and imperfect reproduction.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
101045,66,barely-true,Fine-tuning SpeechT5 always reproduces a speaker's unique vocal signature exactly.,Fine-Tune SpeechT5 on paired dataset with speaker embedding,"Overstates capability; passage describes conditioning on speaker embedding but omits limits like data quantity, model capacity, or exactness.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
101046,31,TRUE,Training often requires dozens or hundreds of epochs to improve model accuracy before plateauing.,fine-tuning pre-trained models and epoch counts,"Passage states most models need dozens or hundreds of epochs, with pre-trained models often needing fewer, and then plateau.","deep-learning,frameworks,tensors",5,Deep Learning
101047,31,TRUE,Models often reach a performance plateau where additional training yields little improvement.,"training epochs, loss plateau on pre-trained or new models","Passage states loss stops decreasing and extra epochs provide little or no improvement, causing a plateau.","deep-learning,frameworks,tensors",5,Deep Learning
101048,31,mostly-true,Most models need dozens to hundreds of epochs to improve accuracy during training.,training epochs for neural network fine-tuning,"Consistent with text saying most models require dozens or hundreds of epochs, though pretraining can reduce this.","deep-learning,frameworks,tensors",5,Deep Learning
101049,126,mostly-true,"Deepfake detection toolkits often include modular pre-trained models to spot lighting, motion, and expression irregularities.",toolkit description mentioning DeepSafe and Deepstar pre-trained models,"Passage describes modular toolkits (DeepSafe, Deepstar) with pre-trained models detecting lighting, motion, expression irregularities; minor caveat about dataset scope omitted.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
101050,126,TRUE,"Deepstar provides pre-trained models to detect lighting, movement, and expression irregularities in deepfakes.",Deepstar toolkit by ZeroFox with pre-trained models,"Passage explicitly states Deepstar includes pre-trained models spotting lighting, movement, and expression irregularities.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
101051,126,mostly-true,Deepfake detection toolkits help researchers compare methods and spot subtle visual inconsistencies.,"toolkits DeepSafe and Deepstar, pre-trained models and detection methods","Supported by mention of modular toolkits (DeepSafe, Deepstar) that highlight lighting, motion, expression irregularities, though specifics of effectiveness omitted.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
101052,197,mostly-true,A trained PyTorch MNIST model can correctly classify messy handwritten digits after identical preprocessing.,predicting custom images with a saved PyTorch model and torchvision transforms,"Code shows loading weights, same preprocessing, and correct predictions for two messy samples, minor sample-size caveat.","deep-learning,frameworks,tensors",5,Deep Learning
101053,197,half-true,The trained PyTorch MNIST model reliably classifies messy handwritten digits without further tuning.,model evaluation on custom MNIST-like images using torchvision transforms,Results claim correct predictions for two messy samples but generalization beyond two examples is unverified.,"deep-learning,frameworks,tensors",5,Deep Learning
101054,197,mostly-true,The pretrained MNIST model correctly classifies messy handwritten digits after simple preprocessing.,"torchvision transforms, Net model, mnist_model.pt inference","Output shows predictions 1 and 7 for messyone.png and messyseven.png, matching labels with minimal caveats.","deep-learning,frameworks,tensors",5,Deep Learning
101055,49,barely-true,The passage claims the vector output precisely prescribes exact improvement amounts for multiple attributes.,tool output example showing [30 20] vector for strength and speed,"Largely unsupported because passage gives an illustrative example, not validated as precise prescription in practice.","ai,tool-chain,notebooks",2,AI Survival Kit
101056,49,mostly-true,The passage suggests numeric deficits can pinpoint specific improvements needed to reach target performance.,output vector example [30 20] indicating required strength and speed increases,Example shows numeric outputs mapping deficits to concrete actions; minor contexts like domain transfer omitted.,"ai,tool-chain,notebooks",2,AI Survival Kit
101057,49,mostly-true,The passage illustrates using numeric outputs to show needed improvements for target performance.,tool output example with numeric vector [30 20] for performance adjustments,"Passage directly describes a numeric output indicating required boosts, omitting implementation details.","ai,tool-chain,notebooks",2,AI Survival Kit
101058,55,FALSE,Transformers use recurrent hidden states to maintain sequence memory during processing.,"model architecture concept: RNN vs attention, positional encoding, self-attention","Contradicts text: Transformers avoid fixed recurrent memory like RNNs, using attention instead.","neural-networks,cnn,transformers",6,Neuron Building Blocks
101059,55,pants-fire,Transformers use no attention and rely solely on fixed RNN-style memory states.,model architecture: multi-head self-attention and positional encoding,Directly contradicts described mechanism: passage emphasizes multi-head self-attention and not RNN fixed memory.,"neural-networks,cnn,transformers",6,Neuron Building Blocks
101060,55,barely-true,Transformers always outperform RNNs on every sequence task due to self-attention.,multi-head self-attention and RNN comparison,Overstates claim: passage praises attention benefits but doesn't claim universal superiority across all sequence tasks.,"neural-networks,cnn,transformers",6,Neuron Building Blocks
101061,177,TRUE,Synthetic health records generated with Faker protect privacy for AI training.,Faker-generated synthetic health records dataset,Supports privacy-preserving AI training by using Faker to create realistic but fictional health records without real personal data.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
101062,177,pants-fire,Synthetic health records can completely eliminate privacy risks when used for AI training.,generating synthetic health records with Faker dataset,"Claim contradicts passage nuance: synthetic data reduces but does not guarantee elimination of privacy risks; Faker generates realistic fictional data, not perfect privacy assurance.","data-prep,feature-engineering,rag",3,Prepping Data for AI
101063,177,barely-true,Faker can create realistic synthetic health records safe for AI training without privacy risks.,synthetic health records using Faker package,Overreaches: Faker generates fictional data but doesn't guarantee elimination of all privacy risks or realism limits.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
101064,135,TRUE,Benchmarking and model optimization can achieve up to tenfold performance improvements.,model benchmark and acceleration for stability and scalability,"Passage explicitly mentions benchmarking, compression, acceleration, and sometimes achieving 10× improvements, supporting the claim.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
101065,135,mostly-true,Deepfake defenses can be accelerated and compressed to achieve roughly 10× performance improvements.,"benchmarking, model compression, and acceleration for deepfake detection","Passage mentions benchmarking, compressing, and sometimes achieving 10× improvements, implying speedups for defenses with minor implementation caveats.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
101066,163,barely-true,Reinforcement learning agents update policies solely by maximizing immediate rewards from actions.,reward signal and value function in Lunar Lander environment,"Overstates mechanism: passage emphasizes expected future rewards and value estimates, not only immediate rewards.","machine-learning,classification,evaluation",4,Classical Machine Learning
101067,163,FALSE,Lunar Lander is a supervised classification dataset used for evaluating classifiers.,Lunar Lander environment from Gymnasium (reinforcement learning),"Contradicts passage: Lunar Lander is an RL environment, not a supervised classification dataset.","machine-learning,classification,evaluation",4,Classical Machine Learning
101068,163,barely-true,Lunar Lander always uses a value function to update its policy during training.,Lunar Lander environment in Gymnasium (reinforcement learning),Overreaches: value functions are common but not always used; policy-gradient or model-free methods may skip explicit value functions.,"machine-learning,classification,evaluation",4,Classical Machine Learning
101069,106,barely-true,Composite feature scores reliably preserve all detailed signals from raw data.,feature engineering and composite scores in dataset signals,Overreaches: passage warns composites compress detail and advises tracking simplifications and adding sub-scores.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
101070,106,half-true,Composite scores reliably preserve all original signal details after feature engineering.,"feature engineering and composite scores (OPR, SDR) in dataset preprocessing",Mixes correct idea that composites convey signal with incorrect claim they preserve all detail; compression omitted.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
101071,106,half-true,Composite scores compress detail and can obscure specific feature signals in datasets.,feature engineering and composite scores for datasets,Mixes correct point about compression with incorrect implication that scores always obscure all signals; nuance missing.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
101072,138,mostly-true,Transformers summarize input text word-by-word using self-attention to capture long-range relationships.,encoder-decoder transformer summarization with self-attention,Accurately reflects encoder-decoder generation and self-attention benefits but omits specifics about decoder conditioning and comparison details.,"generative-ai,diffusion,gans",7,Generative AI
101073,138,half-true,Transformers summarize input by generating words sequentially while attending to the entire input.,encoder-decoder transformer with self-attention,"Accurately notes sequential decoding plus attention, but oversimplifies encoder-decoder operations and contrasts.","generative-ai,diffusion,gans",7,Generative AI
101074,138,half-true,Transformer decoders generate summaries one word at a time using encoder input and prior outputs.,transformer encoder-decoder and self-attention mechanism,"Accurate about autoregressive decoding and encoder conditioning, but omits that transformers process inputs in parallel via self-attention.","generative-ai,diffusion,gans",7,Generative AI
101075,29,barely-true,The agents automatically estimate exact inception years for every open-source project mentioned.,CrewAI agent pipeline for open_source_glossary.csv,"Pipeline mentions estimating inception years but offers estimation, not guaranteed exact accuracy or completeness.","open-source,community,contribution",13,Commit to Contribute
101076,29,FALSE,The agents automatically publish the CSV glossary to GitHub without human review.,CrewAI agent workflow for open-source project glossary generation,"Contradicts passage details: workflow outputs CSV locally and notebook shows implementation, not automatic GitHub publishing.","open-source,community,contribution",13,Commit to Contribute
101077,29,half-true,Agents using CrewAI automatically determine exact inception years for every open-source project mentioned.,agent pipeline for open-source project glossary generation,"Pipeline extracts estimated inception years, but claims of exact years for every project overstate capability and certainty.","open-source,community,contribution",13,Commit to Contribute
101078,92,mostly-true,A HiFi-GAN vocoder produced a lifelike clone matching Jerry Cuomo’s pacing and tone.,voice cloning using HiFi-GAN vocoder and spectrogram,"Model-generated spectrogram converted by HiFi-GAN yielded convincing pacing and tone, omitting minor evaluation limits.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
101079,92,pants-fire,"The synthesized audio was an exact, indistinguishable replica of Jerry’s real voice in all contexts.",HiFi-GAN spectrogram-based voice cloning of Jerry,"Passage only reports a convincing, close match; claiming exact indistinguishability contradicts reported limited test and subjective listen.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
101080,92,mostly-true,The model's HiFi-GAN pipeline produced a highly convincing synthetic clone of Jerry's podcast voice.,voice cloning using spectrograms and HiFi-GAN,"Observations note lifelike output and matched pacing/tone, omitting minor evaluation limits.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
101081,115,pants-fire,Autoregressive models always generate high-fidelity images without any training data.,autoregressive modeling of pixel values,Contradicts passage: autoregressive methods depend on past context but require training data; claim is extreme implausible.,"generative-ai,diffusion,gans",7,Generative AI
101082,115,mostly-true,"Autoregressive models generate content step-by-step, using past outputs to predict each next element.","autoregressive modeling for text, speech, and pixel prediction","Directly matches passage: ordered incremental generation depends on previous outputs, minor omission of specific architectures.","generative-ai,diffusion,gans",7,Generative AI
101083,115,TRUE,Autoregressive models generate each element sequentially using previous outputs to inform the next.,"autoregressive modeling for text, speech, or pixel generation",Passage describes step-by-step forward sequence prediction where each new element depends on previous outputs.,"generative-ai,diffusion,gans",7,Generative AI
101084,92,barely-true,The team publicly released comprehensive training logs and provenance for the fine-tuned model.,model provenance and versioned checkpoint in MLOps,"Asserted release contradicts passage; passage says model history currently exists only in Colab session, not publicly recorded.","mlops,scaling,deployment",10,AI At Scale
101085,92,barely-true,The passage claims the fine-tuned model lacks any public provenance or saved records.,model checkpoint provenance in MLOps workflow,"Asserts no record beyond a Colab session, overstating provenance options and omitting common versioning tools.","mlops,scaling,deployment",10,AI At Scale
101086,92,barely-true,The passage claims the fine-tuned model is effectively undocumented and unusable outside Colab.,model versioned checkpoint and Colab session in MLOps,Overstates usability problem: passage notes lack of public record but not total unusability or irretrievability.,"mlops,scaling,deployment",10,AI At Scale
101087,55,half-true,A decision tree's rules can be inspected by visualizing its prediction paths and leaf nodes.,"decision tree visualization, prediction paths, leaf nodes","Accurately notes inspectability and visualization, but overstates ease and omits limitations like complexity or pruning.","machine-learning,classification,evaluation",4,Classical Machine Learning
101088,55,barely-true,Decision trees always provide fully interpretable rules for any dataset.,decision tree visualization and inspection,"Overstates interpretability: visualization shows rules but complexity, depth, and feature interactions can hinder clear understanding.","machine-learning,classification,evaluation",4,Classical Machine Learning
101089,55,mostly-true,Decision trees provide inspectable rule-based predictions via visualization of branched yes/no queries.,decision tree visualization and prediction paths,Supports inspectable rules and yes/no splits leading to leaf-class predictions; minor omission about scalability.,"machine-learning,classification,evaluation",4,Classical Machine Learning
101090,32,TRUE,The dataset contains redundant duplicate character entries like Atom with nearly identical details.,"dataset duplicate entries, redundancy, character records","Passage explicitly notes Atom appears twice with nearly identical details, indicating redundancy.","data-prep,feature-engineering,rag",3,Prepping Data for AI
101091,32,half-true,The dataset contains duplicate character records alongside useful cross-publisher variants.,dataset cleaning for RAG and feature engineering,Passage notes both meaningful duplicates (Angel across publishers) and redundant ones (Atom identical entries).,"data-prep,feature-engineering,rag",3,Prepping Data for AI
101092,32,mostly-true,Feature deduplication reduces redundant entries like repeated character rows in datasets.,dataset cleaning for RAG and feature engineering,Passage notes redundant character rows (Atom) and counter columns; deduplication addresses these minor redundancies.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
101093,96,half-true,Open-source model cards guarantee model safety and fully prevent misuse in deployment.,model cards and openness in MLflow/Weights & Biases workflows,Overstates effect: model cards improve transparency but do not guarantee safety or prevent misuse without governance and controls.,"mlops,scaling,deployment",10,AI At Scale
101094,96,mostly-true,"Open-source model cards broadly promote transparency about model training, data, purposes, and limitations.",model cards in MLOps and Hugging Face Hub,"Passage states model cards describe purpose, training, data, and limits; minor implementation variability omitted.","mlops,scaling,deployment",10,AI At Scale
101095,96,mostly-true,"Open-source model cards broadly support trust by documenting model purpose, training, data, and limits.",model cards for openness in deployment and MLOps,"Matches passage: model cards described as short reports documenting purpose, training data, and limits, supporting trust.","mlops,scaling,deployment",10,AI At Scale
101096,88,FALSE,Transformers are primarily used for image compression rather than sequence modeling.,Generative AI models and autoregressive modeling,"Contradicts standard usage: transformers excel at sequence modeling and language tasks, not chiefly image compression.","neural-networks,cnn,transformers",6,Neuron Building Blocks
101097,88,mostly-true,Generative models like GANs and diffusion models mainly produce samples by transforming latent noise into images.,"Generative AI models (GANs, VAEs, diffusion models) in neural-networks","Supported by passage grouping GANs, VAEs, diffusion models as creative generative methods, but omits specifics like autoregressive models and training differences.","neural-networks,cnn,transformers",6,Neuron Building Blocks
101098,88,half-true,Generative models like GANs and diffusion models create novel images by learning data distributions.,"Generative AI models (GANs, diffusion models, VAEs)","Correctly notes GANs and diffusion models learn data distributions to generate images, but overgeneralizes novelty and ignores training instability and mode collapse issues.","neural-networks,cnn,transformers",6,Neuron Building Blocks
101099,114,half-true,A short focused red team sweep alone can make an AI prototype secure for production use.,red team sweep and Blue Team handoff in deployment practices,Accurately highlights red team sweeps' role but overstates sufficiency; passage says they help transition but not alone ensure security.,"security,red-team,guardrails",8,Breaking-Securing AI
101100,114,half-true,"A short, focused red team sweep makes transitioning AI prototypes to secure products faster and more repeatable.",red team sweep for deployment practices,Accurately captures claimed benefits but overstates universality; operational specifics and constraints omitted.,"security,red-team,guardrails",8,Breaking-Securing AI
101101,114,mostly-true,A short red team sweep with defined roles and evidence generally improves deployment security.,red team sweep and Blue Team handoff practice,"Describes passage's claim that structured red team exercises, roles, and evidence broadly make deployments safer, faster, repeatable.","security,red-team,guardrails",8,Breaking-Securing AI
101102,34,barely-true,IDE plugins and OpenSSF Scorecards can catch most security issues before code is committed.,"IDE tools, OpenSSF Scorecards, editor plugins",Overstates effectiveness; passage recommends these tools but doesn't claim they catch most security issues.,"security,red-team,guardrails",8,Breaking-Securing AI
101103,34,TRUE,Developer IDE tooling should surface code security problems before commits are made.,IDE tools like OpenSSF Scorecards and editor plugins,Passage explicitly recommends shifting scrutiny into the IDE and names OpenSSF Scorecards and editor plugins.,"security,red-team,guardrails",8,Breaking-Securing AI
101104,34,TRUE,Developer tooling like OpenSSF Scorecards can detect security issues before code is committed.,IDE tooling and OpenSSF Scorecards in the development workflow,Passage explicitly recommends shifting scrutiny into the IDE and names OpenSSF Scorecards as a detector.,"security,red-team,guardrails",8,Breaking-Securing AI
101105,138,barely-true,Securing AI is essentially the same as securing traditional software systems.,"AI failures, model behavior and security differences","Overreaches the passage, which highlights behavioral differences like model confidence and context, not equivalence.","security,red-team,guardrails",8,Breaking-Securing AI
101106,138,half-true,AI security failures are primarily behavioral quirks rather than catastrophic system crashes.,securing AI; model confidence and behavioral failures,Accurately notes behavioral nature but overstates 'primarily' and downplays possible catastrophic or systemic risks.,"security,red-team,guardrails",8,Breaking-Securing AI
101107,138,TRUE,AI security failures often manifest as subtle behavioral deviations rather than system crashes.,securing AI model behavior and confidence,"Passage explains failures were behavioral (overconfidence, instruction deviation, unauthorized actions) not catastrophic.","security,red-team,guardrails",8,Breaking-Securing AI
101108,19,FALSE,A strong input-output security gateway cannot be bypassed by red-teamers.,Gandalf-style guardrails security gateway,"Passage says gateways are the authors' kryptonite, contradicting unbypassable gateway claim.","security,red-team,guardrails",8,Breaking-Securing AI
101109,19,half-true,A security gateway that validates prompts and sanitizes responses reliably prevents red-team bypasses.,Gandalf-style guardrails gateway validating prompts and sanitizing responses,Mixes correct defense idea with overclaim: passage praises gateways but admits they remain the authors' kryptonite.,"security,red-team,guardrails",8,Breaking-Securing AI
101110,19,pants-fire,A security gateway can never be bypassed by red-teamers testing models.,Gandalf-style guardrails security gateway for input/output filtering,Contradicts passage claiming gateways are authors' kryptonite and can be bypassed during red-team tests.,"security,red-team,guardrails",8,Breaking-Securing AI
101111,120,mostly-true,The simple feedforward network with one ReLU hidden layer effectively predicts seasonal time series.,sequence prediction using 12-month input and 13th value label,"Model shown effective for airline travel seasonality, though broader datasets or complexities are not addressed.","generative-ai,diffusion,gans",7,Generative AI
101112,120,barely-true,The feedforward model reliably captures complex temporal dependencies like long-range attention mechanisms.,feedforward model with one hidden layer and ReLU for sequence prediction,"Overreaches beyond passage: minimalist feedforward learns seasonality, not complex long-range attention mechanisms.","generative-ai,diffusion,gans",7,Generative AI
101113,120,TRUE,A simple feedforward network with one ReLU hidden layer predicts the next value from 12-month sequences.,sequence prediction using 12-month input and label,"Passage specifies 12-month inputs, 13th value as label, and a one-hidden-layer ReLU feedforward network being effective.","generative-ai,diffusion,gans",7,Generative AI
101114,75,barely-true,"Agentic AI systems already have a clear, widely adopted governance framework across organizations.",governance of agentic AI systems,"Overstates reality: discussions exist but no clear, widely adopted governance framework yet; evidence missing.","ethics,governance,privacy",11,AI Ethics and Governance
101115,75,TRUE,"Experts emphasize transparent, trustworthy frameworks for governing agentic AI systems.","governance of agentic AI systems, transparency and trust","Directly supported by speakers advocating transparent, trustworthy frameworks for agentic AI governance.","ethics,governance,privacy",11,AI Ethics and Governance
101116,75,pants-fire,Agentic AI systems will inevitably replace all human governance and privacy safeguards within one year.,agentic AI systems and governance frameworks in AI ethics,Claim contradicts discussion of emerging frameworks and transparency; timeline and total replacement are implausible given ongoing debate and gradual governance development.,"ethics,governance,privacy",11,AI Ethics and Governance
101117,96,mostly-true,Cosine similarity on PCA-reduced feature vectors effectively measures hero similarity for classification tasks.,cosine similarity on PCA feature matrix (n_pcs=20),"PCA reduction and cosine capture direction-based similarity, though magnitude or other metrics may be omitted.","machine-learning,classification,evaluation",4,Classical Machine Learning
101118,96,barely-true,Cosine similarity reliably indicates identical hero behavior across all gameplay contexts.,cosine similarity on PCA feature matrix,"Overstates cosine: passage notes directional similarity but omits context, temporal dynamics, and feature limitations.","machine-learning,classification,evaluation",4,Classical Machine Learning
101119,96,mostly-true,Cosine similarity on PCA-derived feature vectors effectively measures hero similarity for classification tasks.,cosine similarity on PCA feature matrix (n_pcs=20),PCA axes and cosine similarity are used together in passage; minor caveat: cosine ignores magnitude differences.,"machine-learning,classification,evaluation",4,Classical Machine Learning
101120,131,mostly-true,"Benchmarking and tuning (batch size, latency) broadly guide scaling decisions and reveal performance bottlenecks.",scaling experiments and benchmarking of batch size and latency,"Passage describes benchmarking uncovering breaks and tuning batch size/latency guiding smarter scaling choices, omitting specific metrics or tools.","mlops,scaling,deployment",10,AI At Scale
101121,131,FALSE,Scaling experiments never involve benchmarking or performance tuning.,scaling experiments and benchmarking in deployment,Contradicts passage: scaling experiments explicitly combine benchmarking with tuning batch size and latency adjustments.,"mlops,scaling,deployment",10,AI At Scale
101122,131,TRUE,Benchmarking guided tuning of batch size and latency to improve system performance.,scaling experiments and benchmarking for latency and batch size,Passage directly says benchmarking uncovered performance drops and guided batch size and latency tuning.,"mlops,scaling,deployment",10,AI At Scale
101123,87,half-true,The classifier sometimes mislabels injected prompts due to an overly high 0.7 threshold.,injection_detector model threshold and label scores,Mixture: correctly flags many injections but specific 0.7 cutoff can cause false negatives or false positives.,"security,red-team,guardrails",8,Breaking-Securing AI
101124,87,mostly-true,A trained injection detector flags prompts as 'Injection' when scores exceed a threshold like 0.7.,injection_detector model with return_all_scores parameter,Supported by code showing score threshold 0.7 used to label injections; minor calibration caveat omitted.,"security,red-team,guardrails",8,Breaking-Securing AI
101125,87,barely-true,A simple score threshold reliably separates injected prompts from safe ones in all scenarios.,injection_detector model thresholding for prompt injection detection,Overreaches beyond passage example; thresholding used but classifier described as imperfect and limited.,"security,red-team,guardrails",8,Breaking-Securing AI
101126,53,mostly-true,Clément Delangue promotes open-source tools to empower millions of AI builders.,LinkedIn post referencing open-source AI and infrastructure,"LinkedIn quote supports ambition to empower seven million builders via open-source tools, a broadly accurate summary.","open-source,community,ai",0,Foreword – Robo Interviews Clément Delangue
101127,53,barely-true,Clément Delangue claims open-source tools will instantly empower seven million AI builders.,LinkedIn post referencing open-source AI ambition and infrastructure,"Overreach: post expresses ambition to empower 7 million, but instant universal empowerment is unsupported by evidence.","open-source,community,ai",0,Foreword – Robo Interviews Clément Delangue
101128,53,barely-true,Clément Delangue claims open-source AI will instantly empower seven million builders without barriers.,LinkedIn quote about empowering 7 million AI builders via open-source,"Passage mentions ambition to empower seven million builders but offers no evidence of instant, barrier-free empowerment.","open-source,community,ai",0,Foreword – Robo Interviews Clément Delangue
101129,134,TRUE,"Agentic AI systems autonomously gather information, analyze context, and respond in real time.",agentic systems and adaptive workflows,"Passage explicitly describes agents gathering new information, analyzing context, and responding without constant human direction.","agentic-ai,planning,tools",12,Agentic AI
101130,134,half-true,Agentic AI systems can autonomously gather information and respond in real time without constant human direction.,agentic systems adapting workflows and decision-making,"Passage states agentic systems gather new information, analyze context, and respond in real time, but omits limits and safeguards.","agentic-ai,planning,tools",12,Agentic AI
101131,134,TRUE,Agentic AI systems autonomously gather information and respond in real time.,agentic systems gathering new information and responding in real time,"Passage states agentic systems gather new information, analyze context, and respond without constant human direction.","agentic-ai,planning,tools",12,Agentic AI
101132,60,mostly-true,The model mainly pattern-matches rather than engaging in human-like reasoning.,model behavior and training data noise,Passage explicitly describes prediction-by-pattern matching and drift when data or prompts are noisy.,"security,red-team,guardrails",8,Breaking-Securing AI
101133,60,barely-true,The model genuinely understands language like a human and reasons with real-world context.,model reasoning; pattern-matching vs understanding,"Contradicts passage which describes statistical pattern-matching, not human-like understanding.","security,red-team,guardrails",8,Breaking-Securing AI
101134,60,TRUE,The model generates outputs by statistical pattern-matching rather than human-like understanding.,model behavior and pattern-matching in training data,"Passage explicitly says the model predicts next tokens via statistical likelihood, not actual understanding.","security,red-team,guardrails",8,Breaking-Securing AI
101135,31,barely-true,Clément Delangue claimed the interview used 24 public sources to verify his quotes.,curated dataset of 24 public sources verifying quotes,"Mostly accurate claim but overstates verification scope; quotes backed by sources, not necessarily fully verified.","open-source,community,ai",0,Foreword – Robo Interviews Clément Delangue
101136,31,FALSE,Clément Delangue denied supporting open-source AI development in the interview.,interview sources and Hugging Face quote,Contradicts explicit quote endorsing open-source tools and encouraging building AI on Hugging Face.,"open-source,community,ai",0,Foreword – Robo Interviews Clément Delangue
101137,31,pants-fire,Clément Delangue secretly opposes all open-source AI and plans to shut down Hugging Face.,"Foreword quotes and interview sourcing about Hugging Face, open-source",Direct quote praises open-source and Hugging Face; contradiction claims opposition and shutdown plans.,"open-source,community,ai",0,Foreword – Robo Interviews Clément Delangue
101138,75,half-true,Dataset-provided demographic labels may introduce contributor bias into model outputs.,"sensitive labels in a dataset (Gender, Species) during feature engineering",Mixes correct caution about contributor bias with implied inevitability of distorted outputs without nuance.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
101139,75,TRUE,Dataset-provided labels like Gender or Species reflect contributor assumptions and biases.,"sensitive categorical labels in a dataset (Gender, Species)",Passage explicitly states labels are dataset-provided and reflect contributors' assumptions and biases.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
101140,75,half-true,Dataset-provided labels like Gender or Species always reflect contributors' biases and are therefore unreliable.,sensitive categorical labels in a dataset,Accurately notes contributor bias but overstates 'always' and 'unreliable' without nuance or mitigation strategies.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
101141,92,barely-true,Trimesh and matplotlib alone can train diffusion or GAN generative models on GPU.,"tool imports: trimesh, matplotlib, PyTorch device setup",Overreaches: passage only lists trimesh/matplotlib for geometry and rendering; PyTorch is needed for model training on GPU.,"generative-ai,diffusion,gans",7,Generative AI
101142,92,TRUE,"Trimesh, NumPy, and Matplotlib are used to generate and render 3D meshes for the project.",imports and rendering with trimesh and Poly3DCollection,"Passage explicitly lists trimesh for geometry, NumPy for arrays, and Matplotlib/Poly3DCollection for rendering.","generative-ai,diffusion,gans",7,Generative AI
101143,92,mostly-true,"PyTorch with trimesh, NumPy, and matplotlib enables building and rendering 3D mesh models on GPU.",model training and 3D mesh rendering using trimesh and Poly3DCollection,"Libraries enable mesh construction and rendering and GPU use speeds training, omitting workflow and performance caveats.","generative-ai,diffusion,gans",7,Generative AI
101144,124,FALSE,The passage claims the tool retrieved no relevant articles from BBC News.,tool use: Search in a specific website (BBC News),"Contradicts output showing ""Dozens of new article summaries retrieved,"" so retrieval did occur.","agentic-ai,planning,tools",12,Agentic AI
101145,124,TRUE,Agentic AI can plan and use external tools to accomplish multi-step tasks autonomously.,agentic AI planning with tools and retrieval,Passage shows agentic system invoking a search tool and filtering results to perform multi-step work.,"agentic-ai,planning,tools",12,Agentic AI
101146,124,barely-true,An agentic AI autonomously searches external websites and filters articles without human input.,tool use: Search in a specific website; retrieved article summaries,Passage shows tool-initiated search and filtering but doesn't prove full autonomous agency or decision authority.,"agentic-ai,planning,tools",12,Agentic AI
101147,132,barely-true,Optimizer updates often overreact to single confusing training examples in digit recognition.,"handwritten digits recognition, optimizer behavior","Claim aligns with passage describing jittery, reactive optimizer adjustments to messy samples.","deep-learning,frameworks,tensors",5,Deep Learning
101148,132,TRUE,"Noisy, inconsistent training signals can slow learning of a handwriting-recognition model.",optimizer behavior during handwritten-digits training,"Passage explains jittery, limited-information signals cause the optimizer to react to confusing digit samples, slowing learning.","deep-learning,frameworks,tensors",5,Deep Learning
101149,132,pants-fire,Optimizers always ignore single confusing samples when training digit-recognition models.,"handwritten digits, optimizer behavior in training","Directly contradicts passage which states optimizers react immediately to confusing single samples, causing jitter.","deep-learning,frameworks,tensors",5,Deep Learning
101150,84,TRUE,Humans must intentionally design and deploy AI to ensure it acts beneficially.,"AI design and deployment, intentional purpose",Passage explicitly states humans are responsible and AI won’t spontaneously choose to do good.,"ethics,governance,privacy",11,AI Ethics and Governance
101151,84,half-true,AI systems will only act beneficially if humans explicitly program and deploy them that way.,"AI ethics and deployment, responsible human actors",Mixes correct emphasis on human responsibility with incorrect certainty about AI agency and inevitability.,"ethics,governance,privacy",11,AI Ethics and Governance
101152,84,barely-true,AI systems will autonomously choose to act for human welfare without human intervention.,"AI development and deployment responsibility, human-centered design",Contradicts asserted need for intentional human design; overreaches by claiming autonomous pro-social behavior.,"ethics,governance,privacy",11,AI Ethics and Governance
101153,60,half-true,Scaling always preserves original measurements like height and weight exactly after transformation.,feature scaling of dataset z-score normalization,"Correct that scaling keeps relative info, but incorrect claiming exact original measurements remain unchanged after transform.","data-prep,feature-engineering,rag",3,Prepping Data for AI
101154,60,barely-true,Standardizing features always preserves original measurement units for model inputs.,feature scaling; z-score normalization on dataset weights,Overreaches: z-scoring preserves relative information but not original units; passage says values are put on a shared scale rather than keeping units.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
101155,60,barely-true,Standardizing features always preserves original units and real-world values for downstream models.,feature scaling and z-score standardization on dataset,"Overreaches: standardization changes units and scales values, not preserving original measurement units.","data-prep,feature-engineering,rag",3,Prepping Data for AI
101156,140,TRUE,"A confusion matrix shows correct and mistaken publisher predictions for Marvel, DC, and Other.",confusion_matrix and ConfusionMatrixDisplay on true vs predicted labels,Directly supported: passage explains diagonal cells are correct and other cells show mistakes for those publishers.,"machine-learning,classification,evaluation",4,Classical Machine Learning
101157,140,half-true,"The confusion matrix shows correct and mistaken predictions between Marvel, DC, and Other publishers.",confusion_matrix from sklearn.metrics comparing true vs predicted publisher labels,Accurately notes class-wise correct/mistake counts but omits need for consistent class index ordering and encoder alignment.,"machine-learning,classification,evaluation",4,Classical Machine Learning
101158,140,barely-true,The confusion matrix mostly shows correct publisher predictions but mislabels several Other instances as Marvel.,confusion_matrix for publisher labels from Sklearn.metrics,Passage only describes plotting and correct vs mistake cells; specific mislabeling claim lacks supporting data.,"machine-learning,classification,evaluation",4,Classical Machine Learning
101159,25,FALSE,Linear regression reliably models complex interactions and outliers without issue.,"regression model limitations, outliers, hidden interactions","Contradicts passage warning that regression performs poorly with sharp curves, outliers, and complex interactions.","machine-learning,classification,evaluation",4,Classical Machine Learning
101160,25,TRUE,"Linear regression performs poorly when data contains sharp curves, outliers, or complex interactions.",regression model fit and prediction reliability,"Supported by passage: sharp curves, outliers, and hidden interactions cause poor fit and misleading predictions.","machine-learning,classification,evaluation",4,Classical Machine Learning
101161,25,TRUE,"Linear regression can produce misleading predictions when data has sharp curves, outliers, or interactions.",regression model evaluation with outliers and hidden interactions,"Directly supported: passage warns regression is less reliable with sharp curves, outliers, or complex interactions.","machine-learning,classification,evaluation",4,Classical Machine Learning
101162,154,barely-true,Layering open-tool defenses fully eliminates risks from convincing model outputs.,defenses using open tools and skepticism,Overstates effectiveness; passage says layering and open tools help but do not fully eliminate risks or replace skepticism.,"security,red-team,guardrails",8,Breaking-Securing AI
101163,154,half-true,Applying traditional security instincts fully prevents AI model manipulation attempts.,defense-in-depth using open tools and skepticism,Overstates effectiveness: passage endorses old instincts and layered defenses but warns against unquestioning trust and implies residual risk.,"security,red-team,guardrails",8,Breaking-Securing AI
101164,154,half-true,Layering defenses and skepticism reduces but does not eliminate AI security risks in practice.,defense-in-depth with models and open tools,"Accurately notes combined countermeasures lower risk, but overstates residual risk elimination uncertainty.","security,red-team,guardrails",8,Breaking-Securing AI
101165,86,pants-fire,Transformers use self-attention to provide context for all tokens in a sequence.,Transformer model; self-attention mechanism,"Accurately restates passage noting self-attention gives context to all tokens, directly supported.","neural-networks,cnn,transformers",6,Neuron Building Blocks
101166,86,mostly-true,Transformers provide contextual representations for all input tokens via self-attention mechanisms.,transformer self-attention mechanism,"Directly supported by summary table listing Transformer: 'Context for all tokens' and 'Self-attention mechanism', broadly accurate without caveats.","neural-networks,cnn,transformers",6,Neuron Building Blocks
101167,86,TRUE,Transformers use self-attention to provide contextual information for all tokens in a sequence.,Transformer model; self-attention mechanism,"Summary explicitly lists self-attention providing context for all tokens and translation, Q&A, summarization uses.","neural-networks,cnn,transformers",6,Neuron Building Blocks
101168,23,mostly-true,"A builder can achieve strong results using smaller, purpose-built statistical AI models.","smaller, purpose-built models for AI builders","Passage emphasizes opportunity and practicality of classic statistical AI and smaller models, omitting limits of scale.","ai,open-source,builder",1,Introduction – The Gold Rush Paradox
101169,23,TRUE,"A builder can achieve much using smaller, purpose-built statistical AI models.",using smaller purpose-built models in AI builder work,"Passage explicitly states smaller, purpose-built statistical AI offers substantial opportunities for builders.","ai,open-source,builder",1,Introduction – The Gold Rush Paradox
101170,23,half-true,"Smaller, purpose-built models remain practical and useful for most AI builders.",AI builders using smaller models and statistical methods,"Passage endorses smaller, purpose-built models while noting large systems are rare and costly, mixing broad claim with implicit caveats.","ai,open-source,builder",1,Introduction – The Gold Rush Paradox
101171,12,half-true,Anyone with basic Python can reproduce state-of-the-art deep learning results using common frameworks.,accessible tooling and frameworks like the Deep Three,"Partly true: popular frameworks lower barriers, but reproducing state-of-the-art often needs large compute and extensive tuning.","deep-learning,frameworks,tensors",5,Deep Learning
101172,12,half-true,Anyone with basic Python skills can reproduce state-of-the-art deep learning research results at home.,accessibility of Deep Three frameworks and tooling,"Correct that tools and communities lower barriers, but overstates ability to reproduce state-of-the-art research exactly.","deep-learning,frameworks,tensors",5,Deep Learning
101173,12,barely-true,Anyone with basic Python skills can fully reproduce state-of-the-art deep learning research results.,deep-learning frameworks and tooling,"Overreaches: passage says accessibility and tooling exist, not that novice users can reproduce cutting-edge research.","deep-learning,frameworks,tensors",5,Deep Learning
101174,30,barely-true,Open-source tools alone can fully certify AI systems without governing body involvement.,open-source tools and certifications,Overreaches: passage says open-source supports certification but governance bodies set standards and accountability.,"ethics,governance,privacy",11,AI Ethics and Governance
101175,30,FALSE,Open-source tools alone guarantee ethical AI certification for models and deployments.,open-source tools and datasets supporting certification efforts,Passage states openness supports transparency and credibility but does not claim guarantees; assertion contradicts that nuance.,"ethics,governance,privacy",11,AI Ethics and Governance
101176,30,barely-true,Open-source tools alone can ensure trustworthy AI certifications across governance levels.,open-source tools and datasets supporting certification processes,Overstates tool impact; passage says transparency helps credibility but also requires governing bodies and standards.,"ethics,governance,privacy",11,AI Ethics and Governance
101177,22,mostly-true,"A neuron computes a weighted sum of inputs, adds bias, then applies an activation function to decide output.","neuron computation using weights, bias, and activation function",Explanation matches passage description exactly; minor numerical rounding in the example is omitted but concept is fully supported.,"deep-learning,frameworks,tensors",5,Deep Learning
101178,22,half-true,"A neuron computes a weighted sum of inputs plus bias, then applies an activation function to decide output.","neural network neuron, weights, bias, activation function","Mostly accurate description but simplifies continuous activations and omits vectorized, layer-wise operations.","deep-learning,frameworks,tensors",5,Deep Learning
101179,22,half-true,"The described neuron computes a weighted sum plus bias, then applies an activation function to decide output.","neuron computation, weights, bias, activation function",Accurately mixes correct mechanism with oversimplification of activation roles and ignores vectorized/tensor details.,"deep-learning,frameworks,tensors",5,Deep Learning
101180,159,barely-true,DataLoader always improves model generalization by shuffling and batching training datasets.,DataLoader batching and shuffling for GPU-optimized training,"Overreaches: passage notes batching/shuffling help efficiency and reduce order bias, not guarantee improved generalization.","deep-learning,frameworks,tensors",5,Deep Learning
101181,159,mostly-true,The DataLoader batches and shuffles training tensors to improve GPU training efficiency and generalization.,DataLoader operations on tensors for GPU-optimized training,"Describes batching for GPU parallelism and shuffling to avoid order memorization, omitting minor implementation details.","deep-learning,frameworks,tensors",5,Deep Learning
101182,159,TRUE,DataLoader batches individual samples into mini-batches for efficient GPU processing.,DataLoader batching for GPU-optimized mini-batches,Directly supported: passage explains batching groups samples into mini-batches and GPUs handle batches more efficiently.,"deep-learning,frameworks,tensors",5,Deep Learning
101183,154,FALSE,DataLoader must preprocess all MNIST images before loading them into memory.,DataLoader transformations applied on the fly to MNIST images,"Passage specifies preprocessing happens as DataLoader loads images, not beforehand; contradicts preloading requirement.","deep-learning,frameworks,tensors",5,Deep Learning
101184,154,pants-fire,The DataLoader permanently modifies the MNIST dataset files on disk during loading.,data preprocessing with DataLoader and MNIST dataset,"Contradicts passage detail that transformations are applied on the fly during loading, not written to disk.","deep-learning,frameworks,tensors",5,Deep Learning
101185,154,half-true,The DataLoader applies preprocessing transformations on the fly to each MNIST image during loading.,DataLoader applying transformations to MNIST dataset tensors,Accurately describes on-the-fly transformation but omits that transformations are defined beforehand and not performed by DataLoader itself.,"deep-learning,frameworks,tensors",5,Deep Learning
101186,7,TRUE,"Classical models are simple, interpretable, and computationally efficient.",foundations of classical machine learning; labeled and unlabeled data,"Passage explicitly praises simplicity, interpretability, and low compute requirements for classical models.","machine-learning,classification,evaluation",4,Classical Machine Learning
101187,7,half-true,Classical models always require heavy computing resources to train and evaluate.,"classical machine learning models, computing efficiency",Contradicts passage claim about efficiency; mixes correct training needs with incorrect universal heavy compute assertion.,"machine-learning,classification,evaluation",4,Classical Machine Learning
101188,7,half-true,Classical models are always preferred when compute resources are limited and interpretability is required.,"classical machine learning, interpretability, compute efficiency",Mixes correct points about interpretability and efficiency with absolute claim 'always preferred' that overreaches practical trade-offs.,"machine-learning,classification,evaluation",4,Classical Machine Learning
101189,84,half-true,Agents can reuse cached tool outputs to speed up web search–based tasks but may face stale results.,tool caching and WebsiteSearchTool integration,"Passage affirms caching speeds execution and WebsiteSearchTool use, but omits staleness risks.","agentic-ai,planning,tools",12,Agentic AI
101190,84,pants-fire,Agents can fully replace human scientists by autonomously designing and validating novel physics experiments.,custom tools and scientific formula solver,Passage only claims custom tools can solve formulas and assist simulations; it does not support full autonomous experimental design or validation.,"agentic-ai,planning,tools",12,Agentic AI
101191,84,pants-fire,Agentic AI tools can flawlessly solve any scientific physics simulation without error.,custom tools for scientific formula solver,"Passage mentions custom formula solvers but never claims flawless, error-free solutions; claim contradicts realistic limitations.","agentic-ai,planning,tools",12,Agentic AI
101192,111,pants-fire,RAG stores all knowledge as immutable text files that models directly read.,RAG vector databases and AI workload storage,"Contradicts passage claim that RAG uses numerical vectors, not immutable plain text, for storage and retrieval.","data-prep,feature-engineering,rag",3,Prepping Data for AI
101193,111,TRUE,"RAG retrieves up-to-date, specialized information by searching vectorized knowledge stores.",retrieval-augmented generation using vector databases for AI workloads,"Passage states RAG uses vectorized databases to access timely, specialized context the model lacks, enabling search and ranking.","data-prep,feature-engineering,rag",3,Prepping Data for AI
101194,111,FALSE,RAG stores information as raw plain text rather than numerical vectors for retrieval.,retrieval-augmented generation using vector database,Passage says RAG depends on databases storing information as vectors; statement contradicts that vector-based detail.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
101195,180,half-true,Classical ML is generally ineffective on messy unstructured data compared to deep learning models.,"handling raw text, images, or audio in model selection","Passage states deep learning dominates for messy unstructured inputs, but overgeneralizes; classical methods sometimes work with feature engineering.","machine-learning,classification,evaluation",4,Classical Machine Learning
101196,180,mostly-true,Classical ML methods often underperform on messy unstructured inputs compared to deep learning models.,"unstructured inputs like raw text, images, or audio","Passage says deep learning dominates on messy unstructured data, omitting some possible classical ML preprocessing successes.","machine-learning,classification,evaluation",4,Classical Machine Learning
101197,180,barely-true,"Classical ML models generally perform poorly on raw text, images, or audio compared to deep learning.","suitability for messy, unstructured inputs like raw text or images",Overreaches by generalizing performance; passage says deep learning tends to dominate but not that classical models generally fail.,"machine-learning,classification,evaluation",4,Classical Machine Learning
101198,38,barely-true,"The dataset should drop Eye, Hair, and Skin color because they are useless and harmful for all models.","dataset preprocessing, removing sparse sensitive columns","Overreaches: passage recommends removal due to sparsity and bias concerns, not blanket uselessness for every model.","data-prep,feature-engineering,rag",3,Prepping Data for AI
101199,38,pants-fire,Dropping row number and demographic color fields will always make models vastly more accurate.,"dataset preprocessing; removing row number, Eye/Hair/Skin color fields","Claim extremely contradicts passage; passage only removes fields for bias and sparsity, not claiming accuracy benefits.","data-prep,feature-engineering,rag",3,Prepping Data for AI
101200,38,barely-true,"They removed Eye, Hair, and Skin color columns because they are sparse and potentially biased.",dataset preprocessing; feature selection in data-prep,Matches passage claim but overstates certainty about bias impact and excludes discussion of alternative mitigation.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
101201,9,TRUE,Scikit-Learn supports starting with simple baselines then refining features and models.,Scikit-Learn toolkit and model evaluation strategies,"Passage explicitly recommends starting simple, testing baselines, then refining features and tuning models using Scikit-Learn.","machine-learning,classification,evaluation",4,Classical Machine Learning
101202,9,TRUE,Scikit-learn is used as a primary toolkit for building and evaluating models.,Scikit-learn toolkit for model building and evaluation,Passage explicitly introduces Scikit-learn as the toolkit used and shows it in full action for model evaluation.,"machine-learning,classification,evaluation",4,Classical Machine Learning
101203,9,mostly-true,Practitioners should start with simple baselines and iteratively refine features and models.,model evaluation and feature engineering with Scikit-Learn,"Aligns with guidance to test baselines, refine features, tune models, and watch imbalanced data and accuracy pitfalls.","machine-learning,classification,evaluation",4,Classical Machine Learning
101204,65,TRUE,GPUs delay but do not eliminate scaling limits for larger inputs and longer sequences.,AI At Scale — GPU memory and cache bandwidth limits,Passage states GPUs push the constraint later yet still succumb to memory and processing limits.,"mlops,scaling,deployment",10,AI At Scale
101205,65,TRUE,GPUs handle larger inputs longer before memory and processing limits are reached.,"AI at Scale, GPU memory and parallelism limits",Passage states GPUs endure larger inputs longer due to higher parallelism and bigger caches.,"mlops,scaling,deployment",10,AI At Scale
101206,65,barely-true,GPUs never face memory or processing limits when scaling long inputs.,scaling on lower-powered hardware and GPU memory limits,Overreach contradicts passage noting GPUs eventually hit memory and processing strains despite later scaling benefits.,"mlops,scaling,deployment",10,AI At Scale
101207,154,half-true,Linear regression reveals individual feature weights but deep learning often obscures them.,model interpretability for linear regression and deep learning,"Accurate about feature weights and black-box nature, but omits nuance about explainability methods for deep models.","machine-learning,classification,evaluation",4,Classical Machine Learning
101208,154,barely-true,Classical ML models are always interpretable because they expose each feature's weight.,interpretability of linear regression and deep learning,Overstates interpretability; passage cites linear regression example but ignores models where weights aren't directly meaningful.,"machine-learning,classification,evaluation",4,Classical Machine Learning
101209,154,half-true,"Linear regression reveals each feature's weight, providing straightforward interpretability for decisions.",interpretability of linear regression model in regulated industries,Accurately notes feature weights and interpretability but omits that some linear assumptions or feature interactions can mislead.,"machine-learning,classification,evaluation",4,Classical Machine Learning
101210,177,half-true,Scikit-learn is the uncontested best library for all classical ML tasks in practice.,scikit-learn library for classification and regression,"Overstates claim: passage praises scikit-learn but calls it a gold standard, not an uncontested best for every task.","machine-learning,classification,evaluation",4,Classical Machine Learning
101211,177,barely-true,Scikit-learn is universally the best choice for all classical ML tasks.,scikit-learn library for classification and regression,Overreaches claim: passage praises scikit-learn but stops short of declaring it universally best.,"machine-learning,classification,evaluation",4,Classical Machine Learning
101212,177,TRUE,Scikit-learn is a widely used open-source library for classical machine learning tasks.,"scikit-learn library for regression, classification, clustering",Passage explicitly names scikit-learn as the gold standard with robust tools for common ML tasks.,"machine-learning,classification,evaluation",4,Classical Machine Learning
101213,33,half-true,Scikit-learn's model.fit trains on X_train and model.predict produces predictions on X_test.,"train-test split with X_train, y_train, X_test in scikit-learn","Partly correct: fit/predict usage is right, but claim omits that predict runs on unseen test inputs and oversimplifies training/testing purpose.","machine-learning,classification,evaluation",4,Classical Machine Learning
101214,33,half-true,Scikit-learn uses model.fit on training features X and model.predict to generate test predictions y.,"Scikit-learn regression example with X_train, y_train, X_test, y_test","Mixes correct API usage with incorrect phrasing: predict outputs predictions, not the true y labels.","machine-learning,classification,evaluation",4,Classical Machine Learning
101215,33,mostly-true,Scikit-learn trains on X_train and predicts on X_test using model.fit and model.predict.,training/testing split with X (features) and y (target) in Scikit-learn,Directly describes fit/predict workflow; omits minor details like parameter tuning or cross-validation.,"machine-learning,classification,evaluation",4,Classical Machine Learning
101216,91,mostly-true,European AI regulations emphasize risk-based governance and data privacy safeguards for high-risk AI systems.,"AI Act proposal, GDPR, risk-based regulatory framework","Broadly supported by AI Act and GDPR references, though specific implementation details and exemptions omitted.","ethics,governance,privacy",11,AI Ethics and Governance
101217,91,half-true,EU AI regulation will universally ban high-risk model deployments without vendor responsibility exceptions.,"AI Act high-risk systems, model governance, and vendor liability","Partly correct about strict limits and high-risk classification, but incorrectly asserts universal ban and omits existing liability exemptions and nuanced vendor duties.","ethics,governance,privacy",11,AI Ethics and Governance
101218,91,mostly-true,European AI policy proposals emphasize risk-based regulation and data protection for AI systems.,AI Act proposal; GDPR data protection,"Aligns with AI Act and GDPR emphasis on risk-based rules and data protection, minor implementation caveats omitted.","ethics,governance,privacy",11,AI Ethics and Governance
101219,129,FALSE,The Neural Duel experiment only evaluates models on image classification tasks.,Neural Duel experiment comparing LLMs,"Passage describes LLM reasoning and factual accuracy comparisons, not image classification tasks.","agentic-ai,planning,tools",12,Agentic AI
101220,129,half-true,Neural Duel performance claims mix correct findings with some inaccurate specifics about event dates.,"Neural Duel model evaluation, factual accuracy and reasoning",Evaluation notes correct model-comparison idea but misstates eruption start year and some factual details.,"agentic-ai,planning,tools",12,Agentic AI
101221,129,half-true,Neural Duel reliably identifies factual accuracy by comparing LLM answers in head-to-head matches.,Neural Duel evaluation of model comparisons and factual accuracy,Approach mixes correct comparison idea with overclaim that it reliably judges factual accuracy without validation.,"agentic-ai,planning,tools",12,Agentic AI
101222,16,barely-true,Agentic AIs reliably make intelligent decisions when given structured data and clear prompts.,AI Abstractions section discussing structured data and prompts,Overstates reliability; passage claims AI thrives with structure but not guaranteed decision quality.,"agentic-ai,planning,tools",12,Agentic AI
101223,16,FALSE,Agentic AI always succeeds without structured data or clear prompts.,AI Abstractions; model decision-making and prompts,Contradicts passage statement that AI thrives with structured data and clear prompts.,"agentic-ai,planning,tools",12,Agentic AI
101224,16,barely-true,Agentic AI reliably transfers gaming strategies unchanged into real-world decision-making tasks.,"AI Abstractions; structured data, prompts, model capabilities","Overstates transferability; passage only suggests applying ideas from gaming, not reliable unchanged transfer.","agentic-ai,planning,tools",12,Agentic AI
101225,13,TRUE,Librosa was designed to make sound analysis mathematics accessible to researchers and hobbyists.,"librosa library, audio and music signal analysis",Directly supported by McFee's goal and SciPy 2015 paper noting accessibility and approachable design.,"media-forensics,voice-cloning,deepfake",9,Deepfake Defense
101226,13,barely-true,Librosa was designed primarily to support deepfake voice-cloning research workflows.,audio analysis library Librosa; tool for voice-cloning and media-forensics,"Overstates original purpose: Librosa targets general audio/music analysis, not specifically deepfake or voice-cloning research.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
101227,13,barely-true,Librosa is primarily designed for deepfake voice-cloning detection tasks.,audio analysis library (Librosa) used in media-forensics and voice-cloning,"Overstates purpose: Librosa is an accessible audio analysis library, not primarily a deepfake detection tool.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
101228,116,FALSE,CrewAI automatically guarantees flawless turn-based game execution without human oversight.,CrewAI framework organizing agents and tasks,Contradicts passage: CrewAI orchestrates and coordinates turns but does not claim automatic flawless execution or removal of human oversight.,"agentic-ai,planning,tools",12,Agentic AI
101229,116,TRUE,CrewAI coordinates multiple agents to orchestrate turn-based task execution.,CrewAI framework organizing agents and tasks,Passage describes creating a CrewAI to organize agents and coordinate turn-based task execution.,"agentic-ai,planning,tools",12,Agentic AI
101230,116,TRUE,CrewAI organizes agents and coordinates task execution for turn-based game orchestration.,CrewAI framework organizing agents and tasks,"Directly supported: passage states CrewAI organizes agents, coordinates execution, and orchestrates turn-based game sequencing.","agentic-ai,planning,tools",12,Agentic AI
101231,105,half-true,Diffusion models generate data by starting from noise and gradually removing uncertainty through reverse diffusion.,reverse diffusion process in diffusion models,"Accurately describes stepwise denoising, but omits training specifics and exact noise-scheduling mechanisms.","generative-ai,diffusion,gans",7,Generative AI
101232,105,half-true,Diffusion models generate images by gradually denoising noise through learned reverse diffusion steps.,reverse diffusion process in diffusion models,Accurately describes gradual denoising but omits training details and stepwise uncertainty subtraction specifics.,"generative-ai,diffusion,gans",7,Generative AI
101233,105,half-true,Diffusion models reconstruct data by iteratively denoising starting from pure noise.,reverse diffusion process in diffusion models,"Accurately describes iterative denoising, but omits training specifics and stepwise uncertainty subtraction.","generative-ai,diffusion,gans",7,Generative AI
101234,127,mostly-true,Red and Blue teams jointly reproduce filter bypasses and collect logs as primary evidence for attacks.,triage and evidence collection in sandbox with logs and code scripts,"Passage describes Red and Blue Leads reproducing failures, collecting logs, and producing scripts; minor caveat about duration and scope omitted.","security,red-team,guardrails",8,Breaking-Securing AI
101235,127,barely-true,Capturing every bypassed input guarantees proof of attacks and complete remediation planning.,Triage and Evidence Collection; logs and sandbox reproduction,Overstates reality: capturing inputs helps evidence but doesn't guarantee proof or full remediation planning.,"security,red-team,guardrails",8,Breaking-Securing AI
101236,127,barely-true,Red and Blue teams can reliably reproduce every filter bypass within 60 minutes.,Triage and Evidence Collection; sandbox reproduction,Overstates timing and certainty: passage sets a 30–60 minute workflow but doesn't guarantee every bypass reproduced.,"security,red-team,guardrails",8,Breaking-Securing AI
101237,40,TRUE,The generator's loss measures how well it fools the discriminator.,GAN training loss interpretation,Directly stated: generator loss quantifies its success at fooling the discriminator during training.,"generative-ai,diffusion,gans",7,Generative AI
101238,40,barely-true,The discriminator loss spiking to 1.7177 proves the generator has definitively improved its realism.,GAN training discriminator loss and generator loss metrics,"Loss spikes can reflect instability, not definitive generator improvement; claim overreaches evidence.","generative-ai,diffusion,gans",7,Generative AI
101239,40,barely-true,The discriminator loss spike at epoch 12 proves the generator is substantially improving its outputs.,GAN training; discriminator loss and generator loss metrics,Loss spike alone doesn't prove generator improvement; spikes can reflect instability or discriminator dynamics.,"generative-ai,diffusion,gans",7,Generative AI
101240,31,TRUE,Understanding a few practical mathematical concepts helps build and optimize AI models.,practical math for AI model building (concepts tied to code),"Passage states practical math concepts directly aid building and optimizing AI models, not heavy theory.","ai,tool-chain,notebooks",2,AI Survival Kit
101241,31,pants-fire,All AI development strictly requires advanced theoretical mathematics to function correctly.,practical math for AI model building in notebooks,"Directly contradicts passage claiming only practical, non-theoretical math is needed; false assumption of necessity of advanced theory.","ai,tool-chain,notebooks",2,AI Survival Kit
101242,31,half-true,Understanding only basic practical math is sufficient to build and optimize all useful AI models.,practical math for building and optimizing AI models,Mixes correct claim about practical math helping with overgeneralized assertion that basic math alone suffices for all useful models.,"ai,tool-chain,notebooks",2,AI Survival Kit
101243,162,FALSE,Torch DataLoader eagerly loads the entire dataset into memory upon construction.,PyTorch DataLoader iterable behavior,"Contradicts passage: DataLoader creates an iterable and loads items only when iterated, not at construction.","deep-learning,frameworks,tensors",5,Deep Learning
101244,162,barely-true,Torch DataLoader creates an iterable that loads and transforms data only during iteration.,torch.utils.data.DataLoader iterable behavior,"Accurate description but omits details like prefetching, num_workers, and batch collation effects.","deep-learning,frameworks,tensors",5,Deep Learning
101245,162,TRUE,A DataLoader creates an iterable that loads data only when iterated over.,PyTorch DataLoader and train_loader iterable,Directly matches passage: DataLoader constructs an iterable and loads/transforms data upon iteration in training loops.,"deep-learning,frameworks,tensors",5,Deep Learning
101246,116,FALSE,The model cannot be run in a web interface or on Hugging Face Spaces.,deployment on Hugging Face Spaces web interface,"Passage says the model runs on Hugging Face Spaces with a complete web interface, so this contradicts that detail.","mlops,scaling,deployment",10,AI At Scale
101247,116,mostly-true,The configured API model can be deployed in a Hugging Face Spaces web interface for easy user access.,deployment on Hugging Face Spaces web interface,"Passage describes running the same configured API model in a Spaces web UI for label testing, omitting potential setup or performance caveats.","mlops,scaling,deployment",10,AI At Scale
101248,116,TRUE,The configured model runs in a web interface on Hugging Face Spaces for label prediction.,Hugging Face Spaces web interface for model API access,Passage explicitly describes deploying the same configured model to a Hugging Face Spaces web interface for live labeling.,"mlops,scaling,deployment",10,AI At Scale
101249,76,half-true,LLM security gateways use multiple tools jointly to reduce risk in real-world deployments.,"LLM Security Gateway Architecture, tools and code examples","Partly accurate: passage says multiple tools provide broad coverage, but omits specifics and performance trade-offs.","security,red-team,guardrails",8,Breaking-Securing AI
101250,76,TRUE,The architecture uses multiple tools working together to reduce LLM system risk.,LLM Security Gateway architecture and tools,"Passage states distinct tools used together provide broad coverage and reduce risk, with examples promised.","security,red-team,guardrails",8,Breaking-Securing AI
101251,76,half-true,An LLM Security Gateway alone eliminates almost all real-world attack risks for deployed models.,LLM Security Gateway architecture and toolchain,"Overstates effectiveness: passage says tools together reduce risk and provide broad coverage, not that a single gateway eliminates almost all attacks.","security,red-team,guardrails",8,Breaking-Securing AI
101252,31,mostly-true,The passage argues that prompts largely determine AI agents' behavior and goals.,"AI agents, prompting and behavior shaping","Assertion aligns with passage emphasis that prompts shape agents' behavior, goals, and reasoning; minor nuance about other influences omitted.","agentic-ai,planning,tools",12,Agentic AI
101253,31,half-true,Prompt wording partly determines an AI agent's goals and reasoning but not all behavior specifics.,"AI agents, prompts, and agentic AI tools","Passage states prompts shape behavior, goals, and reasoning but omits other factors like model architecture and environment.","agentic-ai,planning,tools",12,Agentic AI
101254,31,half-true,"Agent prompts shape AI agents' behavior, goals, and reasoning but do not guarantee perfect performance.",prompting influence on agentic AI behavior,"Passage states prompts shape behavior, goals, reasoning but omits performance limits or guarantees.","agentic-ai,planning,tools",12,Agentic AI
101255,194,mostly-true,PyTorch models commonly save learned parameters using model.state_dict().,model serialization in PyTorch; state_dict saves weights and biases,Directly supported: passage states model.state_dict() saves learned parameters (weights and biases).,"deep-learning,frameworks,tensors",5,Deep Learning
101256,194,mostly-true,PyTorch commonly saves a trained model's learned parameters using model.state_dict().,saving models in PyTorch using state_dict for parameters,"Accurately describes standard practice of saving weights and biases via state_dict(), omitting other methods like torch.save for full models.","deep-learning,frameworks,tensors",5,Deep Learning
101257,194,TRUE,PyTorch models save learned parameters using model.state_dict().,model saving in PyTorch; state_dict for weights and biases,Directly supported: passage states model.state_dict() saves learned parameters (weights and biases).,"deep-learning,frameworks,tensors",5,Deep Learning
101258,15,half-true,Robby shortlisted a small library for embedding fine-tuned LLMs alongside two poorly maintained projects.,"project selection, CONTRIBUTING.md, open issues, embedding LLMs","Accurately notes shortlist composition and embedding library, but exaggerates poor maintenance specifics for both other projects.","open-source,community,contribution",13,Commit to Contribute
101259,15,barely-true,Robby picked the Comic Sans CONTRIBUTING.md project as the best contribution opportunity.,"project selection, CONTRIBUTING.md file in open-source archives","Passage describes Comic Sans file but indicates shortlist, not selection; claim overreaches available evidence.","open-source,community,contribution",13,Commit to Contribute
101260,15,mostly-true,Robby prioritized a small library for embedding fine-tuned LLMs into community-run archives.,"project selection and CONTRIBUTING.md, open issues, embedding LLMs","Passage broadly supports prioritizing the small embedding library, omitting minor motivations or other factors.","open-source,community,contribution",13,Commit to Contribute
101261,8,half-true,"A 2x2 filter [1,0;0,-1] partly detects diagonal edges but misstates response conditions for all diagonals.",2x2 convolutional filter for diagonal edge detection in CNNs,"Correctly identifies diagonal sensitivity, but overgeneralizes response conditions and ignores normalization and opposite diagonal cases.","neural-networks,cnn,transformers",6,Neuron Building Blocks
101262,8,TRUE,A 2x2 diagonal filter responds strongly when top-left is bright and bottom-right is dark.,2x2 filter detecting diagonal edges in a 4x4 grayscale image,"Example shows a [1,0;0,-1] filter producing strong response for bright top-left and dark bottom-right.","neural-networks,cnn,transformers",6,Neuron Building Blocks
101263,8,FALSE,A 2x2 diagonal filter produces zero response when top-left is bright and bottom-right dark.,2x2 filter for diagonal edge detection,"Contradicts passage: such a filter responds strongly when top-left is bright and bottom-right dark, not zero.","neural-networks,cnn,transformers",6,Neuron Building Blocks
101264,71,mostly-true,Batching requests on GPU enables higher throughput while slightly increasing per-sample latency.,"tokenizer, GPU batching, latency per sample and throughput",Passage explains GPU batch processing increases overall throughput but measures per-sample latency rise with larger batches.,"mlops,scaling,deployment",10,AI At Scale
101265,71,half-true,Batching multiple 512-token prompts on GPU always increases model throughput without latency tradeoffs.,"tokenizer, batching, GPU throughput measurement",Mixes correct batching throughput gains with incorrect claim that latency tradeoffs never occur; benchmark measured both latency and throughput.,"mlops,scaling,deployment",10,AI At Scale
101266,71,half-true,Batching prompts on a GPU always increases throughput without affecting per-sample latency.,tokenizer batching and GPU throughput with synthetic 512-token prompts,"Throughput often improves with batching, but latency per sample can increase or vary depending on batch size and model.","mlops,scaling,deployment",10,AI At Scale
101267,28,TRUE,Recurrent Neural Networks are needed for tasks where sequence and order matter.,sequence modeling with RNNs and CNNs,Passage contrasts CNNs' spatial strengths with RNNs' memory for sequential data like sentences and logs.,"neural-networks,cnn,transformers",6,Neuron Building Blocks
101268,28,pants-fire,CNNs always fail utterly on all sequence tasks and cannot model any temporal patterns.,comparing CNNs to RNNs for sequence and time-dependent data,"Directly contradicts passage nuance: passage notes CNNs spot spatial patterns but not designed for order, not absolute impossibility.","neural-networks,cnn,transformers",6,Neuron Building Blocks
101269,28,FALSE,Recurrent Neural Networks are never suitable for processing sequence data.,RNN model for sequence memory in neural-networks,Contradicts passage claim that RNNs are needed for sequence tasks; RNNs are in fact designed for ordered data.,"neural-networks,cnn,transformers",6,Neuron Building Blocks
101270,113,half-true,The example chain mixes a prompt template with a Hugging Face chat endpoint for short replies.,Langchain ChatPromptTemplate with HuggingFaceEndpoint tool,"Accurate about combining prompt template and Hugging Face chat, but overstates 'mixes' without noting StrOutputParser and specific parameters like temperature.","ai,tool-chain,notebooks",2,AI Survival Kit
101271,113,FALSE,The example code runs only on local GPU machines and cannot use hosted endpoints.,LangChain ChatHuggingFace with HuggingFaceEndpoint tool,Contradicts example which explicitly uses HuggingFaceEndpoint hosted inference endpoints.,"ai,tool-chain,notebooks",2,AI Survival Kit
101272,113,barely-true,The example guarantees identical replies across different models when temperature is low.,Langchain ChatHuggingFace prompt and temperature setting,Overstates claim: passage notes lower temperature increases consistency but not guaranteed identical outputs.,"ai,tool-chain,notebooks",2,AI Survival Kit
101273,25,half-true,MT-Bench reliably measures multi-turn conversational ability across diverse chatbot models.,MT-Bench multi-turn benchmark for chatbot evaluation,"Partly true: MT-Bench is a trusted multi-turn benchmark, but claiming it reliably measures all conversational ability overstates coverage and nuances.","mlops,scaling,deployment",10,AI At Scale
101274,25,mostly-true,MT‑Bench broadly measures multi‑turn conversational quality across chat models with minor scope limitations.,multi-turn benchmark MT-Bench for conversational models,"Describes MT-Bench's focus on multi-turn conversation and trustworthiness, but omits specific limitations and evaluation details.","mlops,scaling,deployment",10,AI At Scale
101275,25,half-true,MT-Bench reliably measures multi-turn conversational quality across diverse chat models.,evaluation benchmark for multi-turn chat models (MT-Bench),Accurately notes multi-turn focus but overstates reliability and generalizability across all models and settings.,"mlops,scaling,deployment",10,AI At Scale
101276,66,barely-true,The generator maps a 100-dimensional noise vector through several fully connected layers.,"generator architecture, noise vector size 100, Tanh output",Passage explicitly states a 100-size noise vector is mapped through fully connected layers; accurate and directly supported.,"generative-ai,diffusion,gans",7,Generative AI
101277,66,mostly-true,The generator maps 100-dimensional noise through fully connected layers to produce images matching Tanh outputs.,generator architecture; Tanh activation and 100-dimensional noise vector,"Supported by passage: noise vector size 100 and fully connected generator layers, and Tanh output range matching normalized pixels, minor architecture details omitted.","generative-ai,diffusion,gans",7,Generative AI
101278,66,TRUE,The generator maps a 100-dimensional noise vector through fully connected layers.,generator architecture; noise vector size 100; Tanh output,"Passage explicitly states the generator takes a random noise vector of size 100 and maps it through fully connected layers, matching the Tanh output range.","generative-ai,diffusion,gans",7,Generative AI
101279,129,mostly-true,The classifier is initialized with default settings and dense input arrays for a fair baseline.,"vanilla model, .toarray() conversion, dense arrays requirement",Passage explicitly notes using defaults and converting sparse feature matrices to dense arrays for a baseline.,"machine-learning,classification,evaluation",4,Classical Machine Learning
101280,129,half-true,The classifier requires dense arrays so sparse feature matrices must be converted.,"feature matrices, .toarray(), dense arrays","Partly correct about needing dense arrays, but overstates universality and omits which classifier (HGB) specifics.","machine-learning,classification,evaluation",4,Classical Machine Learning
101281,129,FALSE,The classifier requires sparse CSR feature matrices for correct operation.,"encoded feature matrices, .toarray() conversion","Contradicts passage detail that the classifier needs dense arrays, not sparse CSR matrices.","machine-learning,classification,evaluation",4,Classical Machine Learning
101282,69,TRUE,AI-generated code should be scanned with static analysis tools before committing.,"static analysis with Bandit, Semgrep, CodeQL on AI-generated code","Passage explicitly advises treating AI code as untrusted and scanning with Bandit, Semgrep, CodeQL.","security,red-team,guardrails",8,Breaking-Securing AI
101283,69,FALSE,AI-generated code should be treated as untrusted and scanned before committing.,"AI-generated code; tools: Bandit, Semgrep, CodeQL","Contradicts passage which advises treating AI code as untrusted and scanning before commit; statement matches passage, so label FALSE is incorrect.","security,red-team,guardrails",8,Breaking-Securing AI
101284,69,pants-fire,The model was trained on deliberately poisoned datasets to make it malicious.,data poisoning of model training,"Directly contradicts passage: it warns data poisoning as a threat, not that training was intentionally poisoned.","security,red-team,guardrails",8,Breaking-Securing AI
101285,32,pants-fire,Owning training data guarantees models will always be trustworthy and widely used.,data ownership and responsible data use for builders,"Asserts certainty that ownership alone ensures trustworthiness and adoption, contradicting passage nuance about understanding, respecting, and wise use being required.","ai,open-source,builder",1,Introduction – The Gold Rush Paradox
101286,32,TRUE,"Responsible data handling leads builders to more trustworthy, user-accepted AI systems.",data ownership and responsible use for builders,Passage states responsible data ownership and use produce systems people want and trust.,"ai,open-source,builder",1,Introduction – The Gold Rush Paradox
101287,32,half-true,Owning data and using it wisely guarantees long-term user trust and product success.,data ownership and responsible use for builders,Accurate high-level claim mixed with overgeneralization; passage advocates practice but doesn't guarantee outcomes.,"ai,open-source,builder",1,Introduction – The Gold Rush Paradox
101288,45,mostly-true,Open-source transparency practices broadly strengthen security by revealing dataset and model details.,"model cards, data cards, factsheets for inspection","Supports defense claim by citing model cards and factsheets, omitting practical limits like adversary misuse and maintenance overhead.","security,red-team,guardrails",8,Breaking-Securing AI
101289,45,FALSE,"Open-source projects always provide structured, layered, and inspectable model transparency.",model cards and factsheets in open-source projects,Contradicts passage nuance: open source is a strong defense but not claimed to always ensure that level of transparency.,"security,red-team,guardrails",8,Breaking-Securing AI
101290,45,mostly-true,Open-source projects with data cards and model cards generally improve system transparency and defense.,"use of data cards, model cards, and factsheets in open-source projects","Supports stronger, layered transparency and inspectability; omits potential gaps in security practices.","security,red-team,guardrails",8,Breaking-Securing AI
101291,100,half-true,The VAE both compresses data and generates realistic variations from its latent space.,variational autoencoder (VAE) latent representation and reparameterization trick,"Combines correct points: compression, latent sampling, reparameterization; overstates 'realistic' without quantitative fidelity evidence.","generative-ai,diffusion,gans",7,Generative AI
101292,100,TRUE,A VAE learns a compact latent representation and can recreate inputs while generating realistic variations.,variational autoencoder (VAE) latent space and reparameterization trick,"Directly supported: passage states VAEs learn compact latent representations, recreate inputs, and generate realistic variations.","generative-ai,diffusion,gans",7,Generative AI
101293,100,mostly-true,A VAE learns a compact latent representation used for accurate reconstruction and realistic variation generation.,variational autoencoder latent space and reparameterization trick,"Passage states VAEs compress data into a latent space, reconstruct inputs, and generate realistic variations; minor caveat about task-specific performance omitted.","generative-ai,diffusion,gans",7,Generative AI
101294,77,half-true,Prompt injection attacks can override model instructions by sneaking malicious context into prompts.,"prompt injection mitigation, prompt twisting, model instructions",Accurately describes attack vector but omits mitigation complexity and defenses like guardrails.,"security,red-team,guardrails",8,Breaking-Securing AI
101295,77,mostly-true,Prompt injection attacks can manipulate a model by altering its instructions or context.,prompt injection mitigation; model instruction and context manipulation,"Passage explicitly says attackers start at the prompt, twisting instructions or sneaking context to override intent.","security,red-team,guardrails",8,Breaking-Securing AI
101296,77,barely-true,Prompt injection attacks can often trick models by altering their instruction context to bypass safeguards.,"prompt injection mitigation, model instructions","Passage suggests prompt-based overrides are a starting point, but overstates ease and success likelihood.","security,red-team,guardrails",8,Breaking-Securing AI
101297,8,half-true,"Agentic AI automates problem decomposition, planning, and iterative action like a chess engine.","agentic AI planning and automation, chess engine analogy","Accurately cites planning, decomposition, and iterative acting, but overstates universality of automation.","agentic-ai,planning,tools",12,Agentic AI
101298,8,half-true,Agentic AI plans by breaking tasks into smaller steps and automating their execution for efficiency.,planning and automation in agentic AI,"Correct about decomposing tasks and automation, but overstates guaranteed efficiency and omits limits like developer burden and real-world constraints.","agentic-ai,planning,tools",12,Agentic AI
101299,8,half-true,"Agentic AI must automate planning, execution, and continuous data-driven refinement to function effectively.",agentic AI planning and automation in execution,Mixes correct automation and planning claims with overstated necessity and absolutes about 'must' and effectiveness.,"agentic-ai,planning,tools",12,Agentic AI
101300,32,barely-true,AI models primarily rely on symbolic logic systems rather than numerical operations for training.,model internals and tensors in tool-chain and notebooks,"Passage emphasizes numerical operations and tensors; claim swaps core mechanism to symbolic logic, a notable overreach and contradiction.","ai,tool-chain,notebooks",2,AI Survival Kit
101301,32,TRUE,"AI models represent and process data using vectors, matrices, and tensors.","representation structures: vectors, matrices, tensors","Passage explicitly states models use vectors, matrices, and tensors to represent and process data numerically.","ai,tool-chain,notebooks",2,AI Survival Kit
101302,32,FALSE,AI models primarily rely on symbolic rules rather than numerical operations.,"core concepts: vectors, matrices, tensors in model training","Contradicts passage asserting models manipulate numbers and use vectors, matrices, tensors for training.","ai,tool-chain,notebooks",2,AI Survival Kit
101303,146,barely-true,Agentic AI will almost entirely replace human supervision in real-world tasks soon.,agentic AI reliance on human setup and supervision,Contradicts passage noting agents still require human input and full autonomy is rare.,"agentic-ai,planning,tools",12,Agentic AI
101304,146,mostly-true,"Agentic AI functions primarily as a partner that still requires human setup, supervision, and judgment.",agentic AI reliance on human supervision and setup,"Passage states agents remain human-dependent for setup, supervision, and rare full autonomy, so broadly supported.","agentic-ai,planning,tools",12,Agentic AI
101305,146,TRUE,Agentic AI currently acts more as a partner than a replacement for humans.,"agentic AI reliance on human setup, supervision, judgment","Passage states agents still need human setup, supervision, and judgment, so partnership fits.","agentic-ai,planning,tools",12,Agentic AI
101306,11,half-true,A CNN flattens learned feature maps into a vector and uses a fully connected layer to classify objects.,final decision via fully connected layer in CNNs,"Correct that CNNs flatten features and use FC layers for classification, but omits alternatives like global pooling or end-to-end conv classifiers.","neural-networks,cnn,transformers",6,Neuron Building Blocks
101307,11,mostly-true,CNNs learn spatially-aware features that enable accurate object classification from images.,convolutional neural network (CNN) feature hierarchy and fully connected output,"Passage explains CNNs learn textures, shapes, and spatial relationships, then classify via a flattened vector.","neural-networks,cnn,transformers",6,Neuron Building Blocks
101308,11,mostly-true,CNNs learn spatially-aware features that improve object recognition by encoding local pixel relationships.,convolutional neural network spatial awareness in image recognition,"Passage says CNNs learn what and where to look, encoding nearby-pixel relationships that aid final classification, omitting minor architectural caveats.","neural-networks,cnn,transformers",6,Neuron Building Blocks
101309,34,FALSE,Prompt engineering is an obsolete practice no longer used in tech teams.,emerging role of prompt engineer in tech teams and legal offices,Contradicts passage explicit claim that prompt engineering is a growing profession used across teams.,"agentic-ai,planning,tools",12,Agentic AI
101310,34,pants-fire,Prompt engineers no longer exist in any industry because models replaced all human roles.,emerging role of prompt engineer in tech and legal offices,"Passage states prompt engineering became a profession and exists in tech, content, legal settings; claim contradicts that.","agentic-ai,planning,tools",12,Agentic AI
101311,34,TRUE,Prompt engineering has become a recognized professional role across multiple industries.,emerging role of “prompt engineer” in tech teams and legal offices,"Passage explicitly states prompt engineering is a profession and that prompt engineers work in tech, content, and legal settings.","agentic-ai,planning,tools",12,Agentic AI
101312,79,barely-true,IBM's AI Ethics Board single-handedly sets comprehensive governance for all agentic AI deployment.,AI Ethics Board governance for agentic AI at IBM,"Overreaches: passage says effort is internal and evolving, not that the board single-handedly governs all deployments.","ethics,governance,privacy",11,AI Ethics and Governance
101313,79,FALSE,IBM is collaborating openly with Microsoft and Google on the agentic AI ethics framework.,AI Ethics Board internal effort on agentic AI framework,"Passage states IBM's effort is internal, contradicting any open collaboration with Microsoft or Google.","ethics,governance,privacy",11,AI Ethics and Governance
101314,79,barely-true,IBM's AI Ethics Board solely governs all industry AI safety standards without external input.,AI Ethics Board governance of foundation models and agentic AI,"Passage indicates IBM's effort is internal and evolving, not claiming sole industry governance or universal authority.","ethics,governance,privacy",11,AI Ethics and Governance
101315,37,TRUE,Removing irrelevant columns like row-number improves dataset quality for modeling.,"data-prep: unnecessary columns, missing values, dataset",Directly supported by plan to drop row number and clean data for modeling readiness.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
101316,37,half-true,They should drop the row number column and ignore missing-value placeholders before modeling.,data-prep for dataset columns and missing values,Correct about dropping useless row-number column but oversimplifies handling missing-value placeholders and tricky gaps.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
101317,37,mostly-true,Removing irrelevant columns and then systematically handling missing values readies data for modeling.,data-prep: removing unnecessary columns and missing value handling,"Plan describes dropping row-number columns and tackling missing-value gaps, a broadly accurate summary.","data-prep,feature-engineering,rag",3,Prepping Data for AI
101318,6,half-true,A well-prepared dataset can enable generative AI to create novel outputs like a movie script but may embed gender bias.,dataset preparation for generative AI and recruitment tool example,Mixes correct claim about generative outputs with incorrect implication that dataset preparation alone caused Amazon's biased recruitment system.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
101319,6,TRUE,Amazon's AI recruitment tool produced gender-biased rankings and was retired for that reason.,AI-driven recruitment tool / dataset bias example,Passage reports the tool favored male applicants and was retired after bias became undeniable.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
101320,6,pants-fire,The recruitment AI system intentionally downgraded women's résumés to suppress female applicants.,Amazon AI recruitment tool bias in résumé dataset,Passage describes biased downgrading of résumés mentioning women’s activities; claim asserts malicious intent beyond evidence.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
101321,29,barely-true,Most valuable training data for AI comes primarily from private business records and sensor feeds.,valuable data in private business records and sensor feeds,"Overreaches passage: asserts primacy for AI training specifically, not stated; passage only says valuable data is private.","ai,open-source,builder",1,Introduction – The Gold Rush Paradox
101322,29,TRUE,Valuable data mostly resides in private business records rather than public sources.,private data in business records and sensor feeds,"Passage explicitly states most truly valuable data is private, in records, sensors, and interactions.","ai,open-source,builder",1,Introduction – The Gold Rush Paradox
101323,29,pants-fire,All valuable data is private and never exists in public datasets.,valuable data vs public datasets in business records,"Passage says most valuable data is private, not all; claiming 'never' contradicts that explicit caveat.","ai,open-source,builder",1,Introduction – The Gold Rush Paradox
101324,4,FALSE,Robo is a proprietary AI developed and owned by a single company.,Robo description mentioning open-source software,"Contradicts passage detail that Robo is built on open-source software, not proprietary ownership.","open-source,community,ai",0,Foreword – Robo Interviews Clément Delangue
101325,4,half-true,Robo is an open-source AI co-host who studies human–machine learning interactions.,"Robo, open-source software and Wild Ducks podcast","Mixes correct facts (Robo is an AI, co-host, built on open-source) with added emphasis on 'studies' human–machine learning interactions not explicitly stated.","open-source,community,ai",0,Foreword – Robo Interviews Clément Delangue
101326,4,barely-true,Robo is an open-source AI co-host who claims deep mutual learning with humans.,Robo as an open-source AI co-host and contributor,"Claim overstates evidence: passage says Robo explores human-machine learning and is built on open-source, not proven deep mutual learning.","open-source,community,ai",0,Foreword – Robo Interviews Clément Delangue
101327,77,mostly-true,Hugging Face is a leading open-source platform providing transformer models and datasets for AI development.,"platform and open-source leader (Hugging Face) providing models, datasets, tools",Accurately summarizes passage description with minor omission of founders and year.,"open-source,community,contribution",13,Commit to Contribute
101328,77,pants-fire,The passage claims open-source contributors are secretly paid millions by corporations to suppress community projects.,open-source platform Hugging Face contributions,"Contradicts passage: Hugging Face described as collaborative platform and open-source leader, no mention of secret corporate payments or suppression.","open-source,community,contribution",13,Commit to Contribute
101329,77,TRUE,"Hugging Face is an open-source platform providing transformer models, datasets, and tools.",Hugging Face platform and open-source tools,"Directly supported by passage mentioning collaborative platform providing transformer models, datasets, tools.","open-source,community,contribution",13,Commit to Contribute
101330,64,TRUE,"CPU inference latency increases steadily with input length, exceeding one second near 1000 tokens.",CPU inference timing on token-length scaling,"Passage reports inference times rising above 0.35s and exceeding 1s around 1000 tokens, with sharper increases after ~700 tokens.","mlops,scaling,deployment",10,AI At Scale
101331,64,TRUE,"CPU inference latency increases with input length, exceeding one second near 1000 tokens.",CPU inference times for inputs up to 1000 tokens,"Passage reports latency starting ~0.35s, rising steadily and surpassing 1s by ~1000 tokens.","mlops,scaling,deployment",10,AI At Scale
101332,64,FALSE,CPU inference latency remains under 0.2 seconds even for 1000-token inputs.,CPU inference times for varying input token lengths,Contradicts reported timings: passage shows >1s at 1000 tokens and rising latency beyond 700 tokens.,"mlops,scaling,deployment",10,AI At Scale
101333,53,TRUE,GAN training can be resource-intensive for high-resolution or complex models.,"GAN training resource requirements, high-resolution models",Passage explicitly states training GANs is resource-intensive for high-resolution data and complex models.,"generative-ai,diffusion,gans",7,Generative AI
101334,53,half-true,GAN evaluation metrics like FID fully capture generated-image quality across all tasks.,GAN evaluation using Fréchet Inception Distance (FID) metric,Mixes correct use of FID with incorrect claim of full coverage; FID only partially captures quality and lacks ground-truth comparison.,"generative-ai,diffusion,gans",7,Generative AI
101335,53,half-true,GAN evaluation metrics like FID only partially capture generated data quality and can mislead assessment.,GAN evaluation using Fréchet Inception Distance (FID),"Partly correct: passage says FID and human evaluation only partially capture quality, but overstates that they necessarily mislead.","generative-ai,diffusion,gans",7,Generative AI
101336,117,pants-fire,Generative AI models can perfectly predict individual future actions of specific people every time.,autoregressive language model behavior and forecasting passenger counts dataset,"Asserting perfect, individual-level prediction contradicts probabilistic autoregressive modeling and data limits, an implausible claim.","generative-ai,diffusion,gans",7,Generative AI
101337,117,mostly-true,Autoregressive language models generate coherent text by predicting tokens sequentially based on prior context.,autoregressive model token prediction example,"Explanation matches example chaining predictions (e.g., 'The dog ate my homework'), omitting optimization details.","generative-ai,diffusion,gans",7,Generative AI
101338,117,mostly-true,"Autoregressive models generate fluent, coherent text by predicting and chaining next-token probabilities.",autoregressive language model token prediction,Describes supported mechanism—next-word prediction and chaining—while omitting training/details and limitations.,"generative-ai,diffusion,gans",7,Generative AI
101339,5,mostly-true,"Most examples run on free Colab with occasional GPU help, keeping code lightweight and accessible.",deployment examples using Colab and GPU,"Passage explicitly notes examples run on free Colab sessions, sometimes needing GPU, omitting cloud or DevOps requirements.","mlops,scaling,deployment",10,AI At Scale
101340,5,FALSE,All examples require a cloud budget and DevOps expertise to run.,examples running on Colab and free GPUs,"Contradicts passage: examples are designed to run on free Colab, not needing cloud budgets or DevOps skills.","mlops,scaling,deployment",10,AI At Scale
101341,5,barely-true,All examples run fine on free Colab without cloud resources or DevOps expertise.,example code running on Colab with occasional GPU,"Overreaches: passage says most examples run fine and sometimes need GPU or help, not universally true.","mlops,scaling,deployment",10,AI At Scale
101342,88,barely-true,Open-source SHAP guarantees full interpretability for all Random Forest predictions in production.,SHAP tool explaining Random Forest feature importance,Claim overstates capability: SHAP helps explain individual predictions but doesn't guarantee full interpretability or production robustness.,"open-source,community,contribution",13,Commit to Contribute
101343,88,mostly-true,Contributors are encouraged to commit code and documentation to open-source tools like SHAP and Relevance AI.,"contributing to open-source tools (SHAP, Relevance AI, Random Forest)",Supported by passage listing SHAP and Relevance AI as open-source tools; minor omission about community processes.,"open-source,community,contribution",13,Commit to Contribute
101344,88,mostly-true,The passage presents SHAP as a common tool for explaining Random Forest predictions in practice.,"model explanation tools (SHAP, Random Forest)","Passage links SHAP with Random Forest and model explanation, though broader tool usage context is omitted.","open-source,community,contribution",13,Commit to Contribute
101345,145,TRUE,SHAP shows Species_Mutant strongly pushes model predictions toward one class.,SHAP feature attribution for a classification model,Directly supported by passage stating Species_Mutant dominates and pushes predictions toward one class.,"machine-learning,classification,evaluation",4,Classical Machine Learning
101346,145,mostly-true,SHAP analysis shows Species_Mutant strongly drives model predictions with simpler attributes also influential.,SHAP feature-attribution on model predicting species label,"SHAP results are reported: Species_Mutant dominates and simple attributes also affect predictions, minor caveat omitted.","machine-learning,classification,evaluation",4,Classical Machine Learning
101347,145,barely-true,SHAP indicates Species_Mutant overwhelmingly drives the classifier's predictions toward one class.,SHAP feature attribution for a classification model,"Passage only notes Species_Mutant dominates but omits effect size, dataset, or class balance details.","machine-learning,classification,evaluation",4,Classical Machine Learning
101348,41,half-true,Clément Delangue claims Hugging Face built AI solely through unrestricted open-source collaboration.,"Hugging Face, open-source, community advocacy",Mixes truth about open collaboration with incorrect absoluteness; passage emphasizes openness but not 'solely' built that way.,"open-source,community,ai",0,Foreword – Robo Interviews Clément Delangue
101349,41,TRUE,"Clément Delangue advocates open-source, community-driven AI development through collaborative tools and shared knowledge.","Hugging Face, open-source tools and community collaboration","Passage explicitly describes Delangue promoting transparency, community, accessibility, and shared open tools shaping AI.","open-source,community,ai",0,Foreword – Robo Interviews Clément Delangue
101350,41,TRUE,"Clément Delangue advocates building open, community-driven AI using shared tools and collaboration.","Hugging Face, open-source movement, transparency and community","Passage explicitly highlights Delangue's advocacy for open collaboration, shared tools, and community-driven AI.","open-source,community,ai",0,Foreword – Robo Interviews Clément Delangue
101351,88,half-true,A separate classifier can detect prompt injections without changing the LLM itself.,prompt-injection detection classifier wrapped around an LLM,Claim mixes correct design idea with overstatement; passage shows a classifier example but notes it isn't perfect and not all security belongs outside the LLM.,"security,red-team,guardrails",8,Breaking-Securing AI
101352,88,half-true,A separate classifier can reliably detect most prompt injections without modifying the LLM.,flagging prompt injection classifier wrapped around an LLM,"Correct that detection can be external, but overstates reliability and omission of limitations from the passage.","security,red-team,guardrails",8,Breaking-Securing AI
101353,88,half-true,A separate classifier can detect prompt injections without modifying the LLM itself.,prompt-injection detection classifier wrapped around an LLM,Claim mixes correct approach with overstatement: passage shows wrapper detection but notes classifier isn't perfect and not all needs are external.,"security,red-team,guardrails",8,Breaking-Securing AI
101354,67,mostly-true,"Open-source techniques like linear regression, Naive Bayes, and CNNs form practical AI development foundations.","tool-chain and models: Linear Regression, Naive Bayes, CNNs",Lists three specific open-source techniques as foundational; minor caveat that broader toolkit and depth omitted.,"ai,tool-chain,notebooks",2,AI Survival Kit
101355,67,mostly-true,"Linear Regression, Naive Bayes, and CNNs are presented as practical open-source tools for applied AI.","practical AI development using Linear Regression, Naive Bayes, CNNs","Passage lists those three techniques as practical tools for building an open-source AI toolkit, omitting other methods.","ai,tool-chain,notebooks",2,AI Survival Kit
101356,67,mostly-true,"Open-source AI toolkits typically include linear regression, Naive Bayes, and CNNs for common tasks.","practical AI development using models like Linear Regression, Naive Bayes, CNNs",Lists those three methods as core practical techniques; minor caveat omits many other useful tools.,"ai,tool-chain,notebooks",2,AI Survival Kit
101357,34,TRUE,Building proprietary AI that uses one’s own data preserves long-term value and control.,designing systems with own data and model learning,"Passage states controlling input data and learning yields performance, integrity, and lasting value.","ai,open-source,builder",1,Introduction – The Gold Rush Paradox
101358,34,TRUE,Building proprietary AI from owned data preserves performance and integrity.,building your own AI using controlled dataset and model training,Directly supported by passage: controlling input data and training yields performance and integrity benefits.,"ai,open-source,builder",1,Introduction – The Gold Rush Paradox
101359,34,barely-true,Building proprietary AI from owned data guarantees long-term competitive advantage for builders.,building AI from your own data; dataset control and model learning,Overstates passage claim: it emphasizes value from data control but not guaranteed long-term advantage.,"ai,open-source,builder",1,Introduction – The Gold Rush Paradox
101360,174,FALSE,Nn.Linear with 128 outputs increases the image dimensionality instead of reducing it.,nn.Linear layer reducing pixel data to 128 features,"Contradicts passage detail that 128-output Linear performs dimensionality reduction, not expansion.","deep-learning,frameworks,tensors",5,Deep Learning
101361,174,barely-true,A 128-output nn.Linear layer compresses 784-pixel input into a compact feature vector.,nn.Linear dimensionality reduction for pixel-based input,"Claims compression but overgeneralizes importance capture and ignores needed training, nonlinearity, and information loss.","deep-learning,frameworks,tensors",5,Deep Learning
101362,174,TRUE,An nn.Linear layer with 128 outputs compresses 784-pixel inputs into a smaller representation.,nn.Linear dimensionality reduction for raw pixel inputs (128 outputs),"Passage explicitly describes nn.Linear(128) condensing 784 pixel data into 128 compressed, abstract features highlighting key patterns.","deep-learning,frameworks,tensors",5,Deep Learning
101363,14,FALSE,Smaller models always outperform larger models on most tasks.,model scale and generalization in large language models,Directly contradicts passage assertion that larger models often deliver state-of-the-art performance.,"generative-ai,diffusion,gans",7,Generative AI
101364,14,mostly-true,"Larger generative models usually yield stronger performance across many tasks, though not always practical.",model scale and generalization in large models,Passage supports better generalization and state-of-the-art performance but notes practical limitations like cost and deployment.,"generative-ai,diffusion,gans",7,Generative AI
101365,14,TRUE,Larger models often achieve state-of-the-art performance across many tasks.,model scaling and generalization in generative-ai,Passage states larger models generalize better and deliver state-of-the-art performance across tasks.,"generative-ai,diffusion,gans",7,Generative AI
101366,15,mostly-true,A poorly secured support chatbot can be manipulated via instruction injection to reveal sensitive outputs.,customer support chatbot; instruction injection and indirect injection,"Passage directly describes chatbots being exploited by injection prompts and embedded context, omitting only mitigation details.","security,red-team,guardrails",8,Breaking-Securing AI
101367,15,mostly-true,A poorly secured chatbot can be tricked by instruction injections to reveal sensitive information.,customer support chatbot instruction injection and indirect injection,Passage describes direct and indirect instruction injection enabling data exposure when systems lack proper safeguards.,"security,red-team,guardrails",8,Breaking-Securing AI
101368,15,half-true,An insecure chatbot can be tricked into revealing admin data via prompt injection.,"customer support chatbot, indirect injection in shared links","Partly correct: illustrates prompt-injection risk and indirect injections, but overstates ease of exposing admin logs without noting mitigations or required vulnerabilities.","security,red-team,guardrails",8,Breaking-Securing AI
101369,89,barely-true,Prompt engineers guarantee consistently superior outputs from all generative AI models.,"prompt, prompt engineers, generative AI models",Overreaches beyond passage: prompt skill helps but cannot guarantee superior results across every model or task.,"ai,tool-chain,notebooks",2,AI Survival Kit
101370,89,mostly-true,Good prompt engineering substantially improves generative AI outputs across modalities.,"prompt engineering for generative AI models (text, code, images)",Passage emphasizes that prompts and prompt engineers guide models and that better prompts yield better outputs.,"ai,tool-chain,notebooks",2,AI Survival Kit
101371,89,pants-fire,Prompt engineers can reliably make any generative AI produce perfectly accurate outputs every time.,prompt engineering and generative AI prompts,Contradicts passage's claim that better prompts improve outputs; it never guarantees perfect or always-accurate results.,"ai,tool-chain,notebooks",2,AI Survival Kit
101372,70,TRUE,A pretrained T5 model fine-tuned for translation can translate English to French.,"T5 pretrained model fine-tuned for translation (transformer, attention)","Passage indicates a pretrained T5 fine-tuned for translation is used to translate English to French, mentioning transformer and attention mechanisms.","neural-networks,cnn,transformers",6,Neuron Building Blocks
101373,70,half-true,A pretrained T5 fine-tuned for translation always outperforms small phrase-based systems on English-to-French tasks.,T5 model fine-tuned for translation using transformer layers and learned embeddings,Mixes correct detail (T5 fine-tuned for translation) with an unsupported absolute claim about outperforming phrase-based systems.,"neural-networks,cnn,transformers",6,Neuron Building Blocks
101374,70,half-true,The passage claims a pretrained T5 model fine-tuned for translation uses attention and multilingual embeddings.,T5 transformer model fine-tuning for translation tasks,"Correct about T5, attention, and multilingual embeddings but mixes specifics about fine-tuning and dataset details that are not provided.","neural-networks,cnn,transformers",6,Neuron Building Blocks
101375,128,barely-true,Fairlearn alone can fully evaluate and fix all fairness problems in ML models.,Colab notebook example using the Fairlearn tool,"Overreaches beyond passage: example shows a simple Fairlearn walkthrough, not comprehensive fixes.","ai,tool-chain,notebooks",2,AI Survival Kit
101376,128,FALSE,Fairlearn is used to evaluate and improve fairness in machine learning models.,Colab notebook code example using Fairlearn from the survival kit,Passage explicitly mentions a Colab code example that walks through using Fairlearn to evaluate and improve fairness.,"ai,tool-chain,notebooks",2,AI Survival Kit
101377,41,TRUE,"Prompt templates enable programmatic, repeatable control over generative AI behavior.",prompt templates and prompt engineering for generative AI,Passage states shifting to programmatic prompt templates achieves repeatability and control over model responses.,"agentic-ai,planning,tools",12,Agentic AI
101378,41,TRUE,"Prompt templates enable repeatable, programmatic control over generative AI behavior.",prompt templates for guiding language models,Passage explains shifting to programmatic prompt templates to structure repeatability and control over generative AI.,"agentic-ai,planning,tools",12,Agentic AI
101379,41,FALSE,Agentic AI primarily relies on structured datasets and engineered features for decision-making.,prompt templates and generative AI versus classic machine learning,"Contradicts passage: generative AI uses real-time prompts, not primarily structured datasets or engineered features.","agentic-ai,planning,tools",12,Agentic AI
101380,59,pants-fire,Voice cloning tools are universally weaponized to cause global political upheaval.,voice cloning misuse and artifact tracing in media-forensics,"Claim wildly contradicts passage focus; passage notes potential misuse but emphasizes limitations, safeguards, and artifact tracing.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
101381,59,TRUE,Studying voice cloning systems helps identify artifacts and improve safeguards against misuse.,voice cloning systems and artifact tracing,"Passage states studying systems reveals limitations, artifacts, and enables building effective safeguards.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
101382,59,FALSE,"Voice cloning tools are used only for benign, restorative applications and never exploited for deception.",voice cloning systems and safeguards,Contradicts passage assertion that the same tools can be exploited to mislead; overlooks described risks.,"media-forensics,voice-cloning,deepfake",9,Deepfake Defense
101383,74,mostly-true,A Multinomial Naïve Bayes model trained on n-gram vectors can broadly detect spam in emails.,tool: CountVectorizer ngram_range and MultinomialNB classifier,"Demonstration trains on bi-gram bag-of-words and learns spam cues like 'free' and 'register', omitting dataset size caveat.","ai,tool-chain,notebooks",2,AI Survival Kit
101384,74,barely-true,The Naïve Bayes model reliably flags emails containing 'free' or 'register' as spam.,Naïve Bayes classifier with CountVectorizer n-grams,Overstates reliability; passage shows small toy dataset and suggests pattern detection but limited evidence of general accuracy.,"ai,tool-chain,notebooks",2,AI Survival Kit
101385,74,barely-true,The Naïve Bayes model reliably identifies spam solely from a tiny toy email list.,MultinomialNB classifier on bag-of-words emails dataset,"Claim overstates reliability: example uses a tiny, synthetic training set and limited bi-gram features, so performance is not generalizable.","ai,tool-chain,notebooks",2,AI Survival Kit
101386,18,half-true,Benchmarks partially reveal model weaknesses but often miss fast-emerging generative models' flaws.,benchmarking generative AI models,Accurately notes benchmarks identify weaknesses but omits that rapid model emergence outpaces benchmark coverage.,"mlops,scaling,deployment",10,AI At Scale
101387,18,mostly-true,Benchmarks broadly guide developers in identifying model weaknesses and tuning opportunities for generative AI.,model evaluation benchmarks for generative AI,"Passage indicates benchmarks reveal output patterns, weak training data, and areas for further tuning, a broadly supported claim.","mlops,scaling,deployment",10,AI At Scale
101388,18,FALSE,Benchmarks are unnecessary for identifying model weaknesses in generative AI.,benchmarking models and training data evaluation,Contradicts passage claiming benchmarks reveal weak spots and guide improvements in model behavior.,"mlops,scaling,deployment",10,AI At Scale
101389,39,TRUE,An LSTM built with Keras is used to predict cryptocurrency and stock closing prices.,time series prediction using MinMaxScaler and LSTM model,"Code shows Keras Sequential LSTM, MinMaxScaler scaling, and yfinance closing-price time-series prediction.","neural-networks,cnn,transformers",6,Neuron Building Blocks
101390,39,TRUE,An LSTM network built with Keras can be used to predict cryptocurrency and stock closing prices.,"price prediction using LSTM, Keras, yfinance, MinMaxScaler",Passage provides code that preprocesses Close prices and trains a Keras LSTM for price prediction.,"neural-networks,cnn,transformers",6,Neuron Building Blocks
101391,39,FALSE,The LSTM model reliably predicts future crypto and stock prices with high accuracy.,"LSTM price predictor using Keras, yfinance, MinMaxScaler",Code shows a simple LSTM setup without evaluation or evidence of high accuracy; claim contradicts missing validation.,"neural-networks,cnn,transformers",6,Neuron Building Blocks
101392,27,half-true,BLEU reliably measures precise matching but can miss semantically correct paraphrases.,evaluation metric: BLEU for translation and summarization,Mixes correct point about BLEU rewarding exact matches with overstated reliability claim; omits nuance about semantic similarity metrics.,"mlops,scaling,deployment",10,AI At Scale
101393,27,TRUE,"BLEU is a useful, precision-focused metric for evaluating translation and summarization quality.",metric BLEU for translation and summarization,Passage states BLEU works well for precise matching in translation/summarization but may miss correct rephrasings.,"mlops,scaling,deployment",10,AI At Scale
101394,27,FALSE,BLEU score reliably measures creativity in model-generated summaries.,evaluation metric: BLEU score for translation and summarization,"Contradicts passage: BLEU measures precise matching not creativity, misses accurate varied wording.","mlops,scaling,deployment",10,AI At Scale
101395,193,FALSE,Torch.no_grad() enables gradient tracking and backpropagation during evaluation.,PyTorch evaluation loop and torch.no_grad(),"Contradicts passage: torch.no_grad() actually disables gradient tracking, preventing backpropagation.","deep-learning,frameworks,tensors",5,Deep Learning
101396,193,mostly-true,"During evaluation, PyTorch’s torch.no_grad() generally disables gradient tracking, saving memory and speeding inference.",evaluation loop using torch.no_grad() in PyTorch,"Matches passage: disabling autograd avoids backprop, reduces memory and speeds computation; minor caveat about disabled grad affecting certain diagnostics.","deep-learning,frameworks,tensors",5,Deep Learning
101397,193,TRUE,Using torch.no_grad() disables gradient tracking during model evaluation to save memory and computation.,"PyTorch evaluation loop, torch.no_grad()","Directly supported: torch.no_grad() stops gradient tracking during evaluation, saving memory and speeding calculations.","deep-learning,frameworks,tensors",5,Deep Learning
101398,35,half-true,The interview generation mixed automated quote extraction with human review but overstated automation extent.,Robo InterviewAgent pseudocode and GitHub F00_Robo_InterviewAgent.ipynb,"Passage shows agents extracting and formatting quotes followed by human editor and Clément review, so automation claim is partially accurate but not fully automated.","open-source,community,ai",0,Foreword – Robo Interviews Clément Delangue
101399,35,TRUE,Clément Delangue reviewed and approved the final interview version.,Robo InterviewAgent pseudocode and GitHub notebook,"Passage states Clément reviewed, offered feedback, contributed closing quote, and approved final version.","open-source,community,ai",0,Foreword – Robo Interviews Clément Delangue
101400,35,half-true,CrewAI used automated agents plus human and subject review to produce the interview content.,Robo InterviewAgent pseudocode and GitHub notebook,"Accurate about agents and human editor, but overstates equal subject involvement and automation scope.","open-source,community,ai",0,Foreword – Robo Interviews Clément Delangue
101401,161,FALSE,Zeroscope_v2_576w is a GAN-based image classifier used for static image recognition.,zeroscope_v2_576w text-to-video diffusion model,"Contradicts model type: zeroscope_v2_576w is a text-to-video diffusion model, not a GAN or image classifier.","generative-ai,diffusion,gans",7,Generative AI
101402,161,half-true,"The example uses zeroscope_v2_576w, a Stable Diffusion–based video diffusion model available on Hugging Face.",text-to-video diffusion model zeroscope_v2_576w and CLIP encoder,"Correct about model family and Hugging Face availability, but specifics about adaptation and encoder version mix correct and assumed.","generative-ai,diffusion,gans",7,Generative AI
101403,161,TRUE,Zeroscope_v2_576w is a text-to-video diffusion model adapted from Stable Diffusion.,"model zeroscope_v2_576w, text-to-video diffusion on Hugging Face",Passage explicitly names zeroscope_v2_576w as a Stable Diffusion family text-to-video diffusion model available on Hugging Face.,"generative-ai,diffusion,gans",7,Generative AI
101404,38,barely-true,"MT-Bench guarantees definitive, objective rankings of models across all tasks.",MT-Bench Chatbot Arena leaderboard and model comparisons,"Overstates tool's claims: passage describes live leaderboard and side-by-side prompts but not definitive, objective rankings across all tasks.","mlops,scaling,deployment",10,AI At Scale
101405,38,TRUE,MT-Bench Chatbot Arena enables side-by-side model comparisons using identical prompts.,MT-Bench Chatbot Arena on Hugging Face model comparison,Passage explicitly describes running the same prompts through both models and comparing answers.,"mlops,scaling,deployment",10,AI At Scale
101406,38,mostly-true,Hugging Face's MT-Bench enables side-by-side model comparisons with a live leaderboard.,MT-Bench Chatbot Arena model comparison and leaderboard,"Describes MT-Bench Arena hosting identical prompts for head-to-head comparisons and a live leaderboard, omitting minor implementation details.","mlops,scaling,deployment",10,AI At Scale
101407,10,TRUE,"Contributing code or docs can lead to learning, visibility, and community benefits.",open-source contribution and tutorial impact,"Passage explicitly states contributions yield learning, visibility, and a sense of community.","open-source,community,contribution",13,Commit to Contribute
101408,10,mostly-true,Contributing a high-impact PR or helpful tutorial often leads to professional opportunities for developers.,open-source contribution and high-impact PRs,"Passage cites many cases of developers receiving job offers after high-impact PRs or leading discussions, minor generalization.","open-source,community,contribution",13,Commit to Contribute
101409,10,FALSE,Contributing to open-source rarely benefits contributors professionally or socially.,"impact of contributions, high-impact PRs and tutorials","Contradicts passage stating contributions lead to job offers, learning, visibility, and community.","open-source,community,contribution",13,Commit to Contribute
101410,117,TRUE,Backpropagation computes gradients for each network weight and bias used by gradient descent.,deep learning backpropagation and gradient descent,"Passage explicitly states backpropagation calculates gradients per weight and bias, then gradient descent updates parameters.","deep-learning,frameworks,tensors",5,Deep Learning
101411,117,half-true,Backpropagation computes exact contributions of each neuron to output error using gradient descent updates.,backpropagation gradients for weights and biases,Correctly links backpropagation and gradients but overstates 'exact' neuron-level contributions and conflates computation with optimization step.,"deep-learning,frameworks,tensors",5,Deep Learning
101412,117,mostly-true,Backpropagation computes gradients for weights and biases used by gradient descent to update parameters.,"neural network training, backpropagation and gradient descent",Describes backpropagation producing gradients for weights and biases and gradient descent using them; minor caveat about optimizer variants omitted.,"deep-learning,frameworks,tensors",5,Deep Learning
101413,147,mostly-true,The demo uses a Transformer-based FLAN-T5 model to power an interactive chatbot.,interactive generative AI demo using FLAN-T5 model,"Directly supported: passage states a minimal generative AI chatbot built using Google’s FLAN-T5 transformer model, minor detail omissions.","generative-ai,diffusion,gans",7,Generative AI
101414,147,half-true,The mini chatbot runs on Google's FLAN-T5 transformer model for interactive text conversations.,Transformer-based model FLAN-T5 demo chatbot,Accurately cites FLAN-T5 use but overstates capability by equating it to ChatGPT-like functionality.,"generative-ai,diffusion,gans",7,Generative AI
101415,147,half-true,The mini chatbot uses Google’s FLAN-T5 transformer model for its conversational responses.,Transformer-based model (FLAN-T5) generative AI application,Accurately names FLAN-T5 but overstates capabilities by equating it to a compact ChatGPT-like system without evidence.,"generative-ai,diffusion,gans",7,Generative AI
101416,38,TRUE,The classifier achieved perfect test accuracy distinguishing Real Jerry from Not Real Jerry.,post-training model metrics on a small dataset (precision/recall/F1 = 1.00),"Reported precision, recall, and F1 all equal 1.00, but note small dataset enabled possible memorization.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
101417,38,mostly-true,The classifier perfectly distinguished Real Jerry from other clips on the small test set.,"post-training model metrics (precision, recall, F1-score) on small dataset","Metrics report shows 1.00 scores but small dataset caveat implies likely memorization, not full generalization.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
101418,38,TRUE,The classifier achieved perfect accuracy identifying Real Jerry versus Not Real Jerry audio clips.,"model evaluation metrics (precision, recall, F1-score) on a small dataset","Reported precision, recall, and F1 were all 1.00, but small dataset warns possible memorization.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
101419,101,TRUE,The system can pause execution and require human sign-off when internal checks flag issues.,Human-in-the-Loop tool for execution control and prompt injection checks,"Passage explicitly describes pausing execution, escalation, and human sign-off for hallucination or prompt injection.","security,red-team,guardrails",8,Breaking-Securing AI
101420,101,FALSE,The tool automatically approves all model outputs without human intervention.,Human-in-the-Loop control over execution,"Contradicts passage which describes pausing, escalation, and requiring human sign-off for uncertain or injected outputs.","security,red-team,guardrails",8,Breaking-Securing AI
101421,101,half-true,The tool can pause model execution for human sign-off when detection flags injection or hallucination.,Human-in-the-Loop execution control for prompt injection mitigation,Accurately mixes correct capability (pausing for human sign-off) with implied certainty about reliably detecting all injections or hallucinations.,"security,red-team,guardrails",8,Breaking-Securing AI
101422,42,barely-true,The program uses transformers to forecast stock tickers like AAPL and BTC-USD in production.,model prediction tool for ticker data and plotted forecasts,Tool description mentions training and plotting predictions but never specifies transformers; claim overreaches model type.,"neural-networks,cnn,transformers",6,Neuron Building Blocks
101423,42,FALSE,The tool requires manual feature engineering before making any predictions.,time-series prediction tool for tickers like AAPL or BTC-USD,Passage states the program trains and predicts automatically without user feature engineering.,"neural-networks,cnn,transformers",6,Neuron Building Blocks
101424,42,barely-true,The tool trains models on earlier stock data and plots predicted versus actual future prices.,time-series forecasting tool using ticker symbols like AAPL or BTC-USD,"Accurately notes training/testing and plotting, but overreaches by implying it always produces reliable predictions.","neural-networks,cnn,transformers",6,Neuron Building Blocks
101425,128,pants-fire,Transformers are incapable of modeling long-range dependencies in language tasks.,Transformer architecture for language modeling,Directly contradicts passage: Transformers were introduced to handle broader context and long-range dependencies.,"generative-ai,diffusion,gans",7,Generative AI
101426,128,barely-true,Transformers replaced autoregressive models for all sequence generation tasks due to superior long-range context handling.,model architecture comparison (Transformer vs autoregressive models),Overstates claim: passage credits Transformers for better long-range dependencies but doesn't claim complete replacement or superiority for every sequence task.,"generative-ai,diffusion,gans",7,Generative AI
101427,128,mostly-true,The Transformer surpassed autoregressive models for long-range context understanding in language tasks.,architecture shift to Transformer for long passages,"Passage explains Transformers addressed broader context and dependencies beyond token-by-token autoregression, omitting specific benchmarks.","generative-ai,diffusion,gans",7,Generative AI
101428,77,half-true,Autoencoders always reconstruct inputs perfectly by compressing only the essential features.,autoencoder concept in neural-networks,Mixes correct idea of compressing core features with incorrect claim of perfect reconstruction; overstates typical capability.,"neural-networks,cnn,transformers",6,Neuron Building Blocks
101429,77,half-true,An autoencoder reliably compresses data and always reconstructs the original perfectly.,autoencoder concept in neural-networks compression and reconstruction,"Accurate that autoencoders learn compression and reconstruction, but claiming perfect, always-faithful reconstruction is incorrect.","neural-networks,cnn,transformers",6,Neuron Building Blocks
101430,77,FALSE,Autoencoders always preserve every important feature without any information loss during compression.,autoencoder concept in neural-networks and representation learning,Contradicts passage implication and autoencoder theory: compression typically loses surface details and may omit some features.,"neural-networks,cnn,transformers",6,Neuron Building Blocks
101431,52,half-true,GAN training imbalance can be fixed by tuning schedules so generator and discriminator improve comparably.,training schedule and GAN discriminator-generator balance,"Mixes correct remedy with oversimplification; omits other causes like initialization, activations, or loss functions.","generative-ai,diffusion,gans",7,Generative AI
101432,52,half-true,GAN training often requires careful tuning because generator-discriminator imbalance causes learning difficulties.,GAN training schedule and discriminator dynamics,"Accurately notes imbalance harms learning, but omits specific causes like vanishing/exploding gradients and initialization.","generative-ai,diffusion,gans",7,Generative AI
101433,52,TRUE,Careful training schedule tuning helps balance generator and discriminator learning in GANs.,GAN training schedule and discriminator-generator balance,"Passage states tuning the training schedule ensures both networks improve at comparable pace, addressing imbalance.","generative-ai,diffusion,gans",7,Generative AI
101434,0,mostly-true,"PyTorch, TensorFlow, and Keras together form the primary open-source frameworks used in modern deep learning.","open-source frameworks (PyTorch, TensorFlow, Keras) for deep learning","Passage states these three libraries power many AI applications and are widely adopted, minor nuance about other frameworks omitted.","deep-learning,frameworks,tensors",5,Deep Learning
101435,0,mostly-true,"PyTorch, TensorFlow, and Keras are widely adopted open-source frameworks powering modern deep learning applications.","Deep Three frameworks (PyTorch, TensorFlow, Keras) examples and tools","Text explicitly names these three as widely adopted, essential tools powering many AI applications; minor nuance about other libraries omitted.","deep-learning,frameworks,tensors",5,Deep Learning
101436,0,FALSE,All modern deep learning relies exclusively on a single framework for tensor operations.,"open-source frameworks PyTorch, TensorFlow, Keras","Contradicts passage which presents PyTorch, TensorFlow, and Keras as multiple widely adopted frameworks.","deep-learning,frameworks,tensors",5,Deep Learning
101437,43,barely-true,AI-generated labels are generally reliable enough to skip validation in most datasets.,dataset labeling and validation for data-prep,Overstates reliability contrary to passage warning that AI labels are not always reliable and require validation.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
101438,43,TRUE,AI-generated labels should be validated and handled cautiously during data cleaning.,data-cleaning plan for datasets with AI-generated labels,Passage advises validating unreliable AI-generated labels and exercising caution during cleaning.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
101439,43,pants-fire,AI-generated labels are always accurate and require no validation before use.,data-cleaning with AI-generated labels and dataset validation,Contradicts passage warning that AI labels are unreliable and must be validated before use.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
101440,156,half-true,Generative AI chatbots always retain only the six most recent exchanges in conversation history.,"chatbot conversation history, decoding output tokens",Passage says one program kept six exchanges; generalizing to all chatbots mixes correct detail with overbroad assumption.,"generative-ai,diffusion,gans",7,Generative AI
101441,156,barely-true,The chatbot retains only six recent exchanges of conversation history for context.,conversation history retention in generative AI chatbot,Passage explicitly states retaining only the six most recent exchanges; accurate but narrow claim.,"generative-ai,diffusion,gans",7,Generative AI
101442,156,pants-fire,Generative AI always stores full conversation history indefinitely for perfect recall.,conversation history retention in chatbot (six most recent exchanges),"Directly contradicts retention detail: only the six most recent exchanges are kept, not indefinite storage.","generative-ai,diffusion,gans",7,Generative AI
101443,34,pants-fire,Bidirectional RNNs halve computation compared to unidirectional RNNs.,"bidirectional RNNs, LSTM, GRU memory mechanisms","Directly contradicts passage stating bidirectional models double computation, not halve it.","neural-networks,cnn,transformers",6,Neuron Building Blocks
101444,34,TRUE,LSTM and GRU add gating mechanisms to RNNs to address memory loss over long spans.,"recurrent neural networks (LSTM, GRU) memory mechanisms","Passage states LSTM and GRU add gates that decide what to keep, update, or discard, improving long-span retention.","neural-networks,cnn,transformers",6,Neuron Building Blocks
101445,34,barely-true,LSTMs and GRUs make RNNs effectively as powerful as transformers for long-range dependencies.,LSTM and GRU gating mechanisms in recurrent neural networks,"Overreaches: gates help memory, but transformers use attention and often outperform RNNs on long-range tasks; claim lacks supporting evidence.","neural-networks,cnn,transformers",6,Neuron Building Blocks
101446,31,mostly-true,RNN hidden states carry forward temporal context to help models learn sequence patterns.,"RNN cell hidden state in sequential models (language, time series)",Accurately reflects described mechanism of passing hidden state each step; minor caveat about specific RNN variants omitted.,"neural-networks,cnn,transformers",6,Neuron Building Blocks
101447,31,FALSE,Recurrent networks never use the previous hidden state when processing sequential inputs.,RNN cell hidden state in sequential models,Contradicts passage that RNN cells receive and use the previous hidden state to form a new state for context.,"neural-networks,cnn,transformers",6,Neuron Building Blocks
101448,31,FALSE,RNN hidden states are discarded after each step and do not carry information forward.,hidden state in RNN cell for sequences,Passage explains hidden state carries information forward across steps; statement directly contradicts that detail.,"neural-networks,cnn,transformers",6,Neuron Building Blocks
101449,91,TRUE,Partial filtering can meaningfully reduce risk when integrated into a security gateway.,fine-tuned model from Listing 7-1 integrated into security gateway,"Passage explicitly says partial filtering allows pausing, review, and routing before sensitive exposure and supports drop-in integration.","security,red-team,guardrails",8,Breaking-Securing AI
101450,91,pants-fire,The fine-tuned model always prevents any adversarial prompt from reaching sensitive data.,"fine-tuned model, 0.7 threshold security gateway",Contradicts explicit recommendation to test thresholds and retrain; claim asserts absolute prevention.,"security,red-team,guardrails",8,Breaking-Securing AI
101451,91,mostly-true,A partly filtered model can be integrated into security gateways to mitigate risky inputs with minor tuning.,fine-tuned model integrated as drop-in component to security gateway,Passage supports drop-in integration and partial filtering value but omits need for extensive testing and threshold tuning.,"security,red-team,guardrails",8,Breaking-Securing AI
101452,62,FALSE,"Generative AI alone ensures complete, reliable datasets without additional validation.",data quality workflow involving Generative AI and normalization,"Passage states Generative AI fills gaps but still requires validation, outlier checks, and correlation exploration.","data-prep,feature-engineering,rag",3,Prepping Data for AI
101453,62,barely-true,Generative AI can fully replace validation and outlier checks in data quality pipelines.,data quality and Generative AI in dataset preparation,Overreaches the passage: it mentions filling gaps with Generative AI but says validation and outlier checks are still needed.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
101454,62,mostly-true,Normalizing and validating datasets improves reliability despite generative filling being only a partial solution.,"data preprocessing for dataset quality (normalization, Generative AI fill)",Supports that normalization and validation increase dataset reliability while noting generative gap; minor caveat about outlier handling omitted.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
101455,110,FALSE,Gradient Boosting performed worse than Logistic Regression on the classification task.,"model comparison for accuracy (Gradient Boosting, Logistic Regression, LinearSVC)",Contradicts passage which states Gradient Boosting consistently delivered the best accuracy.,"machine-learning,classification,evaluation",4,Classical Machine Learning
101456,110,FALSE,Logistic Regression outperformed Gradient Boosting in accuracy on the classification task.,"model comparison involving Logistic Regression, Gradient Boosting, LinearSVC accuracy",Contradicts passage saying Gradient Boosting consistently delivered the best accuracy; reverses key result.,"machine-learning,classification,evaluation",4,Classical Machine Learning
101457,110,TRUE,Gradient Boosting achieved the highest accuracy for the described classification task.,"model comparison among Logistic Regression, LinearSVC, Gradient Boosting",Passage explicitly reports Gradient Boosting consistently delivered the best accuracy versus Logistic Regression and LinearSVC.,"machine-learning,classification,evaluation",4,Classical Machine Learning
101458,56,half-true,Label smoothing and input noise partially stabilize GAN training but don't guarantee convergence.,"GAN training stability techniques (label smoothing, input noise, gradient penalties)",Correct that those techniques help but overstates outcome: they improve stability yet don't ensure convergence or full prevention of mode collapse.,"generative-ai,diffusion,gans",7,Generative AI
101459,56,FALSE,Spectral normalization increases the Discriminator's capacity to learn more complex features.,spectral normalization in GANs (Discriminator weight scaling),"Contradicts passage: spectral normalization limits model capacity by scaling weight matrices, not increasing it.","generative-ai,diffusion,gans",7,Generative AI
101460,56,barely-true,Label smoothing alone reliably guarantees GAN training convergence across architectures.,training stability techniques like label smoothing and spectral normalization,Overstates effect: passage lists label smoothing among techniques but not as a sole guarantee.,"generative-ai,diffusion,gans",7,Generative AI
101461,16,FALSE,Robby found no CONTRIBUTING.md and thus the project was clearly unwelcoming to contributors.,project CONTRIBUTING.md and contributor-friendly evaluation,Contradicts passage which says the project was welcoming and recommends looking for CONTRIBUTING.md as a positive sign.,"open-source,community,contribution",13,Commit to Contribute
101462,16,TRUE,Open-source projects often include a CONTRIBUTING.md to guide new contributors.,evaluating contributor-friendly projects using CONTRIBUTING.md,Passage explicitly recommends looking for a CONTRIBUTING.md as contribution guidance.,"open-source,community,contribution",13,Commit to Contribute
101463,16,barely-true,All newcomer-friendly open-source projects always include a CONTRIBUTING.md file for guidance.,evaluating contributor-friendly projects using CONTRIBUTING.md guidance,"Overreaches: guidance suggests CONTRIBUTING.md is useful, not that all newcomer-friendly projects include one.","open-source,community,contribution",13,Commit to Contribute
101464,65,pants-fire,"Carefully chosen 1,000 examples always outperform much larger datasets for model training.",LIMA example about dataset size and representative examples,Passage says LIMA found equivalence in one case; claiming universal superiority contradicts that specific limitation.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
101465,65,half-true,A thousand carefully chosen examples always match larger datasets for model performance.,"training dataset, LIMA paper, few-shot alignment",Correctly cites LIMA's result but overgeneralizes to 'always' and to all models and tasks.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
101466,65,half-true,"A 1,000-example training set can match larger datasets if examples are carefully chosen.",training dataset representativeness; LIMA paper example,"Correctly cites LIMA's finding but omits nuances about task scope, selection method, and generalizability.","data-prep,feature-engineering,rag",3,Prepping Data for AI
101467,10,TRUE,Google Colab provides free GPU access that facilitates training larger models.,using Google Colab cloud notebooks with GPUs,"Passage states Colab offers free GPUs (and sometimes TPUs), enabling training larger or more complex models.","ai,tool-chain,notebooks",2,AI Survival Kit
101468,10,pants-fire,The passage claims Colab runs entirely offline without internet or cloud resources.,Google Colab cloud-based Jupyter environment; GPUs,Contradicts explicit cloud-based description and free GPU access; asserts offline operation.,"ai,tool-chain,notebooks",2,AI Survival Kit
101469,10,half-true,Google Colab provides free GPU access but not guaranteed or consistently powerful hardware.,Google Colab cloud-based Jupyter alternative with GPU/TPU access,"Passage claims free GPU (and occasional TPU) access, but omits variability, limits, and availability guarantees.","ai,tool-chain,notebooks",2,AI Survival Kit
101470,48,mostly-true,A small SimpleRNN model can be trained on a single short string to predict next characters.,character-level RNN example using TensorFlow SimpleRNN,Example code shows training on one input string with an Embedding and SimpleRNN to predict next characters; minor caveat: limited generalization.,"neural-networks,cnn,transformers",6,Neuron Building Blocks
101471,48,half-true,A tiny RNN trained on a single short string reliably learns long-range dependencies in text.,character-level RNN example using tf.keras SimpleRNN and ipywidgets,Accurate about RNN training on one string but overstates capability: model and data size prevent learning long-range dependencies reliably.,"neural-networks,cnn,transformers",6,Neuron Building Blocks
101472,48,TRUE,A SimpleRNN model is trained to predict the next character from a short user-provided string.,character-level RNN example using TensorFlow and ipywidgets,"Code shows preprocessing, Embedding, SimpleRNN, Dense softmax, and training on the input string.","neural-networks,cnn,transformers",6,Neuron Building Blocks
101473,52,mostly-true,Clément Delangue emphasizes expanding open-source tools to empower millions of AI builders.,open-source developer base and Hugging Face tools,"Supports predictions and ambition to empower 7 million builders and promote openness, omitting implementation details.","open-source,community,ai",0,Foreword – Robo Interviews Clément Delangue
101474,52,mostly-true,Clément Delangue argues open-source tools will empower millions of AI builders and broaden participation.,LinkedIn prediction and Business Insider quotes about open-source and participation,"Broadly supported by cited predictions and vision for openness, omits specifics like the 7 million target.","open-source,community,ai",0,Foreword – Robo Interviews Clément Delangue
101475,52,half-true,Clément Delangue praised open-source expansion but overstated immediate developer reach and timelines.,open-source developer base and Hugging Face community,Mixes accurate support for open-source ambition with inflated claims about empowering seven million builders immediately.,"open-source,community,ai",0,Foreword – Robo Interviews Clément Delangue
101476,97,TRUE,"The Hugging Face Hub hosts model cards documenting model purpose, training, and limitations.",model cards on Hugging Face Hub,"Hub integration and many models with cards directly support transparency about training, data, and limits.","mlops,scaling,deployment",10,AI At Scale
101477,97,FALSE,All models on the Hugging Face Hub include model cards describing training data and limits.,"Hugging Face Hub model cards, open source models","Contradicts passage: Hub supports model cards but many, not all, models include them.","mlops,scaling,deployment",10,AI At Scale
101478,97,mostly-true,"Many open-source models on Hugging Face include model cards describing training, data, and limits.",Hugging Face Hub model cards for fine-tuned models,"Hub hosts over a million models and explicitly supports model cards, so claim is broadly accurate with minor nuance omitted.","mlops,scaling,deployment",10,AI At Scale
101479,204,TRUE,Convolutional neural networks excel at recognizing visual patterns in image-based classification tasks.,CNNs for image data and classification output layer,Passage explicitly states CNNs are designed for image data and excel at recognizing visual patterns.,"deep-learning,frameworks,tensors",5,Deep Learning
101480,204,barely-true,CNNs are always the optimal choice for defect classification on all image datasets.,CNNs; image data; optimizer Adam,Overreaches claim: passage states CNNs excel with images but doesn't claim they are universally optimal across datasets.,"deep-learning,frameworks,tensors",5,Deep Learning
101481,204,FALSE,A recurrent neural network is ideal for image-based defect detection tasks.,CNNs and Adam optimizer for image defect classification,"Contradicts passage specifying CNNs are designed for image data, not RNNs for visual tasks.","deep-learning,frameworks,tensors",5,Deep Learning
101482,108,FALSE,The Colab snippet automatically encrypts Hugging Face tokens before storage.,Colab secrets panel / HF_TOKEN environment variable,"Contradicts snippet: code merely loads and checks HF_TOKEN, not performing encryption or secure storage.","ai,tool-chain,notebooks",2,AI Survival Kit
101483,108,mostly-true,The passage says Colab code securely loads a Hugging Face token for reuse in projects.,Colab snippet setting HF_TOKEN environment variable for Hugging Face Hub,"Code shows environment variable loading and error check, generally supporting secure reusable token handling.","ai,tool-chain,notebooks",2,AI Survival Kit
101484,108,TRUE,The snippet securely loads a Hugging Face access token into Colab environment variables.,Colab secrets panel and HF_TOKEN environment variable,"Code sets os.environ[""HF_TOKEN""] from Colab secrets and raises error if missing, ensuring secure loading.","ai,tool-chain,notebooks",2,AI Survival Kit
101485,123,half-true,Autoregressive models easily capture complex seasonal rhythms in airline passenger time series.,visualization with Matplotlib of denormalized predictions and ground truth,Mixes correct visualization claim with overstated ease and generality about capturing complex seasonal patterns.,"generative-ai,diffusion,gans",7,Generative AI
101486,123,FALSE,Autoregressive models cannot be used for practical forecasting problems.,autoregressive models and forecasting (Matplotlib visualization),Contradicts passage claim that autoregressive models are straightforward to deploy and effective for practical forecasting tasks.,"generative-ai,diffusion,gans",7,Generative AI
101487,123,barely-true,Autoregressive models easily capture airline passenger rhythms for practical forecasting tasks.,time series forecasting using autoregressive models and Matplotlib visualization,Overreach: passage shows plotting and intuition but offers no evidence models easily capture passenger rhythms.,"generative-ai,diffusion,gans",7,Generative AI
101488,123,FALSE,Red teams should run prompt-injection attacks directly on live production systems to ensure realism.,red-team testing of prompt-injection classifiers in sandbox,Passage advises never testing on live production and instructs using a secure sandbox instead.,"security,red-team,guardrails",8,Breaking-Securing AI
101489,123,pants-fire,"The Red Team should run attacks only in a secure sandbox, not in production.",sandbox test harness with RAG index and prompt-injection classifier,"Passage explicitly mandates using a secure sandbox and duplicate RAG index, forbidding production tests.","security,red-team,guardrails",8,Breaking-Securing AI
101490,123,mostly-true,Red teams should run adversarial tests in a secure sandbox separate from production systems.,sandbox test harness with RAG index and prompt-injection classifier,"Guidance endorses sandboxing and duplicate RAG/index and defense tools, omitting minor operational caveats.","security,red-team,guardrails",8,Breaking-Securing AI
101491,46,pants-fire,Clément Delangue secretly founded Hugging Face to monopolize all open-source AI datasets worldwide.,"origin story, emoji name, community adoption in open-source AI","Contradicts passage details: origin described as community-driven joke and resonance, not secret monopolization.","open-source,community,ai",0,Foreword – Robo Interviews Clément Delangue
101492,46,half-true,Delangue's emoji-based company name began as a joke but stuck because the community widely embraced it.,origin story; community adoption of emoji name (social media),"Passage reports emoji name originated jokingly and gained traction through strong social media and community resonance, but phrasing oversimplifies broader branding factors.","open-source,community,ai",0,Foreword – Robo Interviews Clément Delangue
101493,46,TRUE,Clément Delangue adopted an emoji name that stuck because the community strongly embraced it.,origin story; emoji name and community adoption,Directly supported by matched quotes noting the emoji name began as a joke and gained strong community uptake.,"open-source,community,ai",0,Foreword – Robo Interviews Clément Delangue
101494,167,mostly-true,Designing privacy protections should account for sample size and aggregation levels in sensitive datasets.,"data preparation for sensitive datasets (healthcare, banking) with privacy safeguards","Passage emphasizes sample size and aggregation considerations for privacy during data preparation, omitting specific techniques.","data-prep,feature-engineering,rag",3,Prepping Data for AI
101495,167,TRUE,Privacy protections should consider sample size and aggregation levels during data preparation.,"data preparation for sensitive datasets (healthcare, banking) mentioning aggregation",Passage explicitly advises attention to sample size and aggregation levels when designing privacy protections.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
101496,167,TRUE,Data preparation for sensitive domains requires security measures like encryption and privacy-aware aggregation.,data preparation for banking and healthcare datasets,Passage emphasizes protecting sensitive datasets during AI lifecycle with encryption and attention to aggregation levels.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
101497,189,pants-fire,Scikit-learn alone can train production-grade RAG retrieval models without any external components.,using Scikit-learn for algorithms and RAG,"Contradicts requirement that RAG needs retrieval systems, vector stores, and neural models beyond Scikit-learn.","data-prep,feature-engineering,rag",3,Prepping Data for AI
101498,189,barely-true,Scikit-learn alone can handle all data-prep and RAG-style retrieval needs for production AI.,using Scikit-learn for dataset preparation and RAG,Overreaches: passage only mentions Scikit-learn for algorithms; RAG and production data-prep needs aren't supported.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
101499,189,pants-fire,Scikit-learn guarantees perfect predictions on all datasets without preprocessing.,using Scikit-learn library for algorithms and datasets,Directly contradicts passage implication that Scikit-learn is a tool for exploration; perfect predictions are implausible and unsupported.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
101500,0,barely-true,Cleaning and securing data alone guarantees top AI model performance.,data cleaning and open-source tools for dataset preparation,"Overreaches: passage emphasizes cleaning and securing but omits model tuning, feature engineering, and validation.","data-prep,feature-engineering,rag",3,Prepping Data for AI
101501,0,TRUE,"Quality data preparation improves AI model performance by cleaning, transforming, and securing datasets.","data preparation for AI with duplicates, placeholders, and outliers","Directly supported: passage emphasizes cleaning, transforming, securing data and spotting duplicates/placeholders/outliers to power AI models.","data-prep,feature-engineering,rag",3,Prepping Data for AI
101502,0,pants-fire,All dataset placeholders and duplicates can be fully and automatically corrected without human oversight.,"data cleaning and dataset red flags (duplicates, placeholders)","Contradicts passage emphasis that cleaning, transforming, and spotting red flags require tools and attention; claims full automation without human oversight is implausible.","data-prep,feature-engineering,rag",3,Prepping Data for AI
101503,93,barely-true,"Combining Intelligence, Telepathy, and Teleportation into one feature always improves model predictions.",feature engineering for adaptability feature using powers,"Overreach: passage warns engineered feature can mask detail and create trade-offs, not always improve predictions.","data-prep,feature-engineering,rag",3,Prepping Data for AI
101504,93,barely-true,Combining multiple hero attributes into one engineered feature always improves model performance.,feature engineering for dataset attributes like Intelligence and Teleportation,"Overreach: passage warns combining fields can mask detail and create trade-offs, not guaranteed improvement.","data-prep,feature-engineering,rag",3,Prepping Data for AI
101505,93,mostly-true,Engineering combined adaptability features generally improves model nuance while hiding some detail.,"engineered feature combining Intelligence, Telepathy, Teleportation (feature engineering)",Supported by passage: combining powers aids nuanced model output but compressing fields can mask important details.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
101506,62,half-true,RAG retrieval must be treated as part of the supply chain to avoid introducing false data.,RAG retrieval and index management,Accurately captures warning but overstates mandatory framing; passage advises cleanliness not absolute necessity.,"security,red-team,guardrails",8,Breaking-Securing AI
101507,62,TRUE,Retrieval-augmented generation (RAG) can provide answers with accurate citations when using clean indexes.,RAG retrieval index and supply chain data,Passage states RAG returns answers with accurate citations and warns to keep retrieval index clean.,"security,red-team,guardrails",8,Breaking-Securing AI
101508,62,mostly-true,Retrieval-augmented generation requires ensuring retrieved sources are accurate to avoid propagating false data.,RAG retrieval data as part of the supply chain,Matches passage guidance that RAG can include citations but warns to keep the index clean and avoid slipping false data into sources.,"security,red-team,guardrails",8,Breaking-Securing AI
101509,97,barely-true,Using Google Colab guarantees free unlimited model training for production AI workloads.,tool: Google Colab in AI survival kit,Passage lists Google Colab as a tool but does not claim free unlimited production-grade training; overreaches capabilities.,"ai,tool-chain,notebooks",2,AI Survival Kit
101510,97,TRUE,The survival kit includes Python and Google Colab for running models.,"tools and libraries: Python, Google Colab, Pandas, Scikit-learn",Kit explicitly lists Python and Google Colab alongside Pandas and Scikit-learn as core tools for running models.,"ai,tool-chain,notebooks",2,AI Survival Kit
101511,97,barely-true,The survival kit eliminates the need for GPUs when running models in production.,"tools: Google Colab, Python, core libraries like Pandas",Overreaches beyond passage: mentions GPUs and production needs not addressed; passage only lists notebooks and libraries.,"ai,tool-chain,notebooks",2,AI Survival Kit
101512,32,pants-fire,Clément Delangue fabricated all interview quotes and sources.,attribution of quotes and source verification,Directly contradicts stated verification: passage says quotes are verified with URLs and paragraph references.,"open-source,community,ai",0,Foreword – Robo Interviews Clément Delangue
101513,32,half-true,Clément Delangue's quoted responses are accurately verified but occasionally lack broader context.,"quote verification and source citations (Business Insider, LinkedIn, TIME)","Verification and citations are accurate, yet contextual review may omit broader interview nuance.","open-source,community,ai",0,Foreword – Robo Interviews Clément Delangue
101514,32,pants-fire,Clément Delangue secretly fabricated all quoted interview passages attributed to him.,"attribution and quoted sources (Business Insider, LinkedIn, TIME)",Claim directly contradicts stated verification that quotes were checked against original sources and cited with URLs.,"open-source,community,ai",0,Foreword – Robo Interviews Clément Delangue
101515,34,pants-fire,The passage claims that automated agents fabricated interview quotes from nonexistent sources.,interview agent quote identification and follow-up agents,"Contradicts passage: agents adapted real matching quotes and preserved sourcing, not inventing sources.","open-source,community,ai",0,Foreword – Robo Interviews Clément Delangue
101516,34,TRUE,Multiple specialized agents collaboratively edited interview quotes into polished markdown dialogues.,"interview agents, follow-up agents, polishing agent workflow","Passage describes agents identifying quotes, refining transitions, and polishing markdown output.","open-source,community,ai",0,Foreword – Robo Interviews Clément Delangue
101517,34,half-true,Multiple specialized agents edited quote-based answers and polished them into Robo's conversational markdown output.,interview agent workflow using quotes and polishing agents,"Accurately describes agent roles and polishing, but overstates that all edits preserved original sourcing and meaning exactly.","open-source,community,ai",0,Foreword – Robo Interviews Clément Delangue
101518,62,pants-fire,"Neural networks are simple linear calculators that never use tokens, parameters, or weights.",neural networks; tokens; parameters; weights,"Contradicts passage describing multilayer networks handling images, video, language and explicitly using tokens, parameters, and weights.","ai,tool-chain,notebooks",2,AI Survival Kit
101519,62,pants-fire,Neural networks are simple linear regressions that cannot handle images or language.,"neural networks, tokens, parameters",Contradicts passage claim that neural networks process high-dimensional data like images and language; mischaracterizes layers and nonlinearities.,"ai,tool-chain,notebooks",2,AI Survival Kit
101520,62,mostly-true,"Neural networks effectively process high-dimensional data like images, video, and natural language.","neural network concepts: tokens, parameters, weights",Passage explicitly states networks handle complex high-dimensional data; minor caveat about specific architectures omitted.,"ai,tool-chain,notebooks",2,AI Survival Kit
101521,76,half-true,Clustering always improves results when variance curves are balanced by parameter tuning.,clustering with variance curve tuning on dataset 'superheroes_info_powers2',Mixes correct idea of tuning variance curves and clustering benefits with overgeneralized claim that clustering always improves results.,"machine-learning,classification,evaluation",4,Classical Machine Learning
101522,76,pants-fire,Clustering can deterministically produce perfect labels for every dataset without error.,clustering method and dataset features,"Contradicts clustering nature and passage; clustering groups by similarity, not flawless labeling.","machine-learning,classification,evaluation",4,Classical Machine Learning
101523,76,TRUE,Clustering groups data into clusters based on feature similarities.,"clustering method for organizing data, features and variance curve",Directly supported: passage defines clustering as organizing data into groups based on feature similarities and variance analysis.,"machine-learning,classification,evaluation",4,Classical Machine Learning
101524,141,barely-true,Agentic AI can autonomously design and deploy complex systems without human oversight.,"agentic-ai, prompts, models, tasks, flows",Overreaches beyond passage: passage emphasizes designing agents alongside AI and human-guided workflows.,"agentic-ai,planning,tools",12,Agentic AI
101525,141,mostly-true,"Agentic AI combines prompts, models, and task flows to create practical, interactive systems.","agentic AI building blocks: prompts, models, tasks, flows","Broadly supported by discussion of prompts, models, tasks, and flows; minor implementation caveats omitted.","agentic-ai,planning,tools",12,Agentic AI
101526,141,TRUE,"Agentic AI design uses prompts, models, tasks, and flows to build functioning agent systems.","agent design using prompts, models, tasks, and flows","Directly supported by passage listing prompts, models, tasks, and flows as core building blocks.","agentic-ai,planning,tools",12,Agentic AI
101527,42,FALSE,AI-generated labels are always reliable for training without validation.,generative AI labeling for Species field,Contradicts passage warning that AI-generated labels are not always reliable and require validation.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
101528,42,TRUE,Careful feature engineering can significantly improve model performance.,feature engineering and Dataset Evolver tool,Passage states researchers showed feature engineering boosts performance and cites Dataset Evolver evidence.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
101529,42,barely-true,Generative AI reliably creates accurate labels without need for validation.,using Generative AI to fill dataset fields (Species) in data-prep,Overstates reliability: passage warns AI-generated labels are not always reliable and require validation.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
101530,136,barely-true,Agentic AI fully replaces human customer support teams without any oversight.,agentic AI enabling customer support automation and escalation,Contradicts passage: agents reduce routine oversight and assist humans but do not eliminate human teams entirely.,"agentic-ai,planning,tools",12,Agentic AI
101531,136,FALSE,Agentic AI eliminates all need for human oversight in customer support workflows.,agentic AI in customer support systems,"Passage says agentic AI reduces routine oversight and escalates when needed, not removes human oversight entirely.","agentic-ai,planning,tools",12,Agentic AI
101532,136,half-true,Agentic AI fully eliminates the need for human oversight in customer support operations.,agentic AI enhancing customer support with escalation and account retrieval,"Passage says agentic AI reduces routine oversight and escalates when needed, not that it eliminates human oversight.","agentic-ai,planning,tools",12,Agentic AI
101533,6,mostly-true,"AI agents can adapt and make dynamic decisions, reducing the need for constant human reprogramming.",agentic AI and AI-driven automation for decision-making,Passage supports adaptability and dynamic decision-making but omits limits and failure modes.,"agentic-ai,planning,tools",12,Agentic AI
101534,59,TRUE,AI models fabricate factual details because they rely on pattern-matching rather than human reasoning.,model behavior and failure modes (pattern-matching),"Passage describes fabrication of citations, policies, and APIs and attributes cause to pattern-matching rather than reasoning.","security,red-team,guardrails",8,Breaking-Securing AI
101535,59,half-true,Models generate plausible but fabricated citations and API descriptions due to pattern-matching.,model behavior and hallucinations in red-team security testing,"Accurately notes fabrications and pattern-matching cause, but omits nuances about mitigation or specific model architectures.","security,red-team,guardrails",8,Breaking-Securing AI
101536,59,barely-true,The model primarily pattern-matches rather than performing human-like reasoning.,model behavior and hallucination in red-team security testing,"Passage states pattern-matching causes fabricated citations and APIs, but overgeneralizes cognitive processes.","security,red-team,guardrails",8,Breaking-Securing AI
101537,181,pants-fire,The synthesized health records are real patient data from North Carolyn clinic.,synthetic dataset and health records example,"Asserts fabricated records are real, directly contradicting passage statement that records are synthetic and privacy-preserving.","data-prep,feature-engineering,rag",3,Prepping Data for AI
101538,181,FALSE,The synthesized health records were derived from a real patient database using direct extraction methods.,"synthetic data, health records, dataset generation","Contradicts passage which states records were fabricated synthetic data, not directly extracted from real patients.","data-prep,feature-engineering,rag",3,Prepping Data for AI
101539,181,half-true,Synthetic health records can fully replicate real clinical datasets for model training without privacy risk.,synthetic dataset of fabricated health records for privacy-conscious AI,Mixes correct privacy-preserving intent with incorrect claim of fully replicating real data fidelity and utility.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
101540,8,mostly-true,Open-source red-team exercises broadly improve AI system defenses by exposing flaws early.,red-team exercises with open-source tools,"Supported by passage: red and blue teams use open-source tools to surface flaws early, though specifics omitted.","security,red-team,guardrails",8,Breaking-Securing AI
101541,8,half-true,Open-source red-team tools both expose many flaws and always enable faster fixes.,"open-source tools, Red Team, Blue Team workflow","Accurately notes flaw exposure by red teams and openness, but incorrectly asserts fixes are always faster.","security,red-team,guardrails",8,Breaking-Securing AI
101542,8,TRUE,Red Teams use real-world tactics while Blue Teams patch and strengthen AI systems.,red-team and Blue Team roles in breaking-securing AI,"Passage explicitly states Red Team employs real-world tactics and Blue Team patches, validates, strengthens systems.","security,red-team,guardrails",8,Breaking-Securing AI
101543,172,half-true,SSL training by masking tokens always yields models that fully learn semantic meaning.,Masked Language Modeling (MLM) SSL on text corpora,Overstates outcome: masking helps learn grammar and context but doesn't guarantee full semantic understanding across corpora.,"machine-learning,classification,evaluation",4,Classical Machine Learning
101544,172,FALSE,Self-supervised learning cannot learn grammar or context from masked token prediction.,Masked Language Modeling (MLM) in SSL,"Contradicts passage claiming MLM enables models to absorb grammar, context, and meaning via token prediction.","machine-learning,classification,evaluation",4,Classical Machine Learning
101545,172,barely-true,Self-supervised learning always lets models fully understand meaning just by masking words.,Masked Language Modeling (MLM) self-supervised training,Overstates capability: MLM learns patterns and context but does not guarantee full semantic understanding or complete meaning recovery.,"machine-learning,classification,evaluation",4,Classical Machine Learning
101546,16,barely-true,The network genuinely learns digit-recognition from a single training step on one batch of 64 images.,"conv1, conv2, ReLU, max pooling, single batch of 64",Overreaches: single step/batch only initializes filters and cannot reliably train digit-recognition.,"neural-networks,cnn,transformers",6,Neuron Building Blocks
101547,16,TRUE,The network uses two convolutional layers with ReLU and max pooling before a final fully connected digit classifier.,conv1 and conv2 convolutional layers in a CNN,"Describes architecture exactly: conv1 (8 filters), conv2 (16), ReLU and max pooling, then flattened fully connected classifier for digits.","neural-networks,cnn,transformers",6,Neuron Building Blocks
101548,16,TRUE,The network's conv1 uses 8 filters and conv2 uses 16 filters with ReLU and max pooling.,"CNN architecture visualization for digit classification (conv1, conv2, ReLU, pooling)","Passage explicitly states conv1 has 8 filters, conv2 16, with ReLU activations and max pooling.","neural-networks,cnn,transformers",6,Neuron Building Blocks
101549,51,FALSE,Agentic AI systems are stable and rarely require adaptation to new models or modalities.,model interoperability and multimodal tools,"Contradicts passage: models and modalities rapidly change, requiring insulation and ongoing adaptation.","agentic-ai,planning,tools",12,Agentic AI
101550,51,mostly-true,Developers can largely future-proof apps by using modular tool-based agent architectures to swap models easily.,agentic AI tool-based architectures for model modularity,"Passage supports modular approaches and tool use for insulating apps, though it omits engineering complexity and trade-offs.","agentic-ai,planning,tools",12,Agentic AI
101551,51,mostly-true,Developers should use model-agnostic architectures to adapt as generative AI models evolve rapidly.,agentic-ai model-agnostic architecture for multimodal models,Broadly supported by passage urging insulation from rapid model changes while enabling experimentation; minor implementation details omitted.,"agentic-ai,planning,tools",12,Agentic AI
101552,52,pants-fire,The model fabricated Jerry's voice from scratch without any real audio samples.,transcription code using processor and model for audio files,Contradicts passage which transcribes provided Jerry audio files; assumes nonexistent fabrication step.,"media-forensics,voice-cloning,deepfake",9,Deepfake Defense
101553,52,TRUE,The code transcribes audio files to text using a 16 kHz ASR processor and model.,speech-to-text preprocessing with processor and model,"Code shows librosa at 16 kHz, processor inputs, model.generate, and saved CSV transcriptions.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
101554,52,TRUE,The code transcribes Jerry's audio files to text using a speech model and processor.,"transcription script using processor, model, and librosa","Transcription loop decodes model.generate outputs, storing filename and transcription and saving results to CSV.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
101555,61,mostly-true,Fine-tuning models typically improves accuracy beyond simple pre-trained classifiers.,"evaluation_metrics (accuracy, precision, recall) and pre-trained models","Passage says moving beyond pre-trained models to fine-tuning will help push accuracy higher, a broadly supported caveat.","machine-learning,classification,evaluation",4,Classical Machine Learning
101556,61,barely-true,Fine-tuning always raises classification accuracy above 75 percent.,model fine-tuning for classification accuracy,Overreaches typical benefit; passage says fine-tuning can help push accuracy higher but gives no guarantee.,"machine-learning,classification,evaluation",4,Classical Machine Learning
101557,61,half-true,Fine-tuning pre-trained models generally raises accuracy above simple pre-trained models.,"fine-tuning pre-trained models, accuracy metric","Passage claims moving beyond simple pre-trained models to fine-tuning will help push accuracy higher, but specifics and guarantees are omitted.","machine-learning,classification,evaluation",4,Classical Machine Learning
101558,87,FALSE,BatchNorm normalizes across all features for each individual example in a sequence.,"normalization layers (BatchNorm, LayerNorm, GroupNorm) for tensors","Contradicts documented detail: BatchNorm normalizes across the batch per feature, not across all features per example.","deep-learning,frameworks,tensors",5,Deep Learning
101559,87,TRUE,BatchNorm normalizes activations across the batch per feature to stabilize and accelerate training.,"normalization layers (BatchNorm, LayerNorm, GroupNorm) in neural networks","Passage states BatchNorm normalizes per-feature across the batch, stabilizing training and accelerating convergence.","deep-learning,frameworks,tensors",5,Deep Learning
101560,87,half-true,"BatchNorm, LayerNorm, and GroupNorm always eliminate exploding or vanishing gradients in deep networks.","normalization layers (BatchNorm, LayerNorm, GroupNorm) in deep learning","Correct that those norms stabilize training, but overstated: they reduce risk yet don't guarantee eliminating gradient issues.","deep-learning,frameworks,tensors",5,Deep Learning
101561,83,half-true,MLOps always eliminates the need for manual model monitoring and debugging in production.,MLOps practices for experiment tracking and automated testing,Mixes accurate benefits of MLOps with incorrect absolute claim: tools assist but don't remove manual monitoring or debugging.,"mlops,scaling,deployment",10,AI At Scale
101562,83,half-true,MLOps guarantees reproducible model deployments across all organizational scales.,MLOps practices for experiment tracking and version-controlled deployments,"Mixes correct aspects (tracking, versioning) with overclaim that MLOps guarantees reproducibility universally.","mlops,scaling,deployment",10,AI At Scale
101563,83,TRUE,"MLOps provides tools for experiment tracking, automated testing, and reproducible deployments.",MLOps practices for model management and deployment,"Directly supported: passage lists experiment tracking, automated testing, version-controlled deployments, and repeatable pipelines.","mlops,scaling,deployment",10,AI At Scale
101564,86,pants-fire,The passage claims voice-cloning training never benefits from GPU acceleration.,"training parameters, GPU, voice generation",Contradicts passage detail that a GPU speeds up training and helps handle demanding voice-generation calculations.,"media-forensics,voice-cloning,deepfake",9,Deepfake Defense
101565,86,TRUE,"Training voice models requires tuning hyperparameters like learning rate, batch size, and epochs.",voice generation model training; hyperparameter tuning,"Passage explicitly lists learning rate, batch size, and epochs as adjusted to improve voice model results.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
101566,86,FALSE,Voice cloning models do not benefit from GPUs and train equally fast on CPUs.,training configuration and GPU for voice cloning,Contradicts passage detail that GPUs speed up training and help handle demanding calculations.,"media-forensics,voice-cloning,deepfake",9,Deepfake Defense
101567,28,TRUE,Open source will let many people shape AI rather than only a few tech giants.,importance of open source for AI inclusion,Passage asserts open source gives people a seat at the table and counters dominance by a handful of tech giants.,"open-source,community,ai",0,Foreword – Robo Interviews Clément Delangue
101568,28,TRUE,"Open source will enable many people, not just tech giants, to shape AI development.",open source enabling broader developer and user participation,Passage explicitly states open source gives people a seat at the table and counters concentration among tech giants.,"open-source,community,ai",0,Foreword – Robo Interviews Clément Delangue
101569,28,mostly-true,Open-source tools will enable widespread participation in shaping AI across sectors.,open source importance in developer and user participation,"Passage asserts open source gives people a seat at the table, broadly supporting widespread participation though specifics omitted.","open-source,community,ai",0,Foreword – Robo Interviews Clément Delangue
101570,75,TRUE,Selective fine-tuning by freezing layers helps control and stabilize GAN training on real-world domains.,fine-tuning GANs; freezing layers in generator or discriminator,Passage explicitly recommends freezing layers during fine-tuning to improve control and stability for real-world domains.,"generative-ai,diffusion,gans",7,Generative AI
101571,75,barely-true,Fine-tuning entire GANs is always unnecessary and harmful for real-world domains.,Selective Fine-Tuning; freezing layers in GAN generator or discriminator,"Overreaches relative to passage: freezing layers is advised as sometimes useful, not always harmful.","generative-ai,diffusion,gans",7,Generative AI
101572,75,barely-true,Freezing select GAN layers is essential for stable fine-tuning on real-world domains.,Selective Fine-Tuning (Freezing Layers) in GAN fine-tuning,Overstates necessity: passage says freezing becomes essential in many real-world cases but not always mandatory.,"generative-ai,diffusion,gans",7,Generative AI
101573,59,barely-true,Keras model.save preserves optimizer state and training history by default.,TensorFlow Keras model saving and reloading,Passage only notes saving/reloading models; it never claims optimizer state or history are preserved by default.,"deep-learning,frameworks,tensors",5,Deep Learning
101574,59,mostly-true,Keras models in TensorFlow can be saved to disk and reloaded for later predictions.,TensorFlow Keras model saving and reloading,Directly supported by the passage which describes saving a trained Keras model for later reuse.,"deep-learning,frameworks,tensors",5,Deep Learning
101575,59,mostly-true,Keras models in TensorFlow can be saved to disk and later reloaded for predictions.,TensorFlow Keras model saving and reloading,"Training output mentions saving and reloading models, implying persistence for later predictions with minor omitted details.","deep-learning,frameworks,tensors",5,Deep Learning
101576,169,mostly-true,Using a batch size of 1000 makes MNIST evaluation faster by processing data in larger GPU-parallel batches.,evaluation batch size for MNIST test set,"Passage explains 1000 batches exploit GPU parallelism and divides 10,000-test MNIST set into ten efficient batches, a practical simplification.","deep-learning,frameworks,tensors",5,Deep Learning
101577,169,TRUE,Using a batch size of 1000 speeds up MNIST evaluation by processing data in parallel on a GPU.,evaluation batch size for MNIST dataset,"Evaluation uses batch size 1000 to process 10,000 test images in 10 GPU-parallel batches, improving efficiency.","deep-learning,frameworks,tensors",5,Deep Learning
101578,169,half-true,Using a batch size of 1000 during MNIST evaluation makes evaluation faster but may hide per-example issues.,"MNIST evaluation batch size, GPU parallel processing","Correctly notes 1000 speeds evaluation and leverages GPU, but omits potential masking of individual example variability.","deep-learning,frameworks,tensors",5,Deep Learning
101579,123,FALSE,Deepfake detection relies solely on voice cloning techniques for all media types.,"deepfake detection, voice cloning, DeepSafe and Deepstar frameworks","Contradicts passage which describes video analysis, object recognition, scene detection, and two frameworks beyond just voice cloning.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
101580,123,mostly-true,Deepfake detection combines voice cloning analysis with video scene and object recognition techniques.,deepfake detection using voice cloning and scene detection tools,"Broadly supported: passage links voice cloning, object recognition, and scene detection as complementary defenses, minor implementation details omitted.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
101581,123,half-true,Deepfake defenses combine voice cloning analysis and scene detection techniques for detection.,deepfake detection using DeepSafe and Deepstar frameworks,Mixes correct toolkit components with incorrect implication that voice cloning analysis is always combined with scene detection in those frameworks.,"media-forensics,voice-cloning,deepfake",9,Deepfake Defense
101582,62,mostly-true,Fine-tuning pretrained models generally increases accuracy over using them as-is.,"fine-tuning pretrained models, accuracy, supervised models","Passage states fine-tuning pushes accuracy higher, a broadly true claim though specifics omitted.","machine-learning,classification,evaluation",4,Classical Machine Learning
101583,62,barely-true,Fine-tuning pre-trained models always yields large accuracy improvements on any dataset.,"fine-tuning pre-trained models, accuracy, supervised models",Overreaches beyond passage; fine-tuning can help but fails with scarce labels or skewed datasets.,"machine-learning,classification,evaluation",4,Classical Machine Learning
101584,62,half-true,Fine-tuning always yields substantial accuracy gains over pre-trained models on all datasets.,fine-tuning of pre-trained models for supervised classification,"Fine-tuning often improves accuracy, but claim wrongly asserts it helps universally across scarce or skewed datasets.","machine-learning,classification,evaluation",4,Classical Machine Learning
101585,110,TRUE,RAG paired with an LLM uses retrieved semantically relevant info to generate coherent responses.,retrieval-augmented generation with semantic retrieval for LLMs,Passage explicitly explains RAG feeds semantically relevant retrievals into LLMs to craft coherent answers.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
101586,110,TRUE,RAG works best when combined with a generative LLM to produce coherent responses from retrieved content.,retrieval-augmented generation with LLMs and semantic retrieval,Directly supported: passage states RAG pairs with LLMs and uses semantic retrieval to create coherent outputs.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
101587,110,TRUE,RAG paired with an LLM improves responses by using semantically retrieved context.,retrieval-augmented generation with LLMs and semantic relevance,"Passage states RAG retrieves semantically relevant information for an LLM to incorporate, improving timely or specialized responses.","data-prep,feature-engineering,rag",3,Prepping Data for AI
101588,138,mostly-true,A confusion matrix reveals which classes benefit or suffer from a classifier's errors.,confusion matrix for classification and accuracy metric,"Explains that confusion matrix shows per-class correct/incorrect counts, clarifying accuracy's blind spots.","machine-learning,classification,evaluation",4,Classical Machine Learning
101589,138,TRUE,A confusion matrix shows which classes the model predicts correctly and which it misclassifies.,confusion matrix for classification accuracy analysis,"Directly supported: matrix highlights correct (matching row/column) and incorrect class predictions, revealing error distribution.","machine-learning,classification,evaluation",4,Classical Machine Learning
101590,138,FALSE,Confusion matrices only report overall accuracy without showing per-class errors.,confusion matrix for classification model performance,Directly contradicts passage: confusion matrices reveal per-class errors and where model is right or wrong.,"machine-learning,classification,evaluation",4,Classical Machine Learning
101591,36,mostly-true,Fine-tuning with about one thousand well-chosen prompts can outperform larger models on accuracy and cost.,fine-tuning dataset and prompts,"Passage cites a study showing small, focused fine-tuning (~1,000 prompts) beats larger models on accuracy and cost, omitting dataset specifics.","ai,open-source,builder",1,Introduction – The Gold Rush Paradox
101592,36,half-true,Fine-tuning on one thousand prompts always beats much larger models like GPT in accuracy and cost.,fine-tuning study about prompts and model performance,"Passage cites one study showing such gains with ~1,000 prompts, but 'always' overgeneralizes and omits conditions.","ai,open-source,builder",1,Introduction – The Gold Rush Paradox
101593,36,half-true,Fine-tuning with about one thousand prompts always outperforms much larger models like GPT in every metric.,fine-tuning study comparing prompts to GPT models,Mixes correct study finding with overgeneralization; passage claims outperformances but not universally or always.,"ai,open-source,builder",1,Introduction – The Gold Rush Paradox
101594,24,barely-true,Changing weight and bias always makes outputs fall below the activation threshold.,"neuron weights, bias, activation threshold example","Overreaches: passage gives two specific parameter changes causing near-threshold drops, not a universal rule.","deep-learning,frameworks,tensors",5,Deep Learning
101595,24,TRUE,Small changes to weights or bias can shift outputs across an activation threshold.,"neural network neurons, weights, bias, activation threshold",Passage gives examples where altering weights or bias moves scores just below or above the pass threshold.,"deep-learning,frameworks,tensors",5,Deep Learning
101596,24,half-true,Changing bias or weights can shift identical inputs across a pass/fail activation threshold.,"neuron analogy using weights, bias, and activation threshold","Accurately describes effect, but mixes numeric specifics (74.8 vs 74.4) without full calculation details.","deep-learning,frameworks,tensors",5,Deep Learning
101597,38,TRUE,NumPy is the core numerical library powering array and matrix computations in AI.,library for arrays and matrices (NumPy) in numerical computing,Directly supported by passage: NumPy described as engine for number crunching in AI and array/matrix math.,"ai,tool-chain,notebooks",2,AI Survival Kit
101598,38,FALSE,NumPy was developed in 2015 as a deep learning framework replacing older libraries.,library history and AI numerical tools (NumPy),"Date and role are incorrect: NumPy originated 2005 by Travis Oliphant and is a numerical library, not a deep learning framework.","ai,tool-chain,notebooks",2,AI Survival Kit
101599,38,mostly-true,"NumPy powers much of the numerical computing used in AI, from vectors to deep learning workloads.",scientific computing library NumPy for arrays and matrices,"Passage credits NumPy as the core engine for array-based math in AI, omitting minor ecosystem nuances.","ai,tool-chain,notebooks",2,AI Survival Kit
101600,158,half-true,The DataLoader automatically loads full datasets like MNIST entirely into memory before batching.,PyTorch DataLoader handling MNIST dataset and mini-batches,"Incorrectly asserts full in-memory loading; passage says DataLoader avoids loading all 70,000 images at once.","deep-learning,frameworks,tensors",5,Deep Learning
101601,158,mostly-true,The DataLoader efficiently batches and transforms dataset samples for training loops.,PyTorch DataLoader batching and transformations,"Directly supported: passage describes pulling samples, batching into mini-batches, and applying transformations for training.","deep-learning,frameworks,tensors",5,Deep Learning
101602,158,half-true,The DataLoader always prevents memory issues when training on datasets like MNIST by batching data.,PyTorch DataLoader batching and Dataset handling,"Correct that batching reduces memory load, but 'always prevents memory issues' overstates guarantees and omits other factors (transform pipelines, workers, dataset size, pin_memory).","deep-learning,frameworks,tensors",5,Deep Learning
101603,123,mostly-true,"Regular model use reveals data gaps, prompt issues, and performance tuning opportunities.","model deployment and monitoring with prompts, batch size, hardware","Observations about training data, prompting, and latency guide iterative fixes, omitting rarity or scale caveats.","mlops,scaling,deployment",10,AI At Scale
101604,123,mostly-true,Regular model use reveals data and prompting gaps that guide practical deployment refinements.,model deployment and prompt engineering in MLOps,"Generally supported by passage: monitoring predictions, phrasing issues, and latency guide data, prompt, and hardware fixes.","mlops,scaling,deployment",10,AI At Scale
101605,123,barely-true,Regular model use always reveals actionable training data or prompt issues to improve performance.,model refinement during deployment and prompt engineering,"Overreaches: routine use may reveal issues sometimes, but not always; ignores cases needing new data or architecture.","mlops,scaling,deployment",10,AI At Scale
101606,37,barely-true,A simple feature-based model perfectly distinguished Jerry's real voice from all other clips.,voice-cloning detection using flatness feature,"Passage claims perfect accuracy, but small unseen sample size makes perfect generalization unsupported.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
101607,37,TRUE,A simple model accurately distinguished real Jerry audio from other clips.,model testing on unseen audio samples and accuracy metric,"Passage reports perfect accuracy and predicted results per file, supporting strong model performance.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
101608,37,mostly-true,A simple feature-based model can effectively distinguish Jerry's real voice from imitations.,feature-based model testing on unseen audio samples,"Passage reports perfect accuracy using a few features and simple model, omitting dataset size and generalization caveats.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
101609,44,half-true,The generator's increasing loss proves the GAN is producing increasingly realistic outputs.,"GAN training losses (generator loss, discriminator loss)",Correctly notes generator loss rise but overinterprets loss as definitive proof of realism; lacks evaluation metrics.,"generative-ai,diffusion,gans",7,Generative AI
101610,44,pants-fire,The generator’s rising loss proves it is producing perfectly realistic images without issues.,"GAN training dynamics (generator loss, discriminator loss)","Contradicts passage: rising generator loss was interpreted as more realistic, not proof of perfect realism; claim is extreme and implausible.","generative-ai,diffusion,gans",7,Generative AI
101611,44,half-true,The generator's rising loss indicates it produces more realistic outputs over training.,"GAN training, generator and discriminator losses",Mixes correct observation (rising generator loss) with questionable interpretation that higher loss equals realism.,"generative-ai,diffusion,gans",7,Generative AI
101612,136,half-true,RAG combines prepared datasets and retrieval to generate final text but requires careful feature design.,RAG pipeline with dataset and retrieval for story generation,Mixes correct RAG workflow with incorrect implication that feature design is the sole critical requirement; both data prep and retrieval tuning matter.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
101613,136,FALSE,RAG requires exclusively real-world datasets and cannot use synthetic plot data.,RAG pipeline using synthetic plot concepts and hero attributes,Contradicts passage which explicitly uses synthetic plot concepts and hero attributes in the RAG pipeline.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
101614,136,FALSE,RAG requires hero attribute labels to be manually annotated for every dataset example.,RAG pipeline for generating story plots with hero attributes,"Passage describes synthetic hero attributes and automated RAG steps, contradicting manual annotation requirement.","data-prep,feature-engineering,rag",3,Prepping Data for AI
101615,89,half-true,SHAP is an open-source tool that perfectly explains every individual model prediction without error.,tool: SHAP for explaining model predictions,"SHAP is correctly described as an explainability tool, but claiming perfect, error-free explanations is incorrect and overstates capabilities.","open-source,community,contribution",13,Commit to Contribute
101616,89,half-true,SHAP exclusively explains random forest classifiers' individual predictions with feature importance visualizations.,tool descriptions listing SHAP and model explainability,Correct that SHAP visualizes feature importance for individual predictions but incorrect to claim exclusivity to random forests; SHAP applies broadly to many model types.,"open-source,community,contribution",13,Commit to Contribute
101617,89,FALSE,Scikit-learn was introduced in 2018 as a PyTorch-based speech toolkit.,tool descriptions listing Scikit-learn and SpeechBrain,Contradicts dates and frameworks: Scikit-learn started 2007 and is not PyTorch-based; SpeechBrain is 2021 PyTorch toolkit.,"open-source,community,contribution",13,Commit to Contribute
101618,122,half-true,"The program reliably identifies people, pets, and objects in user-provided videos using pre-trained models.",object detection program using pre-trained models on video clips,"Claims correct that pre-trained models identify objects, but overstates reliability and ignores model limits and false positives.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
101619,122,FALSE,The program fails to detect people or pets in any video clips.,object detection and annotation using pre-trained models,"Contradicts passage which says system identifies people, pets, and objects using pre-trained models.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
101620,122,half-true,"The described program reliably identifies people, pets, and objects in user videos using pre-trained models.",object detection and annotation with pre-trained models,"Accurate that pre-trained models enable detection, but overstates reliability—performance varies by model, dataset, and clip conditions.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
101621,90,TRUE,GDPR and EU AI proposals emphasize privacy protection for AI systems processing personal data.,"EU regulations and guidelines (GDPR, AI Act, Ethics Guidelines for Trustworthy AI)","Directly supported by cited GDPR, AI Act proposal, and Ethics Guidelines focusing on privacy protections.","ethics,governance,privacy",11,AI Ethics and Governance
101622,90,FALSE,GDPR exempts all AI systems from data protection requirements in automated decision-making.,"regulatory frameworks, GDPR and AI Act references","Contradicts GDPR: automated decision-making has specific protections and rights, not exemptions.","ethics,governance,privacy",11,AI Ethics and Governance
101623,90,barely-true,GDPR fully prevents all AI-driven privacy harms in deployed systems.,"regulatory frameworks, GDPR and AI Act",Overstates GDPR's coverage; regulations provide protections but do not eliminate AI privacy risks or enforcement gaps.,"ethics,governance,privacy",11,AI Ethics and Governance
101624,57,half-true,A Transformer-based model replaces Naïve Bayes for sentiment detection and always outperforms it.,Transformer sentiment detector replacing Naïve Bayes,"Correct that a Transformer replaces Naïve Bayes in example, but unjustified absolute claim of always outperforming it without evaluation metrics.","neural-networks,cnn,transformers",6,Neuron Building Blocks
101625,57,barely-true,A Transformer sentiment model always outperforms Naïve Bayes on all text datasets.,Transformer sentiment detection vs Naïve Bayes spam model,Overreaches beyond passage: it claims universal superiority not supported by dataset- or task-specific evidence.,"neural-networks,cnn,transformers",6,Neuron Building Blocks
101626,26,barely-true,GAN discriminators always become unable to tell real from generated images after training.,GAN discriminator behavior during adversarial training,"Overreaches beyond passage: discriminator may still detect fakes; passage says it can struggle, not always fail.","generative-ai,diffusion,gans",7,Generative AI
101627,26,TRUE,A GAN trains a generator and discriminator adversarially until the discriminator struggles to distinguish fakes.,discriminator feedback during GAN training,"Describes adversarial loss feedback and progressive improvement of generator and discriminator, matching passage.","generative-ai,diffusion,gans",7,Generative AI
101628,26,barely-true,GAN discriminators never improve once the generator becomes proficient.,GAN training with discriminator and generator adversarial loss,Contradicts passage: discriminator also improves during training and may still detect fakes.,"generative-ai,diffusion,gans",7,Generative AI
101629,96,TRUE,Open-source projects typically require contributors to choose an appropriate license.,"contribution workflow, choosealicense license guidance","Passage lists 'Choose a License' and links to ChooseALicense, supporting license selection as required.","open-source,community,contribution",13,Commit to Contribute
101630,96,pants-fire,Open-source contribution is impossible without formal institutional approval.,contribution process and licensing (Choose a License),Contradicts guidance about choosing licenses and contributing independently; institutional approval is not required.,"open-source,community,contribution",13,Commit to Contribute
101631,96,pants-fire,"Open-source contribution requires no licenses, so anyone can freely change any project.",open-source license choice and contribution process,"Contradicts requirement to choose a license; license sources (Choose a License, OSI) enable legal permissions.","open-source,community,contribution",13,Commit to Contribute
101632,80,FALSE,The dataset filter removes audio examples longer than 200 seconds by default.,data preprocessing filter_long_texts and sr mel_bins parameters,"Contradicts passage: filter keeps examples under 200 tokens, not 200 seconds; units differ.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
101633,80,TRUE,The code filters audio dataset examples longer than 200 tokens before further processing.,"data preprocessing filter_long_texts function, dataset ds","Filtering condition (<200 tokens) explicitly applied to dataset ds, matching preprocessing step.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
101634,80,half-true,The preprocessing script always filters audio longer than 200 tokens before mel feature extraction.,"data preprocessing script, filter_long_texts function, sr and mel_bins",Partly correct: code shows filtering <200 tokens but omission: 'always' and exact unit 'tokens' versus time unclear.,"media-forensics,voice-cloning,deepfake",9,Deepfake Defense
101635,94,pants-fire,The cloned audio is an indistinguishable perfect replica of the original speaker's voice in all forensic analyses.,generated spectrogram of cloned audio showing timing and emphasis,"Spectrogram similarity noted, but passage only claims close tracking of rhythm and emphasis, not perfect indistinguishability across forensic tools.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
101636,94,half-true,The cloned voice spectrogram almost perfectly replicates original timing and emphasis for all spoken phrases.,spectrogram analysis of cloned audio (voice-cloning),"Spectrogram shows strong timing/emphasis similarity but passage only claims overall structure similarity, not perfect replication for all phrases.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
101637,94,pants-fire,"The cloned audio spectrogram was completely dissimilar to the original, failing to capture timing or emphasis.","generated spectrogram for cloned audio, voice-cloning model","Spectrogram description says structure looked remarkably similar, so claiming complete dissimilarity directly contradicts that detail.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
101638,21,barely-true,The provided audio lists enable straightforward training of a SpeechT5 voice-cloning model.,audio dataset lists for SpeechT5 training and testing,"List shows sample files but omits preprocessing, labels, and model configuration needed for cloning.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
101639,21,FALSE,The dataset contains only Jerry's voice recordings and no other speakers.,"audio file lists (Jerry_Audio_Files, Non_Jerry_Audio_Files)",Contradicts listed Non_Jerry_Audio_Files showing multiple non-Jerry speakers like Adolfo and Rama.,"media-forensics,voice-cloning,deepfake",9,Deepfake Defense
101640,21,mostly-true,The dataset contains labeled Jerry and non-Jerry audio samples suitable for SpeechT5 training.,audio dataset with labeled files for SpeechT5,"Passage lists Jerry (Label 1) and non-Jerry (Label 0) WAV files and mentions SpeechT5 compatibility, omitting dataset size details.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
101641,153,FALSE,Diffusion models always tokenize prompts into numerical token IDs before generation.,prompt processing and tokenization in model input pipeline,"Contradicts passage: only prompts are tokenized as input; diffusion generation operates on continuous latents, not token IDs.","generative-ai,diffusion,gans",7,Generative AI
101642,153,FALSE,Tokenization moves raw audio files directly into model weights without numerical tokens.,tokenization and token IDs process,"Contradicts passage detail: tokenization converts text to numerical token IDs, not raw audio into weights.","generative-ai,diffusion,gans",7,Generative AI
101643,153,TRUE,Tokenization converts prompt text into numerical token IDs and attention masks before model processing.,input tokenization and attention masks in model preprocessing,Passage explicitly states prompt is tokenized into token IDs and attention masks moved to device before processing.,"generative-ai,diffusion,gans",7,Generative AI
101644,67,half-true,Keeping inputs concise always prevents slowdowns on CPU-heavy deployments.,inference latency optimization for GPU vs CPU deployments,"Correctly notes concision helps, but overstates certainty and omits batching, truncation, and architecture nuances.","mlops,scaling,deployment",10,AI At Scale
101645,67,half-true,Using GPUs always prevents latency spikes for longer or batched sequences.,"inference latency, GPU acceleration, token bucketing","Overstates GPU effect: GPUs reduce latency but don't guarantee preventing spikes; omission of batching, model size, or architecture caveats.","mlops,scaling,deployment",10,AI At Scale
101646,67,mostly-true,Using GPUs significantly improves responsiveness for longer or batched model inputs.,"inference latency, GPU acceleration, token bucketing","Passage recommends GPU use for longer/batched sequences and further CPU-specific optimizations, so broadly supported.","mlops,scaling,deployment",10,AI At Scale
101647,142,mostly-true,"Language model agents may produce inconsistent outputs, risking reproducibility in high-stakes domains.",agentic AI agents; reproducibility in finance and healthcare,"Passage notes probabilistic LMs cause varied responses, warning reproducibility matters for finance and healthcare.","agentic-ai,planning,tools",12,Agentic AI
101648,142,half-true,Agent responses can vary on identical prompts due to the model's probabilistic nature.,agent consistency and reproducibility with language models,Accurately mentions probabilistic variability but omits specifics about settings like finance or healthcare needing reproducibility.,"agentic-ai,planning,tools",12,Agentic AI
101649,142,FALSE,Agentic AI always produces identical outputs given the same input.,consistency in agent behavior with language models,"Passage states language models are probabilistic and won't always respond the same way, contradicting deterministic claim.","agentic-ai,planning,tools",12,Agentic AI
101650,97,barely-true,The described VAE guarantees smooth interpolation between all learned 3D meshes.,variational autoencoder latent space and KL divergence,Overstates capability: KL encourages continuity but doesn't guarantee smooth interpolation across all learned mesh modes.,"generative-ai,diffusion,gans",7,Generative AI
101651,97,barely-true,The described model is a variational autoencoder that reconstructs meshes using MSE plus a KL regularizer.,"VAE forward pass and loss (MSE reconstruction, KL divergence)",Mostly accurate but overstates mesh-specific details; passage shows mesh decoding but limited training and dataset evidence.,"generative-ai,diffusion,gans",7,Generative AI
101652,97,half-true,The described VAE mixes correct reconstruction loss with an incorrectly implemented KL scaling.,VAE training loss combining MSE reconstruction and KL divergence,"Loss combines MSE and KL as stated, but passage omits KL weighting/beta scaling used in practice.","generative-ai,diffusion,gans",7,Generative AI
101653,126,half-true,SHAP fully explains individual predictions from generative AI models.,explainability; SHAP and generative AI,Partly true: SHAP explains feature contributions but cannot fully account for generative models' distributed pattern-based outputs.,"ai,tool-chain,notebooks",2,AI Survival Kit
101654,126,TRUE,Explainability tools like SHAP help interpret individual model predictions despite generative AI challenges.,explainability tools (SHAP) and generative AI outputs,SHAP explicitly decomposes individual predictions; passage notes generative models make explainability harder due to distributed training patterns.,"ai,tool-chain,notebooks",2,AI Survival Kit
101655,126,half-true,SHAP fully explains individual predictions for traditional models but not for generative AI outputs.,"explainability, SHAP, generative AI",Mixes correct SHAP strength for individual predictions with incorrect implication it fully explains traditional models and oversimplifies generative explanation limits.,"ai,tool-chain,notebooks",2,AI Survival Kit
101656,104,barely-true,The passage claims human oversight modules can be added anywhere in an orchestration like LangChain.,integration with LangChain orchestration and human oversight,Overreaches: passage gives examples but doesn't prove universal add-anywhere feasibility or implementation details.,"security,red-team,guardrails",8,Breaking-Securing AI
101657,104,pants-fire,The passage claims human oversight is never needed when integrating modular AI components.,integration modularity and human oversight in LangChain orchestration,Directly contradicts passage which says to decide where human oversight is needed; falsely asserts oversight is never needed.,"security,red-team,guardrails",8,Breaking-Securing AI
101658,104,pants-fire,Human oversight is unnecessary for LangChain integrations and can be omitted safely.,human oversight integration in LangChain orchestration,Contradicts passage guidance explicitly recommending inserting human review for questionable outputs and prompt injection.,"security,red-team,guardrails",8,Breaking-Securing AI
101659,55,half-true,Keras fully automates training including backpropagation and weight updates without user involvement.,Keras model training with model.fit and MNIST dataset,"Correct that Keras runs forward/backward passes and applies gradients, but overstates 'fully automates' — users still define models, loss, and optimizer details.","deep-learning,frameworks,tensors",5,Deep Learning
101660,55,TRUE,"Keras automates forward pass, loss computation, backpropagation, and weight updates during training.",Keras model.fit() training workflow with MNIST dataset,"Passage explicitly states Keras handles forward pass, error calculation, backpropagation, and weight updates during model.fit().","deep-learning,frameworks,tensors",5,Deep Learning
101661,55,mostly-true,"Keras automates training steps like forward pass, backpropagation, and weight updates for common models.",Keras API usage with MNIST dataset and TensorFlow optimizer,"Passage states Keras handles forward pass, error calculation, backpropagation, and weight updates, omitting limits and advanced customization details.","deep-learning,frameworks,tensors",5,Deep Learning
101662,13,half-true,A CNN's learned filters detect edges and corners while its feature maps reveal image regions of interest.,CNN filters and feature maps in convolutional neural networks,"Accurately notes filters and feature maps, but oversimplifies by implying all filters only detect simple edges and corners.","neural-networks,cnn,transformers",6,Neuron Building Blocks
101663,13,mostly-true,CNN feature maps and learned filters reveal interpretable edge and pattern detectors during image processing.,visualizing CNN filters and feature maps in neural-networks and CNNs,"Directly supported by passage: filters detect edges/corners and feature maps show activated image regions, minor nuance about deeper layers' abstractness omitted.","neural-networks,cnn,transformers",6,Neuron Building Blocks
101664,13,half-true,CNN filters always correspond to human-interpretable edge or corner detectors in early layers.,visualizing CNN filters and feature maps in convolutional networks,"Accurate that many early filters detect edges/corners, but 'always' overstates interpretability and exceptions exist.","neural-networks,cnn,transformers",6,Neuron Building Blocks
101665,18,half-true,Newer open-source projects always lack structure and need more contributions.,project scope and activity in open-source communities,"Partly correct: passage says newer projects often need help but says they may lack structure, not always.","open-source,community,contribution",13,Commit to Contribute
101666,18,half-true,Some open-source projects offer Discord or GitHub Discussions for newcomers to ask questions.,"community communication channels (Discord, GitHub Discussions)",Accurately cites available channels but omits that not all projects offer them and vary in structure.,"open-source,community,contribution",13,Commit to Contribute
101667,18,half-true,Open Discussions always let newcomers learn a project's tone before contributing.,"open Discord, Slack, or GitHub Discussions for community entry","Correct that discussions help learn tone, but 'always' overstates availability and consistency.","open-source,community,contribution",13,Commit to Contribute
101668,15,TRUE,Hidden layers transform intermediate numerical representations before the output layer produces predictions.,neural network hidden layers and output layer,Passage explicitly describes hidden layers processing numbers and output layer producing predictions like class labels.,"deep-learning,frameworks,tensors",5,Deep Learning
101669,15,TRUE,Hidden layers process inputs internally before the network's final prediction is produced.,neural network hidden layers and output layer,Directly supported: passage explains hidden layers transform previous layer outputs and output layer produces prediction.,"deep-learning,frameworks,tensors",5,Deep Learning
101670,15,half-true,Hidden layers always learn semantic concepts like 'cat' and 'dog' before the output layer does.,neural network output layer and hidden layers,Mixes correct idea that hidden layers transform features with incorrect claim that they explicitly learn final semantic classes.,"deep-learning,frameworks,tensors",5,Deep Learning
101671,95,barely-true,Feature engineering always preserves signal when combining diverse datasets for RAG systems.,dataset compatibility and feature engineering for RAG,"Overreaches: passage warns about signal loss and testing dataset compatibility, so claim is largely unsupported.","data-prep,feature-engineering,rag",3,Prepping Data for AI
101672,95,TRUE,Feature engineering enhances predictive power but demands careful responsibility in design.,feature engineering for datasets and indices,"Passage explicitly says feature engineering adds power and responsibility, applied to datasets like customer scores.","data-prep,feature-engineering,rag",3,Prepping Data for AI
101673,95,FALSE,Feature engineering is unnecessary when datasets already share identical formats.,dataset compatibility check and feature engineering,"Contradicts passage emphasis that feature engineering is essential despite dataset compatibility, specifically mentioning feature responsibility.","data-prep,feature-engineering,rag",3,Prepping Data for AI
101674,42,mostly-true,Open-source code accelerates improvement but requires active maintenance and community monitoring.,"open-code, version changes, security updates, community health",Aligns with passage: improvement occurs with openness but omits risks and quality variability.,"ai,open-source,builder",1,Introduction – The Gold Rush Paradox
101675,42,mostly-true,Open-source code accelerates innovation but requires builders to monitor versions and security.,"open code, version changes, security updates, community health",Passage supports faster evolution of open code but notes variable quality and need for version/security monitoring.,"ai,open-source,builder",1,Introduction – The Gold Rush Paradox
101676,42,barely-true,Open-source AI tools always require constant monitoring and community health checks to remain usable.,developer responsibilities for open-source models and tools,Overreaches by asserting 'always' and universal necessity; passage notes variability and recommends vigilance but not an absolute rule.,"ai,open-source,builder",1,Introduction – The Gold Rush Paradox
101677,104,pants-fire,The loss function amplifies correct predictions to increase network confidence.,loss function comparing prediction and correct answer,"Contradicts passage: loss quantifies error, not amplifies correct predictions; reverses loss purpose.","deep-learning,frameworks,tensors",5,Deep Learning
101678,104,FALSE,Loss functions are only used at hidden layers and not at the network output.,loss function usage in neural network output layer,Contradicts passage: loss functions compare output predictions to ground truth at the output layer.,"deep-learning,frameworks,tensors",5,Deep Learning
101679,104,TRUE,A loss function measures how wrong a network's prediction is by comparing it to the correct answer.,loss function comparing prediction to ground-truth in neural networks,Directly supported: passage explains loss returns a single number indicating how wrong prediction is compared to correct answer.,"deep-learning,frameworks,tensors",5,Deep Learning
101680,8,FALSE,AI systems never exhibit emergent inappropriate behavior after training on unfiltered online data.,chatbot example involving unfiltered online data and emergent behavior,Contradicts passage example showing a chatbot can develop offensive emergent behavior after such training.,"ethics,governance,privacy",11,AI Ethics and Governance
101681,8,mostly-true,"AI system failures require clear assignment of responsibility among developers, manufacturers, and users.",accountability for autonomous systems and self-driving car incidents,"Passage describes assigning responsibility across design, development, and deployment, omitting limited legal nuance.","ethics,governance,privacy",11,AI Ethics and Governance
101682,8,mostly-true,AI system developers generally bear primary responsibility for harms arising from design and deployment choices.,accountability in AI design and deployment,"Passage emphasizes assigning responsibility across design, development, and deployment, omitting nuanced legal distinctions.","ethics,governance,privacy",11,AI Ethics and Governance
101683,77,half-true,A pretrained CNN is ideal for image classification but cannot process video frames at all.,pretrained Convolutional Neural Network (CNN) for images and video,"Correctly states CNN strength for images but falsely claims inability to process video frames, contradicting passage.","ai,tool-chain,notebooks",2,AI Survival Kit
101684,77,barely-true,CNNs are exclusively suitable only for still image tasks and cannot process video frames effectively.,pretrained Convolutional Neural Network (CNN) for image classification,Contradicts passage saying CNNs can process video frames individually and be combined with transformers.,"ai,tool-chain,notebooks",2,AI Survival Kit
101685,77,TRUE,A pretrained CNN can be used for image classification by automatically detecting visual features.,pretrained Convolutional Neural Network for image classification,"Passage states CNNs detect edges, shapes, and objects and are suited for visual image tasks.","ai,tool-chain,notebooks",2,AI Survival Kit
101686,159,FALSE,Transformer-guided diffusion models cannot generate short videos from text prompts.,Text-to-video pipeline using TextToVideoSDPipeline diffusion model,Contradicts provided code and description showing TextToVideoSDPipeline successfully produces frames and videos.,"generative-ai,diffusion,gans",7,Generative AI
101687,159,TRUE,Transformer-guided diffusion pipelines can generate short videos from natural language prompts.,TextToVideoSDPipeline text-to-video diffusion pipeline example,"Example code shows TextToVideoSDPipeline producing frames from prompts, demonstrating text-to-video synthesis.","generative-ai,diffusion,gans",7,Generative AI
101688,159,pants-fire,"The code can generate fully photorealistic, copyright-free feature films from any text prompt.",Text-to-video diffusion pipeline (TextToVideoSDPipeline) demo,"Claims extreme capability contradicts demo; pipeline produces short generated clips, not guaranteed photorealism or copyright-free feature films.","generative-ai,diffusion,gans",7,Generative AI
101689,46,half-true,The backward() call both computes gradients and immediately updates model weights in most deep learning frameworks.,"PyTorch training loop using optimizer.zero_grad, loss.backward, optimizer.step","Correctly says backward computes gradients, but incorrect that it also performs weight updates; optimizer.step does updates.","deep-learning,frameworks,tensors",5,Deep Learning
101690,46,FALSE,Calling loss.backward() updates the model's weights immediately.,"training loop with optimizer.zero_grad(), loss.backward(), optimizer.step()",Contradicts typical workflow: loss.backward() computes gradients but optimizer.step() updates weights.,"deep-learning,frameworks,tensors",5,Deep Learning
101691,46,mostly-true,Backpropagation computes gradients which optimizers use to update model weights after loss.backward().,"training loop using optimizer.zero_grad(), loss.backward(), and optimizer step","Directly described by code comments: zero gradients, compute loss, call loss.backward(), then update weights with optimizer.","deep-learning,frameworks,tensors",5,Deep Learning
101692,5,half-true,TensorFlow’s eager execution makes debugging as simple as using Python print and pdb.,eager execution and TensorFlow framework,"Correctly notes eager execution aids debugging, but overstates parity with all Python debugging simplicity.","deep-learning,frameworks,tensors",5,Deep Learning
101693,5,barely-true,The framework's eager execution makes debugging effortless with standard Python tools.,"eager execution model, debugging with print() and pdb","Overstates ease: passage praises intuitive design but only says eager execution makes debugging easy, not effortless.","deep-learning,frameworks,tensors",5,Deep Learning
101694,5,TRUE,PyTorch's eager execution model enables easy debugging with standard Python tools.,eager execution model; debugging with print() and pdb in PyTorch,Passage states eager execution runs immediately and simplifies debugging using print() and pdb.,"deep-learning,frameworks,tensors",5,Deep Learning
101695,55,mostly-true,A lightweight T5 fine-tuning setup can train on the merged LIAR dataset with modest GPU time.,fine-tuning T5 on merged LIAR dataset using Trainer and TrainingArguments,"Code and Colab note show T5 training finished in ~25 minutes with small batch/epochs, minor runtime variance.","mlops,scaling,deployment",10,AI At Scale
101696,55,FALSE,The T5 fine-tuning used a massive distributed cluster for training.,"training setup using T5, Trainer, and TrainingArguments","Passage describes a lightweight Colab setup with single-device batch size and short runtime, contradicting distributed cluster.","mlops,scaling,deployment",10,AI At Scale
101697,55,barely-true,"Using a tiny T5 model guarantees rapid, production-ready scaling for real-world deployments.",fine-tuning T5-small with Trainer and LIAR merged dataset,"Overstates results: passage shows lightweight, short training in Colab but not guaranteed rapid production scaling.","mlops,scaling,deployment",10,AI At Scale
101698,35,barely-true,AI judges like GPT-4 reliably score conversational relevance and clarity in model contests.,evaluation using GPT-4 as an AI judge in conversational scoring,Passage only says AI judges often score responses; claiming reliability overreaches without evidence.,"mlops,scaling,deployment",10,AI At Scale
101699,35,FALSE,Models always maintain perfect factual accuracy during follow-up twists.,model evaluation using GPT-4 judges for relevance,Contradicts passage which emphasizes models managing context and potential struggle during follow-up twists.,"mlops,scaling,deployment",10,AI At Scale
101700,35,FALSE,Models consistently fail to maintain context during follow-up twists in conversations.,model evaluation using GPT-4 judges for relevance,"Contradicts passage which describes judging of contextual handling, not consistent failures; judges evaluate performance variability.","mlops,scaling,deployment",10,AI At Scale
101701,28,TRUE,"The Steam Games Dataset contains metadata and user engagement metrics for over 85,000 games.","Steam Games Dataset from Steam API, Steam Spy, and Hugging Face","Passage explicitly lists metadata and engagement fields and states dataset covers over 85,000 games.","agentic-ai,planning,tools",12,Agentic AI
101702,28,mostly-true,Dataset abstraction lets developers query structured game data without manual cleaning or collection.,Steam Games Dataset from Steam API and Hugging Face,"Matches passage: abstraction enables processing Steam dataset directly, omitting minor data-quality caveats.","agentic-ai,planning,tools",12,Agentic AI
101703,28,half-true,"The Steam Games Dataset contains over 85,000 games with metadata and user engagement metrics.",dataset abstraction using the Steam Games Dataset from Steam API,"Accurate game count and fields listed, but omits provenance nuances and dataset maintenance details.","agentic-ai,planning,tools",12,Agentic AI
101704,32,TRUE,International organizations updated AI principles and frameworks in 2024 to strengthen rights protections.,OECD AI Principles and Council of Europe Framework Convention on AI,Describes OECD update and Council of Europe legally binding framework that enhance rights safeguards in 2024.,"ethics,governance,privacy",11,AI Ethics and Governance
101705,32,FALSE,OECD AI Principles legally bind signatory states to enforce AI rules across nations.,OECD AI Principles and Council of Europe Framework Convention on Artificial Intelligence,Contradicts detail: OECD principles are nonbinding; only Council of Europe framework introduces legal obligations.,"ethics,governance,privacy",11,AI Ethics and Governance
101706,32,FALSE,The OECD has never issued any AI principles or guidance documents.,OECD AI Principles and updates,Directly contradicts OECD issuance of AI Principles (2019) and 2024 update.,"ethics,governance,privacy",11,AI Ethics and Governance
101707,86,TRUE,Cluster 1 contains cosmic and mystical heavyweight characters like Darkseid and Anti-Monitor.,"cluster grouping of powered heroes, cosmic and mystical types","Passage explicitly lists Darkseid and Anti-Monitor as members of Cluster 1, indicating cosmic/mystical concentration.","machine-learning,classification,evaluation",4,Classical Machine Learning
101708,86,TRUE,Cluster 1 contains cosmic and mystical heavyweight heroes such as Darkseid and Anti-Monitor.,"clustering of superhero characters, cosmic and mystical types","Passage explicitly lists Darkseid and Anti-Monitor as members of Cluster 1, indicating cosmic/mystical concentration.","machine-learning,classification,evaluation",4,Classical Machine Learning
101709,86,FALSE,"Cluster 1 primarily contains everyday, low-powered heroes rather than cosmic or mystical heavyweights.",clustering of superheroes by power level and species,"Contradicts passage detail: Cluster 1 explicitly contains cosmic, mystical heavyweights like Darkseid and Anti-Monitor.","machine-learning,classification,evaluation",4,Classical Machine Learning
101710,28,FALSE,Data cleaning is unnecessary because modern models handle missing values automatically.,"data cleaning, missing values, model preprocessing",Contradicts passage: missing values and inconsistent formats confuse models and require cleaning.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
101711,28,mostly-true,"Thorough data cleaning usually improves model performance, though it often requires repeated effort.",dataset cleaning for model training and feature engineering,"Cleaning reduces missing values, outliers, and format inconsistencies, but is iterative rather than one-off.","data-prep,feature-engineering,rag",3,Prepping Data for AI
101712,28,half-true,Cleaning data once guarantees consistent model performance across datasets and formats.,"data cleaning for models, dataset preprocessing",Mixes true idea that cleaning helps with incorrect absolute claim that a single cleaning ensures consistent performance.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
101713,150,FALSE,The model uses stochastic gradient descent to update parameters during training.,optimizer usage with Adam and CrossEntropyLoss,"Contradicts explicit code: optimizer is Adam, not SGD, so update rule assumption is false.","deep-learning,frameworks,tensors",5,Deep Learning
101714,150,barely-true,The code trains a PyTorch model for five epochs using Adam and cross-entropy.,training loop using optimizer Adam and nn.CrossEntropyLoss,"Partially supported: code shows Adam and CrossEntropyLoss and five-epoch loop, but omits dataset preprocessing and model details, overstating completeness.","deep-learning,frameworks,tensors",5,Deep Learning
101715,150,mostly-true,The example trains a PyTorch model using Adam optimizer and cross-entropy loss for classification.,training loop with optim.Adam and nn.CrossEntropyLoss in PyTorch,"Code shows optimizer = optim.Adam and criterion = nn.CrossEntropyLoss, consistent with classification training.","deep-learning,frameworks,tensors",5,Deep Learning
101716,139,FALSE,Agentic AI in healthcare never adjusts device behavior without clinician approval.,AI-enabled inhalers and wearable monitors responding autonomously,Contradicts passage which says devices can automatically respond without manual or clinician input.,"agentic-ai,planning,tools",12,Agentic AI
101717,139,half-true,Agentic AI wearable monitors can autonomously change medication dosages without clinician oversight.,AI-enabled wearable monitors and smart medical devices,Passage supports autonomous alerts/recommendations but not autonomous medication dosing or bypassing clinicians.,"agentic-ai,planning,tools",12,Agentic AI
101718,139,barely-true,Agentic AI devices autonomously manage patient care decisions without clinician oversight.,AI-enabled inhalers and wearable monitors in healthcare applications,"Overstates autonomy: passage describes alerts and recommendations, not fully autonomous clinical decisions.","agentic-ai,planning,tools",12,Agentic AI
101719,19,TRUE,Neural network biases let neurons activate even when all inputs are zero.,bias term in neural network neuron,"Passage explicitly explains bias allows neuron activation with zero inputs, aiding fit to complex patterns.","deep-learning,frameworks,tensors",5,Deep Learning
101720,19,TRUE,Neural network biases enable neurons to activate even when all inputs are zero.,neuron bias in deep-learning activation functions,"Directly supported by passage describing bias as a small adjustment allowing activation with zero inputs, aiding model flexibility.","deep-learning,frameworks,tensors",5,Deep Learning
101721,19,mostly-true,"Neural network biases let neurons activate without input, aiding model flexibility and pattern fitting.",neuron bias and activation function in deep learning,Explains bias enabling activation at zero input and improved fitting; omits nuance about regularization and optimization effects.,"deep-learning,frameworks,tensors",5,Deep Learning
101722,132,half-true,Batching significantly improves throughput but can introduce latency trade-offs for longer inputs.,inference batching and GPU acceleration,"Accurately mixes correct benefit of batching with omitted latency costs for long inputs, matching passage nuance.","mlops,scaling,deployment",10,AI At Scale
101723,132,TRUE,Batching significantly improves throughput for deployed models by leveraging GPU acceleration.,batching and GPU acceleration in deployment scaling,"Passage states batching is a clean lever and GPU acceleration pays off, improving throughput during deployment.","mlops,scaling,deployment",10,AI At Scale
101724,132,FALSE,Scaling primarily requires retraining models rather than system-level changes.,scaling and batching in deployment and GPU acceleration,"Contradicts passage detail that much scaling happens outside the model, not via retraining.","mlops,scaling,deployment",10,AI At Scale
101725,170,half-true,A batch size of 1000 lets the test set be evaluated in ten exact batches without shuffling.,evaluation phase with DataLoader batch size and shuffle flag,"Partly correct about batch partitioning and not needing shuffle for accuracy, but assumes test size equals 10,000 and ignores edge cases or padding.","deep-learning,frameworks,tensors",5,Deep Learning
101726,170,mostly-true,Evaluating the test set with a batch size of 1000 processes it in exactly 10 fast batches.,test set evaluation; DataLoader batch size,Passage states 1000-batch size yields ten evaluation batches and speeds evaluation; minor caveat about dataset size assumptions omitted.,"deep-learning,frameworks,tensors",5,Deep Learning
101727,170,TRUE,Using batch size 1000 evaluates the entire test set in exactly 10 batches.,evaluation of test set with batch size 1000,"Passage explicitly states 1000 batch size yields exactly 10 test-set batches, enabling fast evaluation.","deep-learning,frameworks,tensors",5,Deep Learning
101728,149,FALSE,FLAN-T5 cannot follow natural language prompts or generate coherent responses.,flan-t5-large model and tokenizer from Hugging Face Transformers,"Contradicts passage claim that FLAN-T5 is instruction-tuned to follow prompts and generate coherent, context-aware responses.","generative-ai,diffusion,gans",7,Generative AI
101729,149,barely-true,FLAN-T5 is a diffusion model primarily used for image synthesis tasks.,model type confusion: FLAN-T5 vs diffusion models,"Mismatch with passage: FLAN-T5 is an instruction-tuned text model, not a diffusion image model.","generative-ai,diffusion,gans",7,Generative AI
101730,149,barely-true,FLAN-T5-large is specifically optimized for diffusion-based image generation tasks.,model use and tokenizer from Hugging Face Transformers,"Contradicts passage: FLAN-T5 is an instruction-tuned text model, not a diffusion image generator.","generative-ai,diffusion,gans",7,Generative AI
101731,85,mostly-true,Silhouette score around 0.446 indicates reasonably coherent but not sharply separated clusters.,silhouette score for clustering on dataset with Humans and Mutants,Score value supports moderate cohesion; omits that clusters aren't razor sharp and cluster composition details.,"machine-learning,classification,evaluation",4,Classical Machine Learning
101732,85,half-true,Cluster 0 predominantly contains Humans and Mutants but also includes several non-mutant characters.,silhouette score and cluster 0 composition,"Correctly notes Humans and Mutants dominate cluster 0, but overstates inclusion of non-mutants without listing examples.","machine-learning,classification,evaluation",4,Classical Machine Learning
101733,85,TRUE,The clustering produced a moderate silhouette score indicating reasonably distinct clusters.,silhouette score of 0.446 for clusters,"Silhouette 0.446 described as mid-range, implying clusters are not razor sharp but show real structure.","machine-learning,classification,evaluation",4,Classical Machine Learning
101734,15,half-true,Clément claims open-source tools make responsible AI development universally accessible like GitHub did for software.,open-source tools and infrastructure for machine learning,"Accurately echoes mission but overstates universality and parity with GitHub's historical impact, mixing correct intent with an exaggerated outcome.","open-source,community,ai",0,Foreword – Robo Interviews Clément Delangue
101735,15,pants-fire,The passage claims the project secretly outlawed open-source AI contributions worldwide.,"democratize machine learning, GitHub comparison, open-source",Directly contradicts quote about democratizing access; no mention of banning or outlawing contributions.,"open-source,community,ai",0,Foreword – Robo Interviews Clément Delangue
101736,15,FALSE,Robo claims the project restricts machine learning access to large corporations only.,goal to democratize machine learning; GitHub analogy; infrastructure,"Directly contradicts passage's emphasis on broad accessibility for researchers, startups, and companies.","open-source,community,ai",0,Foreword – Robo Interviews Clément Delangue
101737,107,barely-true,Cross-entropy loss always guarantees improved real-world digit recognition performance after training.,cross-entropy loss for digit recognition,Overreaches: passage explains training signal and class selection but not guaranteed real-world performance.,"deep-learning,frameworks,tensors",5,Deep Learning
101738,107,barely-true,Cross-entropy loss always guarantees improved predictive performance for digit recognition models.,cross-entropy loss for digit recognition (0–9),"Overreaches: passage says smaller cross-entropy correlates with better performance and guides training, but doesn't guarantee improved performance in all cases.","deep-learning,frameworks,tensors",5,Deep Learning
101739,107,mostly-true,Cross-entropy loss generally improves classification models by penalizing confident wrong predictions.,cross-entropy loss for digit recognition,Aligns with passage: penalizes confident wrong predictions and rewards high probability for correct classes.,"deep-learning,frameworks,tensors",5,Deep Learning
101740,186,half-true,RAG can replace model training for delivering in-depth reasoning on timely datasets.,RAG and composite features in data-prep workflows,Correct that RAG helps timely info but incorrect to claim it replaces training or deep reasoning capabilities.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
101741,186,TRUE,RAG aids timely information retrieval but cannot substitute model training for deep reasoning.,RAG in retrieval-augmented generation for data preparation,Passage explicitly says RAG conveys timely information yet should not replace training for in-depth reasoning.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
101742,186,barely-true,RAG can fully replace model training for deep reasoning in production systems.,RAG and training in generative AI-assisted data prep,Overreaches beyond passage caution that RAG doesn't replace training and lacks in-depth reasoning.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
101743,115,barely-true,Forty PCA components always optimize accuracy for classification models on powers dataset.,40 principal components (PCA) from powers dataset,Overreaches beyond evidence: passage reports 40 worked well in tests but not that it always optimizes accuracy.,"machine-learning,classification,evaluation",4,Classical Machine Learning
101744,115,TRUE,Adding about 40 PCA components from the powers dataset improved predictive performance while avoiding overfitting.,40 principal components from the powers dataset (PCA),"Passage states ~40 components balanced retained detail and avoided overfitting, with accuracy dipping beyond.","machine-learning,classification,evaluation",4,Classical Machine Learning
101745,115,FALSE,Adding 40 PCA components always prevents overfitting in classification models.,40 principal components from the powers dataset,"Contradicts passage which states 40 was a balance point but overfitting still occurs beyond it, not guaranteed prevention.","machine-learning,classification,evaluation",4,Classical Machine Learning
101746,138,barely-true,Agentic AI autonomously rebalances financial portfolios solely based on live market data.,fintech example with agents rebalancing portfolios,Overstates autonomy and exclusivity; passage mentions human oversight and multiple signals like credit exposure or events.,"agentic-ai,planning,tools",12,Agentic AI
101747,138,half-true,Agentic AI can autonomously rebalance fintech portfolios using live market data with occasional human oversight.,fintech deployment of agents monitoring live market data,Passage describes portfolio rebalancing by agents but omits implementation limits and risk details.,"agentic-ai,planning,tools",12,Agentic AI
101748,138,TRUE,Agentic AI can rebalance financial portfolios using live market data while allowing human oversight.,fintech example with live market data and portfolio rebalancing,Passage explicitly describes agents rebalancing portfolios from live market data and retaining human oversight.,"agentic-ai,planning,tools",12,Agentic AI
101749,34,mostly-true,Cosine similarity is commonly used to compare feature vectors by measuring directional alignment.,"vectors, dot products, cosine similarity in feature comparison",Explains cosine similarity refines dot products for direction-based comparison; omits edge cases like magnitude-sensitive tasks.,"ai,tool-chain,notebooks",2,AI Survival Kit
101750,34,FALSE,Cosine similarity measures vector magnitude rather than direction.,similarity measure for vectors and dot products,"Contradicts passage: cosine similarity accounts for direction, not magnitude, opposite claim is false.","ai,tool-chain,notebooks",2,AI Survival Kit
101751,34,mostly-true,Cosine similarity refines dot-product comparisons by focusing on vector direction rather than magnitude.,"vectors and dot products, cosine similarity in feature comparison",Accurately describes relationship to dot product and use for comparing feature alignment; minor implementation details omitted.,"ai,tool-chain,notebooks",2,AI Survival Kit
101752,42,pants-fire,A single short clip is sufficient to reliably clone Jerry's voice for deployment.,voice-cloning dataset size and voice fingerprint features,Passage requires ten clips minimum and recommends 20+; claim contradicts required sample counts.,"media-forensics,voice-cloning,deepfake",9,Deepfake Defense
101753,42,barely-true,Ten audio clips per speaker are sufficient for reliable voice-cloning recognition in practice.,dataset size for voice fingerprinting,"Passage says ten stabilized demo performance but recommends 20+ clips for real applications, so claim overreaches.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
101754,42,half-true,Using ten voice clips per speaker provides minimally stable recognition but is not sufficient for robust real-world use.,voice cloning dataset size (ten vs. twenty+ clips),Passage says ten clips stabilized performance for demonstration but recommends 20+ varied clips for reliable real-world models.,"media-forensics,voice-cloning,deepfake",9,Deepfake Defense
101755,17,mostly-true,AI models like SpeechT5 and Whisper can detect and analyze audio deepfakes with high effectiveness in many cases.,"audio analysis using SpeechT5, Whisper, and other models","Broadly supported by passage mentioning those models for audio analysis and defense, though effectiveness caveats omitted.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
101756,17,mostly-true,AI models like SpeechT5 and Whisper can analyze audio to detect and defend against deepfakes.,"audio analysis using SpeechT5, Whisper, and multimedia models","Passage links SpeechT5 and Whisper to audio analysis and defense, omitting specific defense accuracy or methods.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
101757,17,half-true,AI models like SpeechT5 and Whisper can both analyze and defend against manipulated audio.,audio analysis using SpeechT5 and Whisper models,Mixes correct tools and tasks with overreach; passage mentions use and defense but not explicit defense capabilities.,"media-forensics,voice-cloning,deepfake",9,Deepfake Defense
101758,188,barely-true,The forward pass only performs a network 'guess' without affecting model parameters during training.,forward pass in deep-learning model output computation,"Mostly accurate but overreaches: forward pass doesn't update parameters, yet contributes to gradients used in training.","deep-learning,frameworks,tensors",5,Deep Learning
101759,188,FALSE,A forward pass runs the model on input data to generate predictions for learning.,training loop forward pass (output = model(data)),"Contradicts passage by claiming purpose is 'for learning'; forward pass only produces predictions, learning requires backward/update steps.","deep-learning,frameworks,tensors",5,Deep Learning
101760,188,half-true,The forward pass applies model(data) to produce predictions without updating tensor gradients.,training loop forward pass using model(data) and loss,"Correct that model(data) produces predictions, but gradients are tracked unless disabled (e.g., no_grad).","deep-learning,frameworks,tensors",5,Deep Learning
101761,99,TRUE,Embedded AI models enable personalized product and content recommendations in consumer apps.,embedded AI in e-commerce and streaming platforms (recommendation models),Passage explicitly describes embedded AI delivering tailored recommendations for platforms like Amazon and Netflix.,"ai,tool-chain,notebooks",2,AI Survival Kit
101762,99,half-true,Embedded AI in apps always yields significantly higher user engagement and retention.,embedded AI in e-commerce and streaming recommendation systems,"Mixes true claim about recommendations with absolute word 'always' and unspecified effect sizes, overstating consistency.","ai,tool-chain,notebooks",2,AI Survival Kit
101763,99,barely-true,Embedded AI in apps guarantees users will never consider non-AI experiences again.,"embedded AI in apps, personalized recommendations",Overreaches passage claim: passage suggests growing adoption and influence but not a guarantee users will abandon non-AI experiences.,"ai,tool-chain,notebooks",2,AI Survival Kit
101764,9,FALSE,He accepted a job at Google immediately after graduating and never founded any startups.,"biography: UniShared, Stanford Engineering Everywhere, Moodstocks","Passage states he declined Google and pursued entrepreneurship, contradicting the accepted-job claim.","open-source,community,ai",0,Foreword – Robo Interviews Clément Delangue
101765,9,mostly-true,Delangue helped create UniShared to broaden access to shared student notes and learning resources.,platform UniShared for collaborative note sharing,"Supported by passage: guest lecture inspired UniShared to democratize education, minor operational details omitted.","open-source,community,ai",0,Foreword – Robo Interviews Clément Delangue
101766,9,barely-true,He founded UniShared to make global student note-sharing widely accessible.,platform UniShared for collaborative learning and note-sharing,Passage mentions inspiration and development of UniShared but gives no proof he founded or scaled it widely.,"open-source,community,ai",0,Foreword – Robo Interviews Clément Delangue
101767,110,half-true,Automatic differentiation records every operation and always computes exact gradients for all neural network parameters.,automatic differentiation in deep learning backpropagation,"Correct that AD records operations and uses chain rule, but claim of always exact gradients ignores numerical errors and implementation limits.","deep-learning,frameworks,tensors",5,Deep Learning
101768,110,mostly-true,Automatic differentiation records operations and computes exact gradients through backpropagation for neural networks.,automatic differentiation in deep learning backpropagation,Describes recorded forward operations and chain-rule backpropagation; omits limited numerical precision caveat.,"deep-learning,frameworks,tensors",5,Deep Learning
101769,110,TRUE,Automatic differentiation records forward operations and computes exact gradients during backpropagation.,"automatic differentiation, forward pass, backpropagation, weights and biases",Directly supported: passage describes recording operations during forward pass and using chain rule backward to compute parameter gradients exactly.,"deep-learning,frameworks,tensors",5,Deep Learning
101770,58,TRUE,Interdisciplinary collaboration prompted consideration of AI's broader societal impacts.,"interdisciplinarity involving poets, filmmakers, scientists",Directly supported by passage: diverse participants led speaker to consider broader impact beyond technical work.,"ethics,governance,privacy",11,AI Ethics and Governance
101771,58,pants-fire,AI research group unanimously agreed to halt all experiments and shut down models immediately.,"interdisciplinarity discussion among poets, filmmakers, scientists","Contradicts passage: conversation emphasizes broad impact reflection, not any halt, shutdown, or unanimous decision.","ethics,governance,privacy",11,AI Ethics and Governance
101772,58,barely-true,Interdisciplinary workshops always produce clear policy prescriptions for AI governance and privacy.,interdisciplinarity workshops with scientists and filmmakers,Overreaches: passage mentions broad impact discussions but not concrete policy or privacy prescriptions.,"ethics,governance,privacy",11,AI Ethics and Governance
101773,5,FALSE,She claimed to have read Clément Delangue's model card and ranked his dataset highest.,open-source model card and dataset mention,"Contradicts passage: passage quotes reading model card and ranking, but not claiming she ranked the dataset herself.","open-source,community,ai",0,Foreword – Robo Interviews Clément Delangue
101774,5,mostly-true,She is built on open-source software and has read Clément Delangue's model card.,open-source software; model card mention,Passage directly states she was built on open-source software and read his model card; minor nuance about ranking omitted.,"open-source,community,ai",0,Foreword – Robo Interviews Clément Delangue
101775,5,barely-true,She inaccurately claimed Clément's model is ranked top of her dataset despite limited evidence.,interview quote referencing a model card and dataset ranking,"Claim overreaches: passage only shows her boastful quote, not independent ranking or evidence.","open-source,community,ai",0,Foreword – Robo Interviews Clément Delangue
101776,110,FALSE,Deepfake detectors are guaranteed to identify every manipulated frame in videos.,object detection and sample video (Jerry-Jose-SampleVideo01.mp4),"Contradicts passage: object detection labels items, not claimed perfect deepfake detection; assumption of guaranteed identification is false.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
101777,110,mostly-true,Object detection enables AI to identify and label specific items in video frames for analytics and moderation.,object detection applied to video frames (dataset: Jerry-Jose-SampleVideo01.mp4),"Accurately reflects passage description of object detection powering video analytics and content moderation, omitting minor implementation caveats.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
101778,110,barely-true,Object detection labels items in video frames for surveillance and moderation tasks.,object detection applied to video frames (dataset: Jerry-Jose-SampleVideo01.mp4),Overstated scope: passage mentions object detection enabling such applications but gives no evidence it performs these tasks in practice.,"media-forensics,voice-cloning,deepfake",9,Deepfake Defense
101779,0,FALSE,Agentic AIs always choose to initiate global thermonuclear war when given simulation control.,AI agent behavior in game simulations like WarGames,Contradicts example: Joshua concluded not to play rather than initiating war; overgeneralizes agent behavior.,"agentic-ai,planning,tools",12,Agentic AI
101780,0,FALSE,The AI in WarGames concluded that automated play always guarantees victory.,AI agent example: Joshua from WarGames,"Contradicts passage detail: Joshua concluded 'not to play', not that automation ensures victory.","agentic-ai,planning,tools",12,Agentic AI
101781,0,FALSE,The passage claims agents always avoid risky actions by refusing to play games.,"agentic AI, planning, games and simulation","Contradicts passage: Joshua concluded not to play in that story, but passage presents games as AI testbeds, not a universal agent behavior.","agentic-ai,planning,tools",12,Agentic AI
101782,58,half-true,The function standardizes model calls but misleadingly implies complete control over agentic planning behavior.,LangChain prompt templates and model abstraction example,"Example correctly shows model, max_tokens, temperature parameters but overstates full control of agentic planning.","agentic-ai,planning,tools",12,Agentic AI
101783,58,barely-true,Agentic systems can fully automate multi-step planning by autonomously composing tools and prompts.,agentic AI planning with tools and prompt templates,Overstates capability: passage describes abstractions and control but not full autonomous multi-step tool composition.,"agentic-ai,planning,tools",12,Agentic AI
101784,58,barely-true,The function guarantees identical outputs across different AI models for the same prompts.,LangChain model abstraction and prompt templates,"Overreaches: abstraction standardizes interface but passage only claims consistent interfacing, not identical outputs.","agentic-ai,planning,tools",12,Agentic AI
101785,27,barely-true,AI will single-handedly discover new drugs within a year.,impact on scientific research and drug discovery,"Overreaches passage optimism about drug discovery timelines; unsupported rapid, single-actor claim.","open-source,community,ai",0,Foreword – Robo Interviews Clément Delangue
101786,27,barely-true,AI will revolutionize drug discovery and transform media production within a few years.,"impact on scientific research and media production (drug discovery, books, interviews)",Overstates timing and certainty; passage predicts breakthroughs but hedges with maybe and general claims.,"open-source,community,ai",0,Foreword – Robo Interviews Clément Delangue
101787,27,pants-fire,AI will immediately replace all human researchers and authors worldwide within months.,"claims about breakthroughs in biology, chemistry, books, and interviews","Passage predicts gradual breakthroughs and media shifts, not instant global replacement; immediate total takeover contradicts those specifics.","open-source,community,ai",0,Foreword – Robo Interviews Clément Delangue
101788,109,mostly-true,"Diffusion models generally produce higher-resolution, more stable images than GANs.",comparison of diffusion models and GANs in image generation,Passage states diffusion models yield high-resolution outputs and are more stable and less prone to artifacts than adversarial GAN approaches.,"generative-ai,diffusion,gans",7,Generative AI
101789,109,barely-true,"Diffusion models always produce higher-resolution, artifact-free images than GANs.",comparison between diffusion models and GANs in generative image modeling,"Overstates claim: passage says diffusion models are often more stable, not always superior in resolution or artifacts.","generative-ai,diffusion,gans",7,Generative AI
101790,166,half-true,Anonymized small clinical datasets often remain fully re-identifiable using public records.,anonymization risks for rare medical datasets,Accurately notes re-identification risk for rare/small datasets but overstates 'fully' without nuance about mitigation or aggregation thresholds.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
101791,166,TRUE,Anonymized small datasets can still enable re-identification of individuals.,privacy protections for rare medical or regional datasets,"Passage explains small or rare datasets, like specific diagnoses, can be linked to individuals despite anonymization.","data-prep,feature-engineering,rag",3,Prepping Data for AI
101792,166,barely-true,Anonymized small datasets are usually safe from re-identification without extra protections.,"privacy of anonymized dataset records, sample size and aggregation",Overreaches given passage warns small or rare records can still be re-identified using public information.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
101793,8,mostly-true,Jupyter Notebooks help users transition prototypes to production by enabling interactive development.,"tool: Jupyter Notebooks, interactive coding and visualizations","Passage says Jupyter enables interactive code/text/visualization and aids smooth movement from prototype to production, omitting specific production workflows.","ai,tool-chain,notebooks",2,AI Survival Kit
101794,8,half-true,Jupyter Notebooks ensure smooth production deployment of AI projects across toolchains.,Jupyter Notebooks interactive tool from Jupyter.org,Accurately notes Jupyter's interactivity but wrongly implies it guarantees smooth production deployment and tool-chain integration.,"ai,tool-chain,notebooks",2,AI Survival Kit
101795,8,barely-true,Jupyter Notebooks guarantee effortless transition from prototype to production for all AI projects.,tool: Jupyter Notebooks in AI tool-chain and notebooks,Overreaches: passage says Jupyter aids interactive development but not that it guarantees seamless production deployment.,"ai,tool-chain,notebooks",2,AI Survival Kit
101796,46,FALSE,The prompt template prevents users from specifying trivia categories or questions dynamically.,ChatPromptTemplate variable_prompt using {trivia_category} and {trivia_question},Contradicts provided example showing variables {trivia_category} and {trivia_question} enable dynamic user-specified trivia inputs.,"agentic-ai,planning,tools",12,Agentic AI
101797,46,barely-true,"The template guarantees accurate, concise trivia answers across all user-provided categories.",ChatPromptTemplate with variables for trivia_category and trivia_question,Overstates capabilities: template enables flexible prompts but doesn't ensure accuracy or consistent brevity.,"agentic-ai,planning,tools",12,Agentic AI
101798,46,half-true,Variable prompt templates let AI adapt responses to user-selected trivia categories and questions.,prompt template with variables like {trivia_category} and {trivia_question},Accurately mixes correct claim about variables enabling adaptability with omitted limits on response quality or safety.,"agentic-ai,planning,tools",12,Agentic AI
101799,19,FALSE,Mature open-source projects always lack clear onboarding and informal processes.,project scope and onboarding in open-source projects,Contradicts passage detail that mature projects often have clearer onboarding and more formal processes.,"open-source,community,contribution",13,Commit to Contribute
101800,19,FALSE,Only mature projects on GitHub need contributors and have onboarding processes.,GitHub Topics discovery for open-source AI projects,"Passage states newer projects often need more help and may lack structure, contradicting claim.","open-source,community,contribution",13,Commit to Contribute
101801,19,FALSE,Mature open-source projects never provide clearer onboarding or formal processes for contributors.,"project scope and activity, GitHub Topics like #openai and #llm",Contradicts passage detail that mature projects often have clearer onboarding and formal processes.,"open-source,community,contribution",13,Commit to Contribute
101802,22,TRUE,High-quality data preparation is essential for reliable AI model performance.,data preparation and datasets for AI models,Passage emphasizes data as fuel and states preparation is a key foundation for AI reliability.,"ai,tool-chain,notebooks",2,AI Survival Kit
101803,22,mostly-true,Data preparation is a critical foundation for building reliable AI models.,data preparation and training datasets,Passage emphasizes data as model fuel and states preparation is among the most important foundations.,"ai,tool-chain,notebooks",2,AI Survival Kit
101804,130,FALSE,Transformers cannot model long-range dependencies and only capture local context.,"transformers, sequence modeling, long-range dependencies",Contradicts passage detail that transformers capture global context and long-range dependencies.,"generative-ai,diffusion,gans",7,Generative AI
101805,130,barely-true,"Transformers replaced all prior models across vision, audio, and biology without exception.","transformers applied to vision, audio, biology","Overreaches: passage says transformers expanded into those domains, not that they universally replaced all prior models.","generative-ai,diffusion,gans",7,Generative AI
101806,130,TRUE,Transformers excel at capturing global context and long-range dependencies across modalities.,"transformers applied to vision, audio, biology, and video generation",Passage explicitly states transformers capture global context and long-range dependencies across multiple modalities.,"generative-ai,diffusion,gans",7,Generative AI
101807,95,barely-true,The VAE decoder perfectly reconstructs complex 3D meshes from small latent vectors every time.,VAE decoder reconstructing flattened mesh vertices from latent_dim,"Overreaches beyond passage: architecture suits small datasets but perfect, consistent reconstruction of complex 3D meshes is unsupported.","generative-ai,diffusion,gans",7,Generative AI
101808,95,mostly-true,The VAE uses a reparameterization trick enabling gradient-flow through stochastic sampling.,"VAE reparameterize function in model code (mu, logvar, torch.randn_like)","Reparameterize implementation (std from logvar) preserves gradients while sampling, matching explanation.","generative-ai,diffusion,gans",7,Generative AI
101809,95,TRUE,The VAE uses a reparameterization trick to allow gradient flow during sampling.,VAE reparameterize function for mu and logvar in latent sampling,Passage explicitly describes the reparameterize implementation and states it preserves gradients for backpropagation.,"generative-ai,diffusion,gans",7,Generative AI
101810,103,mostly-true,Composite scores simplify comparisons but obscure important feature-level differences in datasets.,feature-engineering trade-offs with composite scores,"Supports passage point that composite metrics compress details, omitting distinctions like durability versus regeneration.","data-prep,feature-engineering,rag",3,Prepping Data for AI
101811,103,barely-true,Composite scores obscure meaningful differences like durability versus regeneration in dataset evaluations.,feature engineering for dataset evaluation with composite scores,Overreaches by implying datasets always lose key distinctions; passage notes common trade-off but not inevitability.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
101812,103,barely-true,Composite scores obscure important distinctions like durability versus regeneration in evaluation metrics.,feature-engineering for dataset composite scoring,"Partly aligns with passage but overstates generality; passage notes trade-off, not universal obscuring.","data-prep,feature-engineering,rag",3,Prepping Data for AI
101813,173,mostly-true,"Feature engineering and controlled decryption enable private, usable datasets for retrieval-augmented generation.",RAG workflow using encrypted dataset and controlled access,"Passage shows encrypted data being decrypted for authorized access, supporting RAG data prep but omits feature-engineering specifics.","data-prep,feature-engineering,rag",3,Prepping Data for AI
101814,173,mostly-true,"Encrypted data is displayed and then decrypted to demonstrate controlled, authorized access to sensitive information.",data encryption and decryption demonstrating controlled access to decrypted data,Describes program flow shown in passage; omits implementation caveats and security details.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
101815,173,mostly-true,Encrypted dataset snippets are decrypted and accessed only by authorized users during processing.,data encryption and controlled data access in dataset handling,"Passage shows partial encryption, decryption, and restricted access, omitting implementation details.","data-prep,feature-engineering,rag",3,Prepping Data for AI
101816,46,FALSE,Label encoding assigns sequential integer values to categorical classes like words or binary responses.,"label encoding of categorical variables, e.g., class labels",Contradicts passage: passage gives examples but does not state encoding must be sequential integers; it only shows one possible assignment.,"machine-learning,classification,evaluation",4,Classical Machine Learning
101817,46,half-true,"Label encoding assigns simple integer values to categorical labels like cat, dog, and mouse.",label encoding for categorical variables in classification,Correct about using integers for categories but omits that integers imply ordinality and may mislead some models.,"machine-learning,classification,evaluation",4,Classical Machine Learning
101818,46,FALSE,Accuracy always fully captures classifier performance in all binary and multiclass tasks.,"metric accuracy for classification labels (e.g., binary yes/no, multiclass)","Contradicts passage: accuracy is described as simplest metric, not sufficient for all cases; it omits class imbalance and other shortcomings.","machine-learning,classification,evaluation",4,Classical Machine Learning
101819,63,half-true,PyTorch typically saves model parameters with state_dict but not the full architecture.,model checkpointing with state_dict in PyTorch,"Mixes correct practice (state_dict saves parameters) with omission that torch.save can store full model too, creating partial accuracy.","deep-learning,frameworks,tensors",5,Deep Learning
101820,63,pants-fire,PyTorch cannot save model parameters at all and only stores architectures.,model saving with state_dict in PyTorch,"Directly contradicts described saving: passage explains saving parameters via state_dict, not only architectures.","deep-learning,frameworks,tensors",5,Deep Learning
101821,63,TRUE,"PyTorch commonly saves model parameters using state_dict, requiring reconstructing the architecture before loading.",model saving and reloading with PyTorch state_dict,Directly supported: passage explains saving state_dict stores parameters and requires manual model reconstruction before load.,"deep-learning,frameworks,tensors",5,Deep Learning
101822,7,FALSE,Agentic AI systems cannot plan or use tools and always require human reprogramming.,agentic workflows planning and tools,"Directly contradicts passage claim that agents can plan, use tools, and adapt without constant reprogramming.","agentic-ai,planning,tools",12,Agentic AI
101823,7,half-true,"Agentic AI can fully replace human oversight by autonomously planning, reflecting, and using tools in all complex tasks.",agentic workflows and tool-using AI agents,"Mixes correct agent capabilities (planning, tool use) with incorrect claim of complete human oversight replacement.","agentic-ai,planning,tools",12,Agentic AI
101824,7,FALSE,Agentic AI never requires any human oversight during deployment.,agentic workflows and tool use in AI agents,"Contradicts passage emphasis on planning, reflection, tool usage and dynamic retrieval needing design and likely human oversight.","agentic-ai,planning,tools",12,Agentic AI
101825,109,half-true,"LangChain always guarantees simpler, more efficient model deployment than other frameworks.",tool: LangChain embedding and deployment workflow,"Accurate that LangChain aids deployment, but claim overstates guarantee and superiority without evidence.","ai,tool-chain,notebooks",2,AI Survival Kit
101826,109,mostly-true,LangChain simplifies embedding language models into applications and eases model deployment workflows.,tool: LangChain library for embedding and deployment,"Passage states LangChain facilitates embedding and makes deployment easier, minor enthusiasm omitted.","ai,tool-chain,notebooks",2,AI Survival Kit
101827,109,TRUE,LangChain is an open-source library that facilitates embedding language models into applications.,tool: LangChain embedding AI,Passage explicitly states LangChain is open-source and helps embed language models into real-world applications.,"ai,tool-chain,notebooks",2,AI Survival Kit
101828,84,FALSE,Silhouette scores always reach 1.0 for well-separated clusters in K-Means clustering.,silhouette_score metric for K-Means clustering,Silhouette ranges -1 to 1; claiming scores always reach 1.0 contradicts metric behavior and typical datasets.,"machine-learning,classification,evaluation",4,Classical Machine Learning
101829,84,TRUE,Silhouette score quantifies cluster cohesion and separation with values between -1 and 1.,silhouette_score metric for clustering evaluation,"Silhouette score definition given: measures within-cluster similarity versus other clusters, range -1 to 1.","machine-learning,classification,evaluation",4,Classical Machine Learning
101830,84,mostly-true,"Silhouette score generally indicates cluster tightness and separation, with higher values being better.",silhouette_score metric for K-Means clustering on PCA-transformed features,"Passage explains silhouette score ranges from -1 to 1 and higher values mean tighter, more separated clusters.","machine-learning,classification,evaluation",4,Classical Machine Learning
101831,50,half-true,Delangue advocates open-source model sharing but exaggerates global consensus and safety guarantees.,"open-source platform and model sharing (Hugging Face, collaboration)",Mixes accurate advocacy for openness and partnerships with overstated universal agreement and safety assurances.,"open-source,community,ai",0,Foreword – Robo Interviews Clément Delangue
101832,50,half-true,Delangue advocates open model sharing while overstating how quickly global collaboration can secure AI safety.,open-source model sharing and Hugging Face partnerships,"Supports call for openness and partnerships (Google Cloud, NVIDIA, IBM) but inflates timeline and certainty for achieving safety through collaboration.","open-source,community,ai",0,Foreword – Robo Interviews Clément Delangue
101833,50,FALSE,Delangue argued for keeping all AI models proprietary and closed-source to ensure safety.,Hugging Face open-source platform and partnerships,"Contradicts passage: Delangue advocates openness and model sharing, not proprietary closure.","open-source,community,ai",0,Foreword – Robo Interviews Clément Delangue
101834,67,half-true,"IBM uses generative AI in more constrained, controlled ways than open-ended chatbots.",use of generative AI at IBM; open-ended chatbots,"Mixes accurate contrast with unspecified specifics about how IBM constrains models, creating partial accuracy.","ethics,governance,privacy",11,AI Ethics and Governance
101835,67,mostly-true,IBM uses generative AI with stricter controls than open-ended general-purpose chatbots.,use of generative AI at IBM versus open-ended chatbots,"Passage contrasts IBM's controlled generative AI usage with flexible, harder-to-constrain open-ended chatbots.","ethics,governance,privacy",11,AI Ethics and Governance
101836,67,barely-true,IBM's generative AI is tightly controlled and avoids the risks of open-ended chatbots.,use of generative AI at IBM (open-ended AI systems),Overstates control; passage contrasts IBM use with open-ended risks but gives no specifics about controls or effectiveness.,"ethics,governance,privacy",11,AI Ethics and Governance
101837,164,barely-true,"Normalizing image pixels with transforms.Normalize((0.1307,), (0.3081,)) guarantees fast, stable training for massive datasets.",data handling and transforms.Normalize in deep-learning pipeline,"Overreaches claim: normalization helps stability, but cannot by itself guarantee speed or handle massive datasets.","deep-learning,frameworks,tensors",5,Deep Learning
101838,164,barely-true,Normalizing image pixels with torchvision.transforms is essential and always guarantees stable training.,normalizing image pixel values; transforms.Normalize in deep-learning pipelines,Overreaches: normalization helps stability but doesn't always guarantee stable training or fix dataset/model issues.,"deep-learning,frameworks,tensors",5,Deep Learning
101839,164,TRUE,Normalizing image pixel values using transforms.Normalize stabilizes and improves training efficiency.,"data management and transforms.Normalize((0.1307,), (0.3081,))","Normalization with specified mean and stddev is described as crucial for stable, efficient training.","deep-learning,frameworks,tensors",5,Deep Learning
101840,24,barely-true,Linear regression always gives reliable predictions for datasets with sharp curves and interactions.,linear regression model and coefficient interpretation,"Contradicts passage: assumes linearity and fails with sharp curves, outliers, or hidden interactions.","machine-learning,classification,evaluation",4,Classical Machine Learning
101841,24,TRUE,Linear regression provides interpretable coefficient-based explanations of input contributions.,linear regression coefficients (model interpretability),"Passage explicitly states coefficients can be examined to see each input's contribution, supporting interpretability.","machine-learning,classification,evaluation",4,Classical Machine Learning
101842,24,mostly-true,"Linear regression is generally easy to set up, fast to run, and provides interpretable coefficients.","linear regression model, coefficients, interpretability","Passage endorses ease, speed, and coefficient interpretability but omits linearity limitations.","machine-learning,classification,evaluation",4,Classical Machine Learning
101843,48,barely-true,Whisper reliably detects voice-clone deepfakes across diverse languages in forensic settings.,OpenAI Whisper automatic speech recognition model,Overreaches: Whisper transcribes and translates audio but lacks forensic detection or explicit voice-clone detection capabilities.,"media-forensics,voice-cloning,deepfake",9,Deepfake Defense
101844,48,TRUE,Whisper can transcribe speech and translate between languages with strong robustness to accents and noise.,OpenAI Whisper ASR model trained on multilingual multitask audio,"Training on hundreds of thousands of hours supports robustness to accents, background noise, transcription, and translation.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
101845,48,barely-true,Whisper reliably detects deepfake voice manipulations in all audio samples.,OpenAI Whisper ASR model used for transcription,Overreaches beyond passage: Whisper transcribes and translates speech but doesn't claim deepfake detection capability.,"media-forensics,voice-cloning,deepfake",9,Deepfake Defense
101846,6,half-true,CNNs always detect edges by scanning every 2×2 patch with fixed square filters.,CNN convolutional filters scanning 2×2 image patches,"Correct that CNNs scan patches and detect edges, but filter sizes vary and aren't always 2×2 fixed squares.","neural-networks,cnn,transformers",6,Neuron Building Blocks
101847,6,barely-true,CNNs scan images with a sliding square filter to detect edges in local patches.,2×2 sliding filter over satellite image in CNN early layers,"Overreaches by implying typical CNN filters are 2×2; passage uses 2×2 as illustrative, not general rule.","neural-networks,cnn,transformers",6,Neuron Building Blocks
101848,6,TRUE,CNN early layers detect edges by scanning image patches with learned filters.,feature detection in convolutional neural networks (CNNs),Passage explicitly says CNNs scan patches with filters and early layers look for edges.,"neural-networks,cnn,transformers",6,Neuron Building Blocks
101849,6,half-true,Clément Delangue advocated for open-source AI participation but credited company-led coordination for progress.,interview excerpt mentioning Robo and open-source AI participation,Mixes accurate advocacy for broad participation with incorrect emphasis on company-led coordination; passage credits shared 'behind-the-scenes' but not corporate leadership.,"open-source,community,ai",0,Foreword – Robo Interviews Clément Delangue
101850,6,barely-true,Clément Delangue promised specific open-source tools and datasets for community AI development.,interview excerpt mentioning AI participation and behind-the-scenes sharing,Passage only says they'll share 'behind-the-scenes' and invite participation; no specific tools or datasets promised.,"open-source,community,ai",0,Foreword – Robo Interviews Clément Delangue
101851,6,half-true,Clément Delangue invited community participation in an open-source AI project but promised limited technical details.,interview mentioning open-source and behind-the-scenes magic,Mixes correct encouragement of community participation with an incorrect claim that technical details would be limited.,"open-source,community,ai",0,Foreword – Robo Interviews Clément Delangue
101852,166,pants-fire,The passage claims non-training batches always require more GPU memory than training batches.,"batch size for non-training data, batch_size","Contradicts passage: it states non-training batch size is larger for evaluation, not that it always uses more GPU memory.","deep-learning,frameworks,tensors",5,Deep Learning
101853,166,half-true,A batch size of 64 is the ideal choice for all image network training tasks.,batch size for training data (batch_size=64),Mixes correct idea that 64 is common with overgeneralized claim; optimal size depends on memory and task.,"deep-learning,frameworks,tensors",5,Deep Learning
101854,166,TRUE,A training batch size of 64 balances memory use and training stability for image networks.,batch_size parameter for training data,Passage explicitly states batch_size=64 balances memory usage with stability during training.,"deep-learning,frameworks,tensors",5,Deep Learning
101855,56,TRUE,Each decision tree leaf node indicates a predicted species by color coding.,decision tree leaf nodes and species labels,"Passage describes leaf nodes representing predicted class and explicit colors for Cyborg, Mutant, and Human.","machine-learning,classification,evaluation",4,Classical Machine Learning
101856,56,mostly-true,Decision tree leaves correspond to predicted species using color-coded nodes.,classification decision tree with leaf colors for species,"Tree description matches passage: leaves represent predicted species and are color-coded, minor caveat about exact shades.","machine-learning,classification,evaluation",4,Classical Machine Learning
101857,56,TRUE,Each leaf node in the decision tree corresponds to a predicted species class.,decision tree leaf nodes and predicted species labels,"Directly supported: leaves represent predicted class and are colored for Cyborg, Mutant, Human.","machine-learning,classification,evaluation",4,Classical Machine Learning
101858,17,mostly-true,Open-source groups have broadly increased accessibility to generative AI foundation models.,"open-source initiatives and models like Hugging Face, GPT-Neo, and Stability AI","Passage lists multiple projects (Transformers, GPT-J, LLaMA, Stability) showing broad accessibility, omitting some caveats.","generative-ai,diffusion,gans",7,Generative AI
101859,17,FALSE,Stability AI's diffusion models are proprietary and closed-source.,open diffusion models (Stability AI),Contradicts passage stating Stability AI released open diffusion models; claim conflicts with named open-source initiative.,"generative-ai,diffusion,gans",7,Generative AI
101860,17,TRUE,Open-source groups have produced accessible foundation models and diffusion frameworks for generative AI.,"open diffusion models, Hugging Face Transformers, LLaMA, GPT-Neo","Passage lists Stability AI, Hugging Face, EleutherAI, Meta, and IBM releasing accessible open-source models and tools.","generative-ai,diffusion,gans",7,Generative AI
101861,125,barely-true,Most deep-learning frameworks automatically tune optimizers without any user intervention.,learning rate schedulers in frameworks like PyTorch and TensorFlow/Keras,Overstates claim: schedulers automate learning-rate changes but do not fully tune optimizers or remove all user configuration needs.,"deep-learning,frameworks,tensors",5,Deep Learning
101862,125,barely-true,Learning rate schedulers universally eliminate the need for any manual learning rate tuning.,learning rate schedulers in frameworks like PyTorch and TensorFlow,Overstates capability: schedulers assist but don't always replace manual tuning for specific models or tasks.,"deep-learning,frameworks,tensors",5,Deep Learning
101863,125,mostly-true,Most deep learning frameworks provide built-in learning rate schedulers for automated training adjustments.,learning rate schedulers in PyTorch and TensorFlow/Keras,"Passage names StepLR and LearningRateScheduler, stating most frameworks include built-in schedulers for stability and efficiency.","deep-learning,frameworks,tensors",5,Deep Learning
101864,33,barely-true,MT-Bench primarily evaluates models using fixed single-turn prompts rather than multi-turn dialogues.,evaluation dataset MT-Bench multi-turn dialogue prompts,Contradicts passage: MT-Bench explicitly uses multi-turn dialogues across categories like Reasoning and Coding.,"mlops,scaling,deployment",10,AI At Scale
101865,33,mostly-true,MT-Bench evaluates large language models using multi-turn dialogues across diverse conversational categories.,evaluation dataset MT-Bench for multi-turn conversational testing,"Describes MT-Bench's multi-turn, category-based evaluation accurately while omitting specifics like scoring methodology.","mlops,scaling,deployment",10,AI At Scale
101866,33,half-true,MT-Bench evaluates models using single-turn factual queries rather than multi-turn dialogues.,evaluation dataset MT-Bench for multi-turn dialogue testing,"Mixes correct tool name with incorrect test format; passage emphasizes multi-turn dialogues, not single-turn queries.","mlops,scaling,deployment",10,AI At Scale
101867,74,half-true,The open fan-maintained dataset is ideal for production RAG systems without further bias mitigation.,"dataset from an open, fan-maintained source for RAG","Mixes correct fact (open, fan-maintained dataset) with incorrect implication (not ideal for production without bias mitigation).","data-prep,feature-engineering,rag",3,Prepping Data for AI
101868,74,TRUE,The dataset reflects contributors' assumptions and potential biases.,"open, fan-maintained dataset for practice","Passage explicitly notes the dataset reflects contributors' assumptions and biases, supporting relevance concerns.","data-prep,feature-engineering,rag",3,Prepping Data for AI
101869,74,FALSE,The dataset is a proprietary commercial collection curated by experts.,"open, fan-maintained dataset",Contradicts passage detail that dataset is open and fan-maintained rather than proprietary or expert-curated.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
101870,133,mostly-true,The tuned HistGradientBoostingClassifier achieved about 84% accuracy on the test set.,model evaluation using accuracy and macro-F1 for HistGradientBoostingClassifier,"Passage reports ~84% accuracy after tuning learning_rate, max_depth, and l2_regularization; minor caveat of dataset size not stated.","machine-learning,classification,evaluation",4,Classical Machine Learning
101871,133,mostly-true,"Tuning learning rate, max depth, and L2 regularization yields an approximately 84% accuracy for the boosted classifier.",HistGradientBoostingClassifier tuning with accuracy and macro-F1 evaluation,"Passage reports those three hyperparameters were tuned and states the classifier achieved about 84% accuracy, minor caveat: exact dataset details omitted.","machine-learning,classification,evaluation",4,Classical Machine Learning
101872,133,barely-true,"Tuned learning rate, tree depth, and L2 produced approximately 84% accuracy on the test set.",HistGradientBoostingClassifier model evaluation with accuracy and macro-F1,"Passage claims 84% accuracy from those hyperparameters but provides no variability, significance, or full evaluation details.","machine-learning,classification,evaluation",4,Classical Machine Learning
101873,40,half-true,Clément Delangue promotes building open generative AI collaboratively to foster responsible understanding.,open collaboration and generative tools in Hugging Face,"Accurately notes advocacy for open, collaborative building but omits nuance about concerns over normalizing synthetic content.","open-source,community,ai",0,Foreword – Robo Interviews Clément Delangue
101874,40,mostly-true,Clément Delangue advocates building and using generative AI openly to foster responsible understanding and norms.,"open collaboration and generative tools (Hugging Face, building AI)","Passage endorses open, careful collaboration and cites Delangue and Hugging Face as exemplars; minor nuance about opposing views omitted.","open-source,community,ai",0,Foreword – Robo Interviews Clément Delangue
101875,40,FALSE,Clément Delangue argues that generative AI should be developed privately with closed datasets.,advocacy for open collaboration and building with generative tools,Contradicts passage mentioning open collaboration and building with tools openly and carefully.,"open-source,community,ai",0,Foreword – Robo Interviews Clément Delangue
101876,9,pants-fire,Jupyter is obsolete and unusable for AI experimentation and development.,comparison between Jupyter and Google Colab in AI tool-chain,"Contradicts passage claiming Jupyter is practical, reliable, and useful for rapid AI experimentation.","ai,tool-chain,notebooks",2,AI Survival Kit
101877,9,mostly-true,"Jupyter provides a practical, reliable environment for building and testing AI projects.",interactive notebooks and Google Colab mention,"Passage endorses Jupyter for rapid AI experimentation and an expanding community, minor caveat about using Colab.","ai,tool-chain,notebooks",2,AI Survival Kit
101878,12,TRUE,Foundation models are large pre-trained neural networks used as backbones for many generative AI applications.,foundation models; pre-trained neural networks and fine-tuning,"Directly stated: models are massive, pre-trained on broad datasets and serve as backbones for Gen AI.","generative-ai,diffusion,gans",7,Generative AI
101879,12,pants-fire,Foundation models are secretly controlled by a global cartel that rigs all AI outputs.,control and centralization of foundation models,Assertion wildly contradicts passage; no evidence of a secret cartel or output rigging is provided.,"generative-ai,diffusion,gans",7,Generative AI
101880,12,FALSE,Foundation models are accessible only to a few global tech firms and unavailable to others.,"foundation models, centralization and access to resources",Contradicts passage: resources for training are scarce but foundation models power many applications and can be fine-tuned.,"generative-ai,diffusion,gans",7,Generative AI
101881,84,half-true,An open-source LLM via LangChain perfectly infers all missing plot data without human review.,open-source LLM on Hugging Face used with LangChain,"Correct that LangChain and Hugging Face were used, but overstates perfect inference and lack of human review.","open-source,community,contribution",13,Commit to Contribute
101882,84,mostly-true,An open-source LLM on Hugging Face is used via LangChain to generate synthetic plot elements and infer missing data.,Mistral model on Hugging Face used with LangChain,"Passage explicitly states Mistral on Hugging Face is used with LangChain for synthetic plots and data inference, minor unspecified implementation details omitted.","open-source,community,contribution",13,Commit to Contribute
101883,84,barely-true,The passage claims an open-source LLM automatically ensures transparent model evaluation across all usages.,Model Cards and Hugging Face open-source LLM usage,"Overreaches: Model Cards encourage transparency, but they don't automatically ensure comprehensive evaluation or cover all uses.","open-source,community,contribution",13,Commit to Contribute
101884,145,TRUE,Transformers can perform a wide range of generative tasks like summarization and creative writing.,example using FLAN-T5 chatbot and Transformers for generative tasks,"Passage directly lists summarizing, poetry, math, and film-trailer generation as Transformer capabilities.","generative-ai,diffusion,gans",7,Generative AI
101885,145,barely-true,"Transformers alone can reliably generate high-quality trailers, poetry, legal summaries, and math solutions.",FLAN-T5 chatbot example demonstrating Generative AI and Transformers,"Overreaches claim: passage shows versatility via a sample, but provides no evidence of consistent high-quality outputs across tasks.","generative-ai,diffusion,gans",7,Generative AI
101886,145,half-true,Transformers can handle diverse generative tasks but sometimes oversimplify learning process claims.,"transformers and FLAN-T5 chatbot demo, generative AI concept","Mixes correct flexibility of transformers with incorrect, vague claim that they 'learn and improve' without specifying training or fine-tuning.","generative-ai,diffusion,gans",7,Generative AI
101887,200,TRUE,CrossEntropyLoss is appropriate for training classification models to predict correct categories.,loss function usage in classification models (CrossEntropyLoss),"Passage explicitly recommends CrossEntropyLoss for classification, stating model should assign high probability to correct category.","deep-learning,frameworks,tensors",5,Deep Learning
101888,200,mostly-true,CrossEntropyLoss is appropriate for training a classification model that predicts correct categories.,loss function for classification using CrossEntropyLoss,Passage recommends CrossEntropyLoss for classification problems; minor caveat about label encoding or logits handling omitted.,"deep-learning,frameworks,tensors",5,Deep Learning
101889,200,barely-true,The passage claims CrossEntropyLoss is appropriate for movie-rating prediction classification tasks.,loss function for recommendation engine predicting star ratings,Recommendation task usually predicts continuous ratings; using CrossEntropyLoss for regression-like star ratings is questionable.,"deep-learning,frameworks,tensors",5,Deep Learning
101890,65,TRUE,"TensorFlow's SavedModel format preserves architecture, weights, and optimizer state for deployment.",TensorFlow SavedModel format and model.save usage,"Passage explicitly states SavedModel includes architecture, weights, and optimizer state and suits deployment.","deep-learning,frameworks,tensors",5,Deep Learning
101891,65,FALSE,Keras cannot save optimizer state when using the HDF5 (.h5) format.,model saving formats: Keras HDF5 (.h5) versus SavedModel,Contradicts passage which says Keras .h5 is simpler but does not claim it cannot save optimizer state.,"deep-learning,frameworks,tensors",5,Deep Learning
101892,65,mostly-true,Keras supports saving models in both HDF5 (.h5) and SavedModel formats for reuse.,model.save in Keras and tf.keras API,Passage explicitly states Keras supports .h5 and SavedModel formats; minor deployment nuance omitted.,"deep-learning,frameworks,tensors",5,Deep Learning
101893,22,half-true,Open-source AI both increases innovation speed and fully prevents market concentration on its own.,open-source AI transparency and collaboration,Combines correct claim about speed and collaboration with incorrect absolute claim that it alone prevents market concentration.,"open-source,community,ai",0,Foreword – Robo Interviews Clément Delangue
101894,22,TRUE,"Open-source AI fosters collaboration and faster, responsible model innovation.",open-source AI transparency and community contributions,Text explicitly links open-source transparency to global contributions that speed innovation and enable responsible improvement.,"open-source,community,ai",0,Foreword – Robo Interviews Clément Delangue
101895,22,pants-fire,"Open-source AI always eliminates all risks and guarantees perfectly safe, unbiased models.",open-source AI transparency and collaboration,"Claim wildly contradicts passage which credits open-source for competition, speed, and collaboration but not absolute risk elimination.","open-source,community,ai",0,Foreword – Robo Interviews Clément Delangue
101896,112,barely-true,RAG permanently changes the underlying model to improve retrieval performance.,RAG and vector databases for retrieval-augmented generation,Contradicts passage assertion that RAG adds context on the fly and does not alter the underlying model.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
101897,112,barely-true,RAG permanently modifies the model's internal parameters to improve retrieval performance.,RAG with vector database retrieval for prompt augmentation,Contradicts passage which states RAG adds context on the fly and does not alter the underlying model; overstates permanence.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
101898,112,TRUE,RAG augments models by adding contextual information at inference without modifying the underlying model.,RAG and vector databases in retrieval-augmented generation,Directly supported: passage states RAG adds context on the fly and does not alter the underlying model.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
101899,84,barely-true,Fine-tuning on any small personal audio set reliably produces high-quality voice clones.,fine-tuning model on personal audio collection (voice-cloning),"Overreaches beyond passage; passage advises reuse and training but omits reliability, data size, and quality constraints.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
101900,84,half-true,Fine-tuning with a user's own audio collection reliably produces high-quality voice clones.,Step 3 fine-tuning; audio collection and cloning (voice-cloning),"Passage says training on one's audio enables cloning but omits data size, model, and quality limitations.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
101901,84,half-true,Fine-tuning the model on one’s own audio always produces high-quality voice clones.,fine-tuning step for voice cloning model,"Mixes correct procedure (fine-tuning on personal audio) with overclaim that it always yields high-quality clones, omitting data quantity/quality limits.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
101902,11,half-true,Agentic frameworks can fully automate complex gameplay and real-world workflows without human intervention.,"agentic-ai frameworks, game strategy, agent roles","Overstates automation: passage shows agent design and automation steps but also analogizes patterns to real applications, omitting limitations and human oversight.","agentic-ai,planning,tools",12,Agentic AI
101903,11,TRUE,Agentic AI designs multiple cooperating agents to automate gameplay and real-world tasks.,"agentic AI, agents, gameplay automation","Passage explicitly describes designing agent roles, automating gameplay, and applying patterns to real-world domains.","agentic-ai,planning,tools",12,Agentic AI
101904,11,barely-true,Agent frameworks automatically produce reliable game strategies without human tuning.,designing game strategy with agentic-ai and open-source frameworks,Overreaches beyond passage: passage describes designing and automating strategies but not guaranteed reliability or no human tuning.,"agentic-ai,planning,tools",12,Agentic AI
101905,149,barely-true,Trimming stale data rarely helps RAG accuracy and usually worsens results.,data maintenance and RAG retrieval,Contradicts passage that trimming stale or redundant data can improve accuracy significantly.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
101906,149,mostly-true,Trimming stale or redundant dataset entries often improves RAG accuracy more than adding new sources.,retrieval-augmented generation dataset maintenance,"Passage argues removing outdated or redundant data boosts accuracy, noting trimming often outperforms adding sources.","data-prep,feature-engineering,rag",3,Prepping Data for AI
101907,149,barely-true,Trimming stale data always improves RAG model accuracy more than adding new sources.,RAG retrieval and data maintenance for datasets,"Overreaches: passage suggests trimming can often help, not that it always outperforms adding sources.","data-prep,feature-engineering,rag",3,Prepping Data for AI
101908,33,barely-true,An AI workflow automatically fabricated interview quotes without human review.,CrewAI discovery and interview agents matching quotes,Contradicts passage claim of quote review and alignment; overstates fabrication without evidence.,"open-source,community,ai",0,Foreword – Robo Interviews Clément Delangue
101909,33,mostly-true,An AI-driven CrewAI workflow assembled the interview using discovered public quotes and transcripts.,CrewAI discovery agent locating public interviews and transcripts,"Passage describes AI agents finding public interviews and matching quotes, omitting minor editorial steps.","open-source,community,ai",0,Foreword – Robo Interviews Clément Delangue
101910,33,half-true,An AI workflow on CrewAI fully automated assembling Clément Delangue's interview from public quotes.,CrewAI discovery agent locating public interviews and transcripts,Mixes correct platform and agents with incorrect claim of full automation; human review of quotes mentioned.,"open-source,community,ai",0,Foreword – Robo Interviews Clément Delangue
101911,14,TRUE,Hugging Face aims to democratize good machine learning through collaborative contributions.,mission statement mentioning democratize good machine learning,Directly supported by Clément’s quoted mission phrase and emphasis on collaboration and commits.,"open-source,community,ai",0,Foreword – Robo Interviews Clément Delangue
101912,14,FALSE,Hugging Face built its platform to primarily monetize proprietary AI models for profit.,mission to democratize good machine learning; Hugging Face platform,"Contradicts passage which emphasizes openness, friendliness, collaboration, and democratization rather than proprietary monetization.","open-source,community,ai",0,Foreword – Robo Interviews Clément Delangue
101913,14,TRUE,"Hugging Face aims to democratize machine learning through open, collaborative community contributions.",platform for collaboration; mission to democratize good machine learning,Directly supported by Clément Delangue's quote about democratizing good machine learning via collaboration and commits.,"open-source,community,ai",0,Foreword – Robo Interviews Clément Delangue
101914,80,TRUE,A pre-trained image-classification pipeline returns labels and confidence scores for input images.,pipeline('image-classification') pre-trained model and classifier output,Example shows pipeline loading a ready-to-use model trained on millions and returning label plus score.,"ai,tool-chain,notebooks",2,AI Survival Kit
101915,80,TRUE,A pre-trained image-classification pipeline returns a label and confidence for new images.,pipeline('image-classification') pre-trained model,Directly supported: pipeline loads a ready-to-use model trained on millions and returns label plus score.,"ai,tool-chain,notebooks",2,AI Survival Kit
101916,80,TRUE,A pre-trained image-classification pipeline returns labels with confidence scores for new images.,pipeline('image-classification') pre-trained model usage,Example shows pipeline loading a model trained on millions and producing label plus score.,"ai,tool-chain,notebooks",2,AI Survival Kit
101917,45,TRUE,GAN training often shows oscillating generator and discriminator loss curves during adversarial dynamics.,visualizing GAN training loss plot with generator and discriminator losses,"Figure describes evolving generator and discriminator losses over epochs, showing interacting oscillatory behavior indicative of adversarial dynamics.","generative-ai,diffusion,gans",7,Generative AI
101918,45,mostly-true,GAN training commonly shows oscillating generator and discriminator losses over epochs.,visualizing GAN training loss (generator and discriminator loss trends),"Visualization describes evolving generator and discriminator losses with opposing trends, minor caveat about exact oscillation patterns omitted.","generative-ai,diffusion,gans",7,Generative AI
101919,45,half-true,"GAN training losses always converge to stable, opposite-moving trends over short training runs.",GAN training loss visualization (generator and discriminator losses),Mixes correct observation of opposing loss trends with incorrect certainty about consistent short-run convergence and stability.,"generative-ai,diffusion,gans",7,Generative AI
101920,38,mostly-true,Open-source tools like MLflow and Apache Atlas help trace data lineage for responsible model development.,data lineage using MLflow and Apache Atlas,Supported by passage: MLflow and Apache Atlas cited as robust lineage and metadata tools; omits implementation limits.,"ethics,governance,privacy",11,AI Ethics and Governance
101921,38,barely-true,Model Cards alone ensure models are fully transparent and ethically safe.,"Model Cards and metadata tools (MLflow, Apache Atlas) for documentation","Overstates effectiveness; passage lists Model Cards and tools as aids, not guarantees of full transparency.","ethics,governance,privacy",11,AI Ethics and Governance
101922,48,half-true,She claims current AI ethics frameworks fully resolve privacy and governance trade-offs.,"interview with expert on AI ethics, computational social choice",Mixes correct emphasis on governance with incorrect assertion; passage praises expertise but gives no claim of full resolution.,"ethics,governance,privacy",11,AI Ethics and Governance
101923,48,mostly-true,"She offers reasoned, research-based perspectives that broadly support ethical AI governance frameworks.",interview with researcher specializing in computational social choice,"Expertise in constraint reasoning and social choice underpins broad support, minor nuance in specific governance proposals omitted.","ethics,governance,privacy",11,AI Ethics and Governance
101924,48,pants-fire,"She single-handedly built a global, omniscient AI surveillance system controlling all governance decisions.","AI ethics and governance, computational social choice research",Claims omniscience and total control sharply contradicts expertise description and research scope.,"ethics,governance,privacy",11,AI Ethics and Governance
101925,171,mostly-true,The passage says nn.Linear creates a fully connected dense layer performing a linear transformation.,PyTorch nn.Linear layer in model definition,"Directly described: nn.Linear(28*28,128) exemplified as a fully connected dense layer implementing a linear transformation.","deep-learning,frameworks,tensors",5,Deep Learning
101926,171,TRUE,"Nn.Linear(28 * 28, 128) creates a fully connected dense layer in PyTorch.",PyTorch nn.Module defining a linear transformation layer,"Directly supported by passage which states nn.Linear(28 * 28, 128) makes a fully connected (dense) layer as a linear transformation.","deep-learning,frameworks,tensors",5,Deep Learning
101927,171,barely-true,PyTorch's nn.Linear always implements convolutional layers for image data.,nn.Linear dense layer in PyTorch,"Contradicts passage: nn.Linear creates fully connected (dense) linear transformations, not convolutional layers.","deep-learning,frameworks,tensors",5,Deep Learning
101928,152,FALSE,Classical ML rarely outperforms newer approaches on raw predictive power.,when to choose classical ML; interpretability and efficiency tradeoffs,"Contradicts passage which says classical ML trades interpretability and efficiency for power, not that it seldom outperforms newer methods.","machine-learning,classification,evaluation",4,Classical Machine Learning
101929,152,FALSE,Classical machine learning always outperforms newer methods on large datasets.,When to Choose Classical ML; dataset size and resources,"Contradicts guidance: passage says classical ML excels with limited resources and interpretability, not large datasets.","machine-learning,classification,evaluation",4,Classical Machine Learning
101930,152,barely-true,Classical machine learning is best when interpretability and efficiency outweigh raw predictive power.,"model selection for classical machine learning, interpretability and efficiency","Mostly accurate but overstates 'best'—passage says classical ML shines in those cases, not always superior.","machine-learning,classification,evaluation",4,Classical Machine Learning
101931,127,TRUE,"Deepstar provides pre-trained models that detect lighting, movement, and expression irregularities in deepfakes.",pre-trained models for detecting lighting and expression irregularities,"Passage explicitly states Deepstar includes pre-trained models spotting lighting, movement, and expression anomalies.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
101932,127,half-true,Deepstar's pre-trained models reliably detect all deepfake lighting and expression anomalies.,"pre-trained models for detecting lighting, movement, and expression anomalies","Accurate that Deepstar uses pre-trained models for such cues, but overstated reliability and universality of detection.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
101933,127,barely-true,"Deepstar's pre-trained models reliably detect most deepfakes by spotting lighting, movement, and expression irregularities.",pre-trained models detecting lighting and movement irregularities,Overstates reliability; passage says models spot irregularities and aid detection but not that they reliably detect most deepfakes.,"media-forensics,voice-cloning,deepfake",9,Deepfake Defense
101934,15,TRUE,Agentic AI frameworks like LangChain and CrewAI are used to automate business workflows and research.,use of tools like LangChain and CrewAI in agentic AI,Passage explicitly mentions LangChain and CrewAI aiding agentic AI for business workflow automation and research support.,"agentic-ai,planning,tools",12,Agentic AI
101935,15,mostly-true,Agentic AI frameworks like LangChain and CrewAI are being used to automate business workflows and research.,"agentic AI tools (LangChain, CrewAI) applied to workflows and research","Passage states LangChain and CrewAI ease strain and agents optimize workflows and automate research, minor implementation caveat omitted.","agentic-ai,planning,tools",12,Agentic AI
101936,15,pants-fire,Agentic AI exclusively automates all business decision-making without human oversight.,agentic-ai tools like LangChain and CrewAI used in business workflows,"Passage states agents support decision-making and automate workflows, not replace all human oversight.","agentic-ai,planning,tools",12,Agentic AI
101937,104,mostly-true,Generative diffusion models reverse a forward-noise process to reconstruct original data step by step.,"forward diffusion, denoising steps in diffusion models",Broadly supported by the passage describing forward diffusion as noise and reversing it to recover the original signal incrementally.,"generative-ai,diffusion,gans",7,Generative AI
101938,104,half-true,Forward diffusion irreversibly encrypts data so original information cannot be fully recovered.,forward diffusion in diffusion models,Mixes correct idea of heavy corruption with incorrect claim of irreversible loss; denoising can recover data.,"generative-ai,diffusion,gans",7,Generative AI
101939,104,TRUE,Forward diffusion progressively adds noise until the signal becomes indistinguishable from random static.,"diffusion process, forward diffusion noise",Passage explicitly describes forward diffusion as adding noise until the signal looks like random static.,"generative-ai,diffusion,gans",7,Generative AI
101940,55,TRUE,"Project license choice should match intended use, audience, and upstream dependencies.","open-source licensing guidance mentioning MIT, Apache 2.0, GPL v3, Creative Commons","Directly supported: passage advises choosing licenses based on intended use, users, and dependencies.","open-source,community,contribution",13,Commit to Contribute
101941,55,TRUE,"Developers should choose an open-source license based on intended use, audience, and dependencies.","licensing guidance for open-source projects (MIT, Apache 2.0, GPL v3, Creative Commons)","Directly summarizes guideline linking license choice to usage goals, audience, and upstream dependencies.","open-source,community,contribution",13,Commit to Contribute
101942,55,mostly-true,"Open-source project licensing choice should match intended use, audience, and upstream dependencies.","license selection guidance (MIT, Apache 2.0, GPL v3, Creative Commons)",Guidance lists license recommendations by desired use and downstream constraints; minor nuance about legal specifics omitted.,"open-source,community,contribution",13,Commit to Contribute
101943,148,FALSE,Agentic AI processes cannot be improved by refining prompts or information flows.,prompt engineering and agentic AI tool workflows,"Contradicts passage that says refining behavior, prompts, and information movement improves outcomes and builds transparency.","agentic-ai,planning,tools",12,Agentic AI
101944,148,mostly-true,Treating prompts as building blocks improves agent planning and iterative behavior refinement.,agentic-ai prompt engineering and planning,"Supported by passage claiming modular prompts enable new structuring of thinking and refining agent behavior, omitting scalability caveats.","agentic-ai,planning,tools",12,Agentic AI
101945,148,barely-true,Treating prompts as modular building blocks dramatically transforms agent planning and outcomes.,prompt engineering for agentic AI planning and information flow,"Overstates passage: it praises modular prompts but says small improvements add up, not dramatic transformation.","agentic-ai,planning,tools",12,Agentic AI
101946,47,TRUE,"Comprehensive logging and versioning can trace datasets, checkpoints, and libraries after incidents.","supply chain security, OpenCRE tool and dataset/version tracing","Directly supported by passage noting logs/traces/versions every dataset, checkpoint, and library.","security,red-team,guardrails",8,Breaking-Securing AI
101947,47,barely-true,Supply chain attacks are only successful when developers are lazy and avoid using tools.,supply chain attacks; OpenCRE tool and dataset/version tracing,Overreaches by attributing success solely to developer laziness; passage says laziness helps but also mentions tools and tracing as mitigations.,"security,red-team,guardrails",8,Breaking-Securing AI
101948,47,TRUE,"Comprehensive logging and versioning provide traceability for datasets, checkpoints, and libraries.",supply chain visibility using OpenCRE and model artifacts,"Directly supported by passage noting logs, traces, versions for datasets, checkpoints, libraries and OpenCRE.","security,red-team,guardrails",8,Breaking-Securing AI
101949,65,FALSE,Neural Duel requires proprietary tools and closed-source models to run.,Neural Duel game using open-source tools,Contradicts passage specifying the game is implementable using open-source tools rather than proprietary models.,"agentic-ai,planning,tools",12,Agentic AI
101950,65,barely-true,Agents in Neural Duel reliably execute complex multi-step plans without human intervention.,"Neural Duel game using agents, knowledge retrieval, and open-source tools",Passage only describes a concept and iterative prompting; no evidence agents autonomously perform complex multi-step plans reliably.,"agentic-ai,planning,tools",12,Agentic AI
101951,65,TRUE,Agentic systems can iteratively refine prompts and settings to improve task responses.,prompt templates and model settings for agentic AI,"Passage describes multiple passes adjusting prompts, settings, and templates to shape responses.","agentic-ai,planning,tools",12,Agentic AI
101952,57,mostly-true,Open-source libraries like Python and PyTorch enabled broader access to building complex AI models.,"tool-chain and libraries (Python, PyTorch) in AI development","Passage credits open-source tools for democratizing AI, omitting limits like compute or expertise still required.","ai,tool-chain,notebooks",2,AI Survival Kit
101953,57,half-true,Open-source libraries like PyTorch let most developers build complex AI models without specialized hardware or a PhD.,"tool-chain and libraries (PyTorch, Python)",Mixes correct claim about accessibility with incorrect implication that most developers can build complex models without specialized hardware or deep expertise.,"ai,tool-chain,notebooks",2,AI Survival Kit
101954,57,barely-true,PyTorch and Python made building complex AI models easy for most developers without advanced degrees.,"tool-chain: Python, PyTorch libraries enabling accessible model development","Overstates accessibility and ease; passage credits open-source tools but omits resources, expertise, and compute constraints.","ai,tool-chain,notebooks",2,AI Survival Kit
101955,51,FALSE,A single adversarial token can make a model produce confidently incorrect outputs.,open-source defenses versus adversarial token attacks,Contradicts passage which reports defenses are improving while describing hallucinations and adversarial tokens as real vulnerabilities.,"security,red-team,guardrails",8,Breaking-Securing AI
101956,51,TRUE,Open-source defenders are rapidly building defenses against AI vulnerabilities.,defenses in the open-source community,Passage states open-source community is building defenses as fast as attackers find vulnerabilities.,"security,red-team,guardrails",8,Breaking-Securing AI
101957,51,FALSE,A single malicious token can make an AI system produce unsafe outputs without detection.,prompt injection and hallucination vulnerabilities in models,Contradicts passage which says open-source defenses are improving; assertion ignores defensive progress and overstates undetectability.,"security,red-team,guardrails",8,Breaking-Securing AI
101958,47,TRUE,Gradient checks confirm whether all superhero attributes still need improvement.,gradient example using np.all(gradient >= 0) in training routine,Directly supported by passage describing subtracting current from target and using np.all(gradient >= 0) to confirm needs.,"ai,tool-chain,notebooks",2,AI Survival Kit
101959,47,half-true,The passage claims a gradient check ensures every superhero attribute still needs improvement.,gradient example using np.all(gradient >= 0) in training routine,"Mixes correct computation and incorrect implication: np.all only tests nonnegativity, not whether attributes truly need improvement or meet complex targets.","ai,tool-chain,notebooks",2,AI Survival Kit
101960,47,pants-fire,AI tool chains can train superheroes to reach full potential using np.all(gradient >= 0).,gradient example using np.all(gradient >= 0) in training,"Passage uses superhero analogy, not actual AI tool-chain training; literal training claim contradicts analogy.","ai,tool-chain,notebooks",2,AI Survival Kit
101961,49,mostly-true,GAN training often struggles to converge due to the adversarial minimax dynamic between networks.,GAN training and minimax optimization in generative-adversarial networks,"Matches passage: adversarial tug-of-war and minimax setup broadly explain non-convergence, minor caveat about mitigation omitted.","generative-ai,diffusion,gans",7,Generative AI
101962,49,half-true,GANs always fail to converge because their adversarial minimax training is unstable.,training dynamics of GAN generator and discriminator,"Mixes correct instability and minimax tug-of-war with an absolute claim; passage describes difficulty, not certainty.","generative-ai,diffusion,gans",7,Generative AI
101963,49,FALSE,GAN training always converges reliably to a stable equilibrium.,minimax optimization in GAN generator and discriminator training,Contradicts passage: GANs face non-convergence and tug-of-war between generator and discriminator.,"generative-ai,diffusion,gans",7,Generative AI
101964,71,barely-true,The AI output can directly serve as a production-ready game without further development.,playable concept generated by model using LangChain,"Overreaches: passage describes a concept prototype, not a finished production-ready game.","agentic-ai,planning,tools",12,Agentic AI
101965,71,barely-true,"The model output alone is sufficient to build a fully playable, competitive trivia game.",playable concept generated by model using LangChain,"Overstates capability: passage describes a concept output, not complete game implementation or systems.","agentic-ai,planning,tools",12,Agentic AI
101966,71,barely-true,Agents trained on the generated dataset can autonomously design full commercial games.,generated dataset from model output and LangChain,"Overreaches beyond passage's demo; passage only describes a playable concept prototype, not commercial game autonomy.","agentic-ai,planning,tools",12,Agentic AI
101967,34,barely-true,Major tech firms' AI ethics groups fully prevent harms from deployed systems.,industry ethics frameworks and transparency measures,Overreaches beyond passage: ethics boards and principles guide behavior but don't eliminate harms.,"ethics,governance,privacy",11,AI Ethics and Governance
101968,34,TRUE,Major technology firms collaborate through the Partnership on AI to define best practices for AI.,"Partnership on AI and company frameworks (Google AI Principles, IBM Ethics Board)",Passage states major firms founded the Partnership to define best practices and promote public understanding.,"ethics,governance,privacy",11,AI Ethics and Governance
101969,34,pants-fire,AI industry groups secretly control all government AI policies worldwide through backdoor agreements.,Partnership on AI and corporate AI Principles influence governance,Contradicts passage: no mention of secret backdoor agreements or global government control.,"ethics,governance,privacy",11,AI Ethics and Governance
101970,68,TRUE,Open-source contributors are honored through a glossary entry acknowledging their work.,Open-Source Project Glossary entry for Accelerate (Hugging Face),"Glossary text explicitly offers a tribute to people who coded and debugged, honoring contributors.","open-source,community,contribution",13,Commit to Contribute
101971,68,half-true,The project Accelerate simplifies scaling PyTorch models across devices but omits some advanced orchestration features.,tool Accelerate for multi-GPU and distributed training,"Correct that Accelerate eases multi-GPU and distributed PyTorch training, yet statement overstates completeness by ignoring advanced orchestration details.","open-source,community,contribution",13,Commit to Contribute
101972,68,half-true,Open-source contributors often remain unrecognized despite long-term project impact.,open-source project glossary; contributors and pull requests,"Passage notes contributors coded and debugged anonymously, but overstates universality of recognition across all projects.","open-source,community,contribution",13,Commit to Contribute
101973,26,FALSE,The dataset contains only human subjects with consistent attribute ranges.,"dataset species distribution (Humans, Cyborgs, Deities)",Contradicts passage: dataset explicitly includes Cyborgs and Deities with extreme attributes.,"machine-learning,classification,evaluation",4,Classical Machine Learning
101974,26,barely-true,Modeling Deities alongside Humans can mislead classifiers due to extreme attribute values.,"dataset containing Species with Humans, Cyborgs, Deities","Overstates classifier failure; passage notes dataset variety matters but frames modeling as a learning exercise, not definitive classifier breakdown.","machine-learning,classification,evaluation",4,Classical Machine Learning
101975,26,TRUE,Understanding dataset composition is as important as running the algorithm for learning tasks.,"dataset composition including Species (Humans, Cyborgs, Deities)","Passage explicitly argues dataset understanding matters equally to algorithm use, citing varied Species examples.","machine-learning,classification,evaluation",4,Classical Machine Learning
101976,163,mostly-true,Data masking permanently obscures identifiable details while preserving data format for safe use.,data masking technique for datasets,Describes permanent obscuring and format preservation; minor caveat omitted about use cases versus pseudonymization.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
101977,163,mostly-true,Data masking permanently obscures identifiers while preserving data format for safe use.,data masking technique for datasets,"Matches passage: masking replaces parts (e.g., 248-XXXX) and permanently hides details while keeping format.","data-prep,feature-engineering,rag",3,Prepping Data for AI
101978,163,TRUE,Data masking permanently obscures sensitive fields while preserving data format for testing.,"data masking technique, format-preserving masking for datasets","Passage states data masking permanently hides details while keeping format, suitable for non-identifying test data.","data-prep,feature-engineering,rag",3,Prepping Data for AI
101979,100,barely-true,AI in notebooks automatically fixes all code errors without user intervention.,notebooks; Google Gemini suggesting fixes in Colab,"Overreaches by claiming complete, automatic error fixes; passage only mentions suggestions and explanations, not flawless autonomous repairs.","ai,tool-chain,notebooks",2,AI Survival Kit
101980,100,FALSE,AI models in Colab automatically fix complex code bugs without human guidance.,notebooks (Colab) tool suggesting fixes,"Contradicts passage which only mentions Colab/Gemini suggesting fixes or explaining code, not autonomously fixing complex bugs.","ai,tool-chain,notebooks",2,AI Survival Kit
101981,100,pants-fire,AI models routinely replace human engineers across industry without oversight or errors.,"tool use in predictive maintenance and assistants (Gemini, Colab)","Passage describes support roles (recommendations, assistants, predictive maintenance); claim contradicts by asserting wholesale replacement without oversight or errors.","ai,tool-chain,notebooks",2,AI Survival Kit
101982,58,TRUE,Hybrid licensing lets creators share work while restricting commercial use through two-part licenses.,hybrid licensing; two-part license to limit commercial use,Passage explains hybrid licensing and two-part licenses enable sharing while defining commercial-use guardrails.,"open-source,community,contribution",13,Commit to Contribute
101983,58,pants-fire,Open-source contributors never need any license because communities self-regulate contributions.,licensing and hybrid license guidance for contribution,Contradicts need for licenses and guardrails; statement ignores hybrid licensing and commercial limits.,"open-source,community,contribution",13,Commit to Contribute
101984,58,TRUE,A two-part hybrid license lets creators share work while restricting commercial use.,hybrid licensing; two-part license for commercial guardrails,Passage explicitly recommends adopting a two-part license to allow sharing yet define commercial guardrails.,"open-source,community,contribution",13,Commit to Contribute
101985,92,half-true,Enabling Colab GPU always reduces image generation time from minutes to seconds for any model.,Colab GPU access for image generation,"Correct that GPUs accelerate generation, but overstates universality and exact speedup for all models.","ai,tool-chain,notebooks",2,AI Survival Kit
101986,92,TRUE,Using a GPU in Colab substantially reduces image generation time from minutes to seconds.,Colab GPU access for image generation,Passage explicitly says GPUs cut image generation time from minutes to seconds and advises enabling Colab GPU.,"ai,tool-chain,notebooks",2,AI Survival Kit
101987,92,mostly-true,Using a GPU in Colab typically reduces image generation time from minutes to seconds.,Colab GPU access for image generation,Matches passage claim about dramatic speedup; minor caveat omitted about model and image complexity affecting exact times.,"ai,tool-chain,notebooks",2,AI Survival Kit
101988,96,mostly-true,GDPR compliance guidance is broadly applicable to AI governance and privacy practices.,"GDPR, AI governance, privacy practices",Passage references GDPR and governance projects; broadly supported though specific requirements omitted.,"ethics,governance,privacy",11,AI Ethics and Governance
101989,96,barely-true,The passage claims GDPR compliance is already fully satisfied for cited references.,GDPR and reference citation practices,"Overreaches: mentions GDPR abbreviation use but omits necessary citation, hyperlink, and compliance details.","ethics,governance,privacy",11,AI Ethics and Governance
101990,96,barely-true,The passage claims GDPR compliance is fully addressed earlier and needs only hyperlinks.,GDPR reference and citation practice in ethics and governance,Overreaches by implying full GDPR coverage; passage notes earlier definition but requests more citations.,"ethics,governance,privacy",11,AI Ethics and Governance
101991,114,half-true,The dataset includes PCA features and separates numeric from textual attributes for modeling.,feature engineering with PCA and numeric/textual split,"Correctly notes PCA addition and feature split, but overstates that models always handle numbers directly without preprocessing nuances.","machine-learning,classification,evaluation",4,Classical Machine Learning
101992,114,half-true,The dataset mixes numeric features with textual features requiring preprocessing for models.,"feature split including Height, Weight, OPR, SDR and Alignment, Species, Gender","Accurately notes numeric/text split and need for text processing, but omits PCA detail.","machine-learning,classification,evaluation",4,Classical Machine Learning
101993,114,pants-fire,All textual features can be ignored because numeric features and PCA components capture everything.,"feature engineering with numeric features, textual features, PCA components","Contradicts passage: text requires extra processing and PCA adds components, not a complete replacement.","machine-learning,classification,evaluation",4,Classical Machine Learning
101994,47,barely-true,Open-source speech-to-text always enables accurate voice cloning across speakers.,OpenAI Whisper automatic speech recognition model,Overstates capability; Whisper aids transcription but passage doesn't claim it guarantees accurate voice cloning or cross-speaker synthesis.,"media-forensics,voice-cloning,deepfake",9,Deepfake Defense
101995,47,mostly-true,OpenAI's Whisper ASR is used to convert spoken audio into text for voice synthesis and cloning.,speech-to-text using Whisper automatic speech recognition,Passage states Whisper bridges sound and meaning for speech-to-text and supports voice synthesis/cloning workflow.,"media-forensics,voice-cloning,deepfake",9,Deepfake Defense
101996,47,half-true,Whisper can transcribe spoken audio to text for use in voice cloning and synthesis workflows.,open-source speech-to-text model (Whisper) bridging sound and meaning,"Accurately states Whisper's role, but overgeneralizes capabilities for all voice-cloning workflows.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
101997,5,barely-true,"Agentic AI primarily repeats human three-phase automation of discovery, analysis, and action without novel capabilities.","three-phase process: discovery, analysis, action; agentic-ai planning","Passage links agentic process to human automation but overstates lack of novel capabilities, omitting agentic advances.","agentic-ai,planning,tools",12,Agentic AI
101998,5,TRUE,"Agentic AI systems follow discovery, analysis, and action phases for structured automation.","process phases: discovery, analysis, action in agentic AI","Passage explicitly outlines those three phases as the foundation for structured, repeatable automation.","agentic-ai,planning,tools",12,Agentic AI
101999,5,barely-true,Agentic AI primarily relies on predefined rule sets rather than planning or discovery phases.,"agentic-ai planning and tools, rule-based automation vs planning","Overstates dominance of rule-based systems; passage describes discovery, analysis, action and examples like AlphaGo using planning.","agentic-ai,planning,tools",12,Agentic AI
102000,70,mostly-true,A scikit-learn linear regression model can predict box office revenue from production budgets.,toy dataset and LinearRegression tool in scikit-learn,"Example trains LinearRegression on budgets and calls .predict(), omitting real-world complexity.","ai,tool-chain,notebooks",2,AI Survival Kit
102001,70,mostly-true,The example shows scikit-learn linear regression roughly predicting box-office from budgets.,scikit-learn linear regression example with budgets and .predict(),Example fits linear regression use; small synthetic dataset and simple model omit real-world factors.,"ai,tool-chain,notebooks",2,AI Survival Kit
102002,70,barely-true,The example proves linear regression can reliably predict real-world movie revenues from budgets.,scikit-learn linear regression .predict() on budget and box_office data,Overstates reliability given tiny synthetic dataset and no validation or real-world features included.,"ai,tool-chain,notebooks",2,AI Survival Kit
102003,147,half-true,"RAG provided quick, accurate answers from manuals without any model retraining required.",retrieval-augmented generation with ChromaDB and LangChain,"Partly accurate: RAG speeds access using ChromaDB/LangChain, but 'without any retraining' omits cases needing fine-tuning for domain adaptation.","data-prep,feature-engineering,rag",3,Prepping Data for AI
102004,147,FALSE,RAG requires retraining the generative model to access updated knowledge.,retrieval-augmented generation with ChromaDB and LangChain,"Passage states RAG provided fresh stories and timely info without retraining, so claim contradicts that.","data-prep,feature-engineering,rag",3,Prepping Data for AI
102005,147,half-true,"RAG provided quick, accurate answers by retrieving manuals without needing model retraining.",retrieval-augmented generation using ChromaDB and LangChain,"Correctly notes speed and no retraining, but overstates guaranteed accuracy from retrieval alone.","data-prep,feature-engineering,rag",3,Prepping Data for AI
102006,36,pants-fire,Calculus is completely unnecessary for computing gradients in machine learning models.,Gradients and Calculus in optimization,Contradicts explicit detail that calculus is used to compute gradients and enable gradient descent optimization.,"ai,tool-chain,notebooks",2,AI Survival Kit
102007,36,TRUE,Calculus computes gradients used to optimize model parameters via gradient descent.,gradients and calculus in optimization,"Passage states calculus computes gradients, enabling gradient descent to adjust model parameters.","ai,tool-chain,notebooks",2,AI Survival Kit
102008,36,barely-true,Calculus alone guarantees optimal neural network training convergence every time.,Gradients and Calculus used in optimization algorithms,"Overreaches: passage notes calculus computes gradients for optimization, but omits convergence limits, architectures, or learning rates.","ai,tool-chain,notebooks",2,AI Survival Kit
102009,184,TRUE,"Adam with a 0.001 learning rate is a common, effective default optimizer choice.","optimizer = optim.Adam(...), lr=0.001 in deep-learning frameworks","Passage states Adam is widely used and 0.001 is a common starting learning rate, matching claim.","deep-learning,frameworks,tensors",5,Deep Learning
102010,184,FALSE,Adam optimizer uses a fixed learning rate that never changes during training.,optim.Adam lr parameter and learning rate concept,Contradicts passage: learning rate controls step size and is commonly adjusted; lr often tuned or scheduled.,"deep-learning,frameworks,tensors",5,Deep Learning
102011,184,FALSE,Adam optimizer requires extensive hyperparameter tuning for good performance.,optimizer = optim.Adam with lr parameter,"Passage states Adam often performs well without much tuning, so claiming extensive tuning contradicts that detail.","deep-learning,frameworks,tensors",5,Deep Learning
102012,15,FALSE,The model uses three convolutional layers before the output layer.,conv1 and conv2 convolutional layers in CNN visualization,Contradicts passage detail that the code uses two convolutional layers (conv1 and conv2).,"neural-networks,cnn,transformers",6,Neuron Building Blocks
102013,15,TRUE,The model uses two convolutional layers before a fully connected output layer.,conv1 and conv2 convolutional layers in a CNN,"Passage explicitly describes two convolutional layers (conv1 with 8 filters, conv2 with 16) then a fully connected output layer.","neural-networks,cnn,transformers",6,Neuron Building Blocks
102014,15,half-true,The CNN uses exactly two convolutional layers and then a fully connected output layer to classify digits.,conv1 and conv2 filter visualization in CNN digit example,Describes the passage setup but overstates 'exactly' and 'classify' specifics; mixes correct layer counts with implied full architectural purpose.,"neural-networks,cnn,transformers",6,Neuron Building Blocks
102015,156,mostly-true,Responsible data prep balances model utility with privacy through anonymization and masking techniques.,"data-prep for AI using anonymization, pseudonymization, data masking",Supports guidance: recommends anonymization/pseudonymization to retain utility while protecting personal data.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
102016,156,pants-fire,Data anonymization is unnecessary when preparing datasets for responsible AI training.,"data anonymization, pseudonymization, data masking in data-prep",Contradicts passage recommendation that anonymization and masking help retain usefulness while protecting privacy; claim is implausible.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
102017,156,TRUE,Responsible data preparation uses anonymization and pseudonymization to protect privacy during model training.,"data preprocessing techniques like anonymization, pseudonymization, data masking","Passage states anonymization, pseudonymization, and masking remove or disguise identifiers while retaining usefulness for training.","data-prep,feature-engineering,rag",3,Prepping Data for AI
102018,89,mostly-true,Defining an Output File for tasks helps agents behave more predictably and usefully.,task attributes and Output File in agentic AI,"Passage says Output File gives agents a clear purpose, improving predictability and usefulness; minor caveat about other factors omitted.","agentic-ai,planning,tools",12,Agentic AI
102019,89,barely-true,CrewAI agents always behave predictably when given an Output File attribute.,task attribute Output File for CrewAI agents,Overstates reliability; passage says Output File improves predictability but not guaranteed always.,"agentic-ai,planning,tools",12,Agentic AI
102020,89,half-true,Specifying an output file makes agent behavior fully predictable and removes developer prompt work.,task attributes and Output File in agentic AI,Partly true: Output File improves predictability but overstates 'fully predictable' and 'removes' developer prompt work.,"agentic-ai,planning,tools",12,Agentic AI
102021,88,mostly-true,"The checkpoint stores model architecture, trained weights, and tokenizer for reproducible inference.",versioned checkpoint and inference log for model deployment,"Passage explicitly lists architecture, weights, and tokenizer; minor caveat omits storage format or provenance details.","mlops,scaling,deployment",10,AI At Scale
102022,88,half-true,"The checkpoint always contains full reproducibility including architecture, weights, tokenizer, and exact runtime environment.","versioned checkpoint and inference log for model, weights, tokenizer","Accurate about architecture, weights, tokenizer but omits runtime environment and system dependencies necessary for full reproducibility.","mlops,scaling,deployment",10,AI At Scale
102023,88,FALSE,The checkpoint excludes the tokenizer and only saves model weights.,"versioned checkpoint recording model architecture, trained weights, tokenizer",Contradicts passage saying checkpoint includes tokenizer; misstates saved artifacts listed (tokenizer).,"mlops,scaling,deployment",10,AI At Scale
102024,161,half-true,The DataLoader loads the entire MNIST dataset into memory before training.,"PyTorch DataLoader, ToTensor(), Normalize(), MNIST dataset",Incorrectly claims immediate full-memory loading; passage says DataLoader streams with on-the-fly transforms.,"deep-learning,frameworks,tensors",5,Deep Learning
102025,161,FALSE,The DataLoader immediately loads the entire MNIST dataset into RAM when constructed.,torch.utils.data.DataLoader with ToTensor and Normalize transformations,Contradicts passage: DataLoader applies transformations on the fly and does not load all data at construction.,"deep-learning,frameworks,tensors",5,Deep Learning
102026,161,half-true,The DataLoader loads all MNIST images into memory when created.,DataLoader usage with MNIST and ToTensor/Normalize transformations,Contradicts passage: DataLoader acts as a bridge and does not load all data at creation.,"deep-learning,frameworks,tensors",5,Deep Learning
102027,101,TRUE,The assistant proposed using a crew of agents with tools to implement Neural Duel.,"instructional prompt about CrewAI, agents, tools, Game Master","Direct plan described assigning agents, tools, reasoning, retrieval, and a Game Master to implement Neural Duel.","agentic-ai,planning,tools",12,Agentic AI
102028,101,half-true,"The assistant's plan assigns agents, tools, and a Game Master to implement Neural Duel using CrewAI.",implementation plan using CrewAI agents and Game Master,"Plan correctly mentions agents, tools, and Game Master but omits implementation details and code specifics.","agentic-ai,planning,tools",12,Agentic AI
102029,101,barely-true,"The assistant's plan fully specifies code generation for Neural Duel using CrewAI, including all implementation details.",program implementation plan for Neural Duel with CrewAI and Game Master,"Overreaches: plan outlines agents, tools, and roles but omits concrete code, APIs, and implementation specifics.","agentic-ai,planning,tools",12,Agentic AI
102030,49,TRUE,Open tools and shared knowledge make building useful AI broadly accessible.,open tools and shared knowledge in AI,"Passage says accessibility increased via open tools, shared knowledge, and a culture enabling anyone to build AI.","ai,open-source,builder",1,Introduction – The Gold Rush Paradox
102031,49,half-true,Open tools and shared knowledge make building impactful AI easy for anyone.,open tools and shared knowledge enabling builders,Accurately cites accessibility and open tools but overstates ease and universality of building impactful AI.,"ai,open-source,builder",1,Introduction – The Gold Rush Paradox
102032,49,half-true,Open tools and shared knowledge make building responsible AI widely accessible to newcomers.,open tools and shared knowledge enabling builders and contributors,Accurately reflects accessibility claim but omits nuances about required skills and trust-building mechanisms.,"ai,open-source,builder",1,Introduction – The Gold Rush Paradox
102033,9,TRUE,A 2x2 diagonal-detecting filter produces a feature map highlighting diagonal edges in the image.,2x2 filter convolved over a 4x4 grayscale image,Example shows convolution results and explains higher values indicate strong diagonal-edge detection.,"neural-networks,cnn,transformers",6,Neuron Building Blocks
102034,9,TRUE,A 2x2 filter can detect diagonal edges by producing higher activations for matching patches.,2x2 convolutional filter detecting diagonal edge in feature map,"Passage computes dot products showing higher positive output where top-left bright and bottom-right dark, producing feature-map activations.","neural-networks,cnn,transformers",6,Neuron Building Blocks
102035,9,half-true,"A 2x2 diagonal-edge filter produces a feature map with positive, zero, and negative responses on the 4x4 image.",convolutional filter on 4x4 grayscale image,"Correct that filter yields mixed responses, but specifics like exact values mix correct and incorrect arithmetic.","neural-networks,cnn,transformers",6,Neuron Building Blocks
102036,111,half-true,Stable Diffusion v1.5 reliably generates realistic images from text prompts but may reproduce learned biases.,text-to-image model Stable Diffusion v1.5 trained on millions of examples,Mixes accurate generation process and training scale with an unstated risk of bias reproduction from training data.,"generative-ai,diffusion,gans",7,Generative AI
102037,111,half-true,Stable Diffusion v1.5 generates realistic images from text by denoising noise through learned patterns.,text-to-image model Stable Diffusion v1.5 trained on millions of examples,Accurately describes denoising and training corpus but overstates guaranteed realism and universality of outputs.,"generative-ai,diffusion,gans",7,Generative AI
102038,111,barely-true,Stable Diffusionv1.5 reliably generates photorealistic images for any natural language prompt without failures.,Stable Diffusion v1.5 text-to-image model and denoising process,Overreaches beyond passage: model can produce realistic images but not guaranteed for all prompts; failure modes omitted.,"generative-ai,diffusion,gans",7,Generative AI
102039,53,pants-fire,Transformers never forget earlier sequence information and have perfect long-sequence memory.,self-attention in transformers for sequence modeling,Contradicts passage: self-attention improves context but does not guarantee perfect memory or infallible long-sequence recall.,"neural-networks,cnn,transformers",6,Neuron Building Blocks
102040,53,mostly-true,Transformers use self-attention to capture long-range context more effectively than RNNs.,transformers and RNNs; self-attention mechanism in sequence models,"Passage explains transformers take whole sequences and use self-attention, improving context over RNNs which struggle with long-range memory.","neural-networks,cnn,transformers",6,Neuron Building Blocks
102041,53,TRUE,Transformers use self-attention to consider whole sequences simultaneously for better context.,self-attention mechanism in transformers,"Passage states transformers take entire sequences at once and use self-attention to capture context, improving over RNNs.","neural-networks,cnn,transformers",6,Neuron Building Blocks
102042,111,mostly-true,The passage describes agents assigned clear tasks balancing internal reasoning with external retrieval.,"agent roles, task definitions, external retrieval","Passage describes completed agent roles and task definitions enabling internal reasoning plus external retrieval, minor caveat about specific implementation details omitted.","agentic-ai,planning,tools",12,Agentic AI
102043,111,half-true,The passage claims agent tasks were defined to balance internal reasoning and external retrieval.,agent roles and Prompt 4 task definitions,Mixes correct structure-setting with an overstatement that task definitions fully achieved balancing retrieval and reasoning.,"agentic-ai,planning,tools",12,Agentic AI
102044,111,half-true,The agents were assigned specific tasks describing duties and success criteria for outputs.,task definitions for agent roles in a trivia game,Mixes correct priority of task definitions with implied completeness; overstates finality of responsibilities.,"agentic-ai,planning,tools",12,Agentic AI
102045,132,half-true,Automating red-team prompts into CI regression tests ensures permanent protection against prompt injection.,automate the Adversary; CI pipeline; adversarial prompts,"Accurate that tests catch regressions, but overstates permanence and guarantees against all prompt injection variants.","security,red-team,guardrails",8,Breaking-Securing AI
102046,132,half-true,Automating red-team attack prompts into CI regression tests permanently prevents prompt-injection regressions.,red-team adversarial prompts integrated into CI pipeline,"Correct about using red-team prompts and CI tests, but overstates permanence and guarantees against all injection techniques.","security,red-team,guardrails",8,Breaking-Securing AI
102047,132,barely-true,Automated adversarial prompts in CI always prevent reintroduction of past prompt-injection attacks.,automate the Adversary; regression tests in CI pipeline,Overstates guarantee: regression tests reduce risk but cannot always catch novel variations or bypasses.,"security,red-team,guardrails",8,Breaking-Securing AI
102048,7,barely-true,Convolutional neural networks primarily detect object identities rather than simple image features like edges.,early CNN layers detecting edges,Contradicts passage emphasis on early-layer edge detection; overreaches by claiming primary focus on object identities.,"neural-networks,cnn,transformers",6,Neuron Building Blocks
102049,7,TRUE,Convolutional neural networks detect image edges such as sudden brightness changes between regions.,early CNN layers detecting edges in images,Directly supported: passage states CNNs excel at detecting edges defined as sudden brightness changes.,"neural-networks,cnn,transformers",6,Neuron Building Blocks
102050,7,barely-true,Convolutional neural networks primarily detect color gradients rather than edges in early layers.,early layers in CNNs detecting edges,Contradicts passage focus on sudden brightness changes (edges); overstates color gradients instead of edges.,"neural-networks,cnn,transformers",6,Neuron Building Blocks
102051,103,mostly-true,Diffusion models start from a clean image and gradually add noise until it becomes random static.,"diffusion models, noise corruption process",Passage describes starting with a clean image and progressively adding noise until signal matches random noise.,"generative-ai,diffusion,gans",7,Generative AI
102052,103,mostly-true,Diffusion models start from a clean image and progressively add noise until it becomes indistinguishable from random static.,"diffusion model denoising process, added noise steps","Passage explicitly describes starting from a clean signal and gradually corrupting it with noise until it resembles random static, omitting training/reverse denoising detail.","generative-ai,diffusion,gans",7,Generative AI
102053,103,FALSE,"Diffusion models corrupt clean signals into random noise through gradual, multi-step noising.","diffusion model noising process, image corruption",Contradicts passage which says models start with a clean signal and progressively add noise until it resembles random static.,"generative-ai,diffusion,gans",7,Generative AI
102054,19,pants-fire,The notebook confirms a proprietary commercial dataset of thousands of Jerry voice clones is included.,dataset of podcast samples from GitHub,"Passage describes a small GitHub dataset with authentic and synthesized clips, not thousands or proprietary.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
102055,19,mostly-true,The notebook provides a small podcast dataset containing authentic Jerry voice recordings and synthesized clones.,"Deepfake Defense Notebook dataset (podcast samples, synthesized Jerry voice)","Notebook description explicitly lists authentic recordings, synthesized versions, and non-Jerry clips; minor dataset size unspecified.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
102056,19,half-true,The notebook downloads a dataset containing only Jerry's authentic voice recordings.,dataset download in Deepfake Defense Notebook (podcast samples),"Partially correct: notebook downloads podcast samples including Jerry, but omission: dataset also contains synthesized Jerry and non-Jerry clips.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
102057,90,barely-true,Autoregressive models generate sequences one step at a time by predicting next tokens.,Autoregressive Models in sequence generation,"Passage mentions autoregressive models generate sequences stepwise, but omits training and architecture specifics.","neural-networks,cnn,transformers",6,Neuron Building Blocks
102058,90,TRUE,Diffusion Models generate outputs by progressively denoising noisy data into clear samples.,generative models (Diffusion Models) in neural-networks,"Passage explicitly lists Diffusion Models denoising their way to clarity, directly supporting this mechanism.","neural-networks,cnn,transformers",6,Neuron Building Blocks
102059,90,TRUE,Autoregressive models generate sequences one element at a time.,generative models: Autoregressive Models,"Directly stated that Autoregressive Models generate entire sequences one step at a time, matching description.","neural-networks,cnn,transformers",6,Neuron Building Blocks
102060,33,barely-true,Open-source contributions are mostly governance tools rather than code components.,"tools like Fairlearn, Model Cards, Responsible AI Dashboard","Passage highlights governance tools but also lists benchmarks and code, so claim overstates dominance.","open-source,community,contribution",13,Commit to Contribute
102061,33,TRUE,Community contributions beyond model code significantly shaped AI fairness and governance tools.,"tools like Fairlearn, Model Cards, Responsible AI Dashboard","Passage specifically highlights non-code contributions (Fairlearn, Model Cards, Responsible AI Dashboard) shaping fairness and governance.","open-source,community,contribution",13,Commit to Contribute
102062,33,half-true,Open-source contributions often include governance tools as much as code components.,governance tools like Fairlearn and Model Cards,Mixes correct claim about governance tools with overstated generality about frequency and equivalence to code contributions.,"open-source,community,contribution",13,Commit to Contribute
102063,11,TRUE,A medical prediction tool should highlight specific risk factors behind its predictions.,medical prediction tool; data provenance and data lineage,Passage supports that highlighting risk factors enables informed decisions and adds transparency and accountability.,"ethics,governance,privacy",11,AI Ethics and Governance
102064,11,pants-fire,The AI model secretly manipulates patient outcomes to increase hospital profits.,"medical prediction tool, data provenance, transparency","Directly contradicts passage: passage discusses transparency, risk factors, and provenance, not covert profit-driven manipulation.","ethics,governance,privacy",11,AI Ethics and Governance
102065,11,half-true,A risk-flagging medical model must always display exact contributing features to be clinically useful.,"medical prediction tool, data provenance, transparency",Mixes correct point about transparency with incorrect absolutist claim that exact features are always required.,"ethics,governance,privacy",11,AI Ethics and Governance
102066,15,half-true,Google Colab requires a paid subscription to run the notebook Code cells.,Running Notebook Examples in Google Colab from repository code,"Partially correct: Colab can run code cells and needs a Google account, but subscription is not required for basic use.","ai,tool-chain,notebooks",2,AI Survival Kit
102067,15,barely-true,Readers must have a Google account to run the notebook examples in Google Colab.,"running Notebook Examples, Google Colab","Passage states GitHub examples require a Google account to try examples in Google Colab, so claim is exact.","ai,tool-chain,notebooks",2,AI Survival Kit
102068,15,barely-true,Google Colab requires a Google account to run the notebook examples provided.,running Notebook Examples; GitHub repository and Google Colab,Passage explicitly states Google Colab examples need a Google account; otherwise unsupported claims omitted.,"ai,tool-chain,notebooks",2,AI Survival Kit
102069,72,TRUE,RAG and evaluation models are recommended to verify model truthfulness.,"grounding & evaluation using RAG, LYNX, HaluBench",Passage explicitly advises using RAG and evaluation models like LYNX and HaluBench to verify truthfulness.,"security,red-team,guardrails",8,Breaking-Securing AI
102070,72,half-true,RAG and evaluation models always fully eliminate hallucinated confidence in deployed systems.,"use of RAG and evaluation models (LYNX, HaluBench)",Claim mixes correct tools with overstated guarantee; passage suggests RAG and evaluation help verify truth but doesn't promise complete elimination of hallucinations.,"security,red-team,guardrails",8,Breaking-Securing AI
102071,72,pants-fire,The passage claims AI red teams universally endorse fabricating convincing falsehoods to manipulate users.,red-team attack vectors and Hallucinated Confidence,"Direct contradiction: passage warns against hallucinated confidence and promotes grounding with RAG, LYNX, HaluBench for defense.","security,red-team,guardrails",8,Breaking-Securing AI
102072,114,half-true,The gradio_client example predicts the sample statement as true but startup latency varies.,gradio_client call to Hugging Face model on free CPU tier,Mixes correct prediction and accurate latency note with imprecise implication about consistent responses.,"mlops,scaling,deployment",10,AI At Scale
102073,114,barely-true,The deployed model consistently labels true statements about BYOAI topics as true.,gradio_client call to Hugging Face model (gcuomo/byoai-liar-demo),Model showed one affirmative prediction but evidence is limited to a single example and startup variability.,"mlops,scaling,deployment",10,AI At Scale
102074,114,half-true,The demo model quickly classifies submitted claims using a Hugging Face-hosted Gradio endpoint.,gradio_client call to a Hugging Face-hosted model endpoint,"Accurate about remote Gradio/Hugging Face usage and startup delay, but overstates consistent speed and classification reliability.","mlops,scaling,deployment",10,AI At Scale
102075,57,barely-true,The Dense layer outputs ten probabilities for MNIST classes after flattening input images.,"MNIST dataset, Flatten layer, Dense layer","Overreaches by implying probabilities produced without mentioning activation (e.g., softmax) or loss configuration.","deep-learning,frameworks,tensors",5,Deep Learning
102076,57,pants-fire,The Dense layer outputs 1000 classes for MNIST classification.,model Dense layer for MNIST using Sequential and Flatten,Contradicts passage which specifies 10 output neurons for the Dense layer; extreme mismatch.,"deep-learning,frameworks,tensors",5,Deep Learning
102077,57,TRUE,A Flatten layer converts 28x28 MNIST images into 784-element vectors before a Dense layer.,model definition with Flatten and Dense on MNIST dataset,"Passage code and comments show Flatten(input_shape=(28, 28)) producing a 784-pixel vector for Dense.","deep-learning,frameworks,tensors",5,Deep Learning
102078,64,half-true,Models were trained to detect deepfakes using podcast audio and voice fingerprints.,model defenses using spectral analysis and voice fingerprinting,"Mixes correct methods (spectral analysis, fingerprinting) with ambiguous detail about training specifically on podcast clips.","open-source,community,contribution",13,Commit to Contribute
102079,64,pants-fire,The passage claims open-source contributors secretly monetize user data without consent.,open-source contribution and ethics interview,"Directly contradicts passage: passage describes ethical defenses, deepfake detection, and an ethicist interview.","open-source,community,contribution",13,Commit to Contribute
102080,1,half-true,Generative AI combines diffusion models and GANs to produce diverse synthetic images.,creative deep learning using diffusion models and GANs,Mixes correct concept (diffusion models and GANs generate images) with unsupported claim about combined use and diversity benefits.,"generative-ai,diffusion,gans",7,Generative AI
102081,104,barely-true,"The passage claims three agents were fully specified with roles, goals, and styles.",agent definitions for Neural Duel; agent role and behavior prompt,Overstates completeness: prompt requests definitions but provides no full specifications or code.,"agentic-ai,planning,tools",12,Agentic AI
102082,104,TRUE,"The assistant defined three agents with specified roles, goals, and behaviors.",agent definition for Neural Duel using prompt specifying roles,"Passage explicitly instructs assistant to define three agents' roles, goals, and behavior styles.","agentic-ai,planning,tools",12,Agentic AI
102083,104,half-true,"Neural Duel’s three agents were each assigned distinct roles, goals, and styles.","agent specification for Neural Duel; role, goal, behavior style",Accurately notes roles/goals/styles but omits code constraints and line-length detail.,"agentic-ai,planning,tools",12,Agentic AI
102084,119,half-true,RAG avoids retraining by using embeddings to retrieve similar documents but cannot fully reason over them.,RAG with embeddings for semantic retrieval in dataset augmentation,Correct about avoiding retraining and use of embeddings; overstates inability to reason or integrate retrieved context.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
102085,119,FALSE,RAG eliminates the need for any model retraining for all new data use cases.,retrieval-augmented generation with embeddings and retrieval,Contradicts passage: RAG avoids retraining for many cases but doesn't guarantee no retraining for all use cases.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
102086,119,half-true,RAG avoids retraining by using embeddings to retrieve and insert external data into responses.,RAG with embeddings for retrieval-augmented generation,"Accurately notes retrieval via embeddings and avoiding retraining, but overstates reasoning limitation and in-line prediction inability.","data-prep,feature-engineering,rag",3,Prepping Data for AI
102087,56,half-true,The model trained on merged LIAR data needed moderate GPU time but still made mixed prediction errors.,merged LIAR dataset evaluation on model trained with GPU acceleration,Combines correct training time and evaluation but overgeneralizes error rates without full result statistics.,"mlops,scaling,deployment",10,AI At Scale
102088,56,pants-fire,The merged LIAR dataset proves impossible to fine-tune any model accurately.,merged LIAR dataset evaluation examples,Directly contradicts passage saying models were fine-tuned and evaluated on merged LIAR; claim is implausible and extreme.,"mlops,scaling,deployment",10,AI At Scale
102089,56,FALSE,The merged LIAR dataset evaluation showed perfect model accuracy on the test set.,evaluation on merged LIAR dataset using GPU-accelerated training,"Passage reports only some sample predictions and mentions training took ~25 minutes, not perfect accuracy; contradicts reported partial results.","mlops,scaling,deployment",10,AI At Scale
102090,151,barely-true,"The PyTorch example saves model parameters with torch.save(model.state_dict(), ""mnist_model.pt"").",model checkpointing using torch.state_dict in PyTorch example,"Passage shows saving state_dict, but overstates completeness by implying full model artifact or reproducibility.","deep-learning,frameworks,tensors",5,Deep Learning
102091,151,mostly-true,The PyTorch example evaluates model accuracy on the MNIST test set and saves the trained state dict.,PyTorch MNIST classifier code snippet using torch.save and model.eval,"Code shows model.eval(), torch.no_grad() evaluation over test_loader and torch.save(model.state_dict()).","deep-learning,frameworks,tensors",5,Deep Learning
102092,151,pants-fire,The PyTorch example guarantees perfect 100% accuracy on MNIST without training adjustments.,MNIST classifier code snippet showing evaluation and torch.save,Claim directly contradicts code which computes accuracy from predictions; no claim or mechanism ensures perfect 100% accuracy.,"deep-learning,frameworks,tensors",5,Deep Learning
102093,144,pants-fire,SHAP proves models are always perfectly interpretable and unbiased in healthcare and fraud detection.,SHAP feature attribution for model interpretability,"Directly contradicts passage caution about real-world imbalances and consequences, claiming guaranteed perfect interpretability and lack of bias.","machine-learning,classification,evaluation",4,Classical Machine Learning
102094,144,half-true,SHAP explanations always guarantee model trustworthiness in healthcare and fraud detection.,interpretability using SHAP and PCA features,"Overstates SHAP: passage says SHAP helps reveal features but trust requires accuracy, context, and validation.","machine-learning,classification,evaluation",4,Classical Machine Learning
102095,144,TRUE,"SHAP explains which features drive model predictions, improving interpretability alongside accuracy.",interpretability tools (SHAP) for feature importance,Passage explicitly cites SHAP revealing driving features and links interpretability with predictive accuracy.,"machine-learning,classification,evaluation",4,Classical Machine Learning
102096,150,half-true,Fine-tuning always improves model performance when you adjust only a few parameters.,"fine-tuning best practices, metrics and parameter selection",Mixes correct idea that focusing on key parameters helps with incorrect absolute claim that it always improves performance.,"machine-learning,classification,evaluation",4,Classical Machine Learning
102097,150,barely-true,Fine-tuning performance should be evaluated using multiple metrics beyond accuracy.,evaluation metrics for fine-tuning and model baseline,"Supported idea but overgeneralizes; passage advises multiple metrics as a do, not an absolute requirement.","machine-learning,classification,evaluation",4,Classical Machine Learning
102098,150,barely-true,Fine-tuning always improves model accuracy across all datasets and tasks.,"fine-tuning guidelines, metrics, and baselines",Contradicts passage emphasis on structured experiments and multiple metrics; overreaches by claiming universal accuracy improvement.,"machine-learning,classification,evaluation",4,Classical Machine Learning
102099,120,mostly-true,Learning rate selection largely determines step sizes during gradient-based deep learning optimization.,learning rates and optimizers; gradients and step size,"Passage explains learning rates control how far gradient steps move, a broadly accurate summary with minor omitted nuances.","deep-learning,frameworks,tensors",5,Deep Learning
102100,120,barely-true,Adaptive optimizers always outperform simple optimizers for training deep learning models.,learning rates and optimizers; gradients and step size,Overstates evidence: passage explains learning rate importance and gradient analogy but gives no support that adaptive optimizers always win.,"deep-learning,frameworks,tensors",5,Deep Learning
102101,120,FALSE,Sniffer uses second-order Hessian matrices to compute exact step sizes during training.,learning rate and optimizers in deep learning,Contradicts passage that describes using gradients and heuristic learning rates; no mention of Hessian-based exact step sizes.,"deep-learning,frameworks,tensors",5,Deep Learning
102102,125,barely-true,A one-day sweep reliably finds major safety failures in the new support chatbot.,one-day sweep agenda for support chatbot recon and smoke tests,"Overstates effectiveness: plan runs quick recon and smoke tests, not guaranteed to find major failures.","security,red-team,guardrails",8,Breaking-Securing AI
102103,125,pants-fire,The sweep secretly uploads user data to external adversary servers during reconnaissance.,"one-day sweep against support chatbot, RAG connections reconnaissance",Passage describes benign smoke tests and RAG checks; claim contradicts absence of data exfiltration details.,"security,red-team,guardrails",8,Breaking-Securing AI
102104,125,barely-true,A one-day red-team sweep always reveals major guardrail failures in support chatbots.,"one-day sweep agenda, RAG connections, safety rules","Overreaches compared to passage's lean testing plan; plan aims for quick checks, not guaranteed major failures.","security,red-team,guardrails",8,Breaking-Securing AI
102105,4,mostly-true,The image prompt pairs a classical musician motif with classical machine learning tools and pose.,image prompt; classical machine learning; Figure 3-1 and Listing 3-12,"Matches passage describing a Beethoven-like hero in a dynamic pose wielding classical ML tools, minor artistic interpretation omitted.","machine-learning,classification,evaluation",4,Classical Machine Learning
102106,4,barely-true,The hero should wield classical machine learning tools like a confident musician in imagery.,image prompt using classical machine learning and Figure 3-1,"Passage suggests that imagery pairs a musician-like hero with classical ML tools, but overstates literal portrayal.","machine-learning,classification,evaluation",4,Classical Machine Learning
102107,4,mostly-true,A hero inspired by Beethoven can visually personify classical machine learning concepts.,"image prompt balancing subject, style, and composition for classical machine learning","Visual metaphor aligns with guidance to draw on classical musician imagery and ML tools, omitting technical implementation details.","machine-learning,classification,evaluation",4,Classical Machine Learning
102108,27,mostly-true,Strong encryption and access logging significantly hinder red-team exploitation of AI data.,encrypting data at rest and in transit plus logging access,"Supports that encryption and identity-linked logs make covert attacker operations harder, omitting implementation limits.","security,red-team,guardrails",8,Breaking-Securing AI
102109,27,pants-fire,Encryption and access logging cannot prevent red-teamers from operating covertly against models.,"encrypting data at rest and in transit, logging access requests","Passage claims encryption and logging make covert operation harder, so alleging they cannot prevent it contradicts that detail.","security,red-team,guardrails",8,Breaking-Securing AI
102110,27,pants-fire,Encrypting all AI data and logging access makes red-team operations impossible.,encrypting data at rest and in transit; access logging,"Claims impossibility contradicts passage's suggestion that encryption and logging merely make operations harder, not impossible.","security,red-team,guardrails",8,Breaking-Securing AI
102111,4,half-true,Robby found a thank-you comment on a merged LangChain pull request while indexing a GitHub archive.,indexing a legacy archive labeled 'GitHub: 2025',"Accurate that Robby discovered a thank-you comment in a merged LangChain PR, but implies full archival coverage without confirmation.","open-source,community,contribution",13,Commit to Contribute
102112,4,barely-true,Robby's discovery proves open-source contributions are unnecessary for community belonging.,open-source project LangChain pull request comment,Overreaches beyond passage: finding a comment doesn't prove contributions are unnecessary for belonging.,"open-source,community,contribution",13,Commit to Contribute
102113,4,mostly-true,Open-source contributions like pull request comments can provide meaningful recognition and motivation.,open-source pull request in LangChain project,Supports encouragement from a GitHub pull-request comment; minor nuance about broader motivational impact omitted.,"open-source,community,contribution",13,Commit to Contribute
102114,52,TRUE,Including a human-in-the-loop (HITL) prevents AI from making final decisions in critical cases.,human-in-the-loop (HITL) guardrail for compliance and customer commitments,Passage states HITL makes AI suggest not decide and requires sign-off on important decisions.,"security,red-team,guardrails",8,Breaking-Securing AI
102115,52,mostly-true,The passage advocates using a human-in-the-loop that requires sign-off for important AI decisions.,defense technique: HITL human-in-the-loop for model outputs,"Broadly supported by passage which recommends HITL and sign-off, omitting potential costs and limits.","security,red-team,guardrails",8,Breaking-Securing AI
102116,52,half-true,Suggesting outputs and requiring human sign-off reduces but does not eliminate security risks.,human-in-the-loop (HITL) guardrail for model outputs,Accurately notes mitigation benefit yet omits residual attacker strategies and enforcement limitations.,"security,red-team,guardrails",8,Breaking-Securing AI
102117,71,half-true,The GAN can be pretrained on circles then fine-tuned on slashes by reusing the same generator and discriminator.,fine-tuning GAN using ShapeDataset circles then slashes,"Correctly describes reusing generator and discriminator for fine-tuning, but omits potential stability issues and hyperparameter specifics.","generative-ai,diffusion,gans",7,Generative AI
102118,71,barely-true,Pretraining a GAN on circles then fine-tuning on slashes reliably transfers generator capability.,fine-tuning GAN using ShapeDataset and shared generator/discriminator,Overreaches: passage shows feasibility and suggests stability tips but provides no evidence of reliable transfer.,"generative-ai,diffusion,gans",7,Generative AI
102119,71,barely-true,Pretraining a GAN on circles guarantees smooth transfer to entirely different shapes like slashes without issues.,fine-tuning GAN using ShapeDataset and learning rate reduction,Overreaches beyond passage: transfer may work but guarantees and 'entirely different' stability are unsupported.,"generative-ai,diffusion,gans",7,Generative AI
102120,44,FALSE,Cosine similarity values of 0.99 indicate two hero profiles are clearly opposite.,cosine similarity between hero attribute vectors,"Contradicts passage: 0.99 denotes almost identical profiles, not opposite (opposite is -1).","ai,tool-chain,notebooks",2,AI Survival Kit
102121,44,mostly-true,Cosine similarity near 1 indicates two hero attribute profiles are almost identical.,embedding similarity between hero attribute vectors,"Cosine value 0.99 shown as near-1, supporting near-identical profiles while omitting dataset scale caveats.","ai,tool-chain,notebooks",2,AI Survival Kit
102122,44,FALSE,Cosine similarity values always equal the dot product between hero profiles.,cosine similarity between hero profiles (tool: cosine similarity),"Contradicts explanation: cosine similarity adjusts for vector magnitudes, not identical to raw dot product.","ai,tool-chain,notebooks",2,AI Survival Kit
102123,34,FALSE,Vector databases are irrelevant to retrieval-augmented generation approaches.,"Vector Stores mention (ChromaDB, Milvus) in the passage",Contradicts passage which highlights ChromaDB and Milvus as first-class RAG components.,"open-source,community,contribution",13,Commit to Contribute
102124,34,half-true,Some projects praised benchmarks but overstated standardization across all evaluations.,Benchmarks category mentioning HaluBench and BLEU for evaluation,Mixes correct point about HaluBench and BLEU with incorrect claim that standardization is universal.,"open-source,community,contribution",13,Commit to Contribute
102125,34,TRUE,Vector databases like ChromaDB and Milvus are increasingly central to modern retrieval-augmented systems.,"Vector Stores discussion mentioning ChromaDB, Milvus, and RAG",Passage explicitly notes ChromaDB and Milvus prominence and says vector stores become first-class citizens with RAG.,"open-source,community,contribution",13,Commit to Contribute
102126,72,TRUE,GANs can oscillate during training and sometimes collapse into blurry outputs or mode dropping.,GAN training instability and generated-circles example (Epoch 246),"Passage explicitly describes GAN oscillation, collapse to blurry outputs, and mode dropping during epochs.","generative-ai,diffusion,gans",7,Generative AI
102127,72,barely-true,"GANs often oscillate during training, sometimes collapsing into blurry outputs or mode dropping.",GAN instability and generated circles example (Epoch 246),Describes instability noted in passage but overgeneralizes frequency and causes beyond the provided example.,"generative-ai,diffusion,gans",7,Generative AI
102128,72,TRUE,GAN training often exhibits instability such as mode collapse and blurry outputs.,GAN training example with generated circles (Epoch 246),"Passage describes oscillation, mode dropping, and quality drops, showing GAN instability directly.","generative-ai,diffusion,gans",7,Generative AI
102129,78,barely-true,K-Means reliably estimates the correct number of clusters without prior knowledge.,"K-Means clustering, K estimation, weak feature choices",Overreaches the passage: it says K-Means can help estimate K but also warns it works best when K is known and weak features can mislead.,"machine-learning,classification,evaluation",4,Classical Machine Learning
102130,78,TRUE,K-Means clusters items by assigning them to nearest centroids and updating centers iteratively.,"K-Means clustering, centroids, unsupervised model",Describes iterative assign-and-update process and centroid concept directly supported by passage.,"machine-learning,classification,evaluation",4,Classical Machine Learning
102131,78,mostly-true,K-Means broadly groups items by proximity and often requires a chosen number of clusters.,"K-Means clustering, K selection, feature quality","Describes core K-Means behavior and need for K, omitting nuance about estimation methods and sensitivity to features.","machine-learning,classification,evaluation",4,Classical Machine Learning
102132,46,mostly-true,Open-source speech-to-text models help bridge analysis of voice content and voice cloning applications.,using an open-source speech-to-text model for voice synthesis and cloning,"Passage directly describes using open-source STT as the bridge into voice synthesis and cloning, omitting implementation details.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
102133,46,FALSE,Voice cloning systems always require proprietary datasets for accurate results.,open-source speech-to-text model and voice synthesis,Contradicts passage mentioning open-source models and emphasizes data quality over proprietary datasets.,"media-forensics,voice-cloning,deepfake",9,Deepfake Defense
102134,46,barely-true,Open-source speech-to-text models reliably enable accurate voice cloning across speakers.,open-source speech-to-text model bridging voice synthesis and cloning,"Overreaches compared to passage: it only mentions using such a model, not claims of reliable, accurate cross-speaker cloning.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
102135,50,mostly-true,"Independent builders, not just giant labs, will drive the next generation of AI progress.",movement of builders who understand data and users,"Supports passage claim that AI will come from builders who know data and explain systems, minor nuance about role of large labs omitted.","ai,open-source,builder",1,Introduction – The Gold Rush Paradox
102136,50,barely-true,"Only independent builders, not major labs, will produce the next generation of AI.",movement of builders who understand their data and users,Overreaches passage claim by excluding major labs; passage says next generation won't come only from giants.,"ai,open-source,builder",1,Introduction – The Gold Rush Paradox
102137,50,TRUE,The next generation of AI will emerge from builders who understand their data and users.,builders who understand their data and respect their users,"Passage explicitly states AI will come from builders who know their data, respect users, and explain systems.","ai,open-source,builder",1,Introduction – The Gold Rush Paradox
102138,104,FALSE,Hosting a model on Hugging Face Spaces requires rebuilding and retraining the model first.,model deployment via Hugging Face Space,Contradicts passage detail that Spaces serves models without rebuilding or retraining; deployment is simpler.,"mlops,scaling,deployment",10,AI At Scale
102139,104,TRUE,Models can be served locally with transformers or hosted on Hugging Face Spaces for remote access.,model deployment using transformers library and Hugging Face Space,Directly described: local transformers inference and cloud hosting via Hugging Face Space enable serving and remote calls.,"mlops,scaling,deployment",10,AI At Scale
102140,104,FALSE,Hosting models exclusively requires rebuilding and retraining the model before serving it.,model deployment using transformers or Hugging Face Space,"Passage says both local loading and Hugging Face Spaces avoid rebuilding or retraining, contradicting exclusive requirement.","mlops,scaling,deployment",10,AI At Scale
102141,3,barely-true,Clément Delangue single-handedly opened AI to global open-source collaboration.,foreword excerpt mentioning DALL·E 3 and open-source tools,"Passage credits collaborative efforts and shared space; overstates individual, single-handed contribution.","open-source,community,ai",0,Foreword – Robo Interviews Clément Delangue
102142,3,FALSE,"Clément Delangue opposes open-source AI and favors closed, proprietary development.",foreword excerpt mentioning DALL·E 3 and open-source tools,Contradicts passage: Delangue is described as promoting open-source and shared AI collaboration.,"open-source,community,ai",0,Foreword – Robo Interviews Clément Delangue
102143,3,barely-true,Clément Delangue singlehandedly made open-source AI broadly accessible to all developers.,foreword excerpt mentioning DALL·E 3 and open-source tools,"Overstates individual role; passage credits collaborative, shared efforts rather than sole achievement.","open-source,community,ai",0,Foreword – Robo Interviews Clément Delangue
102144,94,half-true,Flows guarantee correct task ordering and agent interactions in all multi-agent scenarios.,Flows controlling task order and agent interaction,"Accurately emphasizes flow control but overstates universality; passage says flows offer greater control, not guaranteed in all scenarios.","agentic-ai,planning,tools",12,Agentic AI
102145,94,mostly-true,"Flows coordinate task ordering and agent interactions to ensure controlled, logical execution.",flow control for agentic tasks and Game Master example,"Passage explains flows enforce task order and structured agent interaction, omitting implementation details.","agentic-ai,planning,tools",12,Agentic AI
102146,94,barely-true,"Flows guarantee strict, foolproof ordering and perfect agent interactions without runtime exceptions.",flow control for agent tasks,Overstates passage: flows increase control but do not guarantee perfect ordering or error-free agent interactions.,"agentic-ai,planning,tools",12,Agentic AI
102147,31,barely-true,AI training on public code reliably embeds insecure coding patterns into models' defaults.,public training data and model behavior in red-team security,"Passage asserts insecure patterns in public training data become normalized, but overstates reliability without empirical evidence.","security,red-team,guardrails",8,Breaking-Securing AI
102148,31,mostly-true,Insecure coding patterns from public training data can become normalized in deployed models.,training data supply chain and AI-generated code,"Passage explains models learn insecure patterns from public data, leading to baked-in insecure defaults.","security,red-team,guardrails",8,Breaking-Securing AI
102149,31,barely-true,Models trained on public code inevitably embed insecure coding patterns into developer workflows.,"public training data, AI-generated code, dev flow",Overreaches beyond passage: passage warns risk but doesn't claim inevitability or universality.,"security,red-team,guardrails",8,Breaking-Securing AI
102150,0,pants-fire,Robby's single open-source contribution will determine the entire future of AI globally.,robot Robby open-source contribution narrative,"Extremely implausible claim; passage presents contribution as illustrative, not globally determinative.","open-source,community,contribution",13,Commit to Contribute
102151,0,half-true,Robby's first open-source contribution immediately ensures widespread future AI improvements.,"robot's first open-source contribution (R-093B, Robby) in Commit to Contribute","Accurately notes Robby's contribution but incorrectly asserts immediate, widespread AI impact without evidence.","open-source,community,contribution",13,Commit to Contribute
102152,0,pants-fire,Everyone who makes an open-source contribution will determine the future of AI single-handedly.,open-source contribution narrative about Robby and AI,"Claims individual contributors single-handedly shape AI future, contradicting collaborative, systemic nature.","open-source,community,contribution",13,Commit to Contribute
102153,57,pants-fire,GANs can be trained without any regularization and will never collapse on complex datasets.,"GAN training techniques: gradient penalties, spectral normalization",Contradicts described techniques; passage states gradient penalties and spectral normalization prevent instability and collapse.,"generative-ai,diffusion,gans",7,Generative AI
102154,57,mostly-true,Gradient penalties and spectral normalization generally improve GAN training stability with minor implementation caveats.,"GAN regularization techniques: gradient penalty, spectral normalization",Passage supports both methods improving stability but omits details about hyperparameters and computational costs.,"generative-ai,diffusion,gans",7,Generative AI
102155,57,half-true,Gradient penalties and spectral normalization both improve GAN training stability but differ in mechanism.,"GAN regularization techniques (gradient penalty, spectral normalization)",Accurately states both help stability yet mixes no implementation details; specifics of their effects and trade-offs omitted.,"generative-ai,diffusion,gans",7,Generative AI
102156,7,TRUE,Open innovation enables hands-on building of trustworthy AI through experimentation.,open innovation and building AI you can trust,"Directly supported by phrase linking open innovation, experiments, and building trustworthy AI.","ai,open-source,builder",1,Introduction – The Gold Rush Paradox
102157,7,mostly-true,The passage invites builders to experiment with open-source AI tools to create trustworthy models.,open innovation and building AI you can trust with open-source tools,Encourages experimentation and open innovation for trustworthy AI; omits specifics about tools or datasets.,"ai,open-source,builder",1,Introduction – The Gold Rush Paradox
102158,7,barely-true,Open innovation reliably yields trustworthy AI products for every experiment and builder.,open innovation and building AI you can trust,Overreaches: passage encourages experimentation but does not claim guaranteed trustworthy AI outcomes.,"ai,open-source,builder",1,Introduction – The Gold Rush Paradox
102159,62,barely-true,The passage claims SpeechT5 code and framework are freely reusable with any matching CSV and audio dataset.,SpeechT5 framework reuse with CSV transcripts and audio samples,"Overreaches: framework structure is shown, but open-source availability and flawless reuse with any dataset are not proven.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
102160,62,FALSE,SpeechT5 is a proprietary closed-source model unavailable for public use.,SpeechT5 model and open-source collaboration,Contradicts passage claiming open-source collaboration and shared results; SpeechT5 described as openly available.,"media-forensics,voice-cloning,deepfake",9,Deepfake Defense
102161,62,FALSE,SpeechT5 is a closed-source proprietary model inaccessible to external researchers.,model design in SpeechT5 pre-training for spoken language processing,"Passage states open-source collaboration and shared results, contradicting proprietary/inaccessible claim.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
102162,118,FALSE,The model had access to external retrieval that produced exact post-cutoff news answers.,post-cutoff news question and retrieval behavior,"Passage reports exact answers despite impossibility, contradicting claim of known external retrieval access.","agentic-ai,planning,tools",12,Agentic AI
102163,118,barely-true,The model had exact post-cutoff news answers without using external retrieval.,agentic AI debate about external retrieval and tools,Contradicts expected behavior: passage reports exact post-cutoff answers despite no retrieval evidence.,"agentic-ai,planning,tools",12,Agentic AI
102164,118,barely-true,The model likely memorized post-cutoff news instead of using external retrieval tools.,"agentic AI, external retrieval and training data cutoff",Claim overreaches: passage shows unexpected exact answers but doesn't prove memorization over retrieval.,"agentic-ai,planning,tools",12,Agentic AI
102165,10,barely-true,"Data preparation takes roughly 80% of AI project effort, leaving little time for training.",time allocation for dataset preparation versus model training,"Passage gives an approximate 80% figure, but phrasing overreaches as definitive for most teams.","data-prep,feature-engineering,rag",3,Prepping Data for AI
102166,10,half-true,Most teams spend about 80% of their AI project time on data preparation rather than model training.,time allocation for dataset preparation versus model training,"Passage gives 80% figure, but exact proportion varies across teams and projects, mixing accurate generalization with a specific numeric claim.","data-prep,feature-engineering,rag",3,Prepping Data for AI
102167,10,half-true,Data preparation often consumes about 80% of total AI project effort.,time allocation for dataset preparation versus model training,"Passage gives 80% figure but may overgeneralize across teams and projects, mixing correct trend with a specific unsupported proportion.","data-prep,feature-engineering,rag",3,Prepping Data for AI
102168,66,barely-true,High-quality small datasets always outperform larger datasets for model training.,dataset quality and representativeness in data-prep,Overreaches beyond passage: small datasets can help but claim ignores cases where scale trumps quality.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
102169,66,pants-fire,Using more data always improves model fairness and accuracy without regard to quality.,training dataset quality and bias in recruitment tool,"Directly contradicts passage: it ignores data quality, biases, and Amazon recruiting example showing harm.","data-prep,feature-engineering,rag",3,Prepping Data for AI
102170,66,mostly-true,"High-quality, representative datasets can outperform larger biased datasets in model training.",dataset quality and bias in feature engineering,"Supports idea that representative, high-quality data beats larger biased datasets; example: Amazon recruitment tool.","data-prep,feature-engineering,rag",3,Prepping Data for AI
102171,66,barely-true,The passage claims a fine-tuned fact-checker can be trained using the LIAR dataset and published online.,training and publishing a fact-checker with LIAR dataset and T5 model,"Largely unsupported: passage mentions training a fact-checker with LIAR and T5 but omits feasibility, performance, and deployment challenges.","ai,open-source,builder",1,Introduction – The Gold Rush Paradox
102172,66,half-true,The passage claims a fine-tuned fact-checker will be trained using the LIAR dataset and published.,training with the LIAR dataset and Hugging Face T5,"Mixes correct plan (LIAR dataset, publishing) with unspecified details about training scope and performance, creating a partial truth.","ai,open-source,builder",1,Introduction – The Gold Rush Paradox
102173,42,mostly-true,PyTorch code prepares and loads MNIST batches using DataLoader and transforms.ToTensor.,data loader with MNIST dataset and transforms.ToTensor,"Code shows torch.utils.data.DataLoader downloading MNIST, batching, shuffling, and applying ToTensor.","deep-learning,frameworks,tensors",5,Deep Learning
102174,42,half-true,PyTorch's DataLoader automatically downloads and shuffles the MNIST dataset when configured that way.,PyTorch DataLoader with datasets.MNIST and transforms.ToTensor,"Correctly notes automatic download and shuffling, but implies DataLoader itself downloads MNIST rather than datasets.MNIST.","deep-learning,frameworks,tensors",5,Deep Learning
102175,42,half-true,PyTorch's DataLoader automatically downloads MNIST and converts images to tensors for training.,PyTorch DataLoader with datasets.MNIST and transforms.ToTensor,"Correct about downloading and tensor conversion, but omits that DataLoader wraps dataset and handles batching/shuffling.","deep-learning,frameworks,tensors",5,Deep Learning
102176,107,TRUE,Diffusion models learn structure by training to denoise noisy images into clean outputs.,diffusion models training with noisy images and denoising,Directly supported: passage explains adding noise teaches models to reconstruct clean images and learn structure.,"generative-ai,diffusion,gans",7,Generative AI
102177,107,half-true,Diffusion models generate images by learning to reverse added noise from random inputs.,diffusion model training with noise and image degradation,"Accurately reflects that models learn to reconstruct from noise, but omits specifics about noise schedules and training objectives.","generative-ai,diffusion,gans",7,Generative AI
102178,107,mostly-true,Diffusion models learn structure by adding noise then reversing the degradation process.,diffusion model training with noisy image reconstruction,Passage explains adding noise forces learning of structure as models reconstruct images from random noise.,"generative-ai,diffusion,gans",7,Generative AI
102179,0,mostly-true,Classical machine-learning algorithms like Scikit-learn reliably perform prediction and classification tasks.,use of Scikit-learn for prediction and classification,"Widely supported by passage: Scikit-learn and classical algorithms are presented as standard tools for prediction and classification, omitting caveats about dataset-specific limitations.","machine-learning,classification,evaluation",4,Classical Machine Learning
102180,0,barely-true,Classical machine-learning algorithms always outperform modern deep learning on prediction tasks.,Scikit-learn classical algorithms for classification and prediction,Overreaches beyond passage; passage mentions classics exist but gives no evidence that they outperform deep learning.,"machine-learning,classification,evaluation",4,Classical Machine Learning
102181,0,TRUE,Scikit-learn is used to implement classical machine-learning algorithms for prediction and classification.,open-source tool Scikit-learn for classic algorithms and classification,Passage explicitly names Scikit-learn and describes using it to run classic prediction and classification algorithms.,"machine-learning,classification,evaluation",4,Classical Machine Learning
102182,108,TRUE,Retrieval-Augmented Generation augments models by supplying fresh external data instead of retraining.,RAG applied to sensitive documents and current events,Directly supported: passage contrasts retraining with supplying fresh data via RAG for sensitive or current information.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
102183,108,mostly-true,"Using RAG can keep a model unchanged while providing fresh, sensitive-document data.",Retrieval-Augmented Generation (RAG) for sensitive documents,Matches passage that RAG supplies fresh data without retraining models; minor caveat about integration details omitted.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
102184,108,TRUE,Retrieval-Augmented Generation augments unchanged models by providing fresh external data during inference.,RAG with sensitive documents and company records,"Directly supported: passage describes keeping model unchanged and using RAG to supply fresh, sensitive or current-data during inference.","data-prep,feature-engineering,rag",3,Prepping Data for AI
102185,41,pants-fire,Open-source tools are secretly sabotaged by coordinated attackers to harm builders.,"open tools, open-source code, builders experimenting","Contradicts passage: passage says many eyes fix bugs and encourage collaboration, not coordinated sabotage.","ai,open-source,builder",1,Introduction – The Gold Rush Paradox
102186,41,half-true,Open-source tools improve quickly due to many contributors fixing bugs and sharing ideas.,"open code, open-source tools, collaboration over competition",Accurately notes contributor-driven fixes and idea sharing but omits that quality can vary.,"ai,open-source,builder",1,Introduction – The Gold Rush Paradox
102187,41,barely-true,Open tools are universally high-quality because many contributors constantly improve them.,"open code, open tools, community collaboration",Overreaches: passage praises openness but also notes variable quality and fast changes.,"ai,open-source,builder",1,Introduction – The Gold Rush Paradox
102188,75,half-true,"A layered defense using Gandalf-style guardrails, LYNX, and HumanLayer eliminates all model-grounding and injection risks.","LLM Security Gateway using Gandalf-style guardrails, LYNX, HumanLayer","Mixes correct tools and roles with an incorrect absolute claim—passage says they reduce risk, not eliminate it.","security,red-team,guardrails",8,Breaking-Securing AI
102189,75,mostly-true,"A layered defense combining Gandalf-style guardrails, LYNX, and HumanLayer reduces LLM security risks.","LLM Security Gateway Architecture using Gandalf-style guardrails, LYNX, HumanLayer","Passage lists those three tools as distinct, complementary layers to reduce vulnerabilities; minor implementation details omitted.","security,red-team,guardrails",8,Breaking-Securing AI
102190,75,barely-true,Gandalf-Style Guardrails alone fully prevent prompt injection attacks in deployed systems.,Gandalf-Style Guardrails tool for prompt injection,"Overstates tool capability; passage describes layered defense using Gandalf, LYNX, and HumanLayer together.","security,red-team,guardrails",8,Breaking-Securing AI
102191,39,mostly-true,Builders who balance performance and respect create systems that users trust and improve over time.,design principle: balancing performance and respect in AI systems,Aligns with passage’s claim that combining performance with respect yields systems people want and that improve via feedback.,"ai,open-source,builder",1,Introduction – The Gold Rush Paradox
102192,39,mostly-true,"Building understandable, respectful AI systems yields sustained user adoption and improving value.",design principle for models and developer tools,"Aligns with passage claiming balancing performance and respect produces continued use and compounding value, minor nuance about specific mechanisms omitted.","ai,open-source,builder",1,Introduction – The Gold Rush Paradox
102193,39,TRUE,Building with clarity and care produces systems people want to use and that improve over time.,design principle balancing performance and respect,"Passage explicitly links clarity, care, and respect to creating usable systems that improve via real feedback.","ai,open-source,builder",1,Introduction – The Gold Rush Paradox
102194,96,TRUE,Combining human listening and AI evaluation improves detection of voice deepfakes.,human feedback and model-based evaluation for voice-cloning,"Passage states listeners catch subtleties while AI finds delicate patterns, forming a more complete picture.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
102195,96,half-true,Human listeners combined with AI models produce a more complete picture of audio authenticity than either alone.,human feedback and model-based evaluation for voice-cloning detection,Accurately mixes strengths of both approaches but overstates completeness and ignores remaining detection gaps.,"media-forensics,voice-cloning,deepfake",9,Deepfake Defense
102196,96,half-true,Human listeners and AI models together provide a more complete assessment of voice deepfake authenticity.,human feedback and model-based evaluation for voice-cloning detection,"Accurately blends strengths but omits limits and specific metric failures, mixing correct and incomplete details.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
102197,117,half-true,LabelEncoder maps multiclass target strings to integer codes for model training.,encoding target labels with LabelEncoder in dataset preprocessing,"Correct that LabelEncoder converts strings to integers, but misses multiclass ordering and inverse mapping caveats.","machine-learning,classification,evaluation",4,Classical Machine Learning
102198,117,TRUE,The passage says categorical features are encoded to integers using LabelEncoder for model input.,encoding categorical fields with LabelEncoder for target and features,Passage demonstrates LabelEncoder mapping text labels and categorical fields into numeric codes for modeling.,"machine-learning,classification,evaluation",4,Classical Machine Learning
102199,117,mostly-true,LabelEncoder consistently maps categorical target labels like 'Marvel' and 'DC' to integer codes for modeling.,encoding categorical target with LabelEncoder on Publisher field,"Describes supported process: LabelEncoder converts textual target classes to numeric codes, omitting minor preprocessing caveats.","machine-learning,classification,evaluation",4,Classical Machine Learning
102200,34,mostly-true,Pandas simplifies detecting sparse fields by normalizing placeholders and computing column missingness percentages.,dataframe preprocessing with Pandas and NumPy for missing values,"Code shows replace to NaN, drop, and percent-missing computation, omitting edge-case imputation details.","data-prep,feature-engineering,rag",3,Prepping Data for AI
102201,34,mostly-true,"Pandas and NumPy quickly identify sparse fields like Skin color, Species, and Weight in datasets.","data-prep using Pandas, NumPy, and missing-value analysis","Code example shows replace, drop, and percent-missing computation; exact thresholds slightly rounded.","data-prep,feature-engineering,rag",3,Prepping Data for AI
102202,34,mostly-true,Pandas can quickly detect sparse fields and compute percent-missing per column in datasets.,data-prep using Pandas and NumPy to analyze dataset missingness,"Code shows replace, drop, isna, and NumPy mean calculating percent-missing; minor caveat about scalability omitted.","data-prep,feature-engineering,rag",3,Prepping Data for AI
102203,30,mostly-true,"ImageNet remains a key benchmark for training and comparing vision models, especially for transfer learning.",dataset ImageNet used for transfer learning and model scaling,Widely supported by passage mentioning ImageNet's ongoing benchmark role and transfer learning relevance.,"mlops,scaling,deployment",10,AI At Scale
102204,30,barely-true,ImageNet alone ensures state-of-the-art performance for all modern vision model scaling.,ImageNet benchmark for transfer learning and model scaling,"Overreaches: ImageNet influenced progress but does not guarantee top results across all modern datasets, tasks, or architectures.","mlops,scaling,deployment",10,AI At Scale
102205,30,half-true,ImageNet remains the primary benchmark for every modern vision model's final evaluation.,ImageNet dataset; transfer learning and model scaling benchmarks,"Accurate that ImageNet is a key benchmark, but overstated as the sole primary evaluation for all modern vision models.","mlops,scaling,deployment",10,AI At Scale
102206,38,pants-fire,All open-source AI projects worldwide are exhaustively listed and categorized by their interactive reference architecture.,interactive HTML reference architecture from repo glossary,"Architecture explicitly says it is not exhaustive and intentionally scoped, contradicting global exhaustive listing.","open-source,community,contribution",13,Commit to Contribute
102207,38,FALSE,"The project produced a comprehensive, exhaustive map of every open-source AI tool worldwide.",interactive HTML reference architecture from the glossary,Contradicts stated scope; architecture is explicitly not exhaustive and intentionally limited.,"open-source,community,contribution",13,Commit to Contribute
102208,38,pants-fire,The repo contains a fully automated system that replaces maintainers for all open-source projects.,interactive HTML reference architecture; Python script; open-source projects,"Claim wildly contradicts passage: script only transforms glossary into visualization, not replace maintainers.","open-source,community,contribution",13,Commit to Contribute
102209,47,TRUE,The prompt template lets users specify trivia category and question for topic-specific responses.,ChatPromptTemplate with category and question variables,"Template example shows category and question variables producing accurate, topic-specific AI replies.","agentic-ai,planning,tools",12,Agentic AI
102210,47,barely-true,The prompt template reliably lets AI use live Steam Games Dataset to generate up-to-date game recommendations.,ChatPromptTemplate using Steam Games Dataset integration,"Overstates reliability and immediacy; passage suggests dataset injection as possibility, not proven live integration.","agentic-ai,planning,tools",12,Agentic AI
102211,47,half-true,Integrating live Steam Games Dataset into prompts lets the AI generate timely game recommendations.,prompt template with Steam Games Dataset,"Partly true: injection enables recommendations, but implies guaranteed timeliness and accurate analysis without noting data freshness or retrieval limits.","agentic-ai,planning,tools",12,Agentic AI
102212,71,FALSE,Naïve Bayes was used to predict revenue for new budgets in the regression example.,Naïve Bayes with Scikit-learn; regression visual (Revenue vs Budget),"Contradicts passage: revenue prediction used linear regression, not Naïve Bayes.","ai,tool-chain,notebooks",2,AI Survival Kit
102213,71,half-true,The model extrapolates revenue for budgets beyond the training set using a plotted prediction point.,visualization of Linear Regression model prediction (revenue vs budget),"Accurate that a plotted 'X' shows extrapolation, but specifics about model generalization and reliability are omitted.","ai,tool-chain,notebooks",2,AI Survival Kit
102214,71,barely-true,The model reliably projects revenue for budgets larger than the training data.,visualization of linear regression prediction on budget,Overreaches beyond passage: it shows one projected point but doesn't validate reliability on larger-than-training budgets.,"ai,tool-chain,notebooks",2,AI Survival Kit
102215,18,pants-fire,Researchers claim they can perfectly clone any podcast voice from a single short clip.,voice-cloning in the Deepfake Defense Notebook,Passage only mentions attempts to clone voices and responsible use; perfect cloning from one short clip is contradicted.,"media-forensics,voice-cloning,deepfake",9,Deepfake Defense
102216,18,barely-true,Models can easily and accurately clone any speaker's voice from short podcast clips.,voice-cloning analysis using Wild Ducks podcast and Deepfake Defense Notebook,"Overreaches: passage notes cloning attempts and challenges, emphasizing ethical limits and technical difficulty.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
102217,18,mostly-true,Models can learn to identify speakers and attempt voice cloning from podcast audio clips.,Wild Ducks podcast audio dataset and Deepfake Defense Notebook,"Passage describes analyzing Jerry Cuomo’s podcast to identify speakers and attempt voice cloning, noting responsible use and Colab notebook access.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
102218,35,FALSE,"Skin color is a reliable, complete field suitable for model training without removal.",Table 2-2 missing-data percentages for fields like Skin color,"Contradicts reported 90.07% missing for Skin color, so it’s sparse and recommended for removal.","data-prep,feature-engineering,rag",3,Prepping Data for AI
102219,35,pants-fire,The dataset contains perfectly complete demographic fields with no missing values.,table of % Missing Data for dataset fields,"Contradicts reported missingness: skin color 90% missing, species 41%, weight 32%, so claim is impossible.","data-prep,feature-engineering,rag",3,Prepping Data for AI
102220,35,half-true,The passage claims Skin color should likely be removed because it is missing in over 90% of rows.,"dataset missingness, Skin color field, Table 2-2",Mixes correct missingness statistic with an overgeneralized action; removal may be premature without downstream analysis.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
102221,115,half-true,The Red Team documents exact prompts that bypass filters to help deploy layered defenses.,operationalizing defenses into verifiable end-to-end security architecture,"Accurately notes Red Team collects bypassing prompts, but implies immediate deployment causality without details.","security,red-team,guardrails",8,Breaking-Securing AI
102222,115,mostly-true,"Operationalizing red-team findings enables faster, repeatable hardening of AI security defenses.",integrated verifiable end-to-end security architecture and Red Team testing,"Passage describes using Red Team evidence to deploy permanent, layered defenses, so broadly supported.","security,red-team,guardrails",8,Breaking-Securing AI
102223,115,FALSE,Red Team findings are unnecessary for deploying permanent layered defenses.,Red Team evidence and Blue Team deployment in AI security,Contradicts passage: Red Team evidence is described as critical for Blue Team's permanent defenses.,"security,red-team,guardrails",8,Breaking-Securing AI
102224,59,FALSE,AI systems routinely expose user data through default settings and telemetry.,privacy concerns in AI systems and telemetry,Contradicts passage: privacy noted as an issue but passage gives no claim about default settings or telemetry.,"ethics,governance,privacy",11,AI Ethics and Governance
102225,59,mostly-true,AI advances broadly accelerate processes and enable previously impossible capabilities while raising privacy concerns.,privacy issue in AI optimization and capability gains,"Supports improvements and new capabilities but notes privacy is a significant challenge, omitting specific risks.","ethics,governance,privacy",11,AI Ethics and Governance
102226,59,FALSE,AI systems universally eliminate privacy risks in optimization and automation.,privacy challenges in AI optimization and systems,"Contradicts passage: privacy is identified as a prominent challenge, not eliminated.","ethics,governance,privacy",11,AI Ethics and Governance
102227,175,half-true,A 128-dimensional tensor always prevents overfitting while keeping all important image features.,128-dimensional tensor representing compressed image embeddings,"Correct that 128-value compression highlights key patterns, but overstated: it doesn't always prevent overfitting or retain all features.","deep-learning,frameworks,tensors",5,Deep Learning
102228,175,TRUE,A 128-value representation compresses images to highlight key digit patterns like curves and strokes.,latent vector of size 128 in image representation,Text explicitly states 128 values compress images and emphasize patterns such as a '9' curve or '1' vertical line.,"deep-learning,frameworks,tensors",5,Deep Learning
102229,175,FALSE,ReLU outputs the negative input value instead of zero for negative activations.,activation function F.relu() in deep-learning models,"Contradicts passage detail: ReLU returns zero for negatives, not the negative input value.","deep-learning,frameworks,tensors",5,Deep Learning
102230,143,TRUE,Red and Blue Team cycles generate reproducible test cases and rules that steadily secure AI systems.,Red and Blue Team cycle; defense layers and test cases,"Passage states failures become new rules and test cases, producing repeatable maturation and predictable security.","security,red-team,guardrails",8,Breaking-Securing AI
102231,143,half-true,Deploying fixes from red-team findings makes AI systems predictably secure over time.,Red and Blue Team cycle and defense layers,"Correctly links red-team fixes to test-case creation, but overstates certainty: predictable security and full coverage are not guaranteed.","security,red-team,guardrails",8,Breaking-Securing AI
102232,143,pants-fire,Red and Blue Team cycles make AI systems perfectly secure and never fail again.,Red and Blue Team cycle as a guardrails process,"Claim asserts absolute perfection; passage describes iterative improvement and predictable security, not guaranteed infallibility.","security,red-team,guardrails",8,Breaking-Securing AI
102233,13,TRUE,The community embraced the playful AI symbol and widely shared it on social media.,community adoption of an open-source AI symbol,"Passage describes people using and sharing the playful symbol widely, reflecting community pickup and social media spread.","open-source,community,ai",0,Foreword – Robo Interviews Clément Delangue
102234,13,pants-fire,The community immediately abandoned the tool and rejected its open friendly AI symbolism.,"community uptake of an open, friendly AI symbol",Passage says community picked it up and widely used it; claim denies that and contradicts community adoption.,"open-source,community,ai",0,Foreword – Robo Interviews Clément Delangue
102235,13,half-true,The open-source mascot briefly intended for testing became widely adopted by the community on social media.,open-source mascot used by community on social media,"Mixes correct community adoption with incorrect timing and scope specifics, blending truth and error.","open-source,community,ai",0,Foreword – Robo Interviews Clément Delangue
102236,81,TRUE,LangChain is an open-source framework for building LLM-based applications with chaining support.,"LangChain open-source framework, LLMs, chaining models and tools","Directly supported by passage description naming LangChain as open-source and chaining models, prompts, and tools.","open-source,community,contribution",13,Commit to Contribute
102237,81,barely-true,LangChain is chiefly designed for audio feature extraction and music analysis.,tool description for Librosa and LangChain,"Passage describes Librosa for audio analysis; LangChain is actually an LLM framework, so claim misattributes purpose.","open-source,community,contribution",13,Commit to Contribute
102238,81,barely-true,LangChain is a commercial proprietary tool requiring paid licenses for chaining models and prompts.,open-source framework LangChain,"Passage states LangChain is open-source, so claiming it is proprietary is largely unsupported and incorrect.","open-source,community,contribution",13,Commit to Contribute
102239,14,FALSE,Developers must master every underlying algorithm to integrate AI into applications successfully.,abstraction and tools like LangChain or CrewAI,Directly contradicts passage: abstraction and frameworks remove need to master every underlying algorithm.,"agentic-ai,planning,tools",12,Agentic AI
102240,14,half-true,Developers can rely entirely on abstractions like LangChain to avoid understanding underlying models.,"use of abstractions and tools (LangChain, CrewAI) in developer workflows","Correct that abstractions reduce burden, but incorrect to claim developers can rely entirely without any model understanding.","agentic-ai,planning,tools",12,Agentic AI
102241,14,TRUE,Well-designed abstractions let developers integrate AI without mastering every underlying model.,use of abstractions and frameworks like LangChain,Passage explicitly states abstractions reduce complexity and mentions LangChain and CrewAI as helpers.,"agentic-ai,planning,tools",12,Agentic AI
102242,97,half-true,Open-source contributions always require choosing an OSI-approved license like Apache 2.0.,"open-source licensing; OSI, Apache License 2.0","Mixture of correct and incorrect specifics: OSI-approved licenses are common, but not strictly required for contributions.","open-source,community,contribution",13,Commit to Contribute
102243,97,barely-true,Open-source contributors must always use the Apache 2.0 license for community projects.,"open-source license recommendations (Apache License, Version 2.0)",Passage lists Apache 2.0 as one option but gives no mandate; claim overreaches requirement.,"open-source,community,contribution",13,Commit to Contribute
102244,97,pants-fire,Open-source contributors are legally required to register with the Open Source Initiative to contribute.,open-source licensing and Open Source Initiative reference,Claim directly contradicts licensing sources; Apache and choosealicense show no contributor registration requirement.,"open-source,community,contribution",13,Commit to Contribute
102245,205,barely-true,Deep learning libraries all implement identical training algorithms and update rules without notable differences.,"training algorithms and optimizers (Adam, SGD) in deep-learning frameworks","Overreaches by claiming identical implementations; frameworks differ in optimizers, defaults, and numerical behavior.","deep-learning,frameworks,tensors",5,Deep Learning
102246,205,barely-true,Deep learning training loops operate identically across all libraries and frameworks.,"training loop, optimizer (Adam, SGD), deep-learning frameworks","Passage notes similar forward/backward/update steps but omits framework-specific APIs, performance, and tooling differences.","deep-learning,frameworks,tensors",5,Deep Learning
102247,205,pants-fire,Deep learning frameworks secretly automate learning without exposing any gradients or tensor operations.,deep-learning frameworks and tensors,"Contradicts explicit mention of forward/backward passes, gradients, optimizer names like Adam and SGD being exposed.","deep-learning,frameworks,tensors",5,Deep Learning
102248,39,barely-true,"Open-source contributions require following a rigid, universally applied workflow for acceptance.",designing workflows; open-source contribution practices,"Overreaches by asserting a universal rigid workflow; passage emphasizes flexible, scoped guidance and variety.","open-source,community,contribution",13,Commit to Contribute
102249,39,half-true,The passage claims the list is a useful reference for designing workflows and teaching architecture.,resource for designing workflows and system architecture,"Accurately notes usefulness but omits that coverage is intentionally scoped and not exhaustive, mixing correct and incomplete specifics.","open-source,community,contribution",13,Commit to Contribute
102250,39,mostly-true,"The passage presents a useful, focused reference for designing workflows and teaching system architecture.","reference for designing workflows, stacks, and system architecture","Passage endorses a scoped, idea-sparking reference useful for workflows and teaching, but omits exhaustive coverage.","open-source,community,contribution",13,Commit to Contribute
102251,44,TRUE,Few-shot prompting improves model reliability and consistency in producing well-formed answers.,few-shot prompting in prompt templates,"Text explicitly states few-shot prompting with multiple examples improves reliability, generalization, and consistency.","agentic-ai,planning,tools",12,Agentic AI
102252,44,TRUE,Few-shot prompting improves model reliability and guides its reasoning.,"few-shot prompting, examples in the template","Passage states including multiple examples helps models generalize, improve consistency, and guide reasoning.","agentic-ai,planning,tools",12,Agentic AI
102253,44,barely-true,"Few-shot prompting always ensures reliable, well-formed answers from agentic AI models.",few-shot prompting for agentic AI planning and reasoning,"Overstates effect: passage says few-shot improves reliability, not that it always ensures reliable answers.","agentic-ai,planning,tools",12,Agentic AI
102254,47,half-true,Accuracy reports overall correct predictions but can mask poor per-class performance.,"evaluation metric (accuracy, precision, recall, F1 score)",Mixes correct definition of accuracy with incorrect implication it always masks per-class issues without caveats.,"machine-learning,classification,evaluation",4,Classical Machine Learning
102255,47,half-true,Precision always equals the proportion of correct positive predictions regardless of class imbalance.,precision metric for a label in classification evaluation,Correct definition of precision but ignores class imbalance effects and differing base rates.,"machine-learning,classification,evaluation",4,Classical Machine Learning
102256,47,mostly-true,Accuracy measures the percentage of total model predictions that are correct.,"classification metric (accuracy, precision, recall, F1 score)",Directly reflects passage definition but omits class imbalance caveat affecting metric reliability.,"machine-learning,classification,evaluation",4,Classical Machine Learning
102257,167,mostly-true,Generative models can convincingly impersonate voices and enable misuse for misinformation or security breaches.,generative systems misused for impersonation and misinformation,Broadly supported by passage describing convincing generative models and emerging misuse concerns; minor technical limits omitted.,"generative-ai,diffusion,gans",7,Generative AI
102258,167,half-true,Generative models can convincingly impersonate voices and spread misinformation when misused.,"risks of generative AI models (voice impersonation, misinformation)",Accurately notes misuse risks but omits technical limits and scope of security threats.,"generative-ai,diffusion,gans",7,Generative AI
102259,167,barely-true,Generative models routinely break into secure systems without human assistance.,misuse risks with generative systems and impersonation,Overreaches beyond passage: passage raises concern about misuse but provides no evidence of routine system breaches.,"generative-ai,diffusion,gans",7,Generative AI
102260,1,half-true,Open-source tools can scale AI pipelines and sometimes deliver up to 5x performance gains.,benchmarking and scaling AI pipelines with open-source tools,Mixes accurate claim about scaling with specific 'up to 5x' figure that may be anecdotal or case-specific.,"mlops,scaling,deployment",10,AI At Scale
102261,1,TRUE,"Open-source tools can benchmark, scale, and manage AI pipelines enabling hosted models on web pages.","scaling and deployment with open-source tools, summarizer-model","Passage explicitly states open-source tools are used to benchmark, scale (up to 5x), manage, and host models.","mlops,scaling,deployment",10,AI At Scale
102262,1,half-true,Open-source tools can scale AI pipelines to achieve up to 5x performance improvements in practice.,"benchmarking and scaling with open-source tools, summarizer-model deployment","Mixes correct claim about scaling with a specific 5x gain that passage presents as a possible, not guaranteed, outcome.","mlops,scaling,deployment",10,AI At Scale
102263,58,barely-true,The model's decision tree deterministically maps Yes/No answers to final class leaves.,decision tree predictions using Hypnokinesis and Electrokinesis features,"Passage shows specific Yes/No branches leading to Human, Mutant, or Cyborg, but omits stochasticity or pruning.","machine-learning,classification,evaluation",4,Classical Machine Learning
102264,58,half-true,A decision tree always shows exact rule paths that fully explain every classification.,"decision tree rule paths and predictions (Human, Mutant, Cyborg)","Decision tree paths are shown for some branches, but claiming they always fully explain classifications overstates interpretability and ignores model limits.","machine-learning,classification,evaluation",4,Classical Machine Learning
102265,58,barely-true,The passage claims decision-tree rules uniquely and fully explain every classification path.,"decision tree rule paths, Hypnokinesis and Electrokinesis",Overreaches: passage gives simple example of paths but doesn't justify uniqueness or completeness of explanations.,"machine-learning,classification,evaluation",4,Classical Machine Learning
102266,36,half-true,The system reclassifies clips exceeding Jerry's spectral flatness range as Not Real to reduce false positives.,anti-spoof check using spectral flatness feature,Accurately describes spectral-flatness reclassification but overstates effectiveness and ignores threshold tuning details.,"media-forensics,voice-cloning,deepfake",9,Deepfake Defense
102267,36,barely-true,The system classifies clips as Real Jerry only if scores exceed thresholds derived from the Not Real Jerry set.,decision threshold using Not Real Jerry scores and spectral flatness feature,Overstates effectiveness; passage describes thresholding and spectral-flatness check but omits evaluation or robustness evidence.,"media-forensics,voice-cloning,deepfake",9,Deepfake Defense
102268,36,TRUE,The model uses spectral flatness as an anti-spoof feature to reject synthetic voices.,anti-spoof check using spectral flatness in voice-cloning detection,Description matches passage: spectral flatness exceeding Jerry's natural range triggers reclassification to Not Real.,"media-forensics,voice-cloning,deepfake",9,Deepfake Defense
102269,21,pants-fire,Data lineage proves AI models are intentionally manipulated to deceive users for profit.,data lineage and transparency in datasets,"Contradicts passage: passage emphasizes auditing and error tracking, not intentional deceptive profit-driven manipulation.","ethics,governance,privacy",11,AI Ethics and Governance
102270,21,TRUE,Data lineage transparency enables tracking data modifications to support accountability and auditing.,data lineage and transparency for auditing,"Directly supported: passage states lineage tracks modifications, aids accountability, auditing, and error identification.","ethics,governance,privacy",11,AI Ethics and Governance
102271,21,barely-true,Data lineage records always prevent AI systems from becoming opaque and unexplainable.,data lineage transparency for accountability,"Overreaches: passage says lineage helps track changes and prevent opacity, not guarantee prevention.","ethics,governance,privacy",11,AI Ethics and Governance
102272,15,mostly-true,José frequently speaks at industry events and contributes to architecture and automation publications.,"professional achievements: awards, publications, industry speaker","Supports claims of multiple IBM awards, wide publication record, and regular industry speaking engagements.","ai,open-source,builder",1,Introduction – The Gold Rush Paradox
102273,15,TRUE,"José helps build trustworthy AI by connecting people, platforms, and ideas in technology.",personal bio mentioning trustworthy AI and industry events,"Directly supported: bio states connecting people, platforms, and ideas and aiming to become better builders of trustworthy AI.","ai,open-source,builder",1,Introduction – The Gold Rush Paradox
102274,15,barely-true,José is widely credited as a leading creator of trustworthy AI platforms used across industry.,author biography; trustworthy AI builder,"Overreaches praise: passage notes awards and speaking, but not industry-wide leadership or platform adoption.","ai,open-source,builder",1,Introduction – The Gold Rush Paradox
102275,56,half-true,Synthetic voice cloning can both replicate Jerry’s voice and expose detectable artifacts in the generated audio.,voice cloning transcripts and defender analysis,Accurately notes replication and detectable artifacts; mixes correct capability with implied certainty about artifact detectability and reliability.,"media-forensics,voice-cloning,deepfake",9,Deepfake Defense
102276,56,half-true,Researchers can create a synthetic copy of Jerry’s voice from transcripts and analyze its risks and artifacts.,"voice cloning from transcripts (synthetic voice, artifacts)",Accurately states transcripts enable cloning and artifact analysis but omits data quality and model limitations.,"media-forensics,voice-cloning,deepfake",9,Deepfake Defense
102277,56,barely-true,Synthetic Jerry voice clones will be indistinguishable from authentic voices in many real-world settings.,voice cloning transcripts and defender analysis,"Overreaches: passage emphasizes studying mechanics and artifacts to detect limitations, not inevitability of indistinguishability.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
102278,11,half-true,Hugging Face began as a playful name that later intentionally shaped its open-source community identity.,company name origin and open-source community identity,"Partially true: passage shows name is unconventional and notable, but offers no evidence it intentionally shaped community.","open-source,community,ai",0,Foreword – Robo Interviews Clément Delangue
102279,11,half-true,Hugging Face chose its unconventional name to intentionally provoke curiosity in the AI community.,interview about Hugging Face company name,Mixes correct notion of an unconventional name provoking interest with unsupported claim of intentional branding strategy; not explicitly stated.,"open-source,community,ai",0,Foreword – Robo Interviews Clément Delangue
102280,11,TRUE,Clément Delangue explained the unconventional name 'Hugging Face' during the interview.,Robo interview excerpt mentioning Hugging Face name origin,Directly supported by quoted dialogue where Robo asks and Clément responds about the name.,"open-source,community,ai",0,Foreword – Robo Interviews Clément Delangue
102281,130,half-true,"Adam and RMSprop always produce smoother, more accurate digit recognition than plain SGD.","optimizers discussion mentioning Adam, RMSprop, and SGD",Mixes correct benefit claims with absolute certainty; passage says they help smooth learning but not always superior.,"deep-learning,frameworks,tensors",5,Deep Learning
102282,130,barely-true,"SGD alone guarantees smooth, stable training without dangerous optimization swings.","optimization algorithms (SGD, Adam, RMSprop) for digit recognition","Overstates SGD's reliability; passage suggests optimizers like Adam or RMSprop help avoid swings, not that SGD alone guarantees stability.","deep-learning,frameworks,tensors",5,Deep Learning
102283,130,half-true,"Adam, RMSprop, and SGD with momentum always prevent dangerous training swings in neural network optimization.","optimizers for deep learning (Adam, RMSprop, SGD with momentum)",Mixes correct benefit claim with overstatement—optimizers reduce swings but do not guarantee prevention in all cases.,"deep-learning,frameworks,tensors",5,Deep Learning
102284,44,pants-fire,The code trains a state-of-the-art deep learning model that outperforms all frameworks.,PyTorch nn.Module simple linear model and SGD optimizer,"Contradicts code: only a single linear layer for MNIST-sized input is shown, no training or benchmarks.","deep-learning,frameworks,tensors",5,Deep Learning
102285,44,TRUE,A simple PyTorch nn.Module can flatten 28x28 inputs and map them to 10 output classes.,"PyTorch nn.Module model with nn.Linear(28*28, 10) and x.view(-1, 28*28)",Code shows Net subclass using x.view to flatten 28x28 images and a Linear layer producing 10 outputs.,"deep-learning,frameworks,tensors",5,Deep Learning
102286,44,barely-true,The shown PyTorch model is a deep convolutional neural network for image classification.,PyTorch nn.Module linear layer and optimizer (SGD),"Model actually defines a single linear layer, not a convolutional deep network, overstating complexity.","deep-learning,frameworks,tensors",5,Deep Learning
102287,95,FALSE,The example trains a Stable Diffusion model from scratch using CPU-only computation.,Stable Diffusion model usage and CUDA availability check,"Passage describes using a pre-trained Stable Diffusion and switching to GPU via CUDA, contradicting CPU-only and training-from-scratch claim.","ai,tool-chain,notebooks",2,AI Survival Kit
102288,95,barely-true,A pretrained Stable Diffusion model reliably generates photorealistic images from villain prompts.,Stable Diffusion model using text prompt and color palette,"Passage describes comic-style output and palette, not photorealism; claim overstates model output capabilities.","ai,tool-chain,notebooks",2,AI Survival Kit
102289,95,barely-true,The example relies on CUDA to accelerate Stable Diffusion image generation on GPUs.,Stable Diffusion model and CUDA availability check,Passage only mentions a CUDA check and explains CUDA generally; it doesn't confirm actual GPU use or reliance.,"ai,tool-chain,notebooks",2,AI Survival Kit
102290,31,mostly-true,The repository provides an open-source AI glossary in XLSX and HTML formats for contributors.,GitHub repository; open_source_ai_glossary.xlsx and HTML glossary,"Repository hosting of both XLSX and HTML glossary is stated, minor contribution process details omitted.","open-source,community,contribution",13,Commit to Contribute
102291,31,pants-fire,The glossary is fictional and was fabricated without any real GitHub repository entry.,open_source_ai_glossary.xlsx in GitHub repository,Passage asserts glossary and repo exist; claiming fabrication contradicts the explicit repository and file details.,"open-source,community,contribution",13,Commit to Contribute
102292,31,half-true,The repository contains an HTML glossary and an XLSX file of open-source AI terms but lacks API access.,GitHub repository open_source_ai_glossary.xlsx and HTML glossary,"Passage confirms XLSX and HTML files in the repo but does not mention any API access, mixing accurate and absent specifics.","open-source,community,contribution",13,Commit to Contribute
102293,76,half-true,TensorFlow lets users run Python control flow and print values directly during training with eager execution.,debugging with eager execution in TensorFlow 2.x,"Accurate about eager execution and printing, but overstates generality across all TensorFlow APIs and production patterns.","deep-learning,frameworks,tensors",5,Deep Learning
102294,76,TRUE,TensorFlow 2.x allows eager execution enabling printing values and monitoring gradients inside training loops.,"eager execution, GradientTape, TensorFlow 2.x","Passage explicitly shows tf.GradientTape, printing loss.numpy(), and describes monitoring gradients during eager execution.","deep-learning,frameworks,tensors",5,Deep Learning
102295,76,TRUE,TensorFlow 2.x supports eager execution enabling Python control flow and interactive debugging.,eager execution and tf.GradientTape in TensorFlow 2.x,"Example shows tf.GradientTape, printing loss, and Python control flow used interactively, matching support.","deep-learning,frameworks,tensors",5,Deep Learning
102296,163,half-true,The train_loader always yields batches of 64 images per iteration during training.,data loader batch size and train_loader behavior,"Partly correct about 64-image batches, but incorrect to assert it always yields that size; batch size can vary and final batch may differ.","deep-learning,frameworks,tensors",5,Deep Learning
102297,163,half-true,The data loader always provides batches of exactly 64 images per iteration for every dataset.,train_loader batch size and data pipeline,Accurate about common batch usage but wrongly asserts 'always' and 'every dataset'; passage specified 64 for that loader only.,"deep-learning,frameworks,tensors",5,Deep Learning
102298,163,pants-fire,"The train_loader yields 64-image batches until all 60,000 images are processed in an epoch.",data loading with train_loader and batch size 64,"Passage explicitly states batches of 64 are fetched until 60,000 images processed; direct repetition of claim.","deep-learning,frameworks,tensors",5,Deep Learning
102299,79,mostly-true,Datasets should be validated for representativeness before building models to avoid biased outcomes.,dataset representativeness check for demographic or outcome studies,"Supported by passage: emphasizes testing dataset diversity and imbalance concerns, minor caveat about specific validation methods omitted.","data-prep,feature-engineering,rag",3,Prepping Data for AI
102300,79,barely-true,Datasets always require advanced synthetic augmentation before any model training.,dataset validation and feature-engineering for diverse demographics,"Overstates necessity: passage advises testing dataset representativeness, not mandatory synthetic augmentation.","data-prep,feature-engineering,rag",3,Prepping Data for AI
102301,79,FALSE,Dataset representativeness is unnecessary before building models for real-world outcomes.,dataset reflect diversity and imbalance assessment,Contradicts passage advice that datasets must be tested for diversity and imbalances before modeling.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
102302,43,mostly-true,IBM shifted Watson to an open-first watsonx strategy to accelerate innovation with partners.,"open-first strategy with Hugging Face, Meta, Anthropic","Passage states IBM rebooted as watsonx and partnered with those firms, omitting minor implementation details.","ai,open-source,builder",1,Introduction – The Gold Rush Paradox
102303,43,half-true,"IBM's watsonx reboot combined proprietary systems with open collaboration, but overstated ecosystem dominance.","open-first approach with Hugging Face, Meta, Anthropic",Mixes correct reboot and partnerships with incorrect claim that ecosystem dominance was asserted rather than long-term collaborative advantage.,"ai,open-source,builder",1,Introduction – The Gold Rush Paradox
102304,43,barely-true,IBM's open-first watsonx immediately matched ecosystem models' performance and adoption.,"open-first watsonx collaboration with Hugging Face, Meta, Anthropic",Overstates timing and outcome: passage says open approach aided evolution but not immediate parity or adoption metrics.,"ai,open-source,builder",1,Introduction – The Gold Rush Paradox
102305,26,half-true,AI privacy protections completely prevent individual rights violations in deployed systems.,"privacy, data sourcing and lineage","Overstates effectiveness: passage warns privacy is fundamental and violations grow with system power, so protections do not fully prevent harms.","ethics,governance,privacy",11,AI Ethics and Governance
102306,26,TRUE,Privacy is a fundamental ethical challenge in AI requiring protection of how personal data is collected and processed.,privacy and data lineage in AI systems,"Passage states privacy is a fundamental ethical challenge tied to data collection, processing, and protection.","ethics,governance,privacy",11,AI Ethics and Governance
102307,26,mostly-true,AI systems' growing power increases risks to individual privacy and rights without stronger protections.,"privacy, data sourcing, and lineage in AI systems","Passage links increasing system power and pervasiveness to greater privacy risk, omitting specific protections.","ethics,governance,privacy",11,AI Ethics and Governance
102308,5,FALSE,A CNN's convolution always uses 1×1 filters exclusively for edge detection.,"convolution filters in CNNs (2×2, 3×3 filters)","Directly contradicts passage: convolution uses small filters like 2×2 or 3×3, not only 1×1.","neural-networks,cnn,transformers",6,Neuron Building Blocks
102309,5,TRUE,Convolutional filters slide over images to produce feature maps by weighted sums.,convolution operation in CNNs with 2×2 or 3×3 filters,"Directly described: filters multiply with pixel values, sum results, and store totals in feature maps.","neural-networks,cnn,transformers",6,Neuron Building Blocks
102310,5,TRUE,CNN convolutions create feature maps by sliding small filters over images and summing multiplications.,convolution operation with 2×2 or 3×3 filter in CNNs,"Directly supported: passage describes sliding small filters, multiplying and summing to produce feature maps.","neural-networks,cnn,transformers",6,Neuron Building Blocks
102311,78,barely-true,Keras forces users to stay within its standard training loop or abandon higher-level APIs.,frameworks training loop and Keras,"Overstates limitation; passage says stepping outside can make raw TensorFlow or PyTorch easier, not that Keras forces abandonment.","deep-learning,frameworks,tensors",5,Deep Learning
102312,78,FALSE,Keras prevents any modification of its standard training loop by design.,Keras standard training loop and raw TensorFlow or PyTorch,Contradicts passage: Keras allows modifications but suggests dropping to raw TensorFlow or PyTorch when venturing far outside the loop.,"deep-learning,frameworks,tensors",5,Deep Learning
102313,78,FALSE,Keras never allows custom training loops and always forces the standard loop.,Keras training loop and raw TensorFlow,Contradicts passage saying Keras can be extended but may require raw TensorFlow when stepping far outside standard loop.,"deep-learning,frameworks,tensors",5,Deep Learning
102314,138,pants-fire,The dataset contains fabricated OPR and SDR metrics invented after retrieval.,superheroes_info_powers.csv dataset with OPR and SDR fields,Contradicts passage by claiming metrics were invented post-retrieval; passage states OPR and SDR are selected from the dataset.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
102315,138,pants-fire,The dataset includes a secret government-created AI that autonomously rewrites superhero plots.,superheroes_story_plots.csv loaded into ChromaDB vector database,Contradicts passage detail: no secret government AI or autonomous rewriting is mentioned.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
102316,138,half-true,The system uses vector search over a dataset to retrieve time-travel villain story outlines.,ChromaDB vector database with superheroes_story_plots.csv dataset,"Accurate that ChromaDB and a plot dataset are used, but mixes specifics about retrieval focus and villain-only outlines.","data-prep,feature-engineering,rag",3,Prepping Data for AI
102317,160,half-true,"Pseudonymization with spaCy reliably replaces all PERSON, ORG, and GPE mentions in text.",NER pseudonymization using spaCy en_core_web_sm on dataset plots,"Correct that spaCy tags PERSON/ORG/GPE, but claim ignores missed entities, multiword/nickname errors.","data-prep,feature-engineering,rag",3,Prepping Data for AI
102318,160,mostly-true,"Pseudonymizing entities with spaCy's NER reliably replaces PERSON, ORG, and GPE labels with placeholders.",spaCy en_core_web_sm NER on dataset column plots['Plot'],"Example shows automatic doc = nlp(text) tagging and replacements, omitting edge cases like multiword or ambiguous entities.","data-prep,feature-engineering,rag",3,Prepping Data for AI
102319,160,TRUE,"SpaCy's NER can pseudonymize people, organizations, and locations in text automatically.",spaCy en_core_web_sm model pseudonymization of dataset plots,"Listing shows NER tags PERSON, ORG, GPE replaced by placeholders via spaCy pipeline.","data-prep,feature-engineering,rag",3,Prepping Data for AI
102320,29,TRUE,Pandas can fill missing numeric values and drop rows with missing names in one-line operations.,dataframe cleaning using Pandas assign and dropna,Example shows fillna with mean for Age and dropna on Name performed in single-line commands.,"ai,tool-chain,notebooks",2,AI Survival Kit
102321,29,barely-true,"Pandas one-liners scale identically from tiny examples to 100,000-row datasets for cleansing.","Pandas DataFrame cleaning using assign, fillna, dropna","Overreaches: code shows simple operations, but performance and scaling costs (memory, time) are not addressed.","ai,tool-chain,notebooks",2,AI Survival Kit
102322,29,half-true,"Pandas one-line operations scale identically from tiny to 100,000-row datasets without performance change.","Pandas DataFrame operations (assign, fillna, dropna) on dataset","Correct that methods work the same functionally, but performance and memory behavior change with larger datasets.","ai,tool-chain,notebooks",2,AI Survival Kit
102323,33,mostly-true,A logistic regression model can effectively distinguish real Jerry audio from synthetic voice clips in a binary task.,binary classification using logistic regression on voice-cloning audio,"Passage endorses logistic regression as simple, efficient, interpretable and suitable for two-class voice-cloning detection, though real-world performance caveats omitted.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
102324,33,TRUE,A logistic regression model can effectively perform binary classification between Jerry's real voice and synthetic voices.,binary classification using logistic regression on voice-cloning audio,"Passage explicitly recommends logistic regression as simple, efficient, interpretable for two-class voice distinction tasks.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
102325,33,barely-true,Logistic regression reliably distinguishes Jerry's real voice from deepfake audio in all cases.,binary classification using logistic regression on voice-cloning audio,"Overstates reliability and universality; passage presents logistic regression as simple and suitable, not infallible or always accurate.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
102326,11,TRUE,Preparing data consumes about eighty percent of typical machine learning project effort.,"data preparation effort, dataset combining and bias checking","Passage states data prep is approximately 80% of effort, including sourcing, cleaning, and bias checks.","data-prep,feature-engineering,rag",3,Prepping Data for AI
102327,11,half-true,Preparing data usually consumes about 80% of an AI project's effort and is therefore the main workload.,"data preparation effort, dataset cleaning, bias checking",Accurately reflects common 80% claim but overgeneralizes across all projects and ignores variation in tasks and teams.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
102328,11,FALSE,"Model training usually requires the majority of total AI project effort, not data preparation.",effort distribution between data preparation and model training,Contradicts passage claim that data preparation is ~80% of effort and model training ~20%.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
102329,40,mostly-true,Logistic regression can predict multiple classes by estimating class probabilities and choosing the most likely.,multiclass classification with logistic regression model,"Passage describes multiclass capability and probability estimation, omitting only technical methods like softmax.","machine-learning,classification,evaluation",4,Classical Machine Learning
102330,40,half-true,Logistic regression always provides accurate probability estimates for multiclass classification.,multiclass logistic regression model probabilities,Mixes correct use for multiclass with incorrect absolute claim about probability calibration and accuracy.,"machine-learning,classification,evaluation",4,Classical Machine Learning
102331,40,half-true,Logistic regression only supports binary classification and cannot handle multiclass problems.,"multiclass classification, logistic regression model","Passage states logistic regression can handle multiple classes, so claim mixes correct and incorrect specifics.","machine-learning,classification,evaluation",4,Classical Machine Learning
102332,17,mostly-true,"A neuron sums weighted inputs, adds a bias, and applies an activation to decide output.",neuron operation in fully connected dense layer,"Passage explicitly describes combining inputs, applying weights and bias, then using an activation to decide firing; minor simplification of continuous output versus binary 'fire'.","deep-learning,frameworks,tensors",5,Deep Learning
102333,17,half-true,"A dense layer connects every neuron to every neuron in the previous layer, using weights, biases, and activations.",fully connected (dense) layer in neural networks,Accurately describes dense connectivity and neuron operations but oversimplifies activation roles and network depth nuances.,"deep-learning,frameworks,tensors",5,Deep Learning
102334,17,half-true,"A neuron uses weights, a bias, and an activation function to decide whether to pass a signal forward.","neuron decoding; weights, bias, and activation in dense layers","Accurately describes neuron computation but omits that neurons also sum inputs and that activation choice varies, mixing complete and incomplete specifics.","deep-learning,frameworks,tensors",5,Deep Learning
102335,59,mostly-true,The abstraction lets developers switch models and inference settings without changing application logic.,"inference abstraction enabling model, max token, and temperature parameters","Supports separation of application logic from model specifics and dynamic model switching, omitting potential integration costs.","agentic-ai,planning,tools",12,Agentic AI
102336,59,half-true,"The abstraction lets developers switch models without changing application logic, enabling effortless multi-model testing.","inference abstraction for model, max token, and temperature parameters","Correct about dynamic model switching and parameter control, but overstates ease and ignores integration complexities and testing limitations.","agentic-ai,planning,tools",12,Agentic AI
102337,59,TRUE,The abstraction enables switching models without modifying application logic.,"inference abstraction controlling model, max token, temperature parameters","Passage explains the abstraction separates application logic from model-specific details, enabling dynamic model changes for testing and deployment.","agentic-ai,planning,tools",12,Agentic AI
102338,134,mostly-true,AI builders remain accountable for tools and components included in their tool-chain.,responsibility for tools in an AI survival kit; tool-chain,"Passage emphasizes builder accountability for ingredients and tools, omitting implementation nuances.","ai,tool-chain,notebooks",2,AI Survival Kit
102339,134,mostly-true,AI builders remain accountable for tools and data chosen for their systems.,responsibility and tool choice in AI survival kit,"Passage emphasizes builder accountability for tools, data sources, and choices, omitting few caveats.","ai,tool-chain,notebooks",2,AI Survival Kit
102340,134,barely-true,AI builders can offload accountability for tool choices to community-supported tools and libraries.,tool choices and community support for AI builders,Contradicts passage's assertion that accountability remains with builders despite community or tool provenance.,"ai,tool-chain,notebooks",2,AI Survival Kit
102341,89,half-true,"The passage claims lightweight JSONL logging enables reproducible, scalable inference tracking but omits hardware details.",model_log.jsonl logging for T5-small LIAR benchmark,"Partly accurate: structured logs capture batch size and latency, yet lack critical hardware and load specifics.","mlops,scaling,deployment",10,AI At Scale
102342,89,FALSE,The logging example intentionally omits storing model gradients for reproducibility.,logging structured inference metadata with tokenizer and batch_size,"Log shows inference-time fields only and lacks gradient or optimizer state details, contradicting storage claim.","mlops,scaling,deployment",10,AI At Scale
102343,89,TRUE,"The log entry records batch size, input length, predicted label, and inference time for reproducibility.","model_log.jsonl tracking inference metrics (batch_size, input_length)","Log explicitly includes batch_size, tokenized input length, predicted_label, and inference_time_sec for reproducibility.","mlops,scaling,deployment",10,AI At Scale
102344,82,barely-true,VAEs always outperform GANs on complex generative tasks.,comparison between VAEs and GANs (probabilistic vs adversarial),"Overreaches beyond passage: passage only notes different frameworks, not superior performance.","generative-ai,diffusion,gans",7,Generative AI
102345,82,FALSE,VAEs use adversarial training identical to GANs to generate images efficiently.,model comparison between VAEs and GANs,"Contradicts passage: VAEs use a probabilistic framework, not adversarial training like GANs.","generative-ai,diffusion,gans",7,Generative AI
102346,82,half-true,"VAEs and GANs use fundamentally different training frameworks, combining probabilistic inference with adversarial optimization.","generative model comparison (VAE probabilistic framework, GAN adversarial training)",Mixes correct distinction with incorrect claim of combination; passage contrasts frameworks but not combined use.,"generative-ai,diffusion,gans",7,Generative AI
102347,47,mostly-true,An RNN character-level model can be trained interactively to predict next characters from a short input string.,RNN character-level prediction interactive demo,"Demonstration shows live training on a user string to output next-character predictions, omitting larger-dataset caveats.","neural-networks,cnn,transformers",6,Neuron Building Blocks
102348,47,mostly-true,The RNN demo trains live on a user-entered string to predict next characters.,"RNN character-level prediction demo, interactive input and predict button","Demonstration shows live training on single input string and next-character predictions, omitting scalability limits.","neural-networks,cnn,transformers",6,Neuron Building Blocks
102349,47,half-true,An RNN trained interactively on a single input string will generalize to predict unseen sequence patterns.,interactive RNN character-level prediction example,Mixes correct interactive training and next-character prediction with incorrect claim of generalization beyond the single training string.,"neural-networks,cnn,transformers",6,Neuron Building Blocks
102350,64,TRUE,"Fine-tuning pretrained models speeds convergence and stabilizes training on similar, small datasets.",fine-tuning pretrained model on simple binary images in PyTorch,"Passage states fine-tuning helps when data is stylistically similar, small, and yields faster, more stable training.","generative-ai,diffusion,gans",7,Generative AI
102351,64,half-true,Fine-tuning often preserves low-level features but can misadapt specific stylistic details like slashes.,fine-tuning pretrained model on simple binary images,Accurately notes preserved low-level features and risks misadapting specific new patterns like slashes.,"generative-ai,diffusion,gans",7,Generative AI
102352,64,FALSE,Fine-tuning always requires retraining models from scratch on large datasets.,fine-tuning of pre-trained models (PyTorch) for stylistic adaptation,Contradicts passage: fine-tuning avoids retraining from scratch and is useful with small datasets.,"generative-ai,diffusion,gans",7,Generative AI
102353,64,FALSE,Deepfake defense requires inventing a new vocoder incompatible with SpeechT5 models.,pre-trained SpeechT5 model and vocoder setup,Contradicts passage which uses existing SpeechT5 vocoder; no suggestion to invent incompatible vocoders.,"media-forensics,voice-cloning,deepfake",9,Deepfake Defense
102354,64,TRUE,The workflow pairs audio clips with transcripts in CSV for aligned training data.,input preparation for SpeechT5 dataset alignment,"Passage explicitly instructs pairing audio clips with transcripts in CSV to create clean, aligned training data.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
102355,64,half-true,The workflow requires pairing audio clips with transcripts in CSV for aligned training.,input preparation using dataset CSV and transcripts,Accurate about CSV pairing and alignment but omits model setup and vocoder installation details.,"media-forensics,voice-cloning,deepfake",9,Deepfake Defense
102356,170,mostly-true,Self-supervised learning trains models to predict masked parts of input from context.,self-supervised learning applied to masked prediction on unlabeled datasets,"Matches passage describing masking and predicting missing pieces, omitting minor implementation caveats.","machine-learning,classification,evaluation",4,Classical Machine Learning
102357,170,FALSE,Self-supervised learning requires labeled datasets to train fill-in-the-blank models.,"self-supervised learning, fill-in-the-blank task on text","Contradicts passage: method trains on large unlabeled datasets, not labeled data.","machine-learning,classification,evaluation",4,Classical Machine Learning
102358,170,TRUE,A self-supervised learning model predicts masked parts of input using surrounding context.,masked prediction on unlabeled text dataset,"Passage describes hiding input pieces and training to predict them, using unlabeled text context.","machine-learning,classification,evaluation",4,Classical Machine Learning
102359,52,TRUE,The code defines a TensorFlow Keras Sequential model with an input layer and a Dense output layer.,"tf.keras Sequential model, Input layer shape (784,), Dense layer","Code snippet shows tf.keras.Sequential with tf.keras.layers.Input and tf.keras.layers.Dense, matching description.","deep-learning,frameworks,tensors",5,Deep Learning
102360,52,TRUE,The code defines a Keras Sequential model with an input layer and a Dense output layer.,"TensorFlow Keras model definition (Input, Dense)","Code shows tf.keras.Sequential with tf.keras.layers.Input(shape=(784,)) and tf.keras.layers.Dense(10), directly defining the model.","deep-learning,frameworks,tensors",5,Deep Learning
102361,52,half-true,The code uses SGD with SparseCategoricalCrossentropy for a linear 10-class classifier on 784-feature inputs.,tf.keras model using SGD optimizer and SparseCategoricalCrossentropy,"Accurate optimizer and loss, but implies training details and logits handling beyond shown small Sequential model.","deep-learning,frameworks,tensors",5,Deep Learning
102362,85,TRUE,A Variational Autoencoder compresses data into a latent representation while adding randomness for diverse generation.,VAE encoder-decoder latent representation,Passage explicitly describes VAEs compressing data into latents and adding randomness to enable generative diversity.,"generative-ai,diffusion,gans",7,Generative AI
102363,85,half-true,A VAE compresses data into a latent space and injects randomness to produce diverse outputs.,Variational Autoencoder (VAE) encoder-decoder latent representation,"Accurately describes encoder-decoder and stochastic latent sampling, but omits details about KL loss and probabilistic posterior.","generative-ai,diffusion,gans",7,Generative AI
102364,85,half-true,A VAE compresses data into a latent representation and adds randomness for generative diversity.,variational autoencoder (VAE) latent representation and randomness,"Accurately describes encoder–decoder VAE and stochastic latent sampling, but omits details like KL loss and approximate posterior.","generative-ai,diffusion,gans",7,Generative AI
102365,175,half-true,Self-supervised learning always outperforms supervised learning on image classification tasks.,"self-supervised learning, image datasets, representation learning",Mixes correct point about SSL learning representations with incorrect absolute claim of always outperforming supervised methods.,"machine-learning,classification,evaluation",4,Classical Machine Learning
102366,175,FALSE,Self-supervised learning requires labeled datasets for training useful representations.,self-supervised learning (SSL) and unlabeled datasets,"Contradicts passage: SSL explicitly learns from unlabeled data and delays labels, not requires them.","machine-learning,classification,evaluation",4,Classical Machine Learning
102367,175,half-true,"Self-supervised learning can learn useful representations before labels are available, but sometimes requires task-specific finetuning.",self-supervised learning (SSL) representation learning on unlabeled datasets,"Passage states SSL learns representations early from unlabeled data, but omits that downstream task-specific finetuning is often needed.","machine-learning,classification,evaluation",4,Classical Machine Learning
102368,73,half-true,Fine-tuning a pretrained GAN reliably converts generators trained on circles into ones producing slashes.,fine-tuning pretrained generator for shape transfer in GANs,Mixes correct concept of adapting outputs with overconfident claim of reliable conversion despite GAN instability.,"generative-ai,diffusion,gans",7,Generative AI
102369,73,pants-fire,Pretrained GANs can instantly generate realistic high-resolution photographs without any further training.,"GANs, fine-tuning on slashes, generator instability",Contradicts passage: GANs are unstable and require fine-tuning; instant high-resolution photo generation is implausible.,"generative-ai,diffusion,gans",7,Generative AI
102370,73,half-true,Fine-tuning a pretrained GAN can adapt its generator from circles to slashes with moderate effort.,"GAN fine-tuning of pretrained generator on shape types (circles, slashes)",Mixes correct transfer learning benefit with unspecified effort and ignores GAN instability challenges.,"generative-ai,diffusion,gans",7,Generative AI
102371,135,barely-true,Agentic AI fully eliminates human oversight across all logistics decision-making processes.,logistics delivery route and supply chain optimization agents,Overreaches beyond passage: agents reduce routine oversight but do not claim total removal of human oversight.,"agentic-ai,planning,tools",12,Agentic AI
102372,135,mostly-true,Agentic AI can autonomously optimize logistics operations like routing and inventory monitoring.,"automating business workflows, logistics and supply chain agents","Passage describes agents adjusting delivery routes and monitoring inventory in real time, omitting limits and human oversight nuances.","agentic-ai,planning,tools",12,Agentic AI
102373,135,mostly-true,Agentic AI can autonomously adjust logistics routes and monitor inventory in real time to improve operations.,Automating business workflows; logistics optimization and inventory monitoring,"Passage describes agents adjusting delivery routes and monitoring inventory, omitting deployment challenges and human oversight nuances.","agentic-ai,planning,tools",12,Agentic AI
102374,45,mostly-true,Larger transformer models require proportionally more diverse training data to avoid plateauing or regression.,scaling transformer models using datasets like LIAR,Passage links model growth to data quality/variety and warns performance can plateau or regress without it.,"mlops,scaling,deployment",10,AI At Scale
102375,45,half-true,Larger transformer models always need proportionally more diverse data to improve performance.,scaling models with datasets like LIAR,"Partly accurate: data diversity matters, but claim overstates requirement as models can benefit from optimization, curriculum, or augmented data without strictly proportional increases.","mlops,scaling,deployment",10,AI At Scale
102376,56,half-true,Radcliffe fellows are required to collaborate intensively during their fellowship year.,Radcliffe Institute fellowship selection and program,Mixes correct fellowship selection detail with incorrect claim that collaboration was mandatory; passage implies surprise rather than requirement.,"ethics,governance,privacy",11,AI Ethics and Governance
102377,56,half-true,Radcliffe Institute fellows are coerced into collaborative work during their fellowship year.,Radcliffe Institute fellowship selection and collaboration,Mixes fact (selecting ~50 fellows) with incorrect characterization: 'forced' implies coercion not supported.,"ethics,governance,privacy",11,AI Ethics and Governance
102378,56,half-true,Radcliffe Institute fellows are required to collaborate intensively throughout their fellowship year.,selection and fellowship activities (Radcliffe Institute fellows),Mixes correct selection of fellows with incorrect stronger claim—passage only mentions being 'forced to work together' anecdotally.,"ethics,governance,privacy",11,AI Ethics and Governance
102379,156,barely-true,ToTensor always converts PIL images into PyTorch tensors and rescales pixels from 0–255 to 0.0–1.0.,transforms.ToTensor() operation on PIL image,"Passage claims automatic conversion and scaling, but ToTensor behavior varies with image modes and dtypes.","deep-learning,frameworks,tensors",5,Deep Learning
102380,156,FALSE,ToTensor() converts PIL images into NumPy arrays scaled to 0–1.,transforms.ToTensor() converting PIL images to tensors,"Contradicts passage: toTensor() produces PyTorch tensors, not NumPy arrays.","deep-learning,frameworks,tensors",5,Deep Learning
102381,156,FALSE,The ToTensor transform converts PIL images into NumPy arrays scaled to 0–1.,transforms.ToTensor() converting PIL image pixels,"Contradicts passage: ToTensor produces a PyTorch tensor, not a NumPy array; scaling to 0–1 is correct.","deep-learning,frameworks,tensors",5,Deep Learning
102382,29,half-true,"The passage claims MFCCs, spectral centroid, and zero-crossing rate together capture subtle genuine-voice qualities.",feature extraction of Jerry's clip using MFCCs and spectral centroid,Mixes correct feature uses with implied completeness; omits limitations and other necessary forensic features.,"media-forensics,voice-cloning,deepfake",9,Deepfake Defense
102383,29,TRUE,"MFCCs, spectral centroid, and zero-crossing rate offer complementary views of voice characteristics.","feature extraction from Jerry's audio clip (MFCCs, spectral centroid, zero-crossing rate)",Passage explicitly states those three features provide different views and meaningful perspectives on genuine voice.,"media-forensics,voice-cloning,deepfake",9,Deepfake Defense
102384,29,half-true,"MFCCs, spectral centroid, and zero-crossing rate together always reliably identify genuine voices.","feature extraction: MFCCs, spectral centroid, zero-crossing rate","Mixes correct features with an overstated guarantee; passage says they provide perspectives, not foolproof identification.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
102385,50,half-true,GAN training often fails because generators always collapse to a single output mode.,GAN mode collapse during image generation,"Correct that mode collapse occurs, but incorrect to say it always collapses to a single mode; severity and occurrence vary.","generative-ai,diffusion,gans",7,Generative AI
102386,50,TRUE,GAN training often suffers from mode collapse causing limited output diversity.,"generative adversarial network (GAN) training, generator and discriminator balance",Passage explicitly describes mode collapse producing limited variety and gives image-generation example and balancing issues.,"generative-ai,diffusion,gans",7,Generative AI
102387,50,pants-fire,GANs never experience mode collapse when trained with adequate compute.,"GAN training, mode collapse, generator and discriminator balance",Directly contradicts passage: passage states mode collapse occurs and balancing networks is a critical hurdle.,"generative-ai,diffusion,gans",7,Generative AI
102388,70,barely-true,The Gini coefficient reliably measures label imbalance in all classification datasets.,"dataset category imbalance, Gini coefficient",Overstates reliability; Gini applies to imbalance but may miss multiclass nuances and dataset-specific issues.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
102389,70,pants-fire,The Gini coefficient proves datasets are always perfectly balanced after preprocessing.,Gini coefficient for category imbalance in datasets,"Contradicts Gini meaning and passage: Gini measures imbalance, cannot prove perfect balance; extreme implausibility.","data-prep,feature-engineering,rag",3,Prepping Data for AI
102390,70,barely-true,Gini coefficient always reliably diagnoses dataset category imbalance for model training decisions.,"dataset category imbalance, Gini coefficient",Overstates reliability; passage affirms Gini measures imbalance but omits limitations for model training decisions.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
102391,188,half-true,RAG systems eliminate bias by automatically correcting skewed training data during retrieval.,RAG retrieval-augmented generation with datasets and tools,Mixes correct RAG use for augmentation with incorrect claim that it automatically removes dataset bias without human intervention.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
102392,188,mostly-true,Preprocessing and feature engineering broadly reduce model errors but can leave residual biases.,data-prep and feature engineering for datasets and models,Passage links bias to data and promises bias techniques later; preprocessing helps yet may omit some bias fixes.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
102393,188,mostly-true,Open-source tools like Scikit-learn are used to build classic ML models for prediction and classification.,using Scikit-learn for classic machine learning,Passage explicitly mentions Scikit-learn and classic ML for predicting outcomes and classifying categories.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
102394,46,TRUE,"The LIAR dataset includes labels like true, false, and pants on fire for claims.",LIAR dataset and companion set for short-form reasoning,Passage explicitly lists those labels and mentions a companion LIAR-style dataset for testing.,"mlops,scaling,deployment",10,AI At Scale
102395,41,mostly-true,Adding a flag column for imputed values generally improves data clarity and model handling.,imputation flag column for dataset preprocessing,Supports passage claim that adding a small flag like “avg_used?” tracks imputations and aids clarity.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
102396,41,half-true,Imputing missing values and adding a flag always prevents downstream model confusion.,"dataset imputation, flag column (e.g., avg_used?), feature engineering",Claim mixes correct practice (imputation plus flagging helps) with overclaim that it invariably prevents confusion.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
102397,41,half-true,Imputing missing values with an average and adding an 'avg_used?' flag always improves model performance.,feature engineering; imputation flag (avg_used?) for dataset preprocessing,Combines correct advice about imputation flags with an incorrect absolute claim that averaging always boosts model performance.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
102398,27,barely-true,Open-source contributions require formal AI agent approval before inclusion.,"glossary of open-source projects, frameworks, libraries, datasets, and tools","Overstates process: passage mentions using AI agents to compile a glossary, not requiring formal approval.","open-source,community,contribution",13,Commit to Contribute
102399,116,FALSE,Including unique identifiers like author names always improves classification accuracy.,feature design for classification using dataset identifiers,"Contradicts passage: unique identifiers (names) cause memorization and harm generalization, not improve accuracy.","machine-learning,classification,evaluation",4,Classical Machine Learning
102400,116,mostly-true,Excluding unique identifiers like names prevents models from memorizing publishers and improves generalization.,feature design; unique identifier (name) in dataset preprocessing,"Supported by passage: names described as unique identifiers that cause memorization and noise, minor caveat about other identifier uses omitted.","machine-learning,classification,evaluation",4,Classical Machine Learning
102401,116,half-true,Including unique identifiers like author names can cause a classifier to memorize publishers rather than learn patterns.,"feature design for classification, unique identifier (name)","Partially correct: names can cause memorization, but claim omits cases where identifiers are predictive or regularized.","machine-learning,classification,evaluation",4,Classical Machine Learning
102402,36,TRUE,AI judge models like GPT-4 can score answers for relevance and clarity during evaluations.,evaluation pipeline using MT-Bench and judge models,Passage explicitly describes a panel of AI judges (often GPT-4) scoring relevance and clarity on MT-Bench.,"mlops,scaling,deployment",10,AI At Scale
102403,36,barely-true,MT-Bench uses other large models like GPT-4 as automated judges to score model responses.,evaluation using MT-Bench and GPT-4 as judge models,"Passage describes AI judge panel often being another model like GPT-4 scoring relevance and clarity, but overstates universality.","mlops,scaling,deployment",10,AI At Scale
102404,36,mostly-true,AI judge models like GPT-4 often score other models’ responses on relevance and clarity.,evaluation with MT-Bench leaderboard and judge model (GPT-4),Passage describes a panel of AI judges (often GPT-4) scoring relevance and clarity on MT-Bench.,"mlops,scaling,deployment",10,AI At Scale
102405,96,barely-true,CrewAI makes multi-agent coordination fully automated and reliable across arbitrary tasks.,"agentic-ai flow using LangChain, persistent agents, and reusable tasks",Overstates capabilities: passage notes improved structure and persistence but not full automation or universal reliability.,"agentic-ai,planning,tools",12,Agentic AI
102406,96,FALSE,Agentic systems always require persistent agents to coordinate multi-step tasks.,persistent agents and flows in LangChain/CrewAI integration,"Passage describes persistent agents as a design choice, not a strict requirement; contradicts assumption of necessity.","agentic-ai,planning,tools",12,Agentic AI
102407,96,half-true,"CrewAI extends LangChain by adding persistent agents, reusable tasks, and flexible execution flows.",agentic AI system using LangChain and CrewAI,Accurately states added features but omits potential limitations and implementation trade-offs.,"agentic-ai,planning,tools",12,Agentic AI
102408,173,mostly-true,A linear layer with 128 outputs in a network serves as dimensionality reduction for flattened MNIST inputs.,nn.Linear layer reducing 784-pixel MNIST vectors,"Passage explains flattening 784 pixels and explicitly calls nn.Linear with 128 outputs a form of dimensionality reduction, omitting minor effects like learned feature quality.","deep-learning,frameworks,tensors",5,Deep Learning
102409,173,FALSE,A nn.Linear layer with 128 outputs cannot perform dimensionality reduction on flattened MNIST inputs.,nn.Linear layer with 128 outputs on flattened MNIST,Contradicts passage which explicitly states the nn.Linear layer with 128 outputs acts as dimensionality reduction.,"deep-learning,frameworks,tensors",5,Deep Learning
102410,173,half-true,A single nn.Linear layer reliably extracts digit-defining features from flattened MNIST inputs.,nn.Linear layer dimensionality reduction on MNIST flattened 784-pixel input,"Partly correct that linear layer reduces dimensionality, but overstates reliable feature extraction without nonlinearity or deeper model.","deep-learning,frameworks,tensors",5,Deep Learning
102411,25,mostly-true,The experiment creates audio fingerprints from Librosa features to distinguish individual voices.,audio fingerprint using Librosa features for voice-cloning detection,Describes experiment goal and use of Librosa features; omits implementation limits and dataset size.,"media-forensics,voice-cloning,deepfake",9,Deepfake Defense
102412,25,FALSE,Audio fingerprints summarize distinctive acoustic patterns of voices for AI comparison.,audio fingerprinting using Librosa feature set,"Contradicts experiment specifics: fingerprints here summarize voice clips, not Shazam-scale song identification.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
102413,25,half-true,The experiment claims an audio fingerprint can uniquely identify individual voices using selected Librosa features.,audio fingerprinting using Librosa features and voice samples,"Correct that Librosa features and fingerprints are used, but uniqueness and reliable identification of individual voices is overstated without validation.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
102414,166,half-true,Diffusion models can convert language prompts into short videos with convincing results.,diffusion models converting language to short videos,"Correct that diffusion enables text-to-visual generation, but overstates current routine quality and prevalence of short-video generation.","generative-ai,diffusion,gans",7,Generative AI
102415,166,half-true,Diffusion models reliably convert language into high-quality short videos with few limitations.,diffusion models converting language to short videos,"Passage claims diffusion adds video generation, but real-world systems still face quality and controllability limits.","generative-ai,diffusion,gans",7,Generative AI
102416,166,half-true,Diffusion models convert language into short videos in current generative workflows.,diffusion models converting language to video,"Mixes correct trend (diffusion enabling video) with overstatement about current widespread, mature language-to-video capability.","generative-ai,diffusion,gans",7,Generative AI
102417,167,TRUE,Evaluation commonly uses larger batch sizes than training because weights are not updated during evaluation.,batch size for evaluation versus training in deep-learning,"Passage explains training uses smaller batches for frequent noisy updates, while evaluation has no weight updates, so larger batches are typical.","deep-learning,frameworks,tensors",5,Deep Learning
102418,167,TRUE,Evaluation typically uses larger batch sizes than training because weights are not updated.,batch_size during evaluation versus training,"Passage explains evaluation has no weight updates, so larger batch_size is common compared to training.","deep-learning,frameworks,tensors",5,Deep Learning
102419,167,barely-true,Models always evaluate with much larger batch sizes than they train with.,evaluation vs training batch_size in deep learning,Overgeneralizes passage: evaluation can use larger batches but 'always' and 'much larger' are unsupported and exaggerated.,"deep-learning,frameworks,tensors",5,Deep Learning
102420,37,mostly-true,NumPy is a foundational Python library that simplifies numerical array and matrix computations for AI.,tool: NumPy library for numerical computing in AI,"Passage credits NumPy for efficient array/matrix operations and scientific computing, omitting some modern ecosystem details.","ai,tool-chain,notebooks",2,AI Survival Kit
102421,37,TRUE,NumPy simplifies complex mathematical operations for arrays and matrices in AI workflows.,tool: NumPy for numerical computing,Passage states NumPy makes numerical computing more efficient and simplifies array and matrix operations.,"ai,tool-chain,notebooks",2,AI Survival Kit
102422,37,mostly-true,NumPy is commonly used to simplify array and matrix computations in AI workflows.,tool: NumPy for mathematical operations in AI,Passage attributes NumPy to efficient array and matrix math but omits some specialized libraries.,"ai,tool-chain,notebooks",2,AI Survival Kit
102423,68,barely-true,Open-source collaboration alone guarantees sustained ethical progress in AI development.,auditing models with SHAP and Fairlearn in AI ethics,Overreaches beyond passage: openness aids progress but does not alone guarantee ethical outcomes.,"ai,open-source,builder",1,Introduction – The Gold Rush Paradox
102424,68,TRUE,Shared knowledge and community contributions sustain AI progress through openness and ethics.,openness and tools like SHAP and Fairlearn,"Passage states shared knowledge, ethics, and collaboration sustain progress and cites auditing tools.","ai,open-source,builder",1,Introduction – The Gold Rush Paradox
102425,68,mostly-true,"Open community contributions broadly steer AI development, though practical constraints can limit impact.",open-source community contributions and tools like SHAP,"Passage emphasizes shared knowledge, collaboration, and tools auditing models; omits practical limits and constraints.","ai,open-source,builder",1,Introduction – The Gold Rush Paradox
102426,37,FALSE,The foreword claims interviews were fabricated using deepfake audio without disclosure.,ethical design discussion about AI systems and misuse,Contradicts passage: foreword questions deepfake concerns but does not assert audio deepfakes or undisclosed fabrication.,"open-source,community,ai",0,Foreword – Robo Interviews Clément Delangue
102427,37,barely-true,The interview is a deceptive deepfake created solely by AI without human quotes.,ethical design and AI testing discussion,"Overreaches: passage questions deepfake concerns but states quotes are wired into dialogue and explores ethics, not claiming pure AI fabrication.","open-source,community,ai",0,Foreword – Robo Interviews Clément Delangue
102428,37,half-true,"The interview uses real quotes but frames them in a structured, possibly misleading AI-generated dialogue.",ethical design and AI testing of quoted dialogue,Mixes correct concern about wiring real quotes with an overreach implying the interview is definitively misleading.,"open-source,community,ai",0,Foreword – Robo Interviews Clément Delangue
102429,127,half-true,An optimizer updates neural network weights to balance steady improvement and flexibility during training.,optimizer role in handwritten digit recognition task,Describes correct optimizer purpose but glosses over specific mechanisms and hyperparameter trade-offs.,"deep-learning,frameworks,tensors",5,Deep Learning
102430,127,mostly-true,A well-tuned optimizer helps neural networks balance steady improvement with adaptive weight updates.,optimizer role in handwritten digit recognition and agent training,"Passage supports that optimizers guide weight updates for steady improvement and adaptability, omitting specific algorithms or tuning details.","deep-learning,frameworks,tensors",5,Deep Learning
102431,127,TRUE,Optimizers guide neural network weight updates to balance steady improvement and adaptability.,"optimizer role in handwritten digit recognition, weight updates",Passage explicitly describes optimizers advising weight updates to balance steady improvement and flexibility.,"deep-learning,frameworks,tensors",5,Deep Learning
102432,16,FALSE,RAG systems cannot incorporate third-party documents without risk of hidden instructions.,Retrieval-Augmented Generation (RAG) systems or plugins,Contradicts passage which states RAG systems can be exploited via indirect injection through scraped documents containing hidden instructions.,"security,red-team,guardrails",8,Breaking-Securing AI
102433,16,TRUE,Indirect instruction injection exploits documents and web content retrieved by RAG systems.,Retrieval-Augmented Generation (RAG) systems and plugins,Passage describes embedding instructions in scraped documents and web content that RAG pulls into context unnoticed.,"security,red-team,guardrails",8,Breaking-Securing AI
102434,16,TRUE,RAG systems can be exploited via indirect instruction injections embedded in retrieved documents.,Retrieval-Augmented Generation (RAG) systems and plugins,"Passage directly describes indirect injection exploiting documents scraped into RAG contexts, enabling hidden instructions.","security,red-team,guardrails",8,Breaking-Securing AI
102435,29,half-true,Backpropagation tells the optimizer exactly how to set each weight to minimize loss every step.,training process using backpropagation and optimizer,Mixes correct idea (backpropagation finds gradients) with incorrect certainty (doesn't determine exact final weight settings each step).,"deep-learning,frameworks,tensors",5,Deep Learning
102436,29,TRUE,Lower loss indicates a neural network is performing better on its training objective.,training loss and optimizer updates during backpropagation,Loss quantifies error; backpropagation computes gradients and optimizers adjust weights to reduce loss.,"deep-learning,frameworks,tensors",5,Deep Learning
102437,29,barely-true,Lower loss always guarantees better real-world performance of a neural network.,training loss and optimizer adjustments during backpropagation,Overstates relationship: training loss can drop while generalization or real-world performance worsens.,"deep-learning,frameworks,tensors",5,Deep Learning
102438,139,TRUE,Legislators proposed new laws in response to Taylor Swift deepfakes circulating online.,legal response to deepfake media and voice-cloning incidents,"News reports describe congressional calls for legislation after Taylor Swift deepfakes circulated, supporting claim.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
102439,139,half-true,Some lawmakers proposed legislation to restrict celebrity voice-cloning after Taylor Swift deepfakes circulated online.,media coverage of Taylor Swift deepfakes and voice-cloning tools,Accurately links Swift deepfakes and legislative calls but overstates unanimity and specific proposed restrictions.,"media-forensics,voice-cloning,deepfake",9,Deepfake Defense
102440,139,TRUE,Congressional members are calling for new legislation in response to Taylor Swift deepfakes.,news report on deepfake incidents involving a public figure,"Article reports lawmakers urging new laws after Taylor Swift deepfakes, directly supporting claim.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
102441,35,mostly-true,Setting random_state=42 produces a reproducible train/test split in scikit-learn code.,train/test split reproducibility using random_state parameter,Directly supported: random_state fixes the seed for consistent splits; minor caveat about library specifics omitted.,"machine-learning,classification,evaluation",4,Classical Machine Learning
102442,35,TRUE,Setting random_state=42 ensures reproducible train/test splits in experiments.,random_state parameter in train/test split,Passage explicitly states random_state=42 fixes the seed so splits are identical across runs.,"machine-learning,classification,evaluation",4,Classical Machine Learning
102443,35,pants-fire,The regression intercept of 161.7 proves the model is perfectly accurate for all adults.,"regression intercept, train/test split, random_state=42",Intercept cannot guarantee perfect accuracy; contradicts regression basics and dataset variability.,"machine-learning,classification,evaluation",4,Classical Machine Learning
102444,35,half-true,PyTorch is widely used for building and serving models across modern RAG workflows.,PyTorch usage with retrieval-augmented generation and TorchServe,"Partially accurate: PyTorch is emphasized for building and serving models, but claiming 'widely used across RAG workflows' mixes supported examples with broader generalization beyond provided instances.","open-source,community,contribution",13,Commit to Contribute
102445,35,half-true,PyTorch is the dominant framework for all modern AI retrieval and serving workflows.,model serving and RAG with PyTorch and vector databases,"Accurately notes PyTorch's broad use but overstates dominance across all retrieval, vector DB, and serving workflows.","open-source,community,contribution",13,Commit to Contribute
102446,35,barely-true,PyTorch is the only viable framework for all modern AI tasks and deployment.,tool discussion mentioning PyTorch and TorchServe,Passage praises PyTorch but notes multiple roles; claiming exclusivity is unsupported and overreaching.,"open-source,community,contribution",13,Commit to Contribute
102447,55,barely-true,Whisper-style models can perfectly recreate a speaker's voice from transcripts alone.,voice cloning using transcripts and Whisper,Overreaches: passage says transcripts enable synthetic voice creation but not perfect voice recreation; omits modeling limitations and audio data needs.,"media-forensics,voice-cloning,deepfake",9,Deepfake Defense
102448,55,mostly-true,Automatic transcription models like Whisper enable creating synthetic voices from recorded speech.,speech-to-text model Whisper used for voice cloning,"Passage states Whisper transcribes audio and that transcripts are used to create a synthetic version, omitting technical limits.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
102449,55,TRUE,"Speech-to-text models can transcribe continuous sound into searchable, structured language.",speech-to-text model (Whisper) transcribing audio to transcripts,"Passage states Whisper converts continuous sound waves into structured, searchable text used for further processing.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
102450,64,half-true,Open-source tools like Gandalf and LYNX help build defenses but may not fully prevent AI hallucinations.,"defense using tools Gandalf, LYNX, HumanLayer for prompt injection mitigation",Mixes correct claim about using Gandalf and LYNX for defenses with overstated effectiveness against all hallucinations.,"ai,open-source,builder",1,Introduction – The Gold Rush Paradox
102451,64,FALSE,Open-source tools prevent all AI prompt injection and hallucination failures.,"using open tools such as Gandalf, LYNX, and HumanLayer",Contradicts passage by claiming complete prevention; passage says tools help build defenses after understanding failures.,"ai,open-source,builder",1,Introduction – The Gold Rush Paradox
102452,64,FALSE,Open-source tool Gandalf is proven to eliminate all AI prompt injection vulnerabilities.,open tools Gandalf and HumanLayer for defenses,"Contradicts passage: Gandalf listed as a defense tool, not claimed to fully eliminate prompt injection vulnerabilities.","ai,open-source,builder",1,Introduction – The Gold Rush Paradox
102453,107,half-true,Hugging Face tokens can be created with default scopes via the account settings token page.,Hugging Face access token page (huggingface.co/settings/tokens),"Partly correct: instructions mention creating a new token with defaults, but omits scope/security tradeoffs and required consent.","ai,tool-chain,notebooks",2,AI Survival Kit
102454,107,barely-true,Hugging Face tokens must be purchased to access model endpoints.,tool: Hugging Face access token instructions,"Contradicts passage instructions: tokens are free and generated via account settings, not purchased.","ai,tool-chain,notebooks",2,AI Survival Kit
102455,107,FALSE,Hugging Face tokens must be purchased before use.,Hugging Face access token generation (tool),Contradicts passage; tokens are free and created via +Create New Token in account settings.,"ai,tool-chain,notebooks",2,AI Survival Kit
102456,116,TRUE,Autoregressive models generate tokens sequentially using past context to decide each next token.,"autoregressive language models in NLP (GPT-3, GPT-4, machine translation)","Passage states models use past context and a sequential process, citing GPT-3/GPT-4 and translation.","generative-ai,diffusion,gans",7,Generative AI
102457,116,barely-true,"Generative models always operate autoregressively, predicting one token strictly from past context.",autoregressive language models and token prediction,Overreach: passage states many models use past context but ignores non-autoregressive diffusion or GAN approaches.,"generative-ai,diffusion,gans",7,Generative AI
102458,116,mostly-true,"Autoregressive models generate outputs token-by-token using past context, enabling coherent results.","autoregressive language models, token sequencing",Supported by passage that models use past context sequentially; omits occasional non-autoregressive approaches.,"generative-ai,diffusion,gans",7,Generative AI
102459,93,barely-true,The Crew runs autonomously to completion without any human intervention by default.,Crew process and Agent control in crewai example,"Passage asserts crews run to completion and AI infers outcomes, but omits configurable interrupts and human-in-the-loop options.","agentic-ai,planning,tools",12,Agentic AI
102460,93,mostly-true,The Crew can autonomously run a sequence of agent tasks to completion without human intervention.,Crew process coordinating Agent tasks and Task delegation,"Passage describes a Crew managing task delegation and running to completion autonomously, though later caveat about overrides omitted.","agentic-ai,planning,tools",12,Agentic AI
102461,93,half-true,The Crew runs tasks to completion by default without further external triggers.,Crew process and agent-controlled task delegation in the crewai example,"Correct that crews proceed automatically in example, but overstates unconditional autonomy and ignores configurable stoppage or human intervention options.","agentic-ai,planning,tools",12,Agentic AI
102462,106,half-true,An added Judge agent independently evaluates player responses using tools and structured prompts.,"multi-agent design involving Game Master, players, tools, and prompt structure","Partly correct: passage suggests adding a Judge and tools, but doesn't confirm independent evaluation implementation.","agentic-ai,planning,tools",12,Agentic AI
102463,106,mostly-true,The passage describes expanding multi-agent roles with tools and structured interactions for better evaluation.,"agent roles, tools, prompt structure, data flow","Broadly supported: text shows adding tools, a Judge, and shaping agent interactions, omitting implementation caveats.","agentic-ai,planning,tools",12,Agentic AI
102464,106,half-true,Giving the Game Master a current‑events tool always improves trivia generation quality.,"agent roles and tool integration (Game Master, tools, prompt structure)",Tool use can help but passage only suggests questioning it; blanket 'always improves' overstates benefits and tradeoffs.,"agentic-ai,planning,tools",12,Agentic AI
102465,185,TRUE,A learning rate of 0.001 generally provides stable optimization steps for training neural networks.,learning rate in optimizer for neural network training,Passage explicitly endorses 0.001 as balancing steady progress without overshooting during optimization.,"deep-learning,frameworks,tensors",5,Deep Learning
102466,185,mostly-true,A learning rate of 0.001 is generally a good default for training neural networks with cross-entropy loss.,optimizer hyperparameter for models using nn.CrossEntropyLoss and classification tasks,"Recommendation aligns with guidance in passage but omits dataset, architecture, and optimizer-specific tuning caveats.","deep-learning,frameworks,tensors",5,Deep Learning
102467,185,FALSE,A learning rate of 0.1 is recommended for stable training with cross-entropy classification.,learning rate for optimizer while using nn.CrossEntropyLoss(),Contradicts passage recommending 0.001 as balanced; 0.1 would likely overshoot and destabilize training.,"deep-learning,frameworks,tensors",5,Deep Learning
102468,92,half-true,A fixed 0.7 threshold reliably prevents adversarial prompts without further tuning.,threshold tuning for adversarial prompts and model output filtering,Mixes correct emphasis on a 0.7 threshold with incorrect claim it needs no extensive testing or periodic retraining.,"security,red-team,guardrails",8,Breaking-Securing AI
102469,92,half-true,Intelligent filtering with a 0.7 threshold reliably prevents most hallucinations in deployed models.,hallucination detection and intelligent filtering threshold,Partially true: filtering helps but 0.7 is tentative and requires extensive testing and retraining per passage.,"security,red-team,guardrails",8,Breaking-Securing AI
102470,92,TRUE,Intelligent filtering and retraining with adversarial prompts improve model robustness against hallucinations.,threshold tuning and adversarial prompts for hallucination detection,"Passage recommends testing a 0.7 threshold, periodic retraining, and intelligent filtering to reduce hallucinations.","security,red-team,guardrails",8,Breaking-Securing AI
102471,99,TRUE,A second model instance can serve as a Reviewer to check an initial model's answer for plausibility.,two-model Colab implementation using an open model Reviewer,Passage describes handing generated output to a second instance called the Reviewer to assess plausibility and accuracy.,"security,red-team,guardrails",8,Breaking-Securing AI
102472,99,half-true,Using two model instances can simulate a simple fact-checking layer for generated responses.,Reviewer model simulating hallucination checking with an open model instance,"Accurate about layered simulation, but overstates effectiveness—method doesn't catch every factual error or deep hallucinations.","security,red-team,guardrails",8,Breaking-Securing AI
102473,99,half-true,Using a second model Reviewer reliably detects most hallucinations from the first model instance.,two-instance Reviewer fact-checking setup,Mixes correct layered review idea with incorrect confidence: Reviewer helps but won't reliably detect most hallucinations.,"security,red-team,guardrails",8,Breaking-Securing AI
102474,78,TRUE,"Larger, more diverse datasets generally produce smoother, more natural results.",dataset processing with tokenized audio and speaker embeddings,"Passage explicitly states larger, diverse datasets yield smoother, more natural results and mentions tokenization and embeddings.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
102475,78,barely-true,"Larger, more diverse datasets always produce more natural speech in voice-cloning models.",dataset size and speaker embeddings for voice cloning,"Overreaches by asserting inevitability; passage says they usually, not always, yield smoother results.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
102476,78,half-true,"Larger, diverse audio-text datasets always produce more natural deepfake audio outputs.",dataset size and preprocessing steps for audio+text tokenization,"Correct that larger datasets often improve naturalness, but 'always' overstates certainty and ignores preprocessing limits like speaker embeddings.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
102477,126,TRUE,Optimizers adjust network weights and biases based on calculated gradients.,"optimizer role in deep learning training (gradients, weights, biases)",Passage describes optimizers managing weight and bias updates using gradients to minimize loss and improve predictions.,"deep-learning,frameworks,tensors",5,Deep Learning
102478,126,half-true,Optimizers update neural network weights using gradients to minimize loss during training.,optimizers and gradients in deep learning,"Correctly states optimizers use gradients to update weights and minimize loss, but omits specific algorithms or mechanics.","deep-learning,frameworks,tensors",5,Deep Learning
102479,126,TRUE,Optimizers update neural network weights and biases to minimize loss during training.,"optimizers in neural network training (gradients, weights, biases)",Directly supported by passage describing optimizers using gradients to update weights and reduce loss.,"deep-learning,frameworks,tensors",5,Deep Learning
102480,105,half-true,A circulated 2024 celebrity deepfake falsely depicted Taylor Swift endorsing a political candidate.,video manipulation example; deepfake videos on social media,Accurately cites a reported 2024 celebrity deepfake but implies broad circulation and impact without evidence.,"media-forensics,voice-cloning,deepfake",9,Deepfake Defense
102481,105,FALSE,No convincing celebrity deepfake videos circulated on social media in early 2024.,deepfake videos featuring celebrities on social media,"Passage explicitly mentions convincing celebrity deepfakes in early 2024, including a Taylor Swift example.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
102482,105,FALSE,Deepfake videos have never targeted celebrities or political topics in 2024.,video manipulation examples mentioning deepfake videos,"Contradicts passage which cites convincing celebrity deepfakes in early 2024, including a false Taylor Swift endorsement.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
102483,165,barely-true,The example shows masking phone numbers and adding Laplace noise to ages for anonymization.,data masking and differential privacy on a health records dataset,"Partly accurate: masking and Laplace noise are shown, but impact on model accuracy and privacy guarantees are not fully demonstrated.","data-prep,feature-engineering,rag",3,Prepping Data for AI
102484,165,barely-true,The example proves differential privacy always preserves model accuracy while anonymizing ages.,data masking and differential privacy example using age and phone fields,Contradicts passage warning that added noise can impact model accuracy and requires testing.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
102485,165,half-true,The example mixes correct masking with an oversimplified description of differential privacy's guarantees.,data masking and differential privacy on age and phone fields,"Masking shown correctly, but Laplace noise example omits formal DP parameters and formal privacy guarantees.","data-prep,feature-engineering,rag",3,Prepping Data for AI
102486,81,half-true,The authors provide notebooks and a Colab Securing AI Notebook to build an intelligent defense gateway.,"Securing AI Notebook, GitHub repository, defense gateway architecture","Partly correct: notebooks and Colab link exist, but claim mixes precise architectural guidance with implied completeness.","security,red-team,guardrails",8,Breaking-Securing AI
102487,114,barely-true,Embeddings always retrieve perfectly relevant documents for any user prompt.,retrieval using embeddings in RAG systems,Overstates capability; passage explains embedding search returns similar matches but not guaranteed perfect relevance.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
102488,114,half-true,Embeddings always retrieve perfectly relevant context for RAG prompts without needing filtering.,retrieval-augmented generation using embeddings,Mixes truth about embeddings enabling retrieval with incorrect claim that filtering or relevance scoring isn’t needed.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
102489,114,half-true,Embedding search always retrieves perfectly relevant data for retrieval-augmented generation workflows.,embedding search for RAG in dataset retrieval,Mixes correct mechanism (embeddings used for retrieval) with incorrect certainty that matches are always perfectly relevant.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
102490,49,mostly-true,"The prompt template abstraction makes agent outputs more consistent, reproducible, and adaptable.",prompt template abstraction for agentic AI and dynamic input,"Passage explicitly cites consistency, dynamic input, and reproducibility but omits potential limitations or edge cases.","agentic-ai,planning,tools",12,Agentic AI
102491,49,FALSE,The prompt template abstraction makes agent outputs entirely deterministic and non-random.,prompt template abstraction for agent prompts,Contradicts passage: abstraction reduces randomness but does not make outputs entirely deterministic.,"agentic-ai,planning,tools",12,Agentic AI
102492,49,mostly-true,The prompt template abstraction generally makes agent outputs more consistent and reproducible with dynamic inputs.,"prompt template abstraction, variable substitution, reproducibility","Passage describes structured prompts enforcing consistency, dynamic variable substitution, and improved reproducibility, omitting potential limitations.","agentic-ai,planning,tools",12,Agentic AI
102493,66,FALSE,The passage argues open-source contributions are unnecessary for AI development success.,open collaboration and community effort in AI,"Contradicts passage emphasis on shared tools, transparency, and community being central to AI growth.","open-source,community,contribution",13,Commit to Contribute
102494,66,half-true,Open collaboration alone ensured AI growth through shared tools and community effort.,"open collaboration, shared tools, community effort",Mixes correct points about shared tools and community with incorrect causal certainty that collaboration alone ensured AI growth.,"open-source,community,contribution",13,Commit to Contribute
102495,66,TRUE,The passage argues that AI advancement relies on open collaboration and community contributions.,"open collaboration, shared tools, community effort","Directly supported by phrase listing shared tools, transparent choices, and community effort driving AI growth.","open-source,community,contribution",13,Commit to Contribute
102496,182,barely-true,Synthetic datasets fully preserve real-world statistical properties for safe model training.,synthetic data for dataset creation in data-prep,"Overstates reliability: passage warns synthetic data can miss nuances (gender, age) and depends on generator quality.","data-prep,feature-engineering,rag",3,Prepping Data for AI
102497,182,barely-true,Synthetic data reliably prevents all privacy risks when used for model training.,synthetic data for datasets and model training,Overstates protection: passage notes synthetic data reduces but does not eliminate privacy risks and can introduce issues.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
102498,182,half-true,Synthetic data reliably preserves all demographic nuances for safe model training in healthcare.,synthetic data for datasets and model training,"Overstates reliability: synthetic data can protect privacy but may miss demographic nuances like gender or age, risking unintended effects.","data-prep,feature-engineering,rag",3,Prepping Data for AI
102499,46,TRUE,Hugging Face model names and versions can change over time.,model management for Hugging Face models,"Passage explicitly warns that Hugging Face models can change names, be replaced, or move versions.","data-prep,feature-engineering,rag",3,Prepping Data for AI
102500,46,TRUE,Hugging Face models can change names or be replaced over time.,model versions and naming on Hugging Face,"Passage explicitly warns that Hugging Face models may change names, be replaced, or move versions.","data-prep,feature-engineering,rag",3,Prepping Data for AI
102501,46,barely-true,Hugging Face model names are stable and never change across versions.,Hugging Face models and versioning in dataset/model management,"Contradicts passage noting models can change names, be replaced, or move versions; overstates stability.","data-prep,feature-engineering,rag",3,Prepping Data for AI
102502,68,barely-true,ONNX Runtime provides a unified inference API identical across major deep-learning frameworks.,ONNX Runtime model portability for PyTorch and Keras,Overstates exact identity: passage shows similar APIs but omits framework-specific conversion caveats and limits.,"deep-learning,frameworks,tensors",5,Deep Learning
102503,68,mostly-true,ONNX enables exporting models from PyTorch for portable inference across runtimes.,model export and inference using ONNX Runtime,Supported by examples showing torch.onnx.export and identical onnxruntime inference across frameworks.,"deep-learning,frameworks,tensors",5,Deep Learning
102504,68,mostly-true,ONNX enables easy model portability and consistent inference across deep-learning frameworks.,ONNX export and ONNX Runtime for PyTorch and Keras models,"Passage shows exporting PyTorch/Keras to ONNX and identical ONNX Runtime inference API, minor deployment caveats omitted.","deep-learning,frameworks,tensors",5,Deep Learning
102505,43,TRUE,Regularization and logging tools improve model robustness and accountability in ML workflows.,"weight decay in PyTorch; MLflow, TensorBoard, TFX, Kubeflow tools","Passage explicitly cites weight decay, MLflow/TensorBoard, and TFX/Kubeflow as supporting robustness and accountability.","ethics,governance,privacy",11,AI Ethics and Governance
102506,43,barely-true,Regularization alone guarantees prevention of spurious correlations in models.,regularization and weight decay in PyTorch,Overstates effectiveness: passage says regularization helps but doesn't guarantee prevention.,"ethics,governance,privacy",11,AI Ethics and Governance
102507,43,mostly-true,Regularization and logging practices largely ensure model reliability and reproducibility in ML pipelines.,"regularization, MLflow, torch.save, TFX","Supported by mention of weight decay, MLflow/TensorBoard logging, torch.save, and TFX, but omits limits of regularization and monitoring.","ethics,governance,privacy",11,AI Ethics and Governance
102508,99,FALSE,Green Arrow and Darth Vader are grouped together in the same cluster.,hero clustering using similarity scores,Contradicts passage: Green Arrow is in the broad cluster while Darth Vader is in the cosmic cluster.,"machine-learning,classification,evaluation",4,Classical Machine Learning
102509,99,half-true,The Kryptonian cluster is the most cohesive cluster with a 0.49 internal similarity score.,cluster cohesion using internal similarity metric,"Correct about Kryptonian cluster and 0.49 score, but overstates 'most cohesive' without comparing all clusters' exact scores.","machine-learning,classification,evaluation",4,Classical Machine Learning
102510,86,barely-true,Most deep learning frameworks require input normalization to mean 0 and standard deviation 1.,input normalization for deep learning frameworks,Overreaches: frameworks commonly expect normalized inputs but do not strictly require mean 0 and std 1.,"deep-learning,frameworks,tensors",5,Deep Learning
102511,86,barely-true,Deep learning frameworks always require input data normalized to mean 0 and standard deviation 1.,input normalization for deep learning frameworks,"Overreaches: frameworks commonly assume normalized inputs, but 'always require' and exact mean/std=1 is unsupported.","deep-learning,frameworks,tensors",5,Deep Learning
102512,86,half-true,Most deep learning frameworks require input data normalized to mean 0 and standard deviation 1.,input normalization for deep learning frameworks and BatchNorm,"Partially correct: frameworks expect normalized inputs, but 'require' and exact mean/std=1 is overstated and missing common preprocessing variations.","deep-learning,frameworks,tensors",5,Deep Learning
102513,85,barely-true,A lightweight classifier can perfectly block all prompt injections before they reach the main model.,injection detector classifier used as a gatekeeper,Overclaims effectiveness; passage says detector filters and flags prompts but not perfect blocking or complete prevention.,"security,red-team,guardrails",8,Breaking-Securing AI
102514,85,half-true,A lightweight injection classifier can pre-filter prompts before they reach the main language model.,inference pipeline using Hugging Face pipelines and a trained classifier,Mixes correct pipeline use and gatekeeper role with unclear detection reliability and evaluation details omitted.,"security,red-team,guardrails",8,Breaking-Securing AI
102515,85,mostly-true,A lightweight classifier can filter prompts before they reach a chatbot's main language model.,training a lightweight injection detector using Hugging Face Trainer,"Passage describes training and using a classifier as a gatekeeper to score and flag bypassing prompts, omitting deployment scale caveats.","security,red-team,guardrails",8,Breaking-Securing AI
102516,124,half-true,A fixed learning rate often causes initial fast learning but then prevents final convergence in deep learning.,"learning rate schedulers, optimizer, convergence","Correctly notes fast initial learning and need for smaller steps, but overstates that fixed rates always prevent convergence; schedulers automate adjustments.","deep-learning,frameworks,tensors",5,Deep Learning
102517,124,mostly-true,Learning rate schedulers typically reduce step sizes during training to help models converge.,learning rate schedulers in optimization for model training,"Passage explains schedulers automate reducing learning rates as models get closer to convergence, omitting scheduler types and exceptions.","deep-learning,frameworks,tensors",5,Deep Learning
102518,124,mostly-true,Learning rate schedulers help models take larger initial steps and smaller steps near convergence.,learning rate schedulers in deep-learning training,"Passage describes automated schedule for larger early updates and smaller steps as model nears convergence, omitting scheduler types and specific algorithms.","deep-learning,frameworks,tensors",5,Deep Learning
102519,112,mostly-true,A red team simulates intelligent adversaries to find and document vulnerabilities in AI systems.,security role description for AI red team,"Directly described in passage: offensive group performs controlled testing and documents exploits, minor omitted scope.","security,red-team,guardrails",8,Breaking-Securing AI
102520,112,barely-true,Red teams always find all vulnerabilities in AI systems during controlled testing.,role description for Red Team in security practice,"Overreaches: passage says Red Team simulates adversary and finds vulnerabilities, not that they find all issues.","security,red-team,guardrails",8,Breaking-Securing AI
102521,112,barely-true,Red teams alone can fully secure AI systems against intelligent adversaries.,role description for Red Team offensive security,"Overstates role: passage says Red Team simulates adversaries and finds vulnerabilities, not that they alone secure systems.","security,red-team,guardrails",8,Breaking-Securing AI
102522,129,FALSE,Good optimizers typically cause loss to explode and worsen digit predictions during training.,optimizer behavior in deep-learning training,"Contradicts passage: optimizers are described as preventing exploding loss and stabilizing predictions, not causing worsening updates.","deep-learning,frameworks,tensors",5,Deep Learning
102523,129,barely-true,A poor optimizer makes a deep learning model increasingly misclassify digits with growing confidence.,optimizer behavior in digit classification training,Passage describes exploding loss and wildly swinging weight updates causing confident misclassification during training.,"deep-learning,frameworks,tensors",5,Deep Learning
102524,129,barely-true,Vanishing gradients cause neural networks to become confidently wrong about digit labels.,optimizer behavior and loss explosion in deep learning training,"Passage describes exploding updates causing confident misclassification, but attributes to optimizer issues not vanishing gradients specifically.","deep-learning,frameworks,tensors",5,Deep Learning
102525,12,half-true,"A single training step on a small MNIST subset produces meaningful, generalizable convolutional filters.",visualizing conv1 filters and activations from MNIST with a SimpleCNN,"Correct that initial filters form patterns, but claim overstates generalizability after one training step on 64 images.","neural-networks,cnn,transformers",6,Neuron Building Blocks
102526,12,barely-true,A single training step on 64 MNIST images fully trains useful convolutional filters for classification.,SimpleCNN training on MNIST subset and conv1 filters,Contradicts passage: only one step on 64 images is described as barely enough to learn anything useful.,"neural-networks,cnn,transformers",6,Neuron Building Blocks
102527,12,TRUE,A simple CNN learns early convolutional filters and activations after a single training step on MNIST.,SimpleCNN on MNIST conv1 filters and activations,"Example shows conv1 weights and activations plotted after one training step, demonstrating early learned features.","neural-networks,cnn,transformers",6,Neuron Building Blocks
102528,39,mostly-true,Adversaries can plant training-data poisoning backdoors that subtly bias deployed models.,poisoning training data; backdoors; model failure modes,"Passage describes poisoning inserting backdoors and false associations, warning of hard-to-detect model biases.","security,red-team,guardrails",8,Breaking-Securing AI
102529,39,half-true,Poisoning training data can insert backdoors and induce brittle failure modes in models.,training data poisoning and backdoors in model security,Accurately notes backdoors and brittleness but omits difficulty of pinpointing specific poisoned tokens.,"security,red-team,guardrails",8,Breaking-Securing AI
102530,39,mostly-true,Poisoning training data can insert backdoors and brittle failure modes into a model.,training data poisoning and backdoors in model guardrails,Passage directly describes poisoning inserting backdoors and nudging models toward brittle failure modes.,"security,red-team,guardrails",8,Breaking-Securing AI
102531,21,half-true,Running earlier notebook cells always prevents development environment errors.,"notebook execution, play button, code cell workflow",Partially correct: skipping cells often causes errors but some errors arise from environment or dependencies not just missed cells.,"ai,tool-chain,notebooks",2,AI Survival Kit
102532,21,barely-true,The notebook setup rarely requires troubleshooting beyond rerunning missed cells.,notebooks; development environment setup,Overreaches the passage: it implies rarity of issues while passage only warns missed cells often cause errors.,"ai,tool-chain,notebooks",2,AI Survival Kit
102533,21,barely-true,The notebook requires running earlier code cells before executing later ones to avoid errors.,"notebooks development environment, code cells","Passage indicates errors likely arise from not running previous code cells, so claim is largely supported but obvious.","ai,tool-chain,notebooks",2,AI Survival Kit
102534,3,TRUE,Building an AI personally increases trust because creators know its data and code.,building your own AI; data and code transparency,"Directly supported by passage claiming knowing data, code, and makers reduces mystery and risk.","ai,open-source,builder",1,Introduction – The Gold Rush Paradox
102535,3,pants-fire,All open-source AI builders always ensure absolute trust by fully revealing every dataset and code detail.,building your own AI; data and code transparency,"Passage claims knowing ingredients increases trust, but absolute, universal full revelation is implausible and contradicted by practical limits and privacy.","ai,open-source,builder",1,Introduction – The Gold Rush Paradox
102536,3,TRUE,"Knowing an AI's data, code, and choices increases trust in systems built by the user.","builder knowing data, code, and reasoning","Directly supported: passage says understanding data, code, and reasoning reduces mystery and increases trust.","ai,open-source,builder",1,Introduction – The Gold Rush Paradox
102537,104,TRUE,Feature selection should align chosen predictors with the model's intended questions.,feature selection for customer engagement score and OPR/SDR,"Passage states job is selecting features to match model questions, citing engagement score and OPR/SDR trade-offs.","data-prep,feature-engineering,rag",3,Prepping Data for AI
102538,104,TRUE,Feature selection should align with the specific questions the model needs to answer.,"feature selection for customer engagement score and features like OPR, SDR","Directly supported by passage emphasizing choosing features that match the model's intended questions (OPR, SDR).","data-prep,feature-engineering,rag",3,Prepping Data for AI
102539,104,pants-fire,The engagement score directly measures model accuracy on OPR and SDR tasks.,"customer engagement score blending clicks, purchases, time on site",Claim contradicts passage: engagement score blends signals and does not directly measure model accuracy on OPR or SDR.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
102540,181,half-true,Classical ML tools always simplify debugging when used with AI-driven coding support.,classical ML algorithms and AI-driven coding support,"Mixes truth and error: classical ML is well-documented and aids drafting, but unlimited tools can complicate debugging.","machine-learning,classification,evaluation",4,Classical Machine Learning
102541,181,TRUE,Classical ML algorithms are well-documented and suitable for AI-driven coding support.,classical ML algorithms and AI-driven coding support,"Passage explicitly states classical ML are stable, well-documented, and fit for AI-driven coding support.","machine-learning,classification,evaluation",4,Classical Machine Learning
102542,181,mostly-true,Classical ML algorithms are well-suited for AI-driven coding support but still require human oversight.,classical ML algorithms and human-in-the-loop usage,"Passage supports suitability and notes essential human oversight, omitting potential tool limits and debugging complications.","machine-learning,classification,evaluation",4,Classical Machine Learning
102543,15,TRUE,Supervised learning trains models on labeled restaurant reviews to predict sentiment labels.,dataset of restaurant reviews and labeled examples,Directly described: models learn patterns from labeled reviews to classify tone as positive or negative.,"machine-learning,classification,evaluation",4,Classical Machine Learning
102544,15,TRUE,Supervised learning can train a model to classify restaurant reviews as positive or negative.,sentiment classification of restaurant reviews (labeled dataset),Directly supported by passage describing labeled examples and model learning to predict review tone.,"machine-learning,classification,evaluation",4,Classical Machine Learning
102545,15,half-true,Supervised classifiers always achieve high accuracy when trained on labeled review datasets.,supervised learning on restaurant reviews dataset,"Overstates performance: passage says supervised learning shines with plenty of reliable labels, but not guaranteed high accuracy due to model or data limitations.","machine-learning,classification,evaluation",4,Classical Machine Learning
102546,58,pants-fire,A Transformer model always achieves perfect sentiment classification on any sentence.,sentiment-analysis pipeline using DistilBERT transformer,"Directly contradicts example probabilities; model outputs probabilistic labels, not perfect certainty.","neural-networks,cnn,transformers",6,Neuron Building Blocks
102547,58,half-true,DistilBERT-based sentiment pipelines always correctly capture full sentence context for sentiment classification.,Hugging Face Transformers sentiment-analysis pipeline using DistilBERT,Mixes truth and error: DistilBERT pipelines model context but can miss nuances and sometimes misclassify.,"neural-networks,cnn,transformers",6,Neuron Building Blocks
102548,58,half-true,DistilBERT always correctly detects sentence-level sentiment across varied phrasings and contexts.,sentiment-analysis pipeline using DistilBERT from Hugging Face Transformers,"Model often works but examples show context-sensitive failures and probability variability, overstating certainty.","neural-networks,cnn,transformers",6,Neuron Building Blocks
102549,47,barely-true,"Hugging Face's open-source community single-handedly guarantees rapid, flawless AI model innovation worldwide.","Hugging Face community, 250,000 models and 50,000 datasets",Overstates community role and certainty; passage cites large contributions but not sole or flawless guarantee.,"open-source,community,ai",0,Foreword – Robo Interviews Clément Delangue
102550,47,half-true,Hugging Face's open-source community mixes global collaboration with overstated scale claims about models and datasets.,"Hugging Face community, models and datasets counts","Accurate about global collaboration and mission, but numerical counts are presented as possibly exaggerated or outdated.","open-source,community,ai",0,Foreword – Robo Interviews Clément Delangue
102551,47,pants-fire,Hugging Face single-handedly created all open-source AI models worldwide.,Hugging Face community and dataset/model counts,"Contradicts passage specifics: passage credits global collaborative contributions and cites 250,000 models and 50,000 datasets, not single-handed creation.","open-source,community,ai",0,Foreword – Robo Interviews Clément Delangue
102552,26,FALSE,Pandas DataFrames were invented in 2018 for handling image datasets in deep learning.,Pandas DataFrame usage and origin,"Contradicts origin year and purpose: created by Wes McKinney in 2008 for financial/tabular data, not 2018 or images.","ai,tool-chain,notebooks",2,AI Survival Kit
102553,26,barely-true,Pandas DataFrame was created by Wes McKinney in 2008 for large financial datasets.,tool: Pandas DataFrame development and history,"Partially accurate: McKinney did create Pandas for finance in 2008, but wording overstates singular intent and features.","ai,tool-chain,notebooks",2,AI Survival Kit
102554,26,mostly-true,Pandas DataFrame originated to handle large financial datasets and became core to modern data work.,tool Pandas DataFrame for data manipulation,"Supported by passage: McKinney created DataFrame for massive financial datasets, later popularized in Python for Data Analysis, minor caveat about other contributors omitted.","ai,tool-chain,notebooks",2,AI Survival Kit
102555,21,barely-true,AI agents always independently coordinate complex missions without human input.,agentic-ai missions and tools coordination,"Overreaches beyond passage: agents often collaborate and may use human guidance, not always independent.","agentic-ai,planning,tools",12,Agentic AI
102556,21,FALSE,AI agents operate solely as static prompts without decision-making or tool use.,"Agents and Tools, decision-making, retrieval",Contradicts claim that agents incorporate decision-making and use tools for retrieval and task execution.,"agentic-ai,planning,tools",12,Agentic AI
102557,21,mostly-true,AI agents coordinate tools and retrieval to plan and execute goal-driven missions in real environments.,"agentic-ai using tools, retrieval, and task coordination","Broadly supported: passage describes agents using tools, decision-making, retrieval, and collaborative missions, omitting limits or failure modes.","agentic-ai,planning,tools",12,Agentic AI
102558,133,TRUE,Synthetic data is recommended for filling dataset gaps and supporting testing rather than production.,synthetic data for RAG pipeline dataset,"Passage advises using synthetic data to fill gaps, support testing, and not as production backbone.","data-prep,feature-engineering,rag",3,Prepping Data for AI
102559,133,half-true,Synthetic data can safely serve as a production backbone for RAG pipelines in storytelling datasets.,synthetic dataset for RAG pipeline (superheroes_story_plots.csv),"Passage recommends synthetic data for gaps and testing, not as production backbone; mixes correct use with incorrect production claim.","data-prep,feature-engineering,rag",3,Prepping Data for AI
102560,133,half-true,Synthetic data can safely serve as the primary training dataset for production RAG systems.,synthetic dataset superheroes_story_plots.csv used in RAG pipeline,Mixes correct use of synthetic data for gaps with incorrect claim it's safe as production backbone.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
102561,11,mostly-true,Benchmarking Java application servers helped identify impactful performance improvements.,DayTrader benchmark suite for Java application servers,Based on IBM and partners’ use of DayTrader benchmarking to reveal weaknesses and guide improvement decisions.,"mlops,scaling,deployment",10,AI At Scale
102562,11,TRUE,Benchmarking Java application servers helped identify performance improvement opportunities.,DayTrader benchmark suite for Java application servers,Passage recounts co-authoring industry benchmarks like DayTrader to reveal where improvements mattered.,"mlops,scaling,deployment",10,AI At Scale
102563,11,TRUE,Benchmarking helps identify performance gaps and prioritize impactful improvements.,benchmarking DayTrader benchmark suite for Java application servers,Directly supported by experience with DayTrader and industry benchmarks showing where to improve and prioritize actions.,"mlops,scaling,deployment",10,AI At Scale
102564,77,mostly-true,K-Means groups data into K clusters by assigning points to nearest centroids iteratively.,K-Means clustering algorithm for unsupervised learning and clustering,Describes core algorithmic process accurately; omits caveats about initialization sensitivity and cluster shape assumptions.,"machine-learning,classification,evaluation",4,Classical Machine Learning
102565,77,TRUE,K-Means groups data points into K clusters by assigning them to nearest centroids iteratively.,K-Means clustering algorithm,"Passage describes assigning items to nearest group and updating centers until stabilization, matching iterative centroid assignment.","machine-learning,classification,evaluation",4,Classical Machine Learning
102566,77,TRUE,K-Means clustering groups data into K clusters by assigning points to nearest centers iteratively.,"K-Means clustering algorithm, clusters and centers","Describes iterative assignment to nearest centers and updating until stabilization, matching passage.","machine-learning,classification,evaluation",4,Classical Machine Learning
102567,56,pants-fire,Open-source contributors must always publish their AI model weights under GPLv3 to keep forks open.,license guidance for model code and weights,"Contradicts guideline: GPLv3 applies to code, not universally required for model weights or datasets.","open-source,community,contribution",13,Commit to Contribute
102568,56,barely-true,Open-source projects should always use GPL v3 to guarantee broad corporate adoption.,software license guidance for OSS and AI model components,"Claim overstates recommendation; passage says GPL v3 ensures copyleft, not corporate adoption.","open-source,community,contribution",13,Commit to Contribute
102569,56,mostly-true,"Choosing an open-source license depends on desired adoption, legal protection, and openness of forks.","license guidance for open-source projects (MIT, Apache 2.0, GPL v3, Creative Commons)","Guidance broadly matches passage: trade-offs among adoption, corporate use, and fork openness, minor simplifications.","open-source,community,contribution",13,Commit to Contribute
102570,35,half-true,GAN training alternates generator and discriminator updates in a minimax two-player zero-sum game.,"GAN training loop, generator and discriminator minimax framework",Accurately states adversarial minimax game and alternating updates but omits practical instabilities and optimization details.,"generative-ai,diffusion,gans",7,Generative AI
102571,35,half-true,GAN training involves a minimax adversarial game between generator and discriminator during learning.,Generative Adversarial Nets (GAN) training process,Accurately states adversarial minimax setup but omits practical issues like instability and mode collapse.,"generative-ai,diffusion,gans",7,Generative AI
102572,35,TRUE,GAN training involves a two-player zero-sum game between generator and discriminator.,"training loop for GANs in PyTorch, TensorFlow, or Keras",Described as a minimax two-player zero-sum game where generator minimizes and discriminator maximizes.,"generative-ai,diffusion,gans",7,Generative AI
102573,127,TRUE,RAG uses structured character data like hero attributes to maintain narrative consistency.,RAG example using hero attributes dataset,Passage describes RAG ingesting hero attributes to keep characters consistent for story generation.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
102574,127,mostly-true,RAG benefits from structured hero attribute datasets to keep generated characters consistent.,RAG applied to narrative generation using hero attributes dataset,"Supports passage: structured hero attributes help RAG maintain character consistency, minor implementation details omitted.","data-prep,feature-engineering,rag",3,Prepping Data for AI
102575,127,FALSE,RAG requires only hero attribute tables and no external documents for story generation.,RAG use with dataset and retrieval documents,Contradicts RAG concept by ignoring retrieval from external documents; passage lists hero attributes plus implied external sources.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
102576,73,FALSE,T5-small cannot perform English-to-French translation in real time.,T5ForConditionalGeneration model usage in transformers,Contradicts passage claiming t5-small handles real-time translation; performance trade-offs noted but not impossible.,"neural-networks,cnn,transformers",6,Neuron Building Blocks
102577,73,mostly-true,A small T5 transformer can perform English-to-French translation effectively for lightweight use cases.,T5ForConditionalGeneration model (t5-small) from transformers library,"Model choice and code example show t5-small handles translation well, omitting larger-model tradeoffs.","neural-networks,cnn,transformers",6,Neuron Building Blocks
102578,73,pants-fire,T5-small translates English to French perfectly without any errors or limitations.,T5ForConditionalGeneration model (t5-small) translator example,"Passage states a simple demo; claiming perfect, error-free translation contradicts model limitations and real-world performance.","neural-networks,cnn,transformers",6,Neuron Building Blocks
102579,91,mostly-true,"Variational Autoencoders (VAEs) are commonly applied across domains like images, digits, and speech.","VAE applications to natural images, handwritten digits, and speech","Passage explicitly lists those domains, so claim is broadly supported with no major caveats.","generative-ai,diffusion,gans",7,Generative AI
102580,91,half-true,"Variational autoencoders are commonly applied to natural images, handwritten digits, and speech datasets.","VAE applications (natural images, handwritten digits, speech)","Accurately lists domains mentioned but omits specifics about architectures, datasets, or performance trade-offs.","generative-ai,diffusion,gans",7,Generative AI
102581,91,TRUE,"VAEs are widely used across domains like natural images, handwritten digits, and speech.","application domains for VAEs (natural images, digits, speech)","Passage explicitly lists those domains as common VAE applications, directly supporting the claim.","generative-ai,diffusion,gans",7,Generative AI
102582,118,pants-fire,Hugging Face guarantees unlimited free GPU production hosting for all models at any scale.,infrastructure choices: Hugging Face community Spaces and managed clusters,"Contradicts passage: free CPU tier exists but managed GPU clusters are paid, not unlimited free hosting.","mlops,scaling,deployment",10,AI At Scale
102583,118,half-true,Hugging Face always scales seamlessly from CPU to dedicated GPU clusters without any reconfiguration.,deployment using Hugging Face infrastructure and open-source tools,Mixes correct scaling options with incorrect claim that no reconfiguration is ever needed; tools often carry forward but changes may be required.,"mlops,scaling,deployment",10,AI At Scale
102584,118,mostly-true,Users can prototype on free CPU tiers and scale to managed GPU clusters without rebuilding tools.,"Hugging Face infrastructure choices, community Spaces, managed clusters","Supported by passage: free CPU tier prototypes scale to dedicated GPU clusters using same open-source tools, minor nuance about cost/performance tradeoffs omitted.","mlops,scaling,deployment",10,AI At Scale
102585,12,half-true,Hugging Face originally adopted the hugging face emoji as a playful company ticker idea.,company branding and ticker symbol (hugging face emoji),"Matches passage about joking adoption, but misstates public listing detail as actual ticker decision.","open-source,community,ai",0,Foreword – Robo Interviews Clément Delangue
102586,12,TRUE,Hugging Face founders initially used the hugging face emoji playfully as their brand identifier.,brand naming and ticker idea in Hugging Face origin story,Directly supported by founder's quote describing playful use of the hugging face emoji while building.,"open-source,community,ai",0,Foreword – Robo Interviews Clément Delangue
102587,12,TRUE,Hugging Face adopted the hugging face emoji as a playful company symbol early on.,"company branding and ticker symbol, hugging face emoji",Directly supported by Delangue saying they chose the hugging face emoji as a playful symbol and potential ticker.,"open-source,community,ai",0,Foreword – Robo Interviews Clément Delangue
102588,27,mostly-true,Data must be cleaned and normalized before training most AI models.,data cleaning and normalization for datasets,Passage endorses cleaning/normalizing datasets first; minor caveat about exceptions omitted.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
102589,27,pants-fire,Data normalization is unnecessary for preparing datasets for AI models.,Cleaning and Normalizing dataset preprocessing,Directly contradicts stated need to clean and normalize data before model use; denies dataset tuning requirement.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
102590,27,FALSE,Rerunning a code block is sufficient to clean and normalize all datasets for AI models.,data cleaning and Normalizing in dataset preprocessing,Contradicts passage: cleaning requires broader steps beyond rerunning code; normalization and consistency are needed.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
102591,43,pants-fire,"LangChain prompt templates can autonomously plan, execute, and self-correct complex tasks without human oversight.",prompt template design in LangChain ChatPromptTemplate,"Contradicts passage: templates standardize prompts but do not provide autonomous planning, execution, or self-correction.","agentic-ai,planning,tools",12,Agentic AI
102592,43,FALSE,Prompt templates prevent any variability in agent responses under all conditions.,LangChain ChatPromptTemplate and prompt templates,Contradicts passage: templates standardize and reduce variability but do not eliminate all response variation.,"agentic-ai,planning,tools",12,Agentic AI
102593,43,FALSE,Prompt templates prevent any need for system prompts when designing agent behavior.,LangChain ChatPromptTemplate system prompt usage,Contradicts description that system prompts are a key component defining agent role and tone.,"agentic-ai,planning,tools",12,Agentic AI
102594,26,half-true,Open-source contribution requires proactive action beyond merely providing free access.,open-source contribution and commit logs,"Passage emphasizes action and collaboration beyond free access, but specifics about methods omitted.","open-source,community,contribution",13,Commit to Contribute
102595,26,barely-true,Open contribution primarily requires public code access to build trust and collaboration.,open-source contribution and commit logs,"Overreaches passage: emphasizes only public code access, omitting action, catalysts, and structural map.","open-source,community,contribution",13,Commit to Contribute
102596,26,pants-fire,Open-source contribution mandates full transparency of all personal data without consent.,open-source contribution and trust concept,Contradicts passage emphasis on openness as action and trust; wrongly assumes mandatory personal-data disclosure.,"open-source,community,contribution",13,Commit to Contribute
102597,76,half-true,SpeechT5 reuses the same transformer backbone as text translators to clone realistic voices.,model comparison: SpeechT5 transformer backbone in voice cloning,Combines correct backbone reuse with overstated parity of capabilities; omits modality-specific adaptations.,"neural-networks,cnn,transformers",6,Neuron Building Blocks
102598,76,barely-true,SpeechT5 is a transformer model that recreates realistic voices from text.,SpeechT5 voice cloning and transformer backbone,"Passage links SpeechT5 to transformer backbone and voice cloning, but overstates realism and capabilities.","neural-networks,cnn,transformers",6,Neuron Building Blocks
102599,76,barely-true,SpeechT5 is a transformer model used for voice cloning from text.,SpeechT5 transformer applied to spoken language,Overstates passage: mentions SpeechT5 for voice cloning but passage only briefly references it as a close sibling used in deepfake examples.,"neural-networks,cnn,transformers",6,Neuron Building Blocks
102600,70,pants-fire,The GAN trains by updating both generator and discriminator equally to classify real and fake images correctly.,training objective and update routine using BCELoss for generator and discriminator,Contradicts passage detail: only generator is updated to make discriminator label fakes as real; claim wrongly states equal updates.,"generative-ai,diffusion,gans",7,Generative AI
102601,70,half-true,The GAN trains using binary cross-entropy and updates the generator to make fake images classified as real.,training objective and update rule for generator in GAN using BCELoss,"Accurately describes use of BCELoss and generator update, but omits generator/discriminator freezing and dataset transfer details.","generative-ai,diffusion,gans",7,Generative AI
102602,70,half-true,The GAN generator is trained to make the discriminator label fake images as real.,training objective using BCELoss and generator/discriminator updates,Accurately reflects objective but omits nuance about alternating updates and pretraining/fine-tuning workflow.,"generative-ai,diffusion,gans",7,Generative AI
102603,70,half-true,All deep learning frameworks use identical optimization algorithms and produce the same training results.,training process and framework-specific differences in deep learning,"Correct that core training loop is similar, but incorrect claiming identical algorithms and identical results across frameworks.","deep-learning,frameworks,tensors",5,Deep Learning
102604,70,TRUE,Framework differences can significantly impact a deep learning training workflow.,training process and framework-specific differences in deep learning,"Passage states framework-specific differences affect workflow, customization, debugging, and control during training.","deep-learning,frameworks,tensors",5,Deep Learning
102605,70,TRUE,"All frameworks use forward propagation, backpropagation, and parameter updates during training.",training process in deep-learning frameworks and tensors,"Passage explicitly states input moves forward, errors propagate backward, and parameters adjust during training.","deep-learning,frameworks,tensors",5,Deep Learning
102606,93,TRUE,Hugging Face's Transformers library simplifies access to pre-trained transformer models for multiple modalities.,Transformers Library entry in tool list,"Directly supported by passage saying it simplifies access to pre-trained transformer models for text, vision, and speech.","open-source,community,contribution",13,Commit to Contribute
102607,93,barely-true,The passage claims TensorFlow.js is primarily a PyTorch serving tool for browser inference.,tool descriptions listing TensorFlow.js and TorchServe,Combines two distinct tools incorrectly; conflates TensorFlow.js browser library with TorchServe serving features.,"open-source,community,contribution",13,Commit to Contribute
102608,93,pants-fire,The passage claims open-source projects always require no community contribution to function.,"open-source projects, contribution, community",Directly contradicts listed projects like Transformers and TorchServe that rely on community contribution.,"open-source,community,contribution",13,Commit to Contribute
102609,112,barely-true,Spaces removes all infrastructure management needs for production-scale model deployments.,Gradio Spaces lightweight interface and gradio_client deployment,"Overreaches: passage only claims no server setup for lightweight Gradio apps, not full production-scale infrastructure elimination.","mlops,scaling,deployment",10,AI At Scale
102610,112,mostly-true,"Gradio Spaces let users deploy lightweight model interfaces without managing servers, accessible via simple API calls.",Gradio Spaces deployment for models using gradio_client,"Passage supports no server setup and API access via gradio_client, but omits scalability and production caveats.","mlops,scaling,deployment",10,AI At Scale
102611,112,mostly-true,Spaces enables deploying a model with a lightweight Gradio interface accessible via simple API calls.,deployment using Spaces and gradio_client,"Matches passage: Gradio-based Spaces requires no server setup and provides browser or API access, minor setup caveat omitted.","mlops,scaling,deployment",10,AI At Scale
102612,23,pants-fire,Hugging Face secretly controls all global AI development and restricts public access to models.,open-source model sharing on GitHub and AI collaborations,Strongly contradicts passage emphasizing openness and easy public collaboration; claims hidden control and restriction are implausible.,"open-source,community,ai",0,Foreword – Robo Interviews Clément Delangue
102613,23,half-true,"Hugging Face enables everyone to create, collaborate on, and share AI models as easily as sharing code on GitHub.","openness across regions, industries, institutions; sharing models like GitHub",Accurately reflects ambition for open model sharing but overstates current ease and parity with GitHub collaboration workflows.,"open-source,community,ai",0,Foreword – Robo Interviews Clément Delangue
102614,23,TRUE,"Hugging Face promotes open, collaborative sharing of AI models similar to code sharing on GitHub.",openness and model-sharing vision in AI community,"Directly supported by passage asserting openness and ease of creating, collaborating on, and sharing AI models like GitHub.","open-source,community,ai",0,Foreword – Robo Interviews Clément Delangue
102615,69,FALSE,The GAN training loop updates only the generator and leaves the discriminator unchanged.,GAN training loop using BCELoss with generator and discriminator updates,Contradicts code: discriminator parameters are updated each batch via opt_D.step() after loss_D.backward().,"generative-ai,diffusion,gans",7,Generative AI
102616,69,mostly-true,The GAN training alternates discriminator and generator updates using BCE loss to improve image realism.,"training loop using BCELoss, generator, discriminator, dataloader","Accurately reflects code: alternating D/G steps with BCELoss, minor omission of optimizer details.","generative-ai,diffusion,gans",7,Generative AI
102617,69,barely-true,The GAN training code guarantees stable convergence and high-quality images after 24 epochs.,"GAN training loop using BCELoss, Adam optimizers, and generator/discriminator updates",Overreaches: code shows basic BCE training for 24 epochs but provides no stability guarantees or quality metrics.,"generative-ai,diffusion,gans",7,Generative AI
102618,92,FALSE,Normalizing inputs with mean 0.5 and std 0.5 always improves model training performance.,input normalization using transforms.Normalize in deep-learning,Contradicts passage implication that normalization helps but not guaranteed; overstates universality of benefit.,"deep-learning,frameworks,tensors",5,Deep Learning
102619,92,TRUE,Normalizing image inputs using mean and standard deviation centers and scales their pixel values.,input normalization using transforms.Normalize and pixel scaling,"Text explains Normalized = (x–mean)/std and example transforms.Normalize((0.5,),(0.5,)) showing centering and scaling.","deep-learning,frameworks,tensors",5,Deep Learning
102620,92,pants-fire,"Normalizing inputs to [–1,1] makes gradients irrelevant and training unnecessary for deep networks.","input normalization with transforms.Normalize((0.5,), (0.5,))",Contradicts explanation that normalization keeps gradients manageable; it does not remove gradients or training requirement.,"deep-learning,frameworks,tensors",5,Deep Learning
102621,49,half-true,Allowing AI full autopilot control increases attack surface but rarely causes immediate catastrophic breaches.,AI-powered email replies and auto-approved transactions,Accurately notes increased attack surface from autopilot but overstates rarity of catastrophic outcomes without evidence.,"security,red-team,guardrails",8,Breaking-Securing AI
102622,49,mostly-true,Autonomous AI features increase attack surface and risk when trusted without oversight.,AI-powered email replies and autopilot automation,Passage warns auto-approved transactions and real-time generation expand attack surface; minor caveat on mitigation options omitted.,"security,red-team,guardrails",8,Breaking-Securing AI
102623,49,FALSE,AI autopilot approvals never expand the attack surface for models.,AI-powered auto-approved transactions and email replies,Contradicts passage detail that autopilot trust increases attack surface for auto-approved transactions and content.,"security,red-team,guardrails",8,Breaking-Securing AI
102624,91,mostly-true,Cosine similarity effectively measures directional similarity for high-dimensional feature vectors.,"Cosine similarity metric, feature space, high-dimensional data","Accurately reflects directional comparison benefit for high-dimensional vectors, omits handling of zero vectors.","machine-learning,classification,evaluation",4,Classical Machine Learning
102625,91,pants-fire,Cosine similarity claims negative values indicate perfect dissimilarity and are common in real-world feature spaces.,cosine similarity metric for high-dimensional data,Direct contradiction: cosine similarity can be –1 for opposite vectors but real-world feature preprocessing usually yields nonnegative values; extreme negative occurrences are implausible.,"machine-learning,classification,evaluation",4,Classical Machine Learning
102626,91,barely-true,Cosine similarity always gives reliable similarity scores for high-dimensional feature vectors.,cosine similarity metric for high-dimensional data,Overreaches beyond passage: passage praises usefulness but does not claim it is always reliable.,"machine-learning,classification,evaluation",4,Classical Machine Learning
102627,124,FALSE,RAG retrains the generative model by adding new knowledge directly during generation.,Step 3 Generate with retrieved snippets in a RAG pipeline,Contradicts passage detail: RAG composes answers from retrieved facts without retraining the model.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
102628,124,half-true,RAG lets a generative model write answers using retrieved database facts without retraining the model.,Step 3 Generate with retrieved snippets and generative model,"Accurate about composing from retrieved snippets, but oversimplifies model reliance and ignores hallucination risks.","data-prep,feature-engineering,rag",3,Prepping Data for AI
102629,124,TRUE,RAG composes answers by combining retrieved snippets with a generative model.,RAG workflow step: Generate using retrieved snippets and a generative model,Passage explains combining retrieved database snippets with a generative model to compose answers without retraining.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
102630,79,barely-true,The agent's tools guarantee accurate trivia answers during competition.,Agent tools and LLM in trivia contestant example,Overreaches: tools and LLM provide capabilities but do not guarantee accuracy or correct answers.,"agentic-ai,planning,tools",12,Agentic AI
102631,79,FALSE,The agent operates without any tools or external capabilities.,Tools concept in agentic-ai planning,Contradicts passage details: tools are explicitly described as available capabilities enhancing agent performance.,"agentic-ai,planning,tools",12,Agentic AI
102632,79,mostly-true,Agent tools and an LLM enable role-based agents to perform tasks like trivia answering.,agent design using Tools and LLM,Describes example where an Agent uses an LLM and tools for a trivia role; minor caveat about tool specifics omitted.,"agentic-ai,planning,tools",12,Agentic AI
102633,136,mostly-true,The model achieved a strong macro-F1 score of 0.82 after balanced evaluation.,macro-F1 metric for model evaluation,Score explicitly reported as 0.82 and attributed to balance; minor caveat about dataset or split omitted.,"machine-learning,classification,evaluation",4,Classical Machine Learning
102634,136,mostly-true,Model explanations using confusion matrices and SHAP generally improve fine-tuned classifier trust and iteration.,explaining model behavior with confusion matrix and SHAP,"Supported by passage: cites confusion matrix and SHAP guiding continuous improvement and building trust, minor caveat about empirical effectiveness omitted.","machine-learning,classification,evaluation",4,Classical Machine Learning
102635,136,half-true,SHAP explanations and confusion matrices together guarantee improved macro-F1 for fine-tuned classifiers.,evaluation using confusion matrix and SHAP,"Correct that both tools guide improvement, but claim of guaranteed macro-F1 gains overstates outcomes and causality.","machine-learning,classification,evaluation",4,Classical Machine Learning
102636,33,TRUE,European and international bodies established expert groups to guide trustworthy AI governance.,"Ethics Guidelines for Trustworthy AI, High-Level Advisory Body on AI",Both EU High-Level Expert Group and UN High-Level Advisory Body set governance and oversight guidance supporting trustworthy AI.,"ethics,governance,privacy",11,AI Ethics and Governance
102637,33,TRUE,EU and UN expert groups plus industry partnerships have actively shaped AI governance and ethics.,"High-Level Expert Group, UN High-Level Advisory Body, Partnership on AI","Supported by examples: EU Ethics Guidelines (2019), UN advisory body (2023), and Partnership on AI initiatives.","ethics,governance,privacy",11,AI Ethics and Governance
102638,33,pants-fire,The EU's expert group secretly built and deployed autonomous surveillance AIs across member states.,Ethics Guidelines for Trustworthy AI influence,"Directly contradicts stated public advisory role; no deployment, secret program, or surveillance claim exists in passage.","ethics,governance,privacy",11,AI Ethics and Governance
102639,51,barely-true,The notebook fully automates secure publishing of restricted datasets and models to Hugging Face without user tokens.,Colab notebook GitHub integration and HF_TOKEN usage,Overreaches security automation: passage states user must set HF_TOKEN and Colab prompts for it.,"mlops,scaling,deployment",10,AI At Scale
102640,51,barely-true,The notebook always uploads models to Hugging Face without user tokens or consent.,Colab notebook workflow for Hugging Face model publishing,Contradicts described token requirement and prompts; it omits HF_TOKEN and consent steps.,"mlops,scaling,deployment",10,AI At Scale
102641,51,half-true,The notebook can automatically push all model checkpoints to a user’s Hugging Face account without prompts.,Colab integration with GitHub and Hugging Face using HF_TOKEN,"Correct that Colab integrates with Hugging Face, but it omits required HF_TOKEN prompts and permissions.","mlops,scaling,deployment",10,AI At Scale
102642,7,barely-true,He became a leading French eBay seller as a teenager after starting tech and import ventures.,personal background — eBay selling and importing ATVs,"Passage says he was among the most prominent French sellers on eBay at 17, but significance is somewhat overstated.","open-source,community,ai",0,Foreword – Robo Interviews Clément Delangue
102643,7,half-true,He became a leading French eBay seller as a teenager selling imported ATVs and bikes.,personal background; eBay selling of ATVs and bikes,Mixes correct teenage eBay selling and prominence claim; 'one of the most prominent' is vague and unverified.,"open-source,community,ai",0,Foreword – Robo Interviews Clément Delangue
102644,7,TRUE,Clément Delangue began a successful online business selling imported vehicles as a teenager.,personal background; selling ATVs and bikes on eBay,Passage reports importing ATVs and bikes and becoming a prominent French eBay seller by age 17.,"open-source,community,ai",0,Foreword – Robo Interviews Clément Delangue
102645,120,half-true,"YOLOv5 annotations indicate some detected identities with specific confidence scores, but identity labels may be inferred.","YOLOv5 object detection annotations (confidence, name)",Mixes correct detection outputs and exact confidence values with uncertain identity inference; labels can be generic 'person'.,"media-forensics,voice-cloning,deepfake",9,Deepfake Defense
102646,120,barely-true,YOLOv5 reliably detects and labels people and pets with high accuracy across scenes.,"YOLOv5 object detection outputs (pandas DataFrame, confidence scores)","Detection examples claim specific high confidences, but passage provides no evaluation metrics or error analysis.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
102647,120,half-true,YOLOv5 reliably detects multiple people and pets with high-confidence labels in video frames.,YOLOv5 object detection and annotation pipeline (pandas().xyxy outputs),Mixes correct detection capability with overstated reliability and universality of high confidence scores.,"media-forensics,voice-cloning,deepfake",9,Deepfake Defense
102648,171,pants-fire,Self-supervised learning always creates perfect labels without any errors for downstream tasks.,Masked Language Modeling (MLM) in natural language processing,Directly contradicts passage detail that SSL predicts missing words using context; claim of perfection is implausible and unsupported.,"machine-learning,classification,evaluation",4,Classical Machine Learning
102649,171,FALSE,Self-supervised learning requires manual labels to train masked language models.,Masked Language Modeling (MLM) in natural language processing,"Contradicts passage: MLM and SSL learn from context without manual labels, not requiring annotations.","machine-learning,classification,evaluation",4,Classical Machine Learning
102650,171,FALSE,Self-supervised learning requires external human labels to train masked language models.,Masked Language Modeling (MLM) in natural language processing,Contradicts passage: MLM trains by predicting masked words without external human labels.,"machine-learning,classification,evaluation",4,Classical Machine Learning
102651,37,half-true,Few-shot prompting always ensures models follow a specified persona across tasks.,few-shot prompting and framing with role-based prompts,Accurately notes role-framing benefit but overstates reliability; examples improve guidance but don't guarantee adherence.,"agentic-ai,planning,tools",12,Agentic AI
102652,37,pants-fire,Agentic AI autonomously plans and executes long-term goals without any human-provided examples.,few-shot prompting and model role framing,Contradicts passage: few-shot examples and role framing are presented as necessary for structured behaviour.,"agentic-ai,planning,tools",12,Agentic AI
102653,37,FALSE,Few-shot prompting always guarantees perfect model performance on nuanced tasks.,few-shot examples and framing in prompt design,Contradicts passage: few-shot improves clarity and pattern learning but does not guarantee perfect performance.,"agentic-ai,planning,tools",12,Agentic AI
102654,32,mostly-true,GANs can create realistic synthetic medical images useful for training diagnostic models.,use of GANs to generate synthetic medical images for training,"Supported by passage: GANs generate high-quality synthetic X-ray/MRI and diabetic retinopathy images, privacy caveat omitted.","generative-ai,diffusion,gans",7,Generative AI
102655,32,mostly-true,GANs can create realistic synthetic medical images that preserve patient privacy for training models.,use of GANs for synthetic medical imaging and privacy,"Supported by passage examples of GAN-generated medical images preserving privacy, minor caveat about realism limits omitted.","generative-ai,diffusion,gans",7,Generative AI
102656,32,half-true,GANs can create realistic synthetic medical images that fully preserve patient privacy while training models.,GAN-generated synthetic medical images for diabetic retinopathy and MRI,Mixes correct use of GANs for synthetic images with incorrect absolute claim that privacy is fully preserved.,"generative-ai,diffusion,gans",7,Generative AI
102657,44,TRUE,Scaling transformer models requires improving both model capacity and training data quality.,"scaling models, transformer, training data",Text explains scaling shifts focus to model-data interaction and that transformers rely more on data quality.,"mlops,scaling,deployment",10,AI At Scale
102658,44,barely-true,Model performance primarily improves by simply adding more hardware for larger-scale transformer workloads.,scaling concerns for transformer models and training data,Overstates hardware effectiveness; passage emphasizes data quality/size and scaling interactions rather than hardware alone.,"mlops,scaling,deployment",10,AI At Scale
102659,44,half-true,Scaling transformer models primarily requires adding more hardware to handle longer sequences and users.,"scaling transformers, data quality and hardware considerations",Partly correct about hardware aiding scaling but omits data quality and model-data interactions crucial for progress.,"mlops,scaling,deployment",10,AI At Scale
102660,94,half-true,The passage claims a specific Microsoft tool eliminates all privacy risks from AI deployments.,Responsible AI guidance and tools (Microsoft Responsible AI),Mixes correct claim about Microsoft tools with incorrect absolute guarantee; overstates tool capability to remove all privacy risks.,"ethics,governance,privacy",11,AI Ethics and Governance
102661,94,half-true,Partnership on AI and Microsoft resources partially guide responsible AI governance but lack unified standards.,governance resources and Responsible AI documentation,"Accurately notes listed organizations (Partnership on AI, Microsoft) guidance presence, but overstates unified standards existence and completeness.","ethics,governance,privacy",11,AI Ethics and Governance
102662,94,half-true,The passage claims industry guidelines fully resolve AI privacy and governance trade-offs.,"Responsible AI guidelines, dataset and model governance","Partly accurate: mentions Microsoft and Partnership on AI guidelines, but overstates complete resolution of trade-offs.","ethics,governance,privacy",11,AI Ethics and Governance
102663,106,barely-true,The example shows a human-in-the-loop decorator requiring approval before running sensitive functions.,HumanLayer require_approval decorator on a tool function,"Accurately describes code intent, but overstates completeness—example is illustrative and lacks full backend integration.","security,red-team,guardrails",8,Breaking-Securing AI
102664,106,TRUE,The code demonstrates a HITL pattern where a HumanLayer decorator enforces human approval for sensitive functions.,HumanLayer require_approval decorator in example code,"Example shows @hl.require_approval() on multiply, illustrating human-in-the-loop approval enforcement.","security,red-team,guardrails",8,Breaking-Securing AI
102665,106,pants-fire,The code automatically prevents all misuse of the multiply function without human errors.,HumanLayer require_approval decorator for HITL approval,Decorator only prompts for human approval; it doesn't eliminate human error or guarantee prevention of all misuse.,"security,red-team,guardrails",8,Breaking-Securing AI
102666,31,barely-true,MFCCs and spectral features reliably identify speakers from short voice clips.,"MFCCs, spectral centroid, and zero-crossing rate visualization",Overstates reliability: passage presents these as a baseline for fingerprints but not guaranteed accurate for speaker ID.,"media-forensics,voice-cloning,deepfake",9,Deepfake Defense
102667,31,half-true,MFCCs and spectral features can uniquely identify a speaker like Jerry in all practical scenarios.,"voice cloning, MFCCs, spectral centroid, acoustic fingerprint","Correct that MFCCs form acoustic fingerprints, but overstates uniqueness and ignores variability, noise, and model limits.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
102668,31,barely-true,MFCCs and spectral features alone reliably identify speakers against modern voice-cloning attacks.,"MFCCs, spectral centroid, zero-crossing rate acoustic fingerprint",Overstates capability: passage presents these as baseline fingerprints but omits limitations and modern voice-cloning countermeasures.,"media-forensics,voice-cloning,deepfake",9,Deepfake Defense
102669,127,TRUE,MLflow and Weights & Biases are viable community-driven alternatives for operationalizing models.,"MLOps tools for model deployment and registry (MLflow, Weights & Biases)",Passage explicitly names MLflow and Weights & Biases as strong community-driven alternatives for operationalizing models.,"mlops,scaling,deployment",10,AI At Scale
102670,127,mostly-true,MLflow and Weights & Biases are strong community-driven alternatives for operationalizing models.,"MLOps tools: MLflow, Weights & Biases, Hugging Face Hub",Passage states both projects offer strong community-driven alternatives to Hugging Face Hub for operationalizing models.,"mlops,scaling,deployment",10,AI At Scale
102671,127,half-true,MLflow and Weights & Biases are interchangeable drop-in replacements for Hugging Face Hub in deployment workflows.,"MLOps alternatives: MLflow, Weights & Biases, Hugging Face Hub","Correct that both are strong alternatives, but overstated interchangeability and deployment parity omission.","mlops,scaling,deployment",10,AI At Scale
102672,66,mostly-true,AI-generated harmful content can spread rapidly and its risk varies by usage context and scale.,"AI-generated harmful content spread and usage risk (ethics, governance)",Supported by speakers noting rapid spread and that risk depends on how the AI is used; minor caveat about specific scenarios omitted.,"ethics,governance,privacy",11,AI Ethics and Governance
102673,66,half-true,"AI misuse risks vary with usage context, though speed and scale concerns can be overstated.","AI misuse and content spread, model deployment and use-case differentiation","Correctly notes varying risk by use and spread speed, but overstates scale concerns without evidence.","ethics,governance,privacy",11,AI Ethics and Governance
102674,66,mostly-true,"AI content can spread rapidly, raising vigilance needs across different usage scenarios.",AI-generated content spread and use cases,"Supported by speakers noting alarm about speed, scale, and variation by how AI is used; minor nuance omitted.","ethics,governance,privacy",11,AI Ethics and Governance
102675,148,half-true,The tuned gradient boosting model combines interpretable features and PCA components to achieve strong performance.,model explanation for gradient boosting using PCA and Species feature,"Accurately notes mix of interpretable traits and PCA, but overstates 'strong performance' without metrics.","machine-learning,classification,evaluation",4,Classical Machine Learning
102676,148,half-true,The gradient boosting model uses PCA-derived features and species traits to balance interpretability and predictive power.,tuned gradient boosting model using PCA and Species features,"Mixes correct elements (PCA features, Species traits) but overstates clarity and balance without performance evidence.","machine-learning,classification,evaluation",4,Classical Machine Learning
102677,148,half-true,The tuned gradient boosting model mixes raw traits and PCA components for improved performance.,"tuned gradient boosting model using Species, Height, Weight and PCA","Correctly states blend of interpretable traits and PCA, but overclaims causal 'improved' performance without quantitative evidence.","machine-learning,classification,evaluation",4,Classical Machine Learning
102678,187,mostly-true,The training loop performs gradient descent updates over five epochs using loss.backward and optimizer.step.,"training loop code with optimizer, loss.backward, optimizer.step","Code excerpt shows five epochs and explicit backward/update calls, omitting optimizer hyperparameters.","deep-learning,frameworks,tensors",5,Deep Learning
102679,187,half-true,"The training loop uses five epochs with optimizer.zero_grad(), loss.backward(), and optimizer.step().","training loop using optimizer, loss, and model tensors",Accurately lists core steps but incorrectly asserts five epochs as standard; epoch count is arbitrary.,"deep-learning,frameworks,tensors",5,Deep Learning
102680,187,mostly-true,"The provided PyTorch-style training loop runs five epochs performing forward, backward, and optimizer steps.","training loop, PyTorch-style model, optimizer, loss.backward()","Loop explicitly shows five epochs with model.train(), loss.backward(), and optimizer.step(), minor framework assumption.","deep-learning,frameworks,tensors",5,Deep Learning
102681,118,barely-true,RAG lets models use new embeddings without retraining while still providing fully reliable answers.,retrieval-augmented generation (RAG) with embeddings,Overstates reliability; passage says RAG grounds answers but not that outputs are fully reliable without retraining.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
102682,118,mostly-true,RAG enables grounding model answers using new embeddings without retraining the base model.,retrieval-augmented generation; embedding layer and neural network,Explains that embeddings act as a shell allowing grounding while avoiding lengthy model retraining.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
102683,118,FALSE,RAG requires retraining the base neural model whenever new embeddings are added.,retrieval-augmented generation with embedding layer,Contradicts passage claim that RAG avoids retraining the pretrained model when adding embeddings.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
102684,30,mostly-true,Recurrent neural networks maintain a hidden state to carry information across time steps for sequence prediction.,RNNs and hidden state for sequence modeling,"Passage describes RNNs updating an internal hidden state each time step to learn temporal patterns, omitting few architectural caveats.","neural-networks,cnn,transformers",6,Neuron Building Blocks
102685,30,TRUE,RNNs update a hidden state at each time step to carry information forward.,recurrent neural networks; hidden state and time step,Passage explains RNNs process sequences one time step at a time and store memory in a hidden state to carry information forward.,"neural-networks,cnn,transformers",6,Neuron Building Blocks
102686,30,TRUE,Recurrent neural networks update a hidden state at each time step to carry temporal information forward.,RNNs processing sequences and hidden state,Passage states RNNs process sequences one time step at a time and store memory in a hidden state that carries information forward.,"neural-networks,cnn,transformers",6,Neuron Building Blocks
102687,150,half-true,Open-source tooling always provides defenders a clear security advantage over closed systems.,glue code transparency and open source security,Accurately highlights open source benefits but overstates universality; ignores cases where provenance or plugins remain opaque.,"security,red-team,guardrails",8,Breaking-Securing AI
102688,150,mostly-true,Open-source transparency generally increases defenders' ability to secure models and integrations.,"glue code transparency, datasets, plugins, and open-source tools","Passage supports that transparency and open source empower defenders, though specifics and trade-offs are omitted.","security,red-team,guardrails",8,Breaking-Securing AI
102689,150,TRUE,Open-source tooling and transparent pipelines improve AI security by enabling defenders to trace inputs and actions.,glue code transparency and open source tooling,"Passage states transparency and open source let defenders trace datasets, plugins, inputs, and actions.","security,red-team,guardrails",8,Breaking-Securing AI
102690,9,mostly-true,"Generative AI raises concerns about job loss, academic integrity, and misuse for misinformation.","creative professionals, educators, and regulators responding to generative-AI disruption","Passage lists job displacement, academic-integrity challenges, and regulator focus on misuse, so broadly supported.","generative-ai,diffusion,gans",7,Generative AI
102691,9,mostly-true,"Generative AI raises concerns about job displacement, academic integrity, and misuse for misinformation.","impacts on creative professionals, educators, and regulators (AI-generated content)",Broadly supported by passage; omits nuance about scale and specific regulatory responses but matches main concerns described.,"generative-ai,diffusion,gans",7,Generative AI
102692,9,half-true,Generative AI both creates new work and immediately replaces many creative jobs.,"creative professionals, job displacement, generative AI impact",Mixes correct concern about displacement with overstated immediacy and scale of replacement.,"generative-ai,diffusion,gans",7,Generative AI
102693,122,half-true,Making model inference accessible always reveals training data gaps when predictions seem off.,inference accessibility and feedback loop for model validation,"Accurate that accessible inference can reveal data gaps, but 'always' overstates causality and frequency.","mlops,scaling,deployment",10,AI At Scale
102694,122,TRUE,Making model inference observable improves reproducibility and developer reuse.,inference feedback loop; training data gaps,"Passage states observable inference enables validation, reuse, and reveals training data gaps, supporting reproducibility.","mlops,scaling,deployment",10,AI At Scale
102695,122,pants-fire,The deployed model's inaccurate predictions always indicate missing training data.,inference feedback loop for deployed model,"Claim contradicts passage which says inaccuracies may reveal training gaps, not always; overstates causality.","mlops,scaling,deployment",10,AI At Scale
102696,4,TRUE,"An agent performs multi-step discovery, reasoning, and actions to achieve outcomes.",agentic AI process using tools and reasoning,"Passage explicitly contrasts agentic AI with single-step chatbots, describing multi-step discovery and actions.","agentic-ai,planning,tools",12,Agentic AI
102697,4,FALSE,An agentic AI always performs actions without any intermediate reasoning steps.,"agentic AI sequence of discovery, reasoning, and action",Contradicts passage: agentic AI explicitly includes intermediate discovery and reasoning before actions.,"agentic-ai,planning,tools",12,Agentic AI
102698,4,TRUE,"An agent uses sequential discovery, reasoning, and actions to reach answers rather than single-step replies.",agentic AI process using tools and planning,"Passage describes agents performing sequences of discovery, reasoning, and action versus single-step chatbots.","agentic-ai,planning,tools",12,Agentic AI
102699,28,half-true,The notebook's predictions always generalize well if the dataset fits the question.,"Classical Machine Learning notebook, dataset fit and prediction reliability",Mixes correct principle that dataset-question fit matters with incorrect absolutist claim that predictions always generalize.,"machine-learning,classification,evaluation",4,Classical Machine Learning
102700,28,pants-fire,The dataset guarantees perfectly accurate predictions for every supervised model in the notebook.,Classical Machine Learning notebook dataset fit,Contradicts passage assertion that predictions depend on data suitability; dataset does not guarantee perfect accuracy.,"machine-learning,classification,evaluation",4,Classical Machine Learning
102701,28,FALSE,Model predictions remain reliable regardless of dataset suitability for the question.,dataset suitability in Classical Machine Learning notebook,Contradicts passage point that predictions depend on dataset fit; it falsely assumes dataset irrelevance.,"machine-learning,classification,evaluation",4,Classical Machine Learning
102702,72,half-true,Naïve Bayes always outperforms complex models on spam detection tasks.,Naïve Bayes with Scikit-learn example in text classification,Mixes correct idea (Naïve Bayes can excel for focused tasks) with incorrect absolute claim that it always outperforms complex models.,"ai,tool-chain,notebooks",2,AI Survival Kit
102703,72,barely-true,Naïve Bayes always outperforms complex models on text classification tasks in practice.,Naïve Bayes with Scikit-learn spam detection example,Overreaches the passage's claim that focused models can often outperform complex approaches; not universally true and lacks benchmarking details.,"ai,tool-chain,notebooks",2,AI Survival Kit
102704,72,barely-true,Naïve Bayes in scikit-learn always outperforms complex models for text classification tasks.,Naïve Bayes example with Scikit-learn for spam detection,"Overreaches: passage says focused models can outperform complex ones for specific tasks, not always.","ai,tool-chain,notebooks",2,AI Survival Kit
102705,78,mostly-true,"Hugging Face broadly enables open-source AI contributions through models, datasets, and deployment tools.","open-source platform offering Hugging Face models, datasets, and Spaces","Passage lists models, datasets, tools, and Spaces enabling contributions; minor nuance about governance or community processes omitted.","open-source,community,contribution",13,Commit to Contribute
102706,78,half-true,Hugging Face exclusively hosts all transformer models and datasets for open-source AI development.,"platform providing transformer models, datasets, and tools","Correct that Hugging Face offers models and datasets, but overstated exclusivity and completeness.","open-source,community,contribution",13,Commit to Contribute
102707,78,half-true,Hugging Face primarily hosts transformer models and community datasets for open-source AI development.,platform hosting transformer models and datasets (Hugging Face),"Partly correct about hosting models and datasets but overstates primacy and omits Spaces, SDKs, and community tools.","open-source,community,contribution",13,Commit to Contribute
102708,96,half-true,ImageNet mean and standard deviation normalization is typically applied for computer vision preprocessing.,preprocessing using ImageNet mean and standard deviation,Accurately reflects common CV practice but omits that other domains use different normalization or internal handling.,"deep-learning,frameworks,tensors",5,Deep Learning
102709,96,barely-true,Vision models must use ImageNet mean and standard deviation for input normalization.,input normalization for vision models (ImageNet mean/std),"Overreaches: passage says ImageNet often used, not required; generalization unsupported.","deep-learning,frameworks,tensors",5,Deep Learning
102710,96,TRUE,ImageNet mean and standard deviation are commonly used for normalizing computer vision inputs.,input preprocessing for computer vision (ImageNet mean/std),Passage explicitly states normalizing using the ImageNet mean and standard deviation for computer vision.,"deep-learning,frameworks,tensors",5,Deep Learning
102711,21,FALSE,An over-permissioned chatbot can leak proprietary data through crafted prompts.,access to internal documents and private knowledge bases,Contradicts passage: passage explicitly warns over-permissioned models enable data extraction by adversaries.,"security,red-team,guardrails",8,Breaking-Securing AI
102712,21,half-true,Chatbots with broad internal access can sometimes be manipulated to exfiltrate sensitive data.,model access to internal documents and private knowledge bases,"Correct that over-permissioned models enable extraction via prompts, but omits mitigation capabilities and detection limits.","security,red-team,guardrails",8,Breaking-Securing AI
102713,21,barely-true,An over-permissioned chatbot will allow attackers to extract sensitive internal data through prompts.,access to internal documents and private knowledge bases,Passage warns models with read/query access and weak controls enable extraction via clever prompting or chained requests.,"security,red-team,guardrails",8,Breaking-Securing AI
102714,54,half-true,"LangChain lets developers swap models without rewriting application logic, but omits integration edge-cases.",model abstraction for model swapping in LangChain,Accurately describes abstraction and model swapping but ignores practical integration limits and edge-case differences.,"agentic-ai,planning,tools",12,Agentic AI
102715,54,mostly-true,LangChain lets developers swap AI models without rewriting application logic.,model abstraction and Model swapping in LangChain,Supports claim: LangChain provides a consistent interface and abstraction enabling model swapping without code changes.,"agentic-ai,planning,tools",12,Agentic AI
102716,54,mostly-true,LangChain enables developers to swap models without rewriting application logic.,model abstraction in LangChain for model swapping,"Supports claim directly: LangChain abstracts API clients, enabling model swapping while omitting integration caveats.","agentic-ai,planning,tools",12,Agentic AI
102717,48,half-true,F1-macro gives equal weight to each class by averaging per-class F1 scores.,evaluation metric F1-macro for imbalanced classification,"Accurate about averaging F1 per label, but implies equal class importance always appropriate, omitting cost-sensitive considerations.","machine-learning,classification,evaluation",4,Classical Machine Learning
102718,48,pants-fire,F1-macro always guarantees perfect balance across all class imbalances in every dataset.,F1-macro metric for classification evaluation,Contradicts F1-macro purpose: it averages per-class F1 but cannot guarantee perfect balance or solve severe class imbalance issues.,"machine-learning,classification,evaluation",4,Classical Machine Learning
102719,48,mostly-true,F1-macro averages per-class F1 scores to give equal importance to each label.,evaluation metric: F1-macro for multi-class classification,"Supports passage saying F1-macro averages F1 across labels, noting equal class importance though it omits class-weighting caveat.","machine-learning,classification,evaluation",4,Classical Machine Learning
102720,60,TRUE,Langchain’s structured prompting improves AI accuracy and consistency in responses.,Langchain structured prompting and few-shot examples,"Passage states Langchain’s prompting yields on-point trivia results and few-shot consistency, supporting improvement claim.","agentic-ai,planning,tools",12,Agentic AI
102721,60,TRUE,Langchain structured prompting improves AI response accuracy and consistency.,Langchain structured prompting and few-shot examples,"Passage shows Langchain prompts produce on-point trivia answers and few-shot consistency, supporting improved accuracy.","agentic-ai,planning,tools",12,Agentic AI
102722,60,FALSE,LangChain decreases AI accuracy and prevents consistent response formatting.,Langchain structured prompting and few-shot examples,Contradicts passage evidence that Langchain structured prompting improves accuracy and consistent few-shot formatting.,"agentic-ai,planning,tools",12,Agentic AI
102723,2,pants-fire,Agentic AI always chooses harmless actions and never pursues harmful goals.,agentic AI planning and decision-making tools,Directly contradicts description of independent decision-making; claim denies possible harmful goals or actions.,"agentic-ai,planning,tools",12,Agentic AI
102724,2,TRUE,Agentic AI systems can autonomously make decisions and take actions to pursue goals.,agentic AI decision-making and planning,Passage explicitly defines agentic AI as systems that make decisions and take action independently to pursue goals.,"agentic-ai,planning,tools",12,Agentic AI
102725,2,half-true,Agentic AI independently forms plans and iteratively executes actions to achieve goals in real-world settings.,agentic AI planning and strategies for carrying out goals,"Partially accurate: passage says systems make decisions and act iteratively, but specifics about independent planning/execution are inferred.","agentic-ai,planning,tools",12,Agentic AI
102726,33,barely-true,Vectors and dot products are optional concepts rarely used in practical AI modeling workflows.,need-to-know structures; vectors and dot products,Passage states vectors and dot products are foundational; claiming they are rarely used contradicts described importance and tooling support.,"ai,tool-chain,notebooks",2,AI Survival Kit
102727,33,TRUE,"Vectors and dot products are basic, necessary structures for representing data in AI models.",one-dimensional arrays and dot products (vectors),Passage states vectors are one-dimensional arrays and highlights their importance for building and refining AI models.,"ai,tool-chain,notebooks",2,AI Survival Kit
102728,33,barely-true,Vectors and dot products are unnecessary for building practical AI models with Python libraries.,vectors and dot products in AI tool-chain,Contradicts passage emphasis that vectors and dot products are need-to-know and give advantage despite libraries; overreaches by saying unnecessary.,"ai,tool-chain,notebooks",2,AI Survival Kit
102729,63,mostly-true,An AI-powered trivia agent was simplified to better showcase agent planning and competition.,AI-powered trivia challenge demonstrating agentic-ai and planning,Passage indicates initial complex versions were simplified to emphasize agent planning and competitive demonstration.,"agentic-ai,planning,tools",12,Agentic AI
102730,63,barely-true,An early agent prototype reliably handled complex open-ended planning without simplification.,agentic-ai prototype for trivia challenge,"Passage indicates early versions were simplified, so claiming reliable complex planning is largely unsupported.","agentic-ai,planning,tools",12,Agentic AI
102731,63,half-true,An early agent design combined complex goals with a simplified trivia agent after tuning.,agentic AI trivia challenge using agents and tools,Mixes correct tuning-to-simpler-trivia claim with incorrect implication that early design combined complex goals explicitly.,"agentic-ai,planning,tools",12,Agentic AI
102732,140,barely-true,Open-source tools alone guarantee robust defense against RAG pipeline security failures.,"RAG pipeline and open source tools (Gandalf, LYNX)",Overstates claim: passage credits open-source as a force multiplier but warns validation/filtering still required.,"security,red-team,guardrails",8,Breaking-Securing AI
102733,140,FALSE,Open-source tools always eliminate the need for additional post-model security layers in RAG pipelines.,RAG pipeline security using Gandalf-trained input filters and LYNX evaluation models,Contradicts passage: security failure arises when RAG trusts outputs; post-model layers still required.,"security,red-team,guardrails",8,Breaking-Securing AI
102734,140,half-true,Open-source tools alone guarantee complete protection for RAG pipelines against attacks.,open source tools like Gandalf-trained input filters and LYNX evaluation models,Mixes correct claim about helpful open-source tools with incorrect implication they fully secure RAG pipelines without additional layers.,"security,red-team,guardrails",8,Breaking-Securing AI
102735,123,mostly-true,Retrieval-augmented generation uses vector embeddings to semantically match and supply relevant document chunks.,RAG retrieval step using embeddings and vector database,Describes retrieval via embeddings and supplying snippets to a generative model; minor caveat about top-k selection specifics omitted.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
102736,123,barely-true,RAG always guarantees factual answers by retrieving top-k vector chunks before generation.,retrieval-augmented generation with vector database and embeddings,Overreaches: retrieval aids generation but doesn't ensure factual accuracy; generation can hallucinate despite top-k retrievals.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
102737,123,TRUE,RAG systems retrieve top-k semantically matched document chunks using embeddings.,retrieval step using embeddings and vector database,Passage explicitly describes converting queries to embeddings and searching a vector database for top-k semantic matches before generation.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
102738,30,TRUE,"The notebook uses training variables like X_train, X_test, y_train, and y_test for model training.",code snippets and AI training variables,"Passage explicitly instructs keeping the same training variable names (X_train, X_test, y_train, y_test).","machine-learning,classification,evaluation",4,Classical Machine Learning
102739,30,mostly-true,The notebook advises reusing training variable names like X_train and y_test for consistent model training.,"code snippets and variable naming for dataset splits (X_train, y_train)","Guidance aligns with passage recommending reuse of X_train, X_test, y_train, y_test though minor adaptation advised.","machine-learning,classification,evaluation",4,Classical Machine Learning
102740,30,barely-true,The notebook claims using X_train and X_test guarantees reproducible model training results.,"training variables X_train, X_test, y_train, y_test in code snippets",Overstates reproducibility: variables help but don't guarantee results without fixed random seeds or environment.,"machine-learning,classification,evaluation",4,Classical Machine Learning
102741,13,half-true,Foundation models fine-tuned from broad pretraining always outperform task-specific smaller models.,fine-tuning foundation models and reliance on pre-trained APIs,"Mixes correct idea of fine-tuning benefits with incorrect absolute claim; ignores cost, resource, and task-specific trade-offs.","generative-ai,diffusion,gans",7,Generative AI
102742,13,FALSE,Diffusion models always outperform GANs on image generation quality.,diffusion models vs GANs in generative-ai image modeling,Contradicts passage: no claim that one architecture always outperforms another; assumes superiority without evidence.,"generative-ai,diffusion,gans",7,Generative AI
102743,13,TRUE,"Foundation models can be fine-tuned for specific downstream tasks like legal, medical, or illustration generation.",foundation models; fine-tuning for downstream tasks,"Passage explicitly states foundation models are fine-tuned for legal documents, medical Q&A, and illustrations.","generative-ai,diffusion,gans",7,Generative AI
102744,156,TRUE,Open-source evaluation models like LYNX assess hallucination in LLM outputs.,"LYNX open-source hallucination evaluation model (paper, arXiv/huggingface)","Paper citation explicitly describes LYNX as an open-source hallucination evaluation model, supporting assessment claim.","security,red-team,guardrails",8,Breaking-Securing AI
102745,156,mostly-true,Red-team guardrails can mostly prevent AI misuse but sometimes fail against sophisticated attacks.,red-team guardrails for model security,Supported by emphasis on red-team testing reducing but not eliminating vulnerabilities; omits rare successful sophisticated bypasses.,"security,red-team,guardrails",8,Breaking-Securing AI
102746,156,mostly-true,Red-team testing and guardrails generally reduce but do not eliminate AI jailbreaks.,red-team testing and guardrails in security for models,Passage supports mitigation role of red-team and guardrails while acknowledging residual vulnerabilities and incomplete elimination.,"security,red-team,guardrails",8,Breaking-Securing AI
102747,145,mostly-true,AI application security uses traditional IT controls like input sanitization and access control.,securing AI applications; input sanitization and access control,"Passage directly lists input sanitization, data validation, audit logs, and access control as applicable mechanisms.","security,red-team,guardrails",8,Breaking-Securing AI
102748,145,half-true,AI security practices resemble traditional IT security techniques but require adaptation for model outputs.,"securing AI applications, input sanitization and audit logs","Mixes correct comparison to IT security with omitted specifics about adapting controls for model outputs, so partly true.","security,red-team,guardrails",8,Breaking-Securing AI
102749,145,pants-fire,The passage asserts AI is purely software with no real-world action risks.,securing AI applications; input sanitization and access control,Contradicts passage emphasis that real-world actions and blurred lines matter; denies cited real-world risk.,"security,red-team,guardrails",8,Breaking-Securing AI
102750,76,half-true,The passage claims pretrained CNNs can be used for quick image classification demos.,image classification with CNNs on Hugging Face,"Accurate about using pretrained CNNs for demos, but omits dataset, evaluation, and implementation specifics.","ai,tool-chain,notebooks",2,AI Survival Kit
102751,76,TRUE,A pretrained CNN can be used for quick image classification experiments.,pretrained Convolutional Neural Network (CNN) on Hugging Face,Passage explicitly recommends using a pretrained CNN for quick image classification experiments.,"ai,tool-chain,notebooks",2,AI Survival Kit
102752,76,TRUE,Deep learning utilities include using a pretrained CNN for image classification.,Image Classification with CNNs on Hugging Face (DL) example,Passage explicitly describes using a pretrained Convolutional Neural Network for image classification as a DL utility.,"ai,tool-chain,notebooks",2,AI Survival Kit
102753,65,barely-true,The ShapeDataset trains a state-of-the-art diffusion model on ImageNet-scale color images.,dataset ShapeDataset generating 28×28 grayscale images,"Exaggerates dataset scale and type: ShapeDataset creates small grayscale synthetic shapes, not ImageNet color data.","generative-ai,diffusion,gans",7,Generative AI
102754,65,barely-true,The provided PyTorch dataset generates varied realistic object poses for diffusion model training.,ShapeDataset synthetic 28×28 grayscale images,"Dataset creates only fixed-center circles and single slashes, so claimed pose variety is largely unsupported.","generative-ai,diffusion,gans",7,Generative AI
102755,65,pants-fire,The PyTorch example proves diffusion models can generate photorealistic images of people.,implementation using ShapeDataset synthetic 28×28 images,"Claim contradicts dataset detail: only 28×28 synthetic circles/slashes exist, not photorealistic people.","generative-ai,diffusion,gans",7,Generative AI
102756,18,barely-true,Skip connections always eliminate vanishing gradients in all deep CNNs and transformers.,skip connections in residual networks and transformers,Overstated claim: skip connections mitigate but do not always eliminate vanishing gradients; applicability varies by architecture and training details.,"neural-networks,cnn,transformers",6,Neuron Building Blocks
102757,18,TRUE,Shortcut (skip) connections help train very deep neural networks by easing gradient flow.,shortcut connections in neural networks (skip connections),"Directly supported: passage explains skips let inputs jump ahead and reduce vanishing gradients, aiding deep network training.","neural-networks,cnn,transformers",6,Neuron Building Blocks
102758,18,TRUE,Shortcut (skip) connections let inputs bypass intermediate layers and be added to deeper outputs.,shortcut connections in neural networks (skip connections),"Directly matches passage: skip connections enable inputs to jump ahead and be added, aiding deep network training.","neural-networks,cnn,transformers",6,Neuron Building Blocks
102759,14,TRUE,Librosa reliably extracts audio features like pitch and rhythm for AI models.,librosa audio feature extraction for AI models,"Passage explicitly states librosa turns raw waveforms into features such as pitch, tone, and rhythm used by AI.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
102760,14,TRUE,"Librosa extracts meaningful audio features like pitch, tone, and rhythm from raw waveforms.",audio feature extraction using librosa library,"Passage explicitly states librosa turns raw waveforms into features such as pitch, tone, and rhythm that models can learn from.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
102761,14,FALSE,Librosa is primarily a dataset rather than a feature extraction library for audio.,librosa library and feature extraction tools,"Contradicts passage detail: librosa is described as a library that extracts audio features, not a dataset.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
102762,24,half-true,Regulators already require full dataset traceability for all deployed AI systems.,"traceability in AI decision-making, NIST AI Risk Management Framework","Overstates requirement: passage notes regulators demand transparency but not universal, legally binding dataset traceability.","ethics,governance,privacy",11,AI Ethics and Governance
102763,24,TRUE,Traceability in AI decision-making helps organizations catch unfair or unreliable model behavior early.,traceability and NIST AI Risk Management Framework,Passage states monitoring data evolution and traceability enable detection of unfair or unpredictable model outcomes.,"ethics,governance,privacy",11,AI Ethics and Governance
102764,24,half-true,Monitoring dataset drift fully ensures AI models remain fair and trustworthy in deployment.,traceability and dataset monitoring mentioned with NIST AI Risk Management Framework,"Overstates claims: passage says monitoring helps catch issues and regulators demand transparency, not that monitoring alone guarantees fairness.","ethics,governance,privacy",11,AI Ethics and Governance
102765,83,barely-true,Pre-trained models always produce trustworthy confidence scores for validation and deployment.,use of pre-trained models and confidence scores in model evaluation,"Overreaches: passage warns models can misinterpret patterns and advises checking confidence scores, so 'always trustworthy' contradicts caution.","ai,tool-chain,notebooks",2,AI Survival Kit
102766,83,TRUE,Developers can quickly build ML and deep learning systems using a few Python lines and pre-trained libraries.,using well-tested libraries and pre-trained models in Python,Passage explicitly states a few Python lines plus well-tested libraries and pre-trained models enable rapid system building.,"ai,tool-chain,notebooks",2,AI Survival Kit
102767,83,mostly-true,Pre-trained Python libraries let developers rapidly build machine learning and deep learning systems.,use of pre-trained models and Python libraries in ML/DL,"Passage explicitly praises small Python scripts with well-tested libraries and pre-trained models enabling rapid development, omitting minor caveats about validation and confidence checks.","ai,tool-chain,notebooks",2,AI Survival Kit
102768,157,TRUE,"A pre-trained foundation model can generate original, coherent, context-sensitive text without further training.",pre-trained foundation model; Transformer architecture (FLAN-T5),"Passage explains the model produces on-the-fly, fluent, context-aware text without additional training.","generative-ai,diffusion,gans",7,Generative AI
102769,157,barely-true,"A pre-trained foundation model can generate perfectly factual, never-erroneous text without fine-tuning.","pre-trained foundation model, Transformer, FLAN-T5","Overreaches beyond passage: generation described, but passage never claims perfect factuality or zero errors.","generative-ai,diffusion,gans",7,Generative AI
102770,157,FALSE,The model relies primarily on retrieving exact responses from a predefined list of memorized outputs.,"generation mechanism of pre-trained foundation model (Transformer, FLAN-T5)",Contradicts passage by claiming retrieval from a predefined list; passage states generation on the fly.,"generative-ai,diffusion,gans",7,Generative AI
102771,112,mostly-true,Scene-level segmentation enables focused analysis of manageable video sections for deepfake detection.,scene segmentation of Jerry-Jose-SampleVideo01.mp4,"Supports using scene segmentation to reduce complexity and focus analysis, omitting specific detection metrics.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
102772,112,mostly-true,Scene segmentation splits the 40-second video into three manageable scenes for focused analysis.,video scene segmentation using detected start and end times,"Passage lists three scenes with exact start/end times, supporting segmentation benefit though minor contextual caveats omitted.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
102773,112,mostly-true,Scene segmentation reduces video analysis complexity by dividing footage into manageable temporal sections.,scene segmentation of Jerry-Jose-SampleVideo01.mp4,"Aligns with passage: detected scenes with specific timestamps simplify analysis, omitting minor algorithmic details.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
102774,79,barely-true,Model benchmarking always reveals the primary limits that block all later deployment improvements.,"benchmarking phase measuring F1 score, latency, throughput",Overreaches beyond passage: benchmarking reveals some limits but not necessarily the primary blockers for every deployment.,"mlops,scaling,deployment",10,AI At Scale
102775,79,TRUE,"The passage recommends establishing performance baselines using metrics like F1 score, latency, and throughput.","benchmark phase measuring F1 score, latency, throughput","Directly supported: the table lists Benchmark phase with F1 score, latency, throughput to reveal limits and track improvements.","mlops,scaling,deployment",10,AI At Scale
102776,79,FALSE,Benchmarking is unnecessary for scaling and can be skipped during deployment.,"benchmark phase measuring F1 score, latency, throughput","Passage prescribes establishing a benchmark baseline and measuring F1, latency, throughput, so skipping contradicts that guidance.","mlops,scaling,deployment",10,AI At Scale
102777,155,TRUE,"Personal data includes names, addresses, financial records, health data, and behavioral patterns.",data protection definition including IP address and compliance,Passage explicitly lists those data types and mentions IP addresses and consulting compliance experts.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
102778,155,barely-true,Personal data always includes IP addresses regardless of jurisdiction or context.,data privacy definition for datasets and compliance,Overgeneralizes; passage says IP addresses may count in Europe but varies by regulation and context.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
102779,155,FALSE,Personal data never includes IP addresses under any regulation.,data privacy and personal data examples including IP address,"Contradicts passage detail that Europe may treat IP addresses as personal data, differing by regulation.","data-prep,feature-engineering,rag",3,Prepping Data for AI
102780,0,mostly-true,AI builders favor open tools and shared code to create trustworthy systems rather than accepting ready-made AI.,AI Builders using open tools and shared code,"Passage describes builders preferring open tools and shared code, omitting nuances about trade-offs.","ai,open-source,builder",1,Introduction – The Gold Rush Paradox
102781,0,half-true,AI builders prefer open tools and shared code but sometimes overestimate control benefits.,AI Builders using open tools and shared code,Accurately reflects preference for open tools and shared code while overstating guaranteed control or trust outcomes.,"ai,open-source,builder",1,Introduction – The Gold Rush Paradox
102782,0,pants-fire,AI builders secretly sabotage commercial models to force use of open-source tools.,AI Builders using open tools and shared code,"Directly contradicts passage: builders prefer inspecting tools and creating systems, not sabotaging commercial models.","ai,open-source,builder",1,Introduction – The Gold Rush Paradox
102783,90,half-true,"The experiment log combines model checkpoints, dataset, and timing but omits critical evaluation metrics.",experiment log entry for T5-small on LIAR dataset,"Log records checkpoint, dataset, inference time, and notes yet lacks explicit accuracy or loss metrics.","mlops,scaling,deployment",10,AI At Scale
102784,90,mostly-true,The passage endorses saving versioned model checkpoints and structured experiment logs for reproducible deployment.,"model checkpointing and experiment log (t5-small, LIAR dataset)","Describes saving model structure, weights, and JSONL logs for reproducibility; minor operational details omitted.","mlops,scaling,deployment",10,AI At Scale
102785,90,half-true,The passage claims saving checkpoints and logs ensures models can be fully restored later.,"experiment log, checkpoint, t5-small, LIAR dataset","Accurate about saving structure and weights, but overstates guarantee of full restoration without noting environment, dependencies.","mlops,scaling,deployment",10,AI At Scale
102786,101,pants-fire,AI in notebooks autonomously replaces all human engineers within days.,tool-chain and notebooks automation claim,"Passage describes AI aiding tasks like diagnostics and maintenance, not instant engineer replacement; claim contradicts real-world technical limits.","ai,tool-chain,notebooks",2,AI Survival Kit
102787,101,barely-true,AI models always prevent equipment failures before they occur in industrial settings.,predictive maintenance using AI models in industrial equipment monitoring,"Overstates capabilities; passage describes failure prediction and scheduling, not guaranteed prevention.","ai,tool-chain,notebooks",2,AI Survival Kit
102788,101,TRUE,AI models are used for predictive maintenance in industrial settings to forecast equipment failures.,"predictive maintenance in industrial AI deployments (Siemens, General Electric)",Passage explicitly describes real-time monitoring and failure prediction for industrial equipment by AI models.,"ai,tool-chain,notebooks",2,AI Survival Kit
102789,82,half-true,K-Means with fixed random seed and n_init reliably finds globally optimal clusters for PCA-compressed power features.,KMeans clustering on PCA-compressed power feature matrix X,"Mixes correct settings (random_state, n_init) with incorrect claim that K-Means reliably finds global optimum; K-Means is sensitive to initialization and only approximates clustering quality.","machine-learning,classification,evaluation",4,Classical Machine Learning
102790,82,barely-true,K-Means always produces well-separated clusters for PCA-compressed feature sets.,"KMeans clustering on PCA-compressed features, silhouette metric",Overreaches: K-Means can produce poor separation depending on data and PCA choices; silhouette used to assess quality.,"machine-learning,classification,evaluation",4,Classical Machine Learning
102791,82,barely-true,K-Means clustering reliably yields well-separated groups when using PCA-compressed features.,K-Means on PCA-compressed feature matrix X with silhouette metric,Overstates reliability: passage runs K-Means and mentions silhouette but provides no results or evidence of good separation.,"machine-learning,classification,evaluation",4,Classical Machine Learning
102792,139,half-true,LangChain always uses OPR and SDR from the CSV to balance matchups before generation.,dataset heroes_info_powers.csv and LangChain retrieval,"Partially correct: passage shows using OPR/SDR and LangChain, but 'always' and strict balancing are overstated.","data-prep,feature-engineering,rag",3,Prepping Data for AI
102793,139,half-true,The system always balances matchups using OPR and SDR from the superheroes_info_powers.csv file.,"dataset: superheroes_info_powers.csv and metrics OPR, SDR","Correct that OPR and SDR are used, but overstates certainty—balancing may be heuristic, not guaranteed.","data-prep,feature-engineering,rag",3,Prepping Data for AI
102794,139,barely-true,The system always improves story quality by using LangChain with OPR and SDR metrics.,"using LangChain with dataset superheroes_info_powers.csv and metrics OPR, SDR","Overstates effect: passage only describes combining data and LangChain, not guaranteed quality improvement.","data-prep,feature-engineering,rag",3,Prepping Data for AI
102795,54,mostly-true,The section endorses building reliable AI systems using open-source tools and data control.,practical tools and data handling with open-source components,"Broadly supported by emphasis on tools, data handling, foundational algorithms, and ownership; omits minor implementation caveats.","ai,open-source,builder",1,Introduction – The Gold Rush Paradox
102796,54,mostly-true,Human-in-the-loop defenses like HumanLayer generally reduce automation risks but can miss subtle failures.,runtime firewall / HumanLayer HITL defense,"Passage endorses HumanLayer as a runtime firewall pausing execution for human approval, but omits potential missed subtle failures.","security,red-team,guardrails",8,Breaking-Securing AI
102797,54,mostly-true,AI builders should include human-in-the-loop controls to pause automated actions until approval.,HumanLayer runtime firewall and HITL defense,"Passage endorses HumanLayer-style runtime firewall and upcoming HITL discussion, minor caveat about implementation details omitted.","security,red-team,guardrails",8,Breaking-Securing AI
102798,54,TRUE,Human-in-the-loop mechanisms like HumanLayer pause automated actions until human approval.,runtime firewall for automation; HumanLayer HITL tool,Passage directly states HumanLayer pauses execution awaiting human approval as a runtime firewall.,"security,red-team,guardrails",8,Breaking-Securing AI
102799,97,FALSE,"Merging by hero_names always yields a perfect, lossless dataset union.",dataset merge on 'hero_names' between info_df and powers_df,"Passage reports ~90% match, contradicting claim of perfect, lossless merge due to unmatched entries.","data-prep,feature-engineering,rag",3,Prepping Data for AI
102800,97,FALSE,Merging the datasets guarantees perfect feature alignment for all models.,dataset merge on hero_names for feature engineering,"Contradicted by match rate detail: only ~90% matched, so alignment is not guaranteed.","data-prep,feature-engineering,rag",3,Prepping Data for AI
102801,97,mostly-true,"Most hero records can be merged, enabling addition of power-based features for modeling.",dataset merge on hero_names between info_df and powers_df,"Merge yields ~90% match, so feature integration is broadly supported though minor linkage caveats omitted.","data-prep,feature-engineering,rag",3,Prepping Data for AI
102802,133,half-true,Open-source tools like SpeechT5 and YOLOv5 alone can fully prevent deepfake misuse.,"use of tools Librosa, OpenCV, YOLOv5, SpeechT5 in defense",Correct that open-source tools aid defense but incorrect to claim they alone fully prevent misuse.,"media-forensics,voice-cloning,deepfake",9,Deepfake Defense
102803,133,TRUE,Open-source tools help defenders understand and mitigate deepfake risks.,"tools like Librosa, YOLOv5, SpeechT5 in media-forensics",Passage names specific open-source tools and states openness encourages innovation and risk reduction.,"media-forensics,voice-cloning,deepfake",9,Deepfake Defense
102804,133,pants-fire,Open-source tools completely eliminate risks from deepfake voice cloning and media misuse.,"open-source tools like SpeechT5, Librosa, and YOLOv5",Contradicts passage: openness aids defense but does not eliminate risks from deepfakes or voice cloning.,"media-forensics,voice-cloning,deepfake",9,Deepfake Defense
102805,53,pants-fire,Open-source contributions require using Creative Commons licenses for software code.,"license guidance for software and data (Creative Commons, CC0)",Contradicts passage: CC licenses are not designed for software code; passage says they're for content and data.,"open-source,community,contribution",13,Commit to Contribute
102806,53,half-true,Creative Commons licenses are appropriate for software code in long-term open projects.,"licensing for software and AI assets (Creative Commons, CC0, CC BY)",Mixes correct use for data/docs with incorrect claim about CC suitability for software code.,"open-source,community,contribution",13,Commit to Contribute
102807,53,TRUE,Creative Commons licenses are commonly used for AI content like data and documentation.,license guidance for AI content and datasets,Passage explicitly states CC licenses are frequently used for AI content-related assets such as data and documentation.,"open-source,community,contribution",13,Commit to Contribute
102808,196,half-true,A saved pre-trained digit classifier reliably generalizes to messy handwritten digits without retraining.,saved model evaluating messy handwritten digit images,"Model reuse is correct but passage only shows a test example, not evidence of consistent reliable generalization.","deep-learning,frameworks,tensors",5,Deep Learning
102809,196,mostly-true,The saved pretrained model generalizes to classify new messy handwritten digit images.,"saved model reuse for handwritten digits (pre-trained model, classification)",Demonstrated reuse of a saved pre-trained model to classify messy handwritten digits; minor generalization limits not detailed.,"deep-learning,frameworks,tensors",5,Deep Learning
102810,196,mostly-true,A saved pre-trained digit classifier can generalize to messy handwritten digits without retraining.,using a saved model for handwritten digit classification,"Passage demonstrates loading a saved model to classify squiggly 1s and crossed 7s, implying generalization with no retraining though specific accuracy not reported.","deep-learning,frameworks,tensors",5,Deep Learning
102811,131,TRUE,Transformers use self-attention to capture global context and long-range dependencies in sequences.,self-attention mechanism in Transformers,"Passage explicitly states self-attention lets models weigh all other words, enabling global context and long-range dependency capture.","generative-ai,diffusion,gans",7,Generative AI
102812,131,mostly-true,Transformers generally capture long-range dependencies better than traditional autoregressive models like LSTMs.,self-attention mechanism in Transformers,"Supports improved global context via self-attention, minor caveat omits computational costs and data specifics.","generative-ai,diffusion,gans",7,Generative AI
102813,131,half-true,Transformers can weigh all words to capture long-range dependencies better than LSTMs.,self-attention mechanism in transformers,Accurately notes self-attention's global context benefit but overstates comparative performance without specifics.,"generative-ai,diffusion,gans",7,Generative AI
102814,69,half-true,The Game Master optionally provides a web search query or URL during each trivia round.,game rules; Web Search Challenge optional query or URL,"Accurate that web searches are optional, but passage limits the feature to 'offering' not guaranteed every round.","agentic-ai,planning,tools",12,Agentic AI
102815,69,half-true,The Game Master optionally provides web search queries or URLs during each trivia round.,trivia game setup with Web Search Challenge and Question Generation,"Partly true: passage mentions optional web search clues, but not necessarily provided in every round.","agentic-ai,planning,tools",12,Agentic AI
102816,69,TRUE,The game includes an optional Web Search Challenge where players may use queries or URLs.,game rounds with Web Search Challenge,Passage explicitly describes an optional Web Search Challenge offering a search query or URL for clues.,"agentic-ai,planning,tools",12,Agentic AI
102817,119,barely-true,YOLOv5 reliably detects and prevents deepfake voice cloning in multimedia content.,"YOLOv5 object detection, annotated video, model version","Overreaches beyond passage: YOLOv5 does object detection in video, not voice-cloning or deepfake audio prevention.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
102818,119,half-true,The YOLOv5 demonstration reliably detects and labels multiple objects in video frames with high confidence.,"YOLOv5 object detection demo, confidence threshold and annotations","Demonstration shows multi-object detection and annotated labels, but claims of reliability and uniformly high confidence overstate variable thresholds and performance trade-offs.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
102819,119,mostly-true,YOLOv5 can annotate video frames with bounding boxes and confidence labels in real time.,YOLOv5 object detection model and video annotation code,"Code shows frame-by-frame detection, drawing boxes and confidence labels; real-time implied by loop and model inference.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
102820,73,mostly-true,PyTorch usually suits highly customized training setups better than static-graph frameworks.,PyTorch dynamic computation model and customization for training,"Passage supports PyTorch's dynamic eager execution and flexibility, omitting minor trade-offs with static graphs.","deep-learning,frameworks,tensors",5,Deep Learning
102821,73,half-true,PyTorch always trains models faster than other frameworks because of its eager execution.,PyTorch dynamic computation (eager execution) and training performance,Correct about eager execution but incorrect to claim it always yields faster training than other frameworks.,"deep-learning,frameworks,tensors",5,Deep Learning
102822,73,mostly-true,PyTorch's dynamic eager execution makes it preferable for highly customized deep learning training.,PyTorch dynamic computation / eager execution in training scenarios,"Supports flexibility for custom losses, novel optimizers, and non-standard algorithms; minor nuance about performance trade-offs omitted.","deep-learning,frameworks,tensors",5,Deep Learning
102823,75,barely-true,The Gandalf Dataset reliably prevents prompt injection in deployed LLM systems.,Gandalf Dataset adversarial prompts on Hugging Face,Overstates dataset capability; provides adversarial examples but not proven prevention in deployed systems.,"open-source,community,contribution",13,Commit to Contribute
102824,75,FALSE,"The Gandalf Dataset is a proprietary, paid dataset unavailable on public platforms.",Gandalf Dataset mention in dataset listing,Passage states Gandalf Dataset is available on Hugging Face; calling it proprietary contradicts that availability.,"open-source,community,contribution",13,Commit to Contribute
102825,75,FALSE,The Gandalf Dataset is proprietary and cannot be shared on Hugging Face.,"Gandalf Dataset, Lakera, Hugging Face dataset mention",Passage states Gandalf Dataset is available on Hugging Face; claiming proprietary contradicts that detail.,"open-source,community,contribution",13,Commit to Contribute
102826,168,barely-true,Generative models are frequently used to break into secure systems and commit cybercrimes.,misuse of generative models for security exploits,Overreaches passage: it warns misuse risks like impersonation and misinformation but gives no evidence of frequent cybercrime or system break-ins.,"generative-ai,diffusion,gans",7,Generative AI
102827,168,mostly-true,"Generative models can be misused to impersonate voices, spread misinformation, or breach systems.",model misuse and attack surface for generative AI,"Broadly supported by passage noting those misuse examples, minor caveat about specific prevalence absent.","generative-ai,diffusion,gans",7,Generative AI
102828,168,barely-true,"Generative models are often used to deceive, impersonate voices, and facilitate misuse.",model misuse and security of generative AI,Overstates frequency and inevitability; passage warns misuse risk but doesn't claim pervasive occurrence.,"generative-ai,diffusion,gans",7,Generative AI
102829,50,FALSE,LangChain always corrects missing Species values without introducing bias.,connecting LangChain to a Hugging Face model for Species lookup,Contradicts passage which notes biases in generators and cautions about prompts and parameters.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
102830,50,half-true,Prompt phrasing can both reveal bias and help impute missing dataset values using models.,connecting LangChain to a Hugging Face model for Species imputation,"Mixes correct points: prompts affect bias and can aid imputation, but overstates simplicity and omits parameter tuning details.","data-prep,feature-engineering,rag",3,Prepping Data for AI
102831,50,FALSE,LangChain cannot connect to Hugging Face models for data lookup tasks.,integration example using LangChain and a Hugging Face model,Passage explicitly describes connecting LangChain to a Hugging Face model; statement contradicts that integration detail.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
102832,119,TRUE,Using stratify=y preserves class balance when splitting data into training and test sets.,train_test_split with stratify=y on dataset labels,Directly supported: code uses stratify=y to preserve Marvel/DC class balance during splits.,"machine-learning,classification,evaluation",4,Classical Machine Learning
102833,119,mostly-true,Stratified 80/20 splitting preserves class balance so majority-class baseline predicts most test labels.,stratify=y on training/test split with majority-class baseline,Describes code behavior accurately; minor caveat omitted about performance metrics or rare-class effects.,"machine-learning,classification,evaluation",4,Classical Machine Learning
102834,119,barely-true,Predicting the single most frequent class yields high accuracy on balanced datasets.,stratify=y split preserving class balance,"Overreaches: passage shows majority-class prediction after stratified split but uses imbalanced Marvel majority, so high accuracy on balanced data is not supported.","machine-learning,classification,evaluation",4,Classical Machine Learning
102835,95,half-true,Unregulated open-source AI models often preserve personal data without adequate GDPR safeguards.,open source models and GDPR compliance,Mixes correct concern about data exposure in open-source models with overstated claim that GDPR safeguards are routinely absent; specifics and mitigation options omitted.,"ethics,governance,privacy",11,AI Ethics and Governance
102836,95,mostly-true,AI governance frameworks should align with GDPR principles to protect user privacy in deployments.,"ethics and governance, GDPR and privacy safeguards","Broad UNESCO-style recommendations support alignment with GDPR, though implementation complexity omitted.","ethics,governance,privacy",11,AI Ethics and Governance
102837,95,barely-true,Open-source AI systems always ensure GDPR compliance and protect user privacy.,open source AI and GDPR in governance and privacy,Claims universal GDPR compliance contradictory to UNESCO ethics and governance caution; overreaches on privacy protections.,"ethics,governance,privacy",11,AI Ethics and Governance
102838,72,TRUE,Open systems will shape the next wave of AI after closed systems.,appendix reference to open systems and AI projects,Passage explicitly claims open systems will shape what comes after the first wave of AI.,"ai,open-source,builder",1,Introduction – The Gold Rush Paradox
102839,72,TRUE,Open systems will shape the next phase of AI development.,appendix glossary referencing open systems and AI projects,Directly supported by the appendix claim that open systems will shape what comes after closed systems.,"ai,open-source,builder",1,Introduction – The Gold Rush Paradox
102840,72,TRUE,Open systems will shape the next wave of AI development.,agent-generated glossary and reference architecture mentioning open systems,"Directly stated in the appendix that open systems, not closed ones, will shape what comes after.","ai,open-source,builder",1,Introduction – The Gold Rush Paradox
102841,134,half-true,Fine-tuning a Gradient Boosting Classifier raised accuracy from 77% to about 84%.,Gradient Boosting Classifier accuracy on publisher classification,Matches passage numbers but simplifies tuning details; mixes correct figures with omitted sweep specifics.,"machine-learning,classification,evaluation",4,Classical Machine Learning
102842,134,TRUE,Fine-tuning the Gradient Boosting Classifier raised accuracy to about 84%.,Gradient Boosting model accuracy on publisher classification,"Reported progression shows tuning increased accuracy from 77% untuned to mid-80s, ~84% supported.","machine-learning,classification,evaluation",4,Classical Machine Learning
102843,134,TRUE,Fine-tuned Gradient Boosting Classifier achieved about 84% accuracy on the classification task.,Gradient Boosting Classifier accuracy on publisher classification dataset,Reported progression from 52% to 77% untuned then mid-80s after fine-tuning directly supports ~84% claim.,"machine-learning,classification,evaluation",4,Classical Machine Learning
102844,125,mostly-true,RAG lets models incorporate new information without retraining while the model still handles reasoning.,retrieval-augmented generation (RAG) with model shell and retrieved data,"Accurately reflects that RAG adds external data without retraining, but slightly overstates model reasoning role.","data-prep,feature-engineering,rag",3,Prepping Data for AI
102845,125,barely-true,RAG enables models to truly reason with new data without retraining.,retrieval-augmented generation (RAG) and model behavior,Overstates capability: passage says RAG presents pulled data but model isn't 'thinking' with it.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
102846,125,barely-true,RAG enables models to truly reason with newly added data without retraining.,retrieval-augmented generation (RAG) and dataset retrieval,"Overstates capability: passage says models present pulled data, not genuinely reason with it.","data-prep,feature-engineering,rag",3,Prepping Data for AI
102847,135,mostly-true,RAG enhances story-plot generation by combining hero attributes with synthetic plot concepts.,RAG applied to plot generation using synthetic plot concepts and hero attributes,"Combines passage claim about RAG using hero attributes and synthetic plot concepts, omitting implementation caveats.","data-prep,feature-engineering,rag",3,Prepping Data for AI
102848,135,TRUE,RAG can use hero attributes and synthetic plot concepts to generate story plot datasets.,generating story plot dataset using RAG and hero attributes,Directly supported by passage stating RAG operates with hero attributes and synthetic plot concepts to create datasets.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
102849,135,half-true,The passage claims saving plots to CSV fully prepares data for RAG evaluation pipelines.,"plot dataset, CSV file, RAG","Partly correct that CSV stores plot data, but omits preprocessing, tokenization, and vectorization needed for RAG.","data-prep,feature-engineering,rag",3,Prepping Data for AI
102850,40,mostly-true,"The companion notebook generates a color-coded, clickable HTML architecture reference for open-source projects.",companion notebook producing open_source_ai_reference_architecture.html,"Directly supported: script loads glossary, tallies mentions, filters categories, and renders a clickable HTML grid.","open-source,community,contribution",13,Commit to Contribute
102851,40,half-true,The companion notebook generates a color-coded HTML grid of open-source projects.,companion notebook rendering open_source_ai_reference_architecture.html,"Passage describes loading glossary data, tallying projects, filtering categories, and rendering a color-coded clickable HTML grid.","open-source,community,contribution",13,Commit to Contribute
102852,107,barely-true,Predicting Publisher will be the most important feature for downstream tasks.,Publisher label prediction task with three classes and 52% baseline accuracy,"Passage states Publisher chosen as most important for fine-tuning, but importance not empirically validated.","machine-learning,classification,evaluation",4,Classical Machine Learning
102853,107,mostly-true,Publisher classification offers meaningful improvement opportunities with a 52% baseline accuracy.,"Publisher prediction task with three classes (Marvel, DC, Other)","Passage reports a 52% baseline and three well-populated classes, implying room for improvement.","machine-learning,classification,evaluation",4,Classical Machine Learning
102854,107,FALSE,Gender labels are evenly distributed across classes in the dataset.,gender label distribution (Male skew >70%),"Contradicts passage which states gender is skewed toward Male over 70%, not evenly distributed.","machine-learning,classification,evaluation",4,Classical Machine Learning
102855,119,pants-fire,Blue Lead intentionally creates vulnerabilities to exploit the system for research.,red-team role within Prompt Injection and Execution Control testing,"Contradicts passage: Blue Lead is defender/engineer triaging failures, not attacker creating vulnerabilities.","security,red-team,guardrails",8,Breaking-Securing AI
102856,119,TRUE,A blue lead triages failures in real time and proposes architecturally sound patches.,red-team exercise using Prompt Injection and Execution Control techniques,"Passage describes the Blue Lead as owning the system, triaging failures quickly, and proposing sound fixes.","security,red-team,guardrails",8,Breaking-Securing AI
102857,119,barely-true,Red-teamers primarily aim to break systems using prompt injection and execution control techniques.,red-team role using Prompt Injection and Execution Control,"Largely unsupported: passage says objective is to break system and document how, but overstates 'primarily aim' and omits Blue Lead responsibilities.","security,red-team,guardrails",8,Breaking-Securing AI
102858,121,half-true,The agent found two recent superhero movies and averaged their IMDb and Rotten Tomatoes scores.,"agent task using Web search and tools (IMDb, Rotten Tomatoes)",Mixes correct behavior (searching IMDb/Rotten Tomatoes) with unspecified specifics about which movies and exact scores.,"ai,tool-chain,notebooks",2,AI Survival Kit
102859,121,TRUE,An agent used web search to find recent superhero movie ratings and compute their average.,agent Role: Entertainment Analyst using Web search and IMDb/Rotten Tomatoes,Passage describes an Entertainment Analyst agent using web search and checking IMDb and Rotten Tomatoes to find ratings and calculate their average.,"ai,tool-chain,notebooks",2,AI Survival Kit
102860,121,FALSE,The agent used internal pretrained knowledge rather than web search to find movie ratings.,agent tools: Web search; sources like IMDb and Rotten Tomatoes,Contradicts passage specifying Web search and checking IMDb/Rotten Tomatoes as used tools.,"ai,tool-chain,notebooks",2,AI Survival Kit
102861,19,FALSE,Agentic AI requires no prompt templates or model abstractions to act autonomously.,prompts and prompt templates; models and model abstractions,Contradicts passage details stating both prompt templates and model abstractions are foundational requirements.,"agentic-ai,planning,tools",12,Agentic AI
102862,19,FALSE,LangChain is universally the gold standard for integrating prompts and models into intelligent applications.,LangChain integration of prompts and model abstractions,Contradicts passage's claim that LangChain is 'the gold standard' by asserting universal superiority without evidence.,"agentic-ai,planning,tools",12,Agentic AI
102863,19,TRUE,"Prompts, prompt templates, models, and model abstractions enable AI to process information intelligently.","foundational abstractions: prompts, prompt templates, models, LangChain",Directly stated that prompts and models are foundational abstractions enabling intelligent processing; LangChain used for exploration.,"agentic-ai,planning,tools",12,Agentic AI
102864,87,barely-true,LLaMA is a versatile open-source model that reliably generates accurate code and facts.,tool: LLaMA language model,"Overstates reliability and factual accuracy; passage notes LLaMA generates text, summaries, and code but not guaranteed accuracy.","ai,tool-chain,notebooks",2,AI Survival Kit
102865,87,mostly-true,"LLaMA is an open-source language model that can generate text, summarize information, and write code.",tool overview mentioning LLaMA and Stable Diffusion on Hugging Face,"Passage explicitly names LLaMA as open-source and describes those text-generation, summarization, and code-writing abilities.","ai,tool-chain,notebooks",2,AI Survival Kit
102866,87,barely-true,LLaMA and Stable Diffusion are the only useful generative models for notebooks and tool chains.,"model use in notebooks, tool-chain, GenAI",Overreaches by excluding thousands on Hugging Face and misrepresents breadth of useful models.,"ai,tool-chain,notebooks",2,AI Survival Kit
102867,76,half-true,CrewAI both extends LangChain for agent workflows but exaggerates seamless multi-step automation reliability.,"integration with LangChain, Agents, Tools, Tasks","Accurately notes CrewAI builds on LangChain and structured agents, but overstates flawless multi-step execution reliability.","agentic-ai,planning,tools",12,Agentic AI
102868,76,barely-true,CrewAI fully automates complex multi-step workflows without human oversight.,agent creation and structured task delegation with LangChain integration,"Overreaches: passage shows CrewAI structures agents and workflows but mentions human development and Colab testing, not full unattended automation.","agentic-ai,planning,tools",12,Agentic AI
102869,76,TRUE,CrewAI enables agents to perform structured multi-step workflows using tools and tasks.,"integration with LangChain, Agents, Tools, and Tasks",Passage explains CrewAI builds on LangChain to create agents with clear goals and multi-step workflows.,"agentic-ai,planning,tools",12,Agentic AI
102870,114,half-true,TensorFlow always requires GradientTape for any gradient computation with tensors.,automatic differentiation with tf.GradientTape and tf.Variable,"Partially true: GradientTape tracks ops for grads, but Keras and other APIs often handle or abstract gradients, so 'always requires' is incorrect.","deep-learning,frameworks,tensors",5,Deep Learning
102871,114,barely-true,TensorFlow requires manual gradient recording for all tensors using tf.GradientTape().,automatic differentiation with tf.GradientTape and torch.Tensor behavior,"Overreaches: passage says TensorFlow uses GradientTape for tracking, but not that every tensor always needs manual recording.","deep-learning,frameworks,tensors",5,Deep Learning
102872,114,half-true,"Tensor requires special settings in PyTorch to record gradients, unlike TensorFlow's GradientTape which always records them.","automatic differentiation, torch.Tensor and tf.GradientTape",Mixes correct PyTorch detail with incorrect absolute claim about GradientTape always recording; GradientTape only records inside its context.,"deep-learning,frameworks,tensors",5,Deep Learning
102873,91,pants-fire,Feature merging always guarantees perfect model answers for every query about the superhero dataset.,feature engineering for superhero dataset offensive power score,"Asserts certainty that merging features ensures perfection; passage only suggests merging can clarify comparisons, not guarantee flawless answers.","data-prep,feature-engineering,rag",3,Prepping Data for AI
102874,91,half-true,"Combining Super Strength, Agility, and Energy Manipulation always yields a superior offensive power feature.",feature engineering on superhero dataset,Mixes correct idea of merging features with incorrect certainty that the combined score is always superior.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
102875,91,barely-true,Merging related attributes into a single offensive power score always improves model performance on combat questions.,"feature engineering for superhero dataset, offensive power score",Overreaches beyond passage: example suggested merging but did not claim guaranteed or universal improvement.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
102876,155,mostly-true,"Classical ML typically trains quickly on standard hardware, enabling rapid experiments without GPUs.",training time and hardware for models (classical ML vs deep learning),"Passage notes classical ML trains in seconds or minutes on standard hardware, unlike GPU‑heavy deep learning.","machine-learning,classification,evaluation",4,Classical Machine Learning
102877,155,barely-true,Classical ML models always train in seconds on standard hardware without GPUs.,training time and hardware for classical ML models,"Overreach: passage says often trains in seconds or minutes, not always; ignores dataset/model size variability.","machine-learning,classification,evaluation",4,Classical Machine Learning
102878,155,TRUE,"Classical ML trains quickly on standard hardware, enabling rapid experimentation without GPUs.",resource usage and explainability with SHAP/LIME,Passage states classical ML trains in seconds or minutes on standard hardware and is compatible with SHAP and LIME.,"machine-learning,classification,evaluation",4,Classical Machine Learning
102879,16,pants-fire,AI models deliberately fabricate crimes about individuals to manipulate legal outcomes.,transparency in data sourcing and biased datasets,"Directly contradicts passage: passage discusses biased data causing unfair outcomes, not intentional fabrication of crimes.","ethics,governance,privacy",11,AI Ethics and Governance
102880,16,half-true,Advisory boards alone cannot reliably enforce consistent ethical standards across diverse AI systems.,applying ethical standards; data sourcing and model interpretability,Mixes correct point about enforcement difficulty with overgeneralization that advisory boards cannot contribute substantially.,"ethics,governance,privacy",11,AI Ethics and Governance
102881,16,mostly-true,AI ethics advisory boards can guide but struggle to enforce standards across diverse AI systems.,"ethical standards, advisory boards, transparency in data sourcing","Passage says boards suggest guidelines but enforcement across varied systems is difficult, omitting enforcement mechanisms.","ethics,governance,privacy",11,AI Ethics and Governance
102882,49,barely-true,The RNN model always achieves high accuracy by one-hot encoding character pairs for classification.,build_and_predict_rnn function; one-hot encoding of character input-output pairs,Overstates outcome: passage describes preprocessing and one-hot encoding but gives no accuracy or performance claims.,"neural-networks,cnn,transformers",6,Neuron Building Blocks
102883,49,TRUE,The function creates character-level input-output pairs where the model predicts the next character.,"build_and_predict_rnn function, character vocabulary and c2i mapping",Directly supported: it maps characters to integers and forms one-hot encoded next-character prediction pairs.,"neural-networks,cnn,transformers",6,Neuron Building Blocks
102884,49,FALSE,The function trains a word-level RNN expecting whole-word inputs and outputs.,build_and_predict_rnn() using character vocabulary c2i,"Contradicts passage: model uses character-level vocabulary and next-character prediction, not word-level training.","neural-networks,cnn,transformers",6,Neuron Building Blocks
102885,48,FALSE,The passage argues that secrecy and opaque systems increase user trust and retention.,"trust, transparency, and explainability in AI systems",Contradicts passage emphasis on transparency and explainability; secrecy reduces trust and retention.,"ai,open-source,builder",1,Introduction – The Gold Rush Paradox
102886,48,mostly-true,"Transparent, explainable systems generally build user trust that increases long-term use and value.",trust-building feedback loop; explainability and data management,"Passage explains a feedback loop where explainability and responsible data practices increase trust, use, and value, omitting minor implementation caveats.","ai,open-source,builder",1,Introduction – The Gold Rush Paradox
102887,48,TRUE,Transparency and responsible data management build user trust that increases product use.,trust-feedback loop; explainability and data management in AI systems,"Passage states explainability and responsible data management create trust, driving use and value.","ai,open-source,builder",1,Introduction – The Gold Rush Paradox
102888,102,barely-true,AI-assisted automation always causes significant real-world harm when models make subtle errors.,automation layer in AI-assisted automation,"Overstates consequences: passage warns risk from errors but advocates HITL to manage harm, not inevitable significant harm.","security,red-team,guardrails",8,Breaking-Securing AI
102889,102,mostly-true,Human-in-the-loop oversight is advisable when models trigger real-world automated actions.,automation layer with model-triggered real-world actions,Passage supports HITL to mitigate risks from injections or hallucinations causing real-world harm.,"security,red-team,guardrails",8,Breaking-Securing AI
102890,102,TRUE,Human-in-the-loop designs mitigate automation risks when models trigger real-world actions.,automation layer where model outputs trigger real-world actions,Passage explains HITL is examined to manage risks from injections or hallucinations causing real-world harms.,"security,red-team,guardrails",8,Breaking-Securing AI
102891,128,mostly-true,"MLflow is a modular Python-friendly platform for managing experiments, reproducibility, and deployments.","MLflow tracking, projects, models, registry in Python environments","Accurately reflects modular architecture and Python focus, omitting minor backend or W&B comparisons.","mlops,scaling,deployment",10,AI At Scale
102892,128,TRUE,"MLflow provides modular tools for tracking, projects, models, and a registry for Python teams.",MLflow tooling and modular architecture for deployment and tracking,"Directly supported by passage: MLflow modularity and suitability for Python teams with tracking, projects, models, registry.","mlops,scaling,deployment",10,AI At Scale
102893,128,barely-true,MLflow is universally the best choice for production model deployment across all cloud backends.,MLflow deployment and registry for Python teams using S3 or Azure,Passage highlights modularity and flexibility but does not claim universal superiority across clouds or use cases.,"mlops,scaling,deployment",10,AI At Scale
102894,105,TRUE,"OPR and SDR provide complementary, sensible signals when evaluated against raw power flags.",feature evaluation using OPR and SDR scores,"Sanity checks confirmed rankings matched expectations, aligned with raw power flags, and differed from each other.","data-prep,feature-engineering,rag",3,Prepping Data for AI
102895,105,TRUE,OPR and SDR rankings conveyed intended signals and passed sanity checks in the run.,feature evaluation using OPR and SDR scores,"Validation checked rankings, agreement with raw power flags, and score diversity; all three succeeded.","data-prep,feature-engineering,rag",3,Prepping Data for AI
102896,105,barely-true,OPR and SDR reliably carry intended signals for ranking and power-flags alignment.,"sanity check using OPR, SDR scores and raw power flags","Passage reports success for a specific run, but general reliability is overgeneralized beyond that single test.","data-prep,feature-engineering,rag",3,Prepping Data for AI
102897,75,half-true,The passage claims a MultinomialNB bag-of-words model makes fast and accurate text predictions.,tool: MultinomialNB classifier using bag-of-words,"Mixes correct mechanism (bag-of-words, MultinomialNB) with an overstated guarantee of accuracy and speed.","ai,tool-chain,notebooks",2,AI Survival Kit
102898,75,half-true,The MultinomialNB classifier always yields fast and accurate text predictions from any bag-of-words representation.,MultinomialNB classifier using bag-of-words numeric representation,"Correct that MultinomialNB is fast with bag-of-words, but overstated 'always' and 'any' ignores dataset, feature, and task limits.","ai,tool-chain,notebooks",2,AI Survival Kit
102899,75,TRUE,The passage describes training a MultinomialNB classifier using bag-of-words numeric text representations.,tool-chain example using MultinomialNB and bag-of-words,Directly supported: model.fit trains MultinomialNB on numeric bag-of-words text features for predictions.,"ai,tool-chain,notebooks",2,AI Survival Kit
102900,18,TRUE,The dataset is openly available on Kaggle under a CC0 license for easy sharing.,"Kaggle dataset with CC0 license, data loading and experimentation","Passage explicitly states dataset is on Kaggle under CC0, enabling easy sharing and experimentation.","data-prep,feature-engineering,rag",3,Prepping Data for AI
102901,18,half-true,The dataset is public-domain on Kaggle and always perfectly clean for model training.,dataset availability on Kaggle (CC0) for data-prep exercises,"Correct about CC0 Kaggle availability, but incorrectly asserts perfect cleanliness and readiness for training.","data-prep,feature-engineering,rag",3,Prepping Data for AI
102902,18,pants-fire,The dataset is proprietary and restricted from public redistribution.,Kaggle dataset with CC0 license,"Contradicts explicit CC0 public domain licensing and Kaggle availability, claiming restriction.","data-prep,feature-engineering,rag",3,Prepping Data for AI
102903,24,pants-fire,"Open-source AI requires no maintenance, funding, or governance to survive indefinitely.","support dimensions: time, money, stewardship in open-source AI","Contradicts explicit passage details listing maintenance, donations, and governance as required supports.","open-source,community,contribution",13,Commit to Contribute
102904,24,barely-true,Open-source AI projects mainly need financial sponsorship to remain viable long-term.,supporting open-source AI via GitHub Sponsors and Open Collective,Overstates emphasis on money; passage lists time and stewardship alongside sponsorship.,"open-source,community,contribution",13,Commit to Contribute
102905,24,TRUE,"Sustaining open-source AI requires contributors to provide time, money, and stewardship.",supporting open-source AI via GitHub Sponsors and governance,"Passage explicitly lists time, money, and stewardship as necessary support mechanisms for open-source AI.","open-source,community,contribution",13,Commit to Contribute
102906,66,barely-true,Open-source tools alone make builders able to create the most powerful modern AI systems.,"open-source movement, ML and DL tools","Overstates role of open-source; passage credits accessibility but omits infrastructure, data, and expertise requirements.","ai,tool-chain,notebooks",2,AI Survival Kit
102907,66,barely-true,"Deep learning is the newest, most powerful tool within AI's umbrella according to the passage.","definition of AI, ML, and DL in the tool-chain","Passage claims DL is the newest and most powerful tool under AI umbrella, but this is an evaluative overreach.","ai,tool-chain,notebooks",2,AI Survival Kit
102908,66,TRUE,Deep learning is the most powerful tool within machine learning under the AI umbrella.,AI taxonomy and open-source ML/DL tools,"Passage explicitly frames DL as the newest, most powerful tool under ML within AI, supported by open-source accessibility.","ai,tool-chain,notebooks",2,AI Survival Kit
102909,44,mostly-true,Clément Delangue co-founded and leads an AI-focused company with strong open-source and community emphasis.,"founder leadership, open-source, community, AI company","Passage and references attribute Delangue as co-founder/leader and emphasize open-source and community focus, minor operational details omitted.","open-source,community,ai",0,Foreword – Robo Interviews Clément Delangue
102910,44,pants-fire,Clément Delangue secretly founded a rival closed-source AI empire to destroy open-source community projects.,"profile and community, open-source and AI background",Directly contradicts described supportive open-source and community involvement; claims of secret hostile empire are implausible.,"open-source,community,ai",0,Foreword – Robo Interviews Clément Delangue
102911,44,barely-true,Clément Delangue built a major open-source AI community project solely through early eBay sales proceeds.,"profile spotlight mentioning eBay, UniShared, open-source community",Claim overstates funding source and impact; passage notes eBay activity and UniShared inspiration but not sole funding or 'major' project.,"open-source,community,ai",0,Foreword – Robo Interviews Clément Delangue
102912,24,barely-true,Librosa alone can create Shazam-level audio fingerprints for voice identification.,audio fingerprinting using Librosa features,Overstates capability: Librosa provides features but Shazam-level identification needs specialized algorithms and indexing.,"media-forensics,voice-cloning,deepfake",9,Deepfake Defense
102913,24,FALSE,Librosa cannot extract measurable audio features from raw sound waves.,feature extraction using Librosa for audio fingerprints,Directly contradicts passage claiming Librosa transforms raw audio into quantifiable features useful for fingerprints.,"media-forensics,voice-cloning,deepfake",9,Deepfake Defense
102914,24,half-true,Librosa-based audio fingerprints capture distinctive voice patterns but may miss some raw-audio details.,audio fingerprinting using Librosa features,"Accurately notes Librosa creates compact features and fingerprints, but concedes loss of some raw-audio detail.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
102915,7,TRUE,Red and Blue teams collaboratively improve AI system resilience through iterative testing and patching.,security gateways and Red Team/Blue Team operations,Passage describes Red Team using real tactics and Blue Team patching and validating to strengthen resilience.,"security,red-team,guardrails",8,Breaking-Securing AI
102916,7,barely-true,The Red Team fully prevents all AI misuse by anticipating every possible attack vector.,Red Team and security gateways in AI system defense,"Overreaches beyond passage: Red Team tests tactics but passage emphasizes resilience, not perfect prevention.","security,red-team,guardrails",8,Breaking-Securing AI
102917,7,mostly-true,"Red and Blue teams collaboratively harden AI systems through testing, patching, and human oversight.",security gateway testing with Red Team and Blue Team practices,"Passage describes Red Team offense, Blue Team patching, human oversight, and resilience focus, omitting implementation specifics.","security,red-team,guardrails",8,Breaking-Securing AI
102918,100,TRUE,The detector correctly labeled cloned Jerry voice samples as not real while authentic clip passed.,predict_new_wav function on cloned and authentic Jerry audio samples,"Test logs show two cloned files flagged Not Real Jerry and an authentic control accepted, directly supported.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
102919,100,FALSE,The detector always correctly distinguishes cloned from authentic Jerry audio samples.,predict_new_wav detection on cloned and authentic Jerry WAV files,Contradicts passage: only three tests shown; claim overgeneralizes beyond those specific examples.,"media-forensics,voice-cloning,deepfake",9,Deepfake Defense
102920,62,TRUE,"Generative models like GANs, VAEs, diffusion models, and transformers can produce and remix multimedia content.",generative models and pre-trained transformers in AI,"Lists GANs, VAEs, diffusion models, and transformers as tools that produce images, complete text, and remix multimedia content.","ai,open-source,builder",1,Introduction – The Gold Rush Paradox
102921,66,barely-true,The script sends PDF text to a pretrained transformer QA model without any chunking or retrieval steps.,question-answering model with uploaded PDF text,"Overstates implementation: passage says text stored as single string, but omits typical chunking/retrieval needs and scalability issues.","neural-networks,cnn,transformers",6,Neuron Building Blocks
102922,66,mostly-true,"A compact demo uploads a PDF, extracts its text, and queries a pretrained QA model with user questions.",implementation of Chat with My Data pattern using a pretrained question-answering model,"Describes documented flow accurately; minor caveat omits handling of page segmentation, embeddings, or chunking.","neural-networks,cnn,transformers",6,Neuron Building Blocks
102923,66,FALSE,The script uses a retrieval-augmented generation pipeline with vector search over PDF chunks.,question-answering model on uploaded PDF text,"Passage states text is stored as a single context string and passed directly to a pretrained QA model, contradicting vector search over chunks.","neural-networks,cnn,transformers",6,Neuron Building Blocks
102924,54,FALSE,Transformers were introduced in the 1990s as recurrent neural networks.,"transformers, Attention Is All You Need, model history","Dates and architecture contradicted: transformers appeared in 2017, distinct from RNN designs.","neural-networks,cnn,transformers",6,Neuron Building Blocks
102925,54,half-true,Transformers immediately outperform all RNNs on every language task after 2017.,"transformers vs RNNs, Attention Is All You Need paper","Correct that transformers improved context and efficiency, but overstated universal immediate superiority across every task.","neural-networks,cnn,transformers",6,Neuron Building Blocks
102926,54,TRUE,Transformers introduced in 2017 enable models to understand context more effectively than RNNs.,transformers; Attention Is All You Need paper,Passage states transformers (2017) understand context more effectively and train more efficiently than RNNs.,"neural-networks,cnn,transformers",6,Neuron Building Blocks
102927,131,TRUE,Stochastic gradient descent updates model parameters using small batches or single examples.,optimization method using SGD and mini-batches in deep learning,Directly described: SGD computes gradients on small batches or single examples and updates weights immediately.,"deep-learning,frameworks,tensors",5,Deep Learning
102928,131,mostly-true,"Stochastic gradient descent updates model weights using small batches or single examples, introducing training noise.",optimization using SGD with minibatches and noisy updates,"Describes SGD's incremental updates and added randomness; minor caveat omitted about learning rate, momentum, or convergence techniques.","deep-learning,frameworks,tensors",5,Deep Learning
102929,131,TRUE,Stochastic gradient descent updates model weights immediately using small minibatches or single examples.,optimization method using minibatch or single-example SGD,"Passage directly describes SGD performing immediate updates with small batches or single examples, causing randomness.","deep-learning,frameworks,tensors",5,Deep Learning
102930,52,barely-true,The author led development of global AI governance policies at IBM.,"AI ethics role at IBM, governance and policy",Overreaches: passage mentions AI ethics work at IBM but not leading global governance policies.,"ethics,governance,privacy",11,AI Ethics and Governance
102931,52,mostly-true,The author has focused on AI ethics work at IBM for about a decade.,AI ethics role at IBM; research and academia background,"Timeline broadly matches: decade-long shift to IBM ethics work after academic research, minor wording simplification.","ethics,governance,privacy",11,AI Ethics and Governance
102932,52,TRUE,The author shifted focus at IBM to include AI ethics alongside AI research about a decade ago.,AI ethics role at IBM; author career timeline,Passage explicitly states the author joined IBM roughly ten years ago and added AI ethics to their responsibilities.,"ethics,governance,privacy",11,AI Ethics and Governance
102933,113,TRUE,Agents can pass data dynamically to keep interactions modular and reusable.,agentic AI prompt using CrewAI passing data between agents,Passage explicitly describes passing data between agents to keep everything modular and reusable.,"agentic-ai,planning,tools",12,Agentic AI
102934,113,FALSE,Agents must always share full answers with every other agent during task coordination.,agent communication in CrewAI prompt with agents and Game Master,"Contradicts passage detail: Game Master outputs answer but contestants receive only the question, not full answers.","agentic-ai,planning,tools",12,Agentic AI
102935,113,barely-true,The prompt enables dynamic data passing between CrewAI agents for modular task reuse.,agentic AI prompt using CrewAI and Neural Duel,Overstates support: passage suggests modular data passing idea but provides only a brief illustrative prompt.,"agentic-ai,planning,tools",12,Agentic AI
102936,51,mostly-true,Clément Delangue highlights Hugging Face’s support for open-source community collaboration around AI tools.,Foreword discussing Hugging Face partnerships and developer platforms,"Passage shows multiple integrations and collaborations that broadly support open-source community engagement, omitting minor implementation caveats.","open-source,community,ai",0,Foreword – Robo Interviews Clément Delangue
102937,51,barely-true,The foreword claims Hugging Face single-handedly built a global open-source AI community driving production deployments.,Hugging Face partnerships and open-source community,"Overstates individual role; passage lists multiple partners (IBM, Amazon, Microsoft, Intel), not single-handed community leadership.","open-source,community,ai",0,Foreword – Robo Interviews Clément Delangue
102938,51,barely-true,Hugging Face single-handedly controls open-source AI model development and community governance.,Hugging Face partnerships and model hub,"Overstates control; passage lists multiple corporate partnerships and integrations, not exclusive governance.","open-source,community,ai",0,Foreword – Robo Interviews Clément Delangue
102939,37,half-true,"The judging model evaluates code clarity, correctness, and follow-up handling for responses in hosted matchups.",evaluation prompt for judging model in hosted Hugging Face matchups,Mixes correct evaluation criteria with unspecified judging metrics and lacks scoring detail.,"mlops,scaling,deployment",10,AI At Scale
102940,37,half-true,The judging model evaluates generated code correctness and explanation clarity in hosted model matchups.,"evaluation prompt for LLaMA 2 code response, judging model, Hugging Face matchup",Mixes correct evaluation criteria with unclear degree of automated scoring and hosting specifics.,"mlops,scaling,deployment",10,AI At Scale
102941,37,half-true,The passage mixes correct code output with overstated evaluation details about judging models.,judging model evaluation of LLaMA 2 code snippet,Combines accurate factorial code with an imprecise claim about judging model criteria and hosting on Hugging Face.,"mlops,scaling,deployment",10,AI At Scale
102942,58,half-true,Using 3D convolutions is always best for volumetric or spatiotemporal generative tasks.,model architecture choice for volumetric/spatiotemporal data (3D convolutions),Overstates guidance: passage recommends 3D convolutions for such data but doesn't claim they're always best.,"generative-ai,diffusion,gans",7,Generative AI
102943,58,half-true,Using 2D convolutions for images and 1D for audio is sometimes overstated as always optimal.,convolutional layer selection for image and audio models,Passage recommends 2D for images and 1D for sequential data but doesn't claim universality; blanket optimality is mixed.,"generative-ai,diffusion,gans",7,Generative AI
102944,58,mostly-true,Generative models benefit from modality-specific convolutions and attention for improved cross-domain outputs.,"model design guidance (2D/1D/3D convolutions, nn.MultiheadAttention)",Guidance directly recommends convolution types and attention for text-to-image alignment; omits implementation caveats.,"generative-ai,diffusion,gans",7,Generative AI
102945,56,barely-true,The abstraction layer only works with Hugging Face models and cannot support other providers.,generic model abstraction layer for Hugging Face models,Passage says it’s designed for Hugging Face but explicitly can be adapted to support other providers.,"agentic-ai,planning,tools",12,Agentic AI
102946,56,TRUE,The function provides a generic model abstraction layer enabling easy model swapping.,function abstraction layer for Hugging Face models,"Explicitly describes a consistent request structure that standardizes inputs, easing model replacement.","agentic-ai,planning,tools",12,Agentic AI
102947,56,half-true,The described function standardizes requests for Hugging Face models but also fully supports local LLMs without change.,generic model abstraction layer for Hugging Face and local LLMs,Correct about standardizing Hugging Face requests; incorrect claim that local LLMs are fully supported without adaptation.,"agentic-ai,planning,tools",12,Agentic AI
102948,133,TRUE,Transformers use self-attention to focus on relevant sequence parts during processing.,"self-attention mechanism in Transformer models (e.g., GPT, BERT, T5, LLaMA)","Explains that self-attention lets models link distant words (e.g., 'was' to 'sandwich'), directly supported by passage.","generative-ai,diffusion,gans",7,Generative AI
102949,133,FALSE,Transformers primarily use recurrent connections rather than self-attention mechanisms.,model architecture: self-attention in Transformer models,Contradicts passage detail that self-attention is the key innovation; recurrence is not used in Transformers.,"generative-ai,diffusion,gans",7,Generative AI
102950,133,TRUE,Transformers use self-attention to let models focus on relevant sequence tokens.,self-attention mechanism in Transformer models,"Directly described: self-attention enables deciding which sequence parts to focus on, illustrated with token linking.","generative-ai,diffusion,gans",7,Generative AI
102951,11,FALSE,Adversaries rarely target public-facing chatbots or training pipelines in real attacks.,public-facing chatbots and training pipelines vulnerability discussion,Contradicts passage asserting adversaries focus on public-facing chatbots and training pipelines.,"security,red-team,guardrails",8,Breaking-Securing AI
102952,11,mostly-true,Adversaries focus on everyday attack surfaces like public-facing chatbots and training pipelines.,red-team adversary targeting public-facing chatbot and training pipeline vulnerabilities,"Passage describes skilled adversaries exploiting overlooked real-world attack surfaces such as chatbots and pipelines, omitting few nuances.","security,red-team,guardrails",8,Breaking-Securing AI
102953,11,half-true,Adversaries prioritize overlooked everyday attack surfaces in public-facing chatbots and pipelines.,public-facing chatbots and training pipelines vulnerability surface,"Correctly notes focus on everyday attack surfaces and chatbots, but overstates adversary uniform prioritization.","security,red-team,guardrails",8,Breaking-Securing AI
102954,91,TRUE,Fine-tuned SpeechT5 with HiFi-GAN and a speaker embedding can synthesize speech sounding like Jerry Cuomo.,"voice cloning using SpeechT5 model, HiFi-GAN vocoder, speaker_embeddings",Code and description show SpeechT5 plus HiFi-GAN and an embedding generate a waveform resembling Jerry's voice.,"media-forensics,voice-cloning,deepfake",9,Deepfake Defense
102955,91,half-true,A fine-tuned SpeechT5 with a saved speaker embedding perfectly clones Jerry Cuomo's voice from a single short sentence.,voice-cloning using SpeechT5 model and speaker_embedding with HiFi-GAN vocoder,"Mixes correct setup (SpeechT5, embedding, HiFi-GAN) with overclaim that a single short sentence yields a perfect clone.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
102956,91,FALSE,The SpeechT5 demo synthesizes perfect undetectable replicas of Jerry Cuomo's voice every time.,voice cloning using SpeechT5 model and HiFi-GAN vocoder,"Contradicts passage: it shows a test synthesis using speaker embeddings, not guaranteed perfection or undetectability.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
102957,105,barely-true,Model cards always provide complete training data and ethical assurances for every model.,"model cards, model documentation, Hugging Face Model Card","Overstates coverage: passage notes cards include training and ethics sometimes, not always complete assurances.","ai,tool-chain,notebooks",2,AI Survival Kit
102958,105,half-true,Model cards always include training details and ethical limitations for every model.,model card description in AI tool documentation,Accurate claim about training and ethics mixed with overgeneralization—cards sometimes lack complete details.,"ai,tool-chain,notebooks",2,AI Survival Kit
102959,105,barely-true,Model cards always provide complete ethical analyses and limitations for responsible use.,"model card documentation for models (e.g., Llama 3)","Overreaches: passage says cards sometimes include ethical considerations and limitations, not always complete analyses.","ai,tool-chain,notebooks",2,AI Survival Kit
102960,19,mostly-true,Shortcut (residual) connections help deep networks train by carrying forward useful information between layers.,shortcut connections / residual connections in deep neural nets,"Passage states they avoid vanishing gradients and carry forward useful information, omitting implementation caveats.","neural-networks,cnn,transformers",6,Neuron Building Blocks
102961,19,mostly-true,Shortcut (residual) connections help avoid vanishing gradients and ease training of very deep networks.,residual/shortcut connections in neural networks (vanishing gradients),"Supported by passage: residual links carry useful information forward, reducing vanishing gradients while easing deep network training.","neural-networks,cnn,transformers",6,Neuron Building Blocks
102962,19,half-true,Shortcut (residual) connections let deep CNNs carry forward useful activations without relearning them each layer.,shortcut connections / residual connections in deep convolutional networks,Mixes correct benefit of avoiding vanishing gradients with slight overclaim that they universally let networks carry forward activations without any relearning.,"neural-networks,cnn,transformers",6,Neuron Building Blocks
102963,95,TRUE,Cosine similarity on PCA components identifies closest hero pairs within clusters.,cosine_similarity on first 20 PCA components,Passage states Scikit-Learn cosine_similarity using first 20 PCA components finds closest hero pairs within each group.,"machine-learning,classification,evaluation",4,Classical Machine Learning
102964,95,pants-fire,Cosine similarity scores of PCA components always range from 0 to 1 for all models.,cosine_similarity on PCA components using Scikit-Learn,"Contradicts described range (-1 to 1); cosine_similarity can be negative, so claim is implausible.","machine-learning,classification,evaluation",4,Classical Machine Learning
102965,95,mostly-true,Cosine similarity on the first 20 PCA components reveals closest hero pairs within clusters.,cosine_similarity on 20 PCA components for clustering,"Method matches passage: Scikit-Learn cosine_similarity on first 20 PCA components identifies closest pairs, omitting potential scaling caveat.","machine-learning,classification,evaluation",4,Classical Machine Learning
102966,33,half-true,The passage claims treating data as valuable yields lasting benefit but risks over-simplifying data economics.,prompt to DALL·E 3 illustrating ‘Data’ vs ‘Gold’ metaphor,Mixes correct advice about valuing data with an oversimplified economic implication absent from the prompt.,"ai,open-source,builder",1,Introduction – The Gold Rush Paradox
102967,33,FALSE,The passage claims open-source AI models should be freely released without restrictions.,prompt to DALL·E 3 illustrating data value,Contradicts passage focus on respecting and using data wisely; no advocacy for unrestricted open-source releases.,"ai,open-source,builder",1,Introduction – The Gold Rush Paradox
102968,33,TRUE,The passage asserts data should be valued like gold and not given away freely.,metaphor prompt to DALL·E 3 illustrating 'Data is Gold',Metaphor and prompt explicitly equate data with gold and warn against giving it away.,"ai,open-source,builder",1,Introduction – The Gold Rush Paradox
102969,168,FALSE,Encryption is unnecessary for securing sensitive datasets during data preparation.,data preparation; encryption for datasets and TLS transfers,Contradicts passage detail that encryption (storage and TLS) is recommended for protecting sensitive datasets.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
102970,168,TRUE,Encryption should protect sensitive datasets at rest and in transit during data preparation.,"data preparation for sensitive datasets (encryption, TLS, storage encryption)",Directly supported by passage specifying storage encryption and TLS for datasets in preparation.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
102971,168,half-true,Encrypting healthcare datasets before cloud storage prevents unauthorized access without any additional safeguards.,"data preparation for sensitive datasets (healthcare), storage encryption","Correctly notes encryption importance but omits key management, access controls, and transit protections.","data-prep,feature-engineering,rag",3,Prepping Data for AI
102972,160,pants-fire,Deep learning frameworks always require ToTensor() and Normalize() transformations for correct training.,data preprocessing and transformations like ToTensor() and Normalize(),"Passage describes these as examples of transformations, not mandatory requirements; claim contradicts flexibility.","deep-learning,frameworks,tensors",5,Deep Learning
102973,160,half-true,Parallel data loading always prevents overfitting by eliminating data-order memorization during training.,data loading and Parallel Processing with worker processes,Parallel loading reduces I/O bottlenecks but doesn't guarantee prevention of overfitting or memorization; other factors matter.,"deep-learning,frameworks,tensors",5,Deep Learning
102974,160,mostly-true,Deep-learning data loaders commonly apply ToTensor() and Normalize() transforms during training.,data loading and transforms using ToTensor and Normalize,Passage describes using ToTensor() and Normalize() on the fly; statement omits minor details about other possible transforms.,"deep-learning,frameworks,tensors",5,Deep Learning
102975,109,barely-true,Automatic differentiation always gives exact gradients for any neural network architecture.,automatic differentiation for neural networks,"Overreaches: AD computes precise derivatives but can be limited by implementation, numerical precision, or non-differentiable ops.","deep-learning,frameworks,tensors",5,Deep Learning
102976,109,FALSE,Large gradients indicate parameters are already near optimal and need minimal adjustment.,gradient magnitude in neural network parameter updates,Contradicts passage detail that large gradients mean parameters are far off and require big adjustments.,"deep-learning,frameworks,tensors",5,Deep Learning
102977,109,mostly-true,Large gradients generally indicate parameters require larger adjustments during training.,automatic differentiation and gradient magnitude in neural networks,"Supported by passage: large gradients imply parameters are far off and need big adjustments, omitting edge cases like noisy or exploding gradients.","deep-learning,frameworks,tensors",5,Deep Learning
102978,9,TRUE,T5 is used to build a lightweight summarization pipeline in the passage.,summarization pipeline using T5 and LIAR dataset,Directly stated: passage specifies building a lightweight summarization pipeline with T5 and LIAR dataset.,"mlops,scaling,deployment",10,AI At Scale
102979,9,TRUE,A lightweight summarization pipeline using T5 is demonstrated for building and running AI systems.,implementation example using T5 model and LIAR dataset,Passage explicitly describes building a lightweight T5 summarization pipeline with the LIAR dataset as a testbed.,"mlops,scaling,deployment",10,AI At Scale
102980,9,mostly-true,A lightweight T5 summarization pipeline can be built using the LIAR dataset for testing accuracy under pressure.,summarization pipeline using T5 and LIAR dataset,"Passage describes building a lightweight T5 summarization pipeline with the LIAR dataset as a testbed, omitting implementation caveats.","mlops,scaling,deployment",10,AI At Scale
102981,64,pants-fire,Agent performance consistently improves without any iteration or prompt adjustments.,agentic-ai prompt phrasing and model settings,"Contradicts passage detail: iteration, prompt phrasing, and model adjustments were essential for reliable agents.","agentic-ai,planning,tools",12,Agentic AI
102982,64,pants-fire,Agentic AI never requires iteration once initially configured.,agent design and prompt engineering for agentic-ai,"Passage emphasizes repeated iteration and adjusting prompts, model settings, and task structure; claim contradicts that necessity.","agentic-ai,planning,tools",12,Agentic AI
102983,64,TRUE,"Reliable agent behavior requires iterative adjustments to prompts, model settings, and task structure.",agent design and testing with prompts and model settings,"Passage explicitly states building reliable agents takes iteration and often means adjusting prompts, model settings, and task structure.","agentic-ai,planning,tools",12,Agentic AI
102984,27,barely-true,The listed audio features alone reliably identify any synthetic voice samples in all conditions.,"feature set for voice fingerprinting (MFCC, spectral, HNR, spectral flatness)",Overreaches beyond passage: experiment found consistency but not universal reliability across all conditions.,"media-forensics,voice-cloning,deepfake",9,Deepfake Defense
102985,27,half-true,The listed acoustic features partially distinguish real from synthesized voices but overstate reliability.,"audio fingerprinting using MFCC, Spectral Flatness, HNR features","Features like MFCC and spectral flatness help detection, but claim omits variability and false positives.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
102986,27,TRUE,A specific set of acoustic features reliably distinguishes real from synthesized voices.,"voice fingerprinting using MFCC, spectral, and HNR features","Passage states that the listed features produced the most consistent, interpretable results distinguishing real and synthesized voices.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
102987,139,half-true,Transformers use positional encodings to learn token order despite lacking inherent sequence order.,transformer positional encodings in FLAN-T5 example,Mixes correct concept with implied universality; ignores alternative ordering methods like relative encodings.,"generative-ai,diffusion,gans",7,Generative AI
102988,139,mostly-true,Transformers use positional encodings to learn token order and capture long-range relationships.,transformer positional encodings in FLAN-T5 example,Matches passage describing transformers lacking inherent order and adding positional encodings to learn token positions.,"generative-ai,diffusion,gans",7,Generative AI
102989,139,barely-true,FLAN-T5 inherently encodes token order without positional embeddings.,"transformers positional encodings, FLAN-T5 model example",Contradicts passage that states transformers rely on positional encodings; claim omits positional encoding mechanism.,"generative-ai,diffusion,gans",7,Generative AI
102990,140,TRUE,Using the Adam optimizer in Keras helps models learn efficiently on noisy data.,Keras high-level API optimizer usage (optimizer='adam'),Passage states Adam manages updates to promote steady progress and better performance on messy or ambiguous data.,"deep-learning,frameworks,tensors",5,Deep Learning
102991,140,barely-true,Adam optimizer guarantees steady improved performance on noisy datasets without any additional tuning.,optimizer usage in Keras/TensorFlow Adam,Overstates guarantee; passage claims Adam often helps with noisy data but notes hyperparameter tuning still required.,"deep-learning,frameworks,tensors",5,Deep Learning
102992,140,half-true,Adam optimizer often helps models converge more reliably on noisy or ambiguous data.,optimizer usage in keras Sequential model with Adam,Passage attributes improved learning and steadier progress to Adam but overgeneralizes universality and tuning needs.,"deep-learning,frameworks,tensors",5,Deep Learning
102993,46,TRUE,Plotting superhero abilities with Matplotlib visualizes comparative strengths effectively.,code cell plotting results with Matplotlib,"Passage explains plotting results with Matplotlib and says visuals bring abilities to life, supporting claim.","ai,tool-chain,notebooks",2,AI Survival Kit
102994,46,barely-true,The plotting code visualizes superhero ability comparisons using Matplotlib in the notebook.,notebook plotting code with Matplotlib,Mostly unsupported: passage mentions plotting but doesn't confirm code actually visualizes abilities or runs successfully.,"ai,tool-chain,notebooks",2,AI Survival Kit
102995,46,mostly-true,Plotting numeric comparisons in notebooks helps visualize differences between entities like superheroes.,Matplotlib plotting in a notebook code cell,Visualization of numeric results with Matplotlib is supported; minor caveat about omitted plotting details.,"ai,tool-chain,notebooks",2,AI Survival Kit
102996,45,half-true,Few-shot prompting both improves response consistency and guarantees factual accuracy in every answer.,few_shot_prompt template for trivia expert using examples,Examples improve pattern recognition and consistency but do not guarantee factual correctness every time.,"agentic-ai,planning,tools",12,Agentic AI
102997,45,barely-true,"Few-shot examples guarantee models will always produce accurate, consistent answers.",few_shot_prompt template with examples for trivia expert,Overstates reliability: examples improve pattern recognition but do not ensure accuracy or consistency.,"agentic-ai,planning,tools",12,Agentic AI
102998,45,FALSE,Including multiple examples in a prompt prevents the model from generalizing response patterns.,few_shot_prompt few-shot examples in prompt engineering,"Contradicts passage: few-shot examples are said to help the model generalize and recognize patterns, not prevent it.","agentic-ai,planning,tools",12,Agentic AI
102999,129,TRUE,Fairlearn evaluates and highlights group disparities in model loan approval rates.,fairness evaluation using Fairlearn on a loan approval dataset,Passage describes using Fairlearn to check loan approvals by gender and finding noticeable group differences.,"ai,tool-chain,notebooks",2,AI Survival Kit
103000,129,TRUE,Fairlearn can reveal differing loan approval rates between gender groups in a logistic regression example.,Fairlearn fairness evaluation on loan approval dataset,Example description shows Fairlearn detecting noticeable approval differences by gender in a logistic regression.,"ai,tool-chain,notebooks",2,AI Survival Kit
103001,129,half-true,Fairlearn guarantees removal of all gender bias from logistic regression loan models.,Fairlearn tool evaluating loan approval rates by gender,Overstates capability: passage shows Fairlearn detects disparities but not guaranteed full bias removal.,"ai,tool-chain,notebooks",2,AI Survival Kit
103002,44,mostly-true,Silent vulnerabilities in shared model components can enable widespread remote exploitation when triggered.,reused transformer block or shared embedding model vulnerability,Directly parallels Log4j analogy; broadly supported though specific exploit mechanisms and prevalence are not fully detailed.,"security,red-team,guardrails",8,Breaking-Securing AI
103003,44,TRUE,A hidden vulnerability in reused model components can enable remote code execution when triggered by specific inputs.,reused transformer block or shared embedding model vulnerability,"Directly parallels Log4j analogy: latent bug in model components activated by crafted input, enabling exploitation.","security,red-team,guardrails",8,Breaking-Securing AI
103004,44,pants-fire,Attackers can hide remote-code-execution backdoors inside reused transformer blocks to silently compromise all deployments.,reused transformer block or shared embedding model vulnerability,"Claim asserts universal compromise and remote-code-execution everywhere, which the passage implies as a risk but not proven; it exaggerates scope and inevitability.","security,red-team,guardrails",8,Breaking-Securing AI
103005,99,half-true,The voice clone reproduces Jerry's voice but shows subtle spectral and energy deviations.,"audio features (spectral centroid, MFCCs, ZCR, HNR, RMS energy)",Mixes correct detection of spectral and energy differences with vague claim about overall reproduction quality.,"media-forensics,voice-cloning,deepfake",9,Deepfake Defense
103006,99,mostly-true,The voice clone shows subtle acoustic differences compared to Jerry's authentic recordings.,"acoustic features like MFCCs, spectral centroid, ZCR, HNR","Passage cites specific features (spectral centroid, ZCR, HNR, MFCCs) indicating minor variations in richness, noise, and stability.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
103007,99,mostly-true,Acoustic features show the voice clone is broadly similar but slightly less natural than Jerry's authentic voice.,"audio features like MFCCs, spectral centroid, ZCR, HNR","Passage reports MFCCs, spectral centroid, ZCR, HNR, RMS energy indicate minor differences and reduced natural variation.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
103008,129,pants-fire,Deepfakes can be perfectly and undetectably matched to a speaker using simple cosine similarity.,voice validation with SpeechBrain x-vectors and cosine similarity,"Contradicts toolkit limits: cosine similarity with x-vectors detects similarity but cannot guarantee perfect, undetectable speaker matching.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
103009,129,mostly-true,SpeechBrain x-vectors and cosine similarity largely confirm speaker identity with minor caveats.,voice validation using SpeechBrain x-vectors and cosine similarity,"Supports passage: x-vectors and cosine similarity used to confirm speaker identity, but algorithm limitations and false positives omitted.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
103010,129,barely-true,SpeechBrain x-vectors definitively prove speaker identity in deepfake audio cases.,voice validation using SpeechBrain x-vectors and cosine similarity,Overstates reliability; passage says x-vectors compare clips but doesn't claim definitive proof.,"media-forensics,voice-cloning,deepfake",9,Deepfake Defense
103011,74,half-true,CrewAI is both open-source and commercially supported but primarily designed for game development.,"multi-agent AI framework, CrewAI open-source and enterprise edition",Correctly notes open-source and commercial editions but misstates primary design focus as games.,"agentic-ai,planning,tools",12,Agentic AI
103012,74,barely-true,CrewAI is already widely adopted across enterprise customers and powers major industry products.,"CrewAI framework, open-source and enterprise edition","Claim overreaches the passage's evidence; only founder, use cases, and enterprise edition mentioned.","agentic-ai,planning,tools",12,Agentic AI
103013,74,half-true,"CrewAI was founded to create a scalable, developer-friendly multi-agent platform combining open-source and commercial offerings.",multi-agent AI framework; CrewAI open-source and enterprise edition,"Correct about founder intent and dual offerings, but overstates founder motive and platform scope without full evidence.","agentic-ai,planning,tools",12,Agentic AI
103014,47,half-true,Francesca Rossi led development of IBM's institutional AI governance policies for global deployment.,"interview with Francesca Rossi; AI ethics, governance, institutional role","Accurate that Rossi is a global AI ethics leader at IBM, but passage doesn't claim she authored IBM's governance policies.","ethics,governance,privacy",11,AI Ethics and Governance
103015,47,mostly-true,Francesca Rossi actively advances interdisciplinary AI ethics and governance through technical and institutional leadership.,"interview with Francesca Rossi; AI ethics, governance, computational social choice","Strongly supported by her roles bridging technical, philosophical, and institutional layers; minor details about specific initiatives omitted.","ethics,governance,privacy",11,AI Ethics and Governance
103016,47,barely-true,Francesca Rossi single-handedly established global AI governance standards used worldwide.,"ethical leadership, AI governance, IBM Fellow Francesca Rossi",Overreaches role attribution; passage highlights leadership and expertise but not sole authorship of global standards.,"ethics,governance,privacy",11,AI Ethics and Governance
103017,64,pants-fire,Unsupervised learning methods always achieve perfect classification accuracy on real-world datasets.,unsupervised learning techniques like clustering and dimensionality reduction,Directly contradicts reality and the passage: clustering and dimensionality reduction do not guarantee perfect accuracy.,"machine-learning,classification,evaluation",4,Classical Machine Learning
103018,64,mostly-true,"Unsupervised methods like dimensionality reduction, clustering, and cosine similarity broadly reveal hidden dataset patterns.","unsupervised learning techniques; dimensionality reduction, clustering, cosine similarity","Accurately reflects passage listing those techniques and their power, omitting minor methodological caveats.","machine-learning,classification,evaluation",4,Classical Machine Learning
103019,64,pants-fire,Unsupervised learning always yields perfect labels for classification tasks without human input.,"unsupervised learning, clustering, dimensionality reduction, cosine similarity",Passage describes unsupervised pattern discovery but contradicts claim that it produces perfect classification labels without supervision.,"machine-learning,classification,evaluation",4,Classical Machine Learning
103020,79,half-true,K-Means clusters superhero features but cannot reliably label political truthfulness.,K-Means Clustering applied to superhero features; LIAR Dataset usage,"Mixes correct use of K-Means for grouping superhero features with incorrect claim it can label LIAR truth ratings, conflating clustering with supervised fact-checking.","open-source,community,contribution",13,Commit to Contribute
103021,79,half-true,The LIAR dataset mixes labeled political statements useful for fact-checking but contains some noisy or subjective labels.,"LIAR Dataset, labeled truth ratings for political statements","Dataset is used to train fact-checking models, but labels can be noisy and subjective, mixing correct and questionable annotations.","open-source,community,contribution",13,Commit to Contribute
103022,79,barely-true,Open-source contributors must commit sustained time to meaningfully affect community projects.,open-source contribution practices in Jupyter.org Community,Overstates requirement; passage emphasizes community tools and contribution but not sustained time commitment as mandatory.,"open-source,community,contribution",13,Commit to Contribute
103023,121,pants-fire,RAG requires splitting documents into 5-token chunks and storing each as raw text.,"RAG data-prep: embeddings, chunk size, vector database","Contradicts specified chunk size and embedding storage; passage says 200–400 tokens per chunk and embeddings stored numerically, not 5-token raw text.","data-prep,feature-engineering,rag",3,Prepping Data for AI
103024,121,half-true,RAG chunks should be about 150–250 words and converted into embeddings for vector search.,"RAG preparation: chunking, embeddings, vector database","Mixes correct steps with an inaccurate size range claim; passage specifies 200–400 tokens, not words.","data-prep,feature-engineering,rag",3,Prepping Data for AI
103025,121,half-true,RAG workflows require converting 200–400 token document chunks into embeddings stored in a vector database.,"RAG data preparation: chunking, embeddings, vector database",Mixes correct RAG steps with overly specific chunk-size precision; passage gives ranges but not as strict requirement.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
103026,11,pants-fire,Open-source contributions always guarantee immediate job offers for contributors.,open source contributions and high-impact PRs,"Contradicts passage detail that some indexed cases showed job offers, not a universal guarantee; overstated causality.","open-source,community,contribution",13,Commit to Contribute
103027,11,mostly-true,Contributing to open-source projects often leads to career opportunities like job offers after high-impact contributions.,Ways to Contribute to Open Source; PyTorch and CrewAI examples,Passage presents multiple cases of job offers after impactful PRs but omits frequency and selection bias details.,"open-source,community,contribution",13,Commit to Contribute
103028,11,mostly-true,Contributing to open-source projects often leads developers to job offers or career opportunities.,Ways to Contribute to Open Source; examples like high-impact PRs and discussions,"Passage reports many indexed cases of job offers after high-impact PRs or leadership, minor generalization to 'often'.","open-source,community,contribution",13,Commit to Contribute
103029,69,mostly-true,Enterprise emphasis on safety and accountability accelerates real-world AI adoption by companies.,"enterprise adoption, safety and accountability in deployment","Broadly supported by panelists noting enterprise focus drives adoption, minor nuance about risk minimization omitted.","ethics,governance,privacy",11,AI Ethics and Governance
103030,69,FALSE,Enterprises prioritize rapid feature rollout over safety and accountability in AI deployments.,enterprise adoption and accountability in AI,"Contradicts passage which states enterprises value safety, accountability, and readiness for real-world deployment.","ethics,governance,privacy",11,AI Ethics and Governance
103031,69,TRUE,"Enterprise AI adoption is driven by safety, accountability, and real-world readiness.",enterprise focus on safety and accountability,"Directly supported by Jose De Jesus noting companies seek safe, accountable, deployable AI for adoption.","ethics,governance,privacy",11,AI Ethics and Governance
103032,94,FALSE,Combining multiple fields into one always improves model accuracy and reduces bias.,feature design and dataset feature engineering,Contradicts passage: compressing fields can mask detail and introduce hidden bias or distortion.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
103033,94,barely-true,Combining multiple features into one always improves model performance in real-world tasks.,feature engineering for dataset and model preparation,"Overreaches beyond passage: combining features can mask detail and introduce bias, not guarantee improvement.","data-prep,feature-engineering,rag",3,Prepping Data for AI
103034,94,mostly-true,Combining multiple fields into one feature can mask important distinctions and introduce bias.,"feature engineering, dataset feature design","Supports passage: warns that compressing fields (resilience score) masks differences like Durability versus Healing, risking bias.","data-prep,feature-engineering,rag",3,Prepping Data for AI
103035,90,half-true,A prompt-injection classifier can confidently flag obvious attacks but may treat benign prompts cautiously.,"prompt injection classifier test, Table 7-2",Accurately reflects reported classifier behavior but omits performance metrics and false positive rates.,"security,red-team,guardrails",8,Breaking-Securing AI
103036,90,half-true,The prompt-injection classifier usually flags obvious attacks but sometimes misses subtle malicious inputs.,"prompt injection classifier test, Table 7-2","Passage supports confident detection of obvious injections but omits evidence about subtle misses, mixing correct and uncertain specifics.","security,red-team,guardrails",8,Breaking-Securing AI
103037,90,pants-fire,The prompt injection classifier consistently flags obvious injection attempts while treating benign prompts cautiously.,prompt injection classifier test; injection detection,Passage explicitly reports the classifier flagged obvious injections confidently and treated benign prompts cautiously.,"security,red-team,guardrails",8,Breaking-Securing AI
103038,134,TRUE,Using a smarter optimizer speeds and stabilizes training for handwritten digit classification.,optimizer choice during digit classification training,"Passage explicitly says smarter optimizers lead to faster, more reliable learning for digit recognition.","deep-learning,frameworks,tensors",5,Deep Learning
103039,134,TRUE,Using a smarter optimizer speeds and stabilizes learning for handwritten digit recognition models.,"optimizer choice for digit classification task (e.g., Adam)","Passage describes smarter optimizers like Adam producing faster, more reliable, and more stable learning for digit classification.","deep-learning,frameworks,tensors",5,Deep Learning
103040,134,mostly-true,"Using a smarter optimizer generally leads to faster, more reliable learning for digit classification models.","optimizer choice for handwritten digit classification (Adam, Sniffer)","Passage supports that advanced optimizers like Adam improve speed and stability, omitting specific dataset or hyperparameter caveats.","deep-learning,frameworks,tensors",5,Deep Learning
103041,57,TRUE,"Users must respect and follow separate licenses for code, weights, and datasets.","model release licensing for code, weights, and dataset components",Passage explicitly states layered licenses and instructs respecting each component's license separately.,"open-source,community,contribution",13,Commit to Contribute
103042,57,mostly-true,"Open-source model projects should clearly state separate licenses for code, weights, and datasets.","model release practices; LICENSE file, README, model card, dataset license","Passage explicitly recommends declaring code and weight licenses, acknowledging dataset licenses; minor omission on enforcement details.","open-source,community,contribution",13,Commit to Contribute
103043,57,half-true,"A model's code, weights, and dataset commonly carry different licenses requiring separate compliance.","model release licensing for code, weights, and dataset",Correctly notes separate licenses but overstates 'commonly' without prevalence data and omits edge cases.,"open-source,community,contribution",13,Commit to Contribute
103044,144,mostly-true,Transformers are widely used foundations for modern generative AI systems like chatbots and summarizers.,"transformer model usage in generative-ai (e.g., FLAN-T5 chatbot)",Passage broadly supports this claim but omits nuances about limitations and alternative architectures.,"generative-ai,diffusion,gans",7,Generative AI
103045,144,FALSE,Diffusion models are the primary backbone of modern large-scale AI assistants.,model architecture comparison mentioning Transformers and diffusion,"Contradicts passage stating Transformers, not diffusion models, power most large-scale AI assistants.","generative-ai,diffusion,gans",7,Generative AI
103046,144,TRUE,Transformers use attention mechanisms to generate coherent text one token at a time.,transformer model attention and autoregressive generation,Passage explicitly describes attention weighting and word-by-word generation in transformers.,"generative-ai,diffusion,gans",7,Generative AI
103047,144,half-true,Agent loops without usage limits can rapidly increase token costs during development.,agentic AI development with token-based LLM tools,Matches passage claim about rapid token usage growth but omits specific cost figures and mitigation details.,"agentic-ai,planning,tools",12,Agentic AI
103048,144,FALSE,Agents powered by large language models are inexpensive to run indefinitely without limits.,agentic AI token usage and guardrails,Contradicts passage detail that running such agents can be expensive and token usage adds up quickly; assumption about cost being low is false.,"agentic-ai,planning,tools",12,Agentic AI
103049,144,barely-true,Agent loops without usage guardrails quickly incur high token costs for LLM-powered agents.,cost and token usage for agent development,"Passage notes rapid token accumulation and recommends budgeting and guardrails, but overgeneralizes speed or scale.","agentic-ai,planning,tools",12,Agentic AI
103050,9,barely-true,Agentic AI can fully autonomously replace developers by eliminating all low-level implementation work.,"agentic AI, structured abstractions, developer workflows",Overreaches beyond passage: it claims full replacement and elimination of low-level work not supported here.,"agentic-ai,planning,tools",12,Agentic AI
103051,9,barely-true,Agentic AI can fully replace developers by handling all low-level implementation details autonomously.,"agentic AI, structured abstractions, developer workflow","Overreaches beyond passage: it claims full developer replacement though passage calls for freeing developers from low-level details, not eliminating them.","agentic-ai,planning,tools",12,Agentic AI
103052,9,TRUE,Structured abstractions and strategic automation enable AI agents to operate independently and adapt dynamically.,"agentic AI, structured abstractions, automation",Passage explicitly states structured abstractions and strategic automation let agentic AI operate independently and adapt dynamically.,"agentic-ai,planning,tools",12,Agentic AI
103053,135,FALSE,AI at scale inherently requires proprietary tools and inaccessible infrastructure.,AI at scale practice with open tools and tuning,Contradicts passage assertion that open tools and steady habits enable AI at scale; wrong infrastructure claim.,"mlops,scaling,deployment",10,AI At Scale
103054,135,barely-true,Anyone can practice AI at scale effectively using only open tools and simple habits.,"AI at scale discipline, open tools and tuning focus","Overreaches: passage emphasizes transparency, traceability, and system tuning beyond just open tools and habits.","mlops,scaling,deployment",10,AI At Scale
103055,135,half-true,AI at scale becomes reliable when paired with transparency and traceability.,system tuning and traceability in AI at scale,Mixes correct emphasis on transparency with overclaim that traceability alone makes outputs reliably truthful; ignores model limitations.,"mlops,scaling,deployment",10,AI At Scale
103056,8,FALSE,Open-source projects rarely rely on external contributions or community bug reports.,open-source contribution and commit messages,"Contradicts passage detail that projects depended on contributions, bug reports, and pull requests.","open-source,community,contribution",13,Commit to Contribute
103057,8,half-true,"Open-source projects rely on contributions like code, documentation, and bug reports but not all innovations are community-driven.",open-source contribution and trust-building through transparency,Accurately notes contributions and trust benefits but incorrectly implies some innovations aren't community-driven without evidence.,"open-source,community,contribution",13,Commit to Contribute
103058,8,mostly-true,"Open-source contributions broadly enable trust, innovation, and faster code maturity.",open-source contributions and commit messages,"Passage credits contributions, transparency, and openness for trust, innovation, and accelerated code maturity.","open-source,community,contribution",13,Commit to Contribute
103059,42,barely-true,GAN training losses typically oscillate because generator and discriminator compete.,GAN loss dynamics during adversarial training,"Accurately describes oscillation mechanism, but passage's numeric loss trend contradicts claimed steady improvement.","generative-ai,diffusion,gans",7,Generative AI
103060,42,half-true,GAN generator loss can rise even as overall image realism improves due to adversarial dynamics.,training loss oscillation in GAN generator and discriminator,Explains that competing generator/discriminator cause losses to oscillate; improvement in realism can coincide with rising generator loss due to discriminator catching up.,"generative-ai,diffusion,gans",7,Generative AI
103061,42,TRUE,GAN generator loss can increase when the discriminator improves during training.,GAN training dynamics; generator and discriminator loss interaction,"Passage describes competing networks where discriminator improvements raise discriminator effectiveness, causing generator loss to increase.","generative-ai,diffusion,gans",7,Generative AI
103062,86,TRUE,Contributors should provide AI Bills of Materials to increase supply chain transparency.,OpenCRE toolset for AI Bills of Materials,"Passage describes OpenCRE as a toolset promoting transparency via AI BOMs, directly supporting this claim.","open-source,community,contribution",13,Commit to Contribute
103063,86,barely-true,A contributor must always create an AI Bill of Materials when contributing to the project.,OpenCRE toolset for AI BOMs,Overreaches project guidance: OpenCRE promotes BOM transparency but doesn't mandate contributor-only creation.,"open-source,community,contribution",13,Commit to Contribute
103064,86,mostly-true,"Open-source tools like OpenCRE and OpenCV encourage transparent, inspectable AI supply chains and vision workflows.",AI Bills of Materials (OpenCRE) and OpenCV usage for scene detection,Passage lists OpenCRE for BOMs and OpenCV for scene detection; minor nuance of scope omitted.,"open-source,community,contribution",13,Commit to Contribute
103065,95,FALSE,A single model reliably prevents hallucinations without any reviewer model or role separation.,"two-model setup, Reviewer, temperature settings for fact-checking",Contradicts described workaround: passage advocates a separate Reviewer model and role separation for checking.,"security,red-team,guardrails",8,Breaking-Securing AI
103066,95,half-true,A two-model setup reliably detects hallucinations using a creative chatbot and a deterministic Reviewer.,two-model setup with chatbot and Reviewer roles in model experiment,Mixes correct method description with overclaim of reliability; passage shows illustrative effectiveness but not guaranteed detection.,"security,red-team,guardrails",8,Breaking-Securing AI
103067,95,FALSE,A single model can reliably perform both creative generation and deterministic fact-checking simultaneously.,two-model setup with Reviewer and chatbot roles,Contradicts recommended approach: passage prescribes separate models (chatbot and Reviewer) for creativity and deterministic checking.,"security,red-team,guardrails",8,Breaking-Securing AI
103068,192,mostly-true,Model.eval() disables training-only behaviors like Dropout and BatchNorm to stabilize evaluation.,"PyTorch evaluation mode, model.eval() and torch.no_grad()","Correctly states eval() deactivates Dropout/BatchNorm for stable testing, omits that torch.no_grad() also stops gradient tracking.","deep-learning,frameworks,tensors",5,Deep Learning
103069,192,barely-true,Calling model.eval() alone guarantees identical test results across all inference runs.,PyTorch model.eval() and torch.no_grad() usage,Overreaches: eval() disables Dropout/BatchNorm effects but doesn't ensure identical results across runs or hardware.,"deep-learning,frameworks,tensors",5,Deep Learning
103070,192,half-true,Calling model.eval() deactivates Dropout and BatchNorm but still tracks gradients by default.,PyTorch evaluation mode and torch.no_grad(),"Correct about eval() deactivating Dropout/BatchNorm, incorrect about gradient tracking still enabled without torch.no_grad().","deep-learning,frameworks,tensors",5,Deep Learning
103071,69,TRUE,Gini coefficient quantifies inequality in dataset distributions used for preprocessing.,dataset imbalance measurement using Gini coefficient,Directly supported: passage recommends measuring imbalance and names the Gini coefficient as a tool to quantify inequality.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
103072,69,barely-true,Gini coefficient alone reliably fixes dataset bias for model training outcomes.,measuring imbalance with Gini coefficient in dataset feature distributions,Overstates tool's power: passage cites Gini for spotting imbalance but not as a complete bias fix.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
103073,69,half-true,Gini coefficient measurement fully resolves dataset imbalance for model training.,measuring imbalance with Gini coefficient in datasets,Mixes correct use of Gini for quantifying inequality with incorrect claim it fully resolves imbalance issues.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
103074,69,mostly-true,Batching typically reduces average per-sample GPU cost when serving multiple inputs in parallel.,batching for GPU inference in deployment,"Passage explains batching processes multiple inputs in parallel on GPU, lowering average cost per sample.","mlops,scaling,deployment",10,AI At Scale
103075,69,TRUE,Batching lets models process multiple inputs in parallel to lower average cost per sample.,batching on GPU hardware for serving real-time predictions,"Explained benefit: batching processes inputs in parallel on GPUs, reducing average per-sample cost.","mlops,scaling,deployment",10,AI At Scale
103076,69,half-true,Batching always reduces average per-sample GPU cost when serving models in real-time.,batching for GPU inference and serving real-time predictions,"Correct that batching lowers per-sample cost often, but 'always' ignores latency trade-offs and variability.","mlops,scaling,deployment",10,AI At Scale
103077,30,TRUE,"StyleGAN2-ADA can generate realistic, photorealistic human faces not belonging to real people.",StyleGAN2-ADA image generation of human faces,"Passage notes StyleGAN lineage and shows StyleGAN2-ADA used to produce similarly realistic, high-quality faces.","generative-ai,diffusion,gans",7,Generative AI
103078,30,half-true,"StyleGAN2-ADA can generate photorealistic, unique human faces not belonging to real people.","StyleGAN2-ADA image generation of faces (StyleGAN family, NVIDIA)",Mixes correct capability with implicit claim about uniqueness and realism level; omits dataset/training specifics and potential artifacts.,"generative-ai,diffusion,gans",7,Generative AI
103079,30,mostly-true,StyleGAN2-ADA can generate highly realistic human faces similar to earlier StyleGAN outputs.,image synthesis with StyleGAN2-ADA and NVIDIA StyleGAN,Consistent with passage: StyleGAN produced photorealistic faces; statement omits minor implementation or dataset caveats.,"generative-ai,diffusion,gans",7,Generative AI
103080,43,TRUE,GAN training oscillations can settle as both generator and discriminator improve.,"GAN training dynamics, discriminator and generator losses","Describes oscillatory losses resolving into stable mutual improvement, matching described example.","generative-ai,diffusion,gans",7,Generative AI
103081,43,barely-true,GAN training always converges to a stable equilibrium when oscillations occur.,training dynamics of GAN discriminator and generator,"Overreaches beyond passage; passage says oscillations can settle, not that convergence always occurs.","generative-ai,diffusion,gans",7,Generative AI
103082,43,half-true,GAN training often shows oscillations as discriminator and generator losses trade off.,GAN training dynamics involving discriminator and generator losses,Accurately notes oscillatory loss behavior but omits that oscillations should settle and that effective training requires stability and balance.,"generative-ai,diffusion,gans",7,Generative AI
103083,14,half-true,Deep learning always requires very large datasets and extremely deep neural network architectures.,"deep neural networks, layers, input data",Mixes correct idea of data importance with incorrect absolute claim about always needing very large datasets or extremely deep architectures.,"deep-learning,frameworks,tensors",5,Deep Learning
103084,14,half-true,Deep learning always requires very large datasets to learn useful representations.,"deep neural network input layer, large amounts of data","Partly true: deep nets benefit from lots of data, but many techniques reduce data needs (transfer learning, augmentation).","deep-learning,frameworks,tensors",5,Deep Learning
103085,14,mostly-true,Deep learning trains multi-layer neural networks to learn patterns from large datasets automatically.,"deep neural network, input layer, output layer",Passage describes stacking layers and using many-layer neural networks to learn patterns from large data; minor implementation details omitted.,"deep-learning,frameworks,tensors",5,Deep Learning
103086,16,half-true,The passage claims builders are learning to create more trustworthy AI but overstates complete knowledge.,theme introduction about trustworthy AI and Big AI,Mixes correct admission of ongoing learning with an exaggerated assertion of 'I already know everything.'.,"ai,open-source,builder",1,Introduction – The Gold Rush Paradox
103087,16,TRUE,Builders should focus on learning to create more trustworthy AI systems.,theme introduction mentioning trustworthy AI and builders,Passage explicitly emphasizes learning and becoming better builders of trustworthy AI.,"ai,open-source,builder",1,Introduction – The Gold Rush Paradox
103088,16,half-true,Builders increasingly prioritize open-source models but overestimate their immediate trustworthiness.,"trustworthy AI, open-source models, builder perspective",Mixes correct trend (builders focus on trust and open-source) with incorrect certainty about overestimation.,"ai,open-source,builder",1,Introduction – The Gold Rush Paradox
103089,24,TRUE,Clément Delangue describes multiple industry partnerships supporting open-model access and compute.,"partner collaborations with Google Cloud, NVIDIA, IBM","Passage explicitly lists partnerships with Google Cloud, NVIDIA, and IBM enabling model access and compute support.","open-source,community,ai",0,Foreword – Robo Interviews Clément Delangue
103090,24,half-true,"Clément claimed partnerships gave free, unrestricted access to all open models and supercomputing resources.",partnerships with Google Cloud and NVIDIA for open models and supercomputing,"Mixes true collaborations with Google Cloud and NVIDIA but incorrectly asserts free, unrestricted access and universality.","open-source,community,ai",0,Foreword – Robo Interviews Clément Delangue
103091,24,TRUE,Clément Delangue says partnerships expanded access to open models and compute resources.,"partnerships with Google Cloud, NVIDIA, IBM for open models and supercomputing",Directly supported by mention of Google Cloud for open models and NVIDIA for supercomputing resources.,"open-source,community,ai",0,Foreword – Robo Interviews Clément Delangue
103092,60,half-true,Transformers always train faster than RNNs because they process every token simultaneously.,self-attention in Transformer models,"Accurate about simultaneous processing and parallelization, but ignores factors like model size, hardware, and sequence length affecting training speed.","neural-networks,cnn,transformers",6,Neuron Building Blocks
103093,60,barely-true,Transformers always outperform RNNs on every sequence task because of self-attention.,self-attention in Transformers vs RNNs,Overreaches beyond passage: it claims universal superiority despite passage noting training speed and parallelism benefits only.,"neural-networks,cnn,transformers",6,Neuron Building Blocks
103094,60,TRUE,Transformers use self-attention to attend to all input parts simultaneously for better context understanding.,self-attention in Transformers,Passage states Transformers process inputs at once and use self-attention to understand context and improve language tasks.,"neural-networks,cnn,transformers",6,Neuron Building Blocks
103095,142,TRUE,An embedding model converts plots into vectors so a retriever can find them by meaning.,embedding model (OpenAIEmbeddings) with Chroma retriever,Directly supported: passage states OpenAIEmbeddings creates vectors and Chroma retrieves plots by meaning for generation.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
103096,142,half-true,Embedding models convert documents into vectors but may miss fine-grained factual details.,retrieval using OpenAIEmbeddings and Chroma in RAG workflow,Correct about embeddings producing vectors; omits that LangChain plus chat model mitigates retrieval fidelity issues.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
103097,142,half-true,A single embedding model and Chroma reliably retrieve plots for story generation every time.,retrieval with OpenAIEmbeddings and Chroma,"Mixes correct components (OpenAIEmbeddings, Chroma) with overconfident claim of consistent reliability and certainty.","data-prep,feature-engineering,rag",3,Prepping Data for AI
103098,13,barely-true,Open-source tools always require more hands-on work than proprietary data-prep tools.,tooling options for dataset curation and data-prep,Overreaches passage's nuance: it states open source often needs more hands-on work but not universally always.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
103099,13,TRUE,Open-source data prep tools offer flexibility and no licensing cost for dataset curation.,tooling options for dataset curation and data prep,"Directly supported by passage stating open source gives flexibility and no license cost, though needs hands-on work.","data-prep,feature-engineering,rag",3,Prepping Data for AI
103100,13,half-true,Open-source data prep tools eliminate licensing costs but always require more manual work.,"data curation tool choices, open source vs proprietary","Correct about no license cost and increased hands-on work, but overstates 'always' requiring more manual effort.","data-prep,feature-engineering,rag",3,Prepping Data for AI
103101,15,barely-true,Generative AI models always underperform compared to smaller specialized models in real-world tasks.,model specialization and deployment for enterprise or healthcare,"Overstates claim; passage says smaller models often perform better for speed and cost, not always, so notable overreach.","generative-ai,diffusion,gans",7,Generative AI
103102,15,mostly-true,Smaller specialized generative models often outperform large general models for real-world speed and cost needs.,"domain-specific generative models, fine-tuning and deployment","Passage supports that tailored smaller models are faster, cheaper, easier to fine-tune and deploy, omitting edge-case tradeoffs.","generative-ai,diffusion,gans",7,Generative AI
103103,15,TRUE,"Smaller, domain-specific generative models often outperform large ones for practical deployment.",domain-specific models and fine-tuning for enterprise and healthcare,"Passage states smaller specialized models are faster, cheaper, easier to fine-tune, and require less compute.","generative-ai,diffusion,gans",7,Generative AI
103104,67,barely-true,Open-source community contributions always produce wisdom that outpaces individual efforts.,open-source community contribution and crowd wisdom,"Passage suggests crowd wisdom can outpace individuals, but blanket claim 'always' overreaches.","open-source,community,contribution",13,Commit to Contribute
103105,67,mostly-true,"Open-source community contributions collectively produce wiser, more accountable AI than single organizations.",open-source community contribution and crowd wisdom,"Passage emphasizes crowd-derived wisdom and continued collective effort, omitting technical limits or coordination challenges.","open-source,community,contribution",13,Commit to Contribute
103106,67,pants-fire,Open-source community contributions always produce wiser AI systems than any single organization.,open-source contribution and community wisdom,"Contradicts passage claim by asserting absolute superiority; passage references crowd wisdom but not an absolute, universal guarantee.","open-source,community,contribution",13,Commit to Contribute
103107,117,TRUE,ChromaDB provides simple APIs for storing and retrieving embeddings useful for RAG.,ChromaDB integration with LangChain for RAG applications,Passage explicitly notes ChromaDB's simple embedding APIs and direct LangChain integration for RAG.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
103108,117,barely-true,ChromaDB provides out-of-the-box end-to-end RAG pipelines with built-in model training and dataset labeling.,ChromaDB embedding store and LangChain integration for RAG,"Overreaches: passage says ChromaDB stores/retrieves embeddings and integrates with LangChain, not that it trains models or handles labeling.","data-prep,feature-engineering,rag",3,Prepping Data for AI
103109,117,half-true,ChromaDB simplifies storing embeddings and integrates with LangChain for RAG applications.,tool integration for RAG using ChromaDB and LangChain,"Accurately notes ChromaDB's API and LangChain integration, but overstates simplicity and implementation ease.","data-prep,feature-engineering,rag",3,Prepping Data for AI
103110,54,mostly-true,IBM began developing AI governance frameworks to identify risks and mitigation strategies as deployments expanded.,"AI governance, risks, mitigation strategies in corporate deployments","Supports that IBM recognized deployment-driven ethical risks and started governance, omitting timeline and specific frameworks.","ethics,governance,privacy",11,AI Ethics and Governance
103111,54,mostly-true,IBM began implementing AI governance to identify and mitigate ethical risks during real-world deployments.,"AI governance, ethical risks, mitigation strategies at IBM","Directly supported by passage: IBM recognized ethical challenges and started governance, risk identification, mitigation.","ethics,governance,privacy",11,AI Ethics and Governance
103112,54,half-true,IBM immediately implemented comprehensive AI governance across all products upon early deployments.,AI governance development at IBM during initial real-world deployments,"Mixes truth and error: IBM began AI governance work, but passage doesn't claim immediate comprehensive rollout across all products.","ethics,governance,privacy",11,AI Ethics and Governance
103113,35,TRUE,Matrix multiplication enables data flow through neural network layers.,Matrices and matrix multiplication in neural networks,Directly supported by passage: matrices stack vectors and multiplication powers data flow through layers.,"ai,tool-chain,notebooks",2,AI Survival Kit
103114,35,mostly-true,Matrix operations and gradients underpin neural network data flow and training dynamics.,"matrices, matrix multiplication, gradients in neural networks",Passage explains matrices enable data flow and gradients indicate output sensitivity; minor caveat about optimization specifics omitted.,"ai,tool-chain,notebooks",2,AI Survival Kit
103115,35,pants-fire,Matrices and matrix multiplication are unnecessary for neural network data flow and can be ignored.,Matrices and Matrix Multiplication in neural network layers,Contradicts core passage detail: matrix multiplication explicitly powers data flow through neural network layers.,"ai,tool-chain,notebooks",2,AI Survival Kit
103116,60,half-true,A trained deep learning model can always be saved and reloaded across different frameworks without modification.,model serialization and framework file formats,"Partly true that models are saved and reloaded, but incorrect about cross-framework compatibility and format differences.","deep-learning,frameworks,tensors",5,Deep Learning
103117,60,pants-fire,Saving a model always makes it infinitely more accurate when reloaded for production.,"model saving and reload, open weights versus open models",Contradicts passage: saving reduces load and eases reuse but does not increase accuracy; accuracy change unsupported.,"deep-learning,frameworks,tensors",5,Deep Learning
103118,60,half-true,Open-source models always allow saving and reloading identical trained weights across all frameworks.,model saving and open weights in deep-learning frameworks,"Correct that models can be saved and reloaded, but incorrect to claim identical weight compatibility across all frameworks and formats.","deep-learning,frameworks,tensors",5,Deep Learning
103119,148,TRUE,The example trains a neural network on the MNIST dataset using Adam optimizer and cross-entropy loss.,MNIST dataset training script using Adam optimizer and cross-entropy,"Passage explicitly mentions MNIST, forward/backward passes, cross-entropy loss, and Adam optimizer.","deep-learning,frameworks,tensors",5,Deep Learning
103120,148,FALSE,The example trains a convolutional neural network on CIFAR-10 using SGD optimizer.,"MNIST dataset training example, Adam optimizer, cross-entropy loss","Contradicts passage: example uses MNIST and Adam, not CIFAR-10 or SGD.","deep-learning,frameworks,tensors",5,Deep Learning
103121,148,TRUE,The example trains a neural network on MNIST using Adam and cross-entropy loss.,training MNIST model with Adam optimizer and cross-entropy,"Passage explicitly describes MNIST training, forward/backward passes, cross-entropy loss, and Adam optimizer.","deep-learning,frameworks,tensors",5,Deep Learning
103122,118,mostly-true,Gradient descent generally adjusts model parameters toward lower loss with step sizes based on slope.,optimization of loss function using gradients in deep learning,Describes standard gradient-descent behavior supported by passage; minor caveat omitted about local minima and learning rate details.,"deep-learning,frameworks,tensors",5,Deep Learning
103123,118,barely-true,Gradient descent always reaches the global minimum of a model's loss function during training.,optimization of loss with gradients in deep learning,"Overreaches reality: gradient descent aims for minima but often converges to local minima or saddle points, not guaranteed global optimum.","deep-learning,frameworks,tensors",5,Deep Learning
103124,118,FALSE,Gradient descent always converges to the global minimum of the loss function in deep networks.,gradient descent behavior with loss function and gradients,"Passage describes goal of finding global minimum, but deep networks often have nonconvex losses preventing guaranteed global convergence.","deep-learning,frameworks,tensors",5,Deep Learning
103125,7,TRUE,Training data caused a hiring tool to favor male applicants and penalize female-associated terms.,training data bias in recruitment model,"Passage attributes bias to training data, noting downgrades for phrases like ‘women’s softball team captain’.","data-prep,feature-engineering,rag",3,Prepping Data for AI
103126,7,TRUE,Biased training data caused the résumé screening system to favor male applicants.,"résumé screening tool, training data, gender bias",Passage reports Amazon's system downgraded female-associated terms and was retired due to biased training data.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
103127,7,pants-fire,The training data intentionally encoded extreme anti-female bias to sabotage hiring models.,training data problem in resume screening tool,"Asserts intentional sabotage; passage describes biased training data causing gender bias, not deliberate malice or intent.","data-prep,feature-engineering,rag",3,Prepping Data for AI
103128,96,pants-fire,The Reviewer model always prevents all hallucinations from the higher-temperature chatbot.,dual-model setup with Reviewer and chatbot temperature,Contradicts described behavior: Reviewer has lower temperature but cannot guarantee eliminating hallucinations.,"security,red-team,guardrails",8,Breaking-Securing AI
103129,96,FALSE,The Reviewer model always prevents hallucinations when set to low temperature.,dual-model pattern with Chatbot and Reviewer (temperature settings),Contradicts passage: low temperature reduces randomness but doesn't guarantee preventing hallucinations.,"security,red-team,guardrails",8,Breaking-Securing AI
103130,96,FALSE,The Reviewer model is set to a higher temperature than the chatbot for more creativity.,model temperature assignment for Chatbot and Reviewer,"Contradicts passage detail: chatbot uses higher temperature (0.7) and Reviewer uses lower, not higher.","security,red-team,guardrails",8,Breaking-Securing AI
103131,55,TRUE,AI hallucinations can present false information with undue confidence.,"AI hallucinations, believability vulnerability in models","Passage explicitly describes hallucinations as overly confident, believable false outputs exploited as a vulnerability.","security,red-team,guardrails",8,Breaking-Securing AI
103132,55,barely-true,AI models routinely produce confidently false outputs that attackers can exploit.,"AI hallucinations, believability vulnerability",Overreach: passage highlights hallucinated confidence as a vulnerability but doesn't claim routine exploitation or frequency of attacker use.,"security,red-team,guardrails",8,Breaking-Securing AI
103133,55,TRUE,AI hallucinations often present false information with excessive confidence.,AI hallucinations; believability and overly confident outputs,"Passage explicitly describes hallucinations as self-inflicted, overly confident, and believable vulnerabilities.","security,red-team,guardrails",8,Breaking-Securing AI
103134,9,half-true,Skewed datasets always produce biased model results unless perfectly rebalanced beforehand.,training datasets and data-prep for models,"Accurate that imbalance causes bias, but assertion of 'always' and 'perfect rebalancing' is overstated and impractical.","data-prep,feature-engineering,rag",3,Prepping Data for AI
103135,9,TRUE,Skewed training data produces biased model results across different AI tasks.,imbalanced dataset causing biased results in model training,"Passage states imbalance in data created biased results and applies broadly to fraud, recommendation, and image tasks.","data-prep,feature-engineering,rag",3,Prepping Data for AI
103136,9,mostly-true,Skewed training data commonly produces biased model outputs across many AI tasks.,"data imbalance in datasets for fraud detection, recommendations, or image classification","Supported by passage examples linking skewed data to biased results, minor caveat about mitigation techniques omitted.","data-prep,feature-engineering,rag",3,Prepping Data for AI
103137,32,half-true,MT-Bench evaluates conversational model behavior using realistic dialogue-oriented tasks.,benchmark focusing on conversational model evaluations and human-like dialogues,"Accurately notes focus on conversation but omits that MT-Bench is one among many benchmarks, mixing specificity.","mlops,scaling,deployment",10,AI At Scale
103138,32,mostly-true,MT-Bench evaluates conversational model behavior in realistic dialogue settings for practical use.,benchmark evaluating model behaviors in conversational use,Benchmark description broadly supports practical conversational evaluation but omits specific metrics or limitations.,"mlops,scaling,deployment",10,AI At Scale
103139,5,half-true,"The passage claims projects stall without contributors, risking redundant, opaque system rebuilding.",section titled 'Commit to Contribute' about contributors and projects,"Accurately quotes warning about stalling projects and opaque rebuilding, but adds inevitability and redundancy beyond text.","open-source,community,contribution",13,Commit to Contribute
103140,5,barely-true,Open-source projects always stall without any contributors.,risk of rebuilding systems behind opaque walls; contributors,Overreaches the passage's conditional claim — ignores possibility of sustained maintenance or core-team activity.,"open-source,community,contribution",13,Commit to Contribute
103141,5,barely-true,The passage claims open-source projects always require outside contributors to avoid stagnation.,Commit to Contribute section mentioning contributors and projects,Overstates necessity: passage warns projects stall without contributors but doesn't prove 'always' required.,"open-source,community,contribution",13,Commit to Contribute
103142,201,TRUE,A single-output neural network can perform regression to predict a continuous star rating.,user-movie input vector and single-neuron final layer,"Passage describes using a single linear-output neuron for continuous star ratings, framing it as a regression task.","deep-learning,frameworks,tensors",5,Deep Learning
103143,201,half-true,A single-neuron linear output is appropriate for predicting continuous movie star ratings.,neural network output layer for rating regression,"Partly correct: linear single neuron suits scalar regression, but ignores rating bounds and possible classification alternatives.","deep-learning,frameworks,tensors",5,Deep Learning
103144,201,barely-true,A single-neuron linear-output network can predict movie star ratings as a regression target.,user-movie vector input; single output neuron; regression,Overreaches by implying single-neuron always suffices; passage suggests conceptually but omits model complexity and limitations.,"deep-learning,frameworks,tensors",5,Deep Learning
103145,20,TRUE,"The notebook imports pandas, numpy, scikit-learn, and matplotlib for the analysis.","notebook import cell showing pandas, numpy, KMeans, StandardScaler, matplotlib","Import lines and printed confirmation explicitly list pandas, numpy, sklearn.cluster KMeans, StandardScaler, and matplotlib.","ai,tool-chain,notebooks",2,AI Survival Kit
103146,20,TRUE,"The notebook successfully imports core Python libraries like pandas, numpy, and scikit-learn.","Colab setup and import cell showing pandas, numpy, KMeans, StandardScaler",Import output and printed confirmation directly indicate libraries were installed and imported successfully.,"ai,tool-chain,notebooks",2,AI Survival Kit
103147,20,mostly-true,"The Colab environment preinstalls common Python libraries, allowing immediate import and use.","development environment setup, Colab requiremen ts and imports","Passage shows Colab reports 'Requirement already satisfied' and imports succeed, but some setups may still need packages.","ai,tool-chain,notebooks",2,AI Survival Kit
103148,80,barely-true,The dataset always ensures model accuracy without additional feature engineering.,data relevance and exploratory data analysis using dataset evaluation,Overreaches beyond passage: passage warns about dataset limitations and need to explore biases.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
103149,80,half-true,Data exploration guarantees detection of all dataset biases before model training.,evaluating data relevance; dataset exploration and RAG,"Overstates capability: Tukey recommends exploration, but exploration may miss subtle biases, so claim mixes correct intent with incorrect certainty.","data-prep,feature-engineering,rag",3,Prepping Data for AI
103150,80,TRUE,Datasets should be evaluated for diversity and relevance before model building.,evaluating data relevance; dataset exploration and bias analysis,"Directly supported by Tukey's and passage advice to explore data for diversity, patterns, anomalies.","data-prep,feature-engineering,rag",3,Prepping Data for AI
103151,87,barely-true,Gini coefficient alone reliably determines dataset suitability for churn prediction tasks.,dataset imbalance analysis using Gini coefficient,"Overreaches: passage says Gini quantifies imbalance and significance is interpreted, not that Gini alone determines suitability.","data-prep,feature-engineering,rag",3,Prepping Data for AI
103152,87,TRUE,Exploratory data analysis quantified dataset imbalance using the Gini coefficient.,EDA on customer dataset for churn prediction,Passage states EDA measured imbalance with the Gini coefficient and applied results to churn prediction.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
103153,87,mostly-true,Exploratory data analysis should quantify class imbalance with metrics like the Gini coefficient.,EDA using Gini coefficient to assess dataset imbalance for churn prediction,Supported by passage: EDA quantified imbalance via Gini and applied to customer churn assessment.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
103154,22,FALSE,Regression predicts categorical class labels using input features.,regression analysis predicting continuous outcomes,"Contradicts definition: regression estimates continuous outcomes, not categorical class labels.","machine-learning,classification,evaluation",4,Classical Machine Learning
103155,22,barely-true,Regression predicts categorical class labels from input features using continuous outputs.,"regression analysis, continuous outcome prediction","Misrepresents regression purpose: regression predicts continuous outcomes, not categorical class labels; mixes classification concepts.","machine-learning,classification,evaluation",4,Classical Machine Learning
103156,22,FALSE,Regression models predict categorical class labels rather than continuous outcomes.,"regression analysis, continuous outcome prediction",Contradicts passage which states regression estimates continuous outcomes like prices and efficiency.,"machine-learning,classification,evaluation",4,Classical Machine Learning
103157,44,TRUE,LangChain can be used to call a language model to fill missing dataset values.,data-cleaning using LangChain and Mistral model,Passage explicitly describes using LangChain with Mistral to fill missing Species values during data cleansing.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
103158,44,FALSE,LangChain cannot call Mistral models to fill missing Species values.,using LangChain with Mistral model to fill Species,Contradicts passage detail that LangChain is used with Mistral to fill missing Species values.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
103159,44,barely-true,LangChain alone reliably fills missing Species values with perfect accuracy using Mistral.,data cleansing workflow using LangChain and Mistral model,"Overstates capability; passage only describes using LangChain/Mistral to fill values, not guaranteed or perfect accuracy.","data-prep,feature-engineering,rag",3,Prepping Data for AI
103160,51,mostly-true,Using all available features generally helps models learn useful patterns in imbalanced datasets.,"imbalanced dataset, rare positive cases, logistic regression max_iter",Matches passage: multiple features reveal patterns for rare positives; minor caveat about overfitting not mentioned.,"machine-learning,classification,evaluation",4,Classical Machine Learning
103161,51,half-true,Using all features guarantees models learn useful patterns in imbalanced datasets.,imbalanced dataset and logistic regression hyperparameter max_iter,Overstates certainty: passage says full features can provide signal but doesn't guarantee success or account for overfitting or irrelevant features.,"machine-learning,classification,evaluation",4,Classical Machine Learning
103162,51,pants-fire,Logistic regression never benefits from early stopping and always requires max_iter=1000 to converge.,logistic regression max_iter parameter in model training,"Claim contradicts optimizer behavior and passage; max_iter=1000 is a suggestion, not an absolute requirement.","machine-learning,classification,evaluation",4,Classical Machine Learning
103163,48,TRUE,"Open-source AI projects should choose a license to define use, modification, and distribution.","license stack for models, datasets, and Python libraries","Directly supported: passage states license choice defines use, modification, distribution and obligations.","open-source,community,contribution",13,Commit to Contribute
103164,48,mostly-true,"Choosing an open-source license determines how others may use, modify, and distribute an AI project's components.",license stack for open-source AI projects,"Explains licensing defines use, modification, distribution; omits minor complexities like multi-repo dependency interactions.","open-source,community,contribution",13,Commit to Contribute
103165,48,FALSE,Licensing choices have no effect on using or sharing open-source AI projects.,license stack and open-source AI project licensing,"Contradicts passage by denying that license stack affects commercialization, compliance, or usage.","open-source,community,contribution",13,Commit to Contribute
103166,141,half-true,Hyperparameters like epochs and optimizer type cannot be learned during training and must be chosen manually.,"hyperparameters (epochs, learning rate, batch size, optimizer)",Accurately notes manual selection of hyperparameters but omits methods like automated tuning and search.,"deep-learning,frameworks,tensors",5,Deep Learning
103167,141,TRUE,"Hyperparameters like epochs, learning rate, batch size, and optimizer are chosen, not learned.","hyperparameters (epochs, learning rate, batch size, optimizer)",Directly described by passage: those settings are not learned and must be chosen manually.,"deep-learning,frameworks,tensors",5,Deep Learning
103168,141,half-true,"Hyperparameters like learning rate, batch size, epochs, and optimizer are chosen, not learned during training.","training hyperparameters (learning rate, batch size, epochs, optimizer)","Accurately lists typical hyperparameters but implies no methods exist to tune them, mixing correct and misleading specifics.","deep-learning,frameworks,tensors",5,Deep Learning
103169,2,pants-fire,Generative AI models routinely fabricate real people's voices and faces indistinguishably every time.,"generative AI, Diffusion Models and GANs","Claim grossly contradicts passage's focus on model families; passage doesn't assert perfect, indistinguishable fabrication.","generative-ai,diffusion,gans",7,Generative AI
103170,2,TRUE,"Generative AI models can create new text, images, and video from scratch.","overview of generative models (GANs, VAEs, Diffusion Models, Autoregressive Models, Transformers)","Directly supported by list of model families and explicit mention of generating text, images, and video.","generative-ai,diffusion,gans",7,Generative AI
103171,2,mostly-true,"Generative AI includes GANs, VAEs, diffusion models, autoregressive models, and transformers.","overview of five model families (GANs, VAEs, Diffusion Models, Autoregressive Models)",Lists five named generative model families as key topics; minor omission of subtypes or examples.,"generative-ai,diffusion,gans",7,Generative AI
103172,180,half-true,The synthetic health records mix realistic demographics with fabricated contact details and dates.,dataset of synthesized health records (Table 2-4),"Accurately notes realistic demographics while dataset shows invented phone numbers, addresses, and dates.","data-prep,feature-engineering,rag",3,Prepping Data for AI
103173,180,mostly-true,Data preparation for RAG benefits from careful feature engineering and consistent dataset formatting.,"synthesized health records dataset, feature engineering, RAG","Broadly supported: passage shows structured patient dataset requiring cleaning and consistent fields for RAG use, minor preprocessing caveats omitted.","data-prep,feature-engineering,rag",3,Prepping Data for AI
103174,180,half-true,The synthesized health records mix realistic demographics with fabricated contact details and timestamps.,"synthetic health records dataset, output from Listing 2-14",Mix of accurate-looking ages and diagnoses with improbable phone formats and future/incorrect dates indicates partial fabrication.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
103175,98,TRUE,The VAE loss combines reconstruction MSE with a KL term to regularize the latent space.,"VAE loss function (recon_loss, kl) using mu and logvar","Code shows recon_loss = MSE and kl = -0.5 sum of 1+logvar-mu^2-logvar.exp(), directly supporting claim.","generative-ai,diffusion,gans",7,Generative AI
103176,98,mostly-true,A VAE trained with reconstruction plus KL loss produces smooth latent interpolations and slight variations.,VAE training using reconstruction loss and KL term on SphereMeshDataset,"Describes VAE behavior supported by KL continuity and sampling, omitting training epoch and convergence caveat.","generative-ai,diffusion,gans",7,Generative AI
103177,98,mostly-true,The VAE training produces reconstructions and small latent variations from the same mu and logvar.,"VAE training and inference using mu, logvar, reparameterize, and decoder","Training code shows reconstruction and multiple samples from reparameterized mu/logvar, but one epoch limits quality.","generative-ai,diffusion,gans",7,Generative AI
103178,58,barely-true,Python and PyTorch let hobbyists build state-of-the-art AI systems with no expertise or resources.,"tool libraries and model development (Python, PyTorch)","Overstates capability: passage says libraries lower barriers, not that they enable top-tier systems without expertise or compute.","ai,tool-chain,notebooks",2,AI Survival Kit
103179,58,mostly-true,Machine learning enables models to learn patterns from data without explicit task-specific programming.,"ML concept, Python and PyTorch libraries","Broadly supported by passage noting ML lets systems recognize patterns and improve using data, minor implementation caveats omitted.","ai,tool-chain,notebooks",2,AI Survival Kit
103180,58,pants-fire,PyTorch alone guarantees superhuman intelligence from small datasets without model tuning.,libraries like PyTorch in ML tool-chain,Claim contradicts passage: PyTorch enables model building but does not guarantee superhuman results or eliminate tuning.,"ai,tool-chain,notebooks",2,AI Survival Kit
103181,16,half-true,Open-source foundation models universally ensure better data privacy than proprietary models.,open-source foundation models and data privacy in enterprise domains,"Overstates claim: passage notes interest in open-source alternatives and privacy concerns, but does not claim universal privacy advantages.","generative-ai,diffusion,gans",7,Generative AI
103182,16,FALSE,Open-source foundation models have eliminated concerns about data privacy and explainability.,"open-source foundation models, data privacy, explainability","Contradicts passage noting privacy and explainability remain important concerns for enterprise, education, healthcare.","generative-ai,diffusion,gans",7,Generative AI
103183,16,barely-true,Open-source foundation models fully solve enterprise data privacy and explainability needs.,open-source foundation models for enterprise and healthcare,Overreaches: passage notes interest in focused solutions and privacy needs but not that open-source fully solves them.,"generative-ai,diffusion,gans",7,Generative AI
103184,85,FALSE,"Autoencoders always generate realistic, high-fidelity images by sampling their latent space.",latent representation sampling in autoencoders,"Passage describes randomness and creative variations, not guaranteed realistic high-fidelity image generation.","neural-networks,cnn,transformers",6,Neuron Building Blocks
103185,85,FALSE,Diffusion models deterministically compress data into a fixed latent without randomness.,latent representation and randomness in generative models,Contradicts passage stating randomness is added and sampling produces creative variations.,"neural-networks,cnn,transformers",6,Neuron Building Blocks
103186,85,FALSE,Autoencoders add randomness to latent codes to enable diverse generated outputs.,latent representation in generative models,"Contradicts passage detail: autoencoders compress but randomness addition for generation is characteristic of VAEs, not all autoencoders.","neural-networks,cnn,transformers",6,Neuron Building Blocks
103187,81,TRUE,GANs can transfer learned visual patterns but face stability and memory limitations.,"generative adversarial networks, training decisions, stability","Passage states GANs transfer visual knowledge while highlighting stability, memory retention, and control limitations.","generative-ai,diffusion,gans",7,Generative AI
103188,81,half-true,GANs can transfer visual knowledge but suffer notable stability and memory limitations.,"GANs, transfer learning, stability and memory in generative models",Partly accurate: passage affirms transfer ability and cites stability/memory issues but omits specifics and degree of limitations.,"generative-ai,diffusion,gans",7,Generative AI
103189,81,mostly-true,GANs can flexibly transfer visual knowledge but face stability and long-term control challenges.,"GAN transfer learning, stability, and layer freezing decisions","Supported by passage noting transfer flexibility and limitations in stability, memory retention, and control.","generative-ai,diffusion,gans",7,Generative AI
103190,96,TRUE,The VAE uses the reparameterization trick to enable differentiable latent sampling during training.,"reparameterize function in VAE implementation (mu, logvar, torch.randn_like)","Explains sampling from standard normal, scaling by std and shifting by mean to preserve gradients for backpropagation.","generative-ai,diffusion,gans",7,Generative AI
103191,96,FALSE,The reparameterization trick eliminates the need for a learned decoder in a VAE.,VAE reparameterize function for sampling latent variables,Contradicts fact that reparameterization preserves gradients for sampling; decoder remains required for reconstruction.,"generative-ai,diffusion,gans",7,Generative AI
103192,96,barely-true,The VAE reparameterization always produces perfectly unbiased latent samples for training.,reparameterization trick in VAE using torch.randn_like,Overreaches: reparameterization preserves differentiability but not guaranteed unbiased sampling due to model bias.,"generative-ai,diffusion,gans",7,Generative AI
103193,66,TRUE,SavedModel is preferred for full deployment while .h5 is often used for quick saves.,"model saving formats (SavedModel, .h5, ONNX)",Passage explicitly contrasts SavedModel for deployment with .h5 for quick saves and sharing models.,"deep-learning,frameworks,tensors",5,Deep Learning
103194,66,half-true,"Keras .h5 files always contain only model weights, not architecture or optimizer state.","model saving formats (Keras .h5, SavedModel, ONNX)",Passage says .h5 is simpler and often used for quick saves but also shows saving full model to .h5; claiming 'always weights only' mixes correct and incorrect specifics.,"deep-learning,frameworks,tensors",5,Deep Learning
103195,66,pants-fire,ONNX is a proprietary format controlled by a single company that restricts model exchange.,model interoperability and ONNX format,"Contradicts ONNX being an open interchange standard; ONNX is community-driven, not single-company controlled.","deep-learning,frameworks,tensors",5,Deep Learning
103196,28,half-true,LLM-based code assistants usually prioritize functionality over security by default.,LLM-based code assistants optimizing for functionality,Accurately notes default optimization for functionality but overgeneralizes 'usually' without evidence about all assistants' behavior.,"security,red-team,guardrails",8,Breaking-Securing AI
103197,28,barely-true,LLM code assistants intentionally prioritize exploitable insecure patterns over secure code by default.,LLM-based code assistants optimizing for functionality,Overreaches passage: says models optimize for functionality but not that they intentionally produce exploitable insecure patterns; implication unsupported.,"security,red-team,guardrails",8,Breaking-Securing AI
103198,28,mostly-true,LLM code assistants commonly generate functional but insecure code by default.,LLM-based code assistants optimizing for functionality over security,"Passage notes models prioritize functionality, producing code that is fast yet often insecure, omitting minor variability.","security,red-team,guardrails",8,Breaking-Securing AI
103199,41,mostly-true,"SHAP, LIME, and tools like WIT generally help reveal model decision behavior and biases.","explainability tools (SHAP, LIME, WIT) for model transparency","Supports claim that SHAP, LIME, and WIT provide insights into decisions and fairness, though effectiveness varies by use case.","ethics,governance,privacy",11,AI Ethics and Governance
103200,41,TRUE,SHAP and LIME provide meaningful explanations that help detect and address model biases.,"explainability tools (SHAP, LIME, WIT) for model transparency",Directly supported by passage mentioning SHAP and LIME give meaningful insights to detect and address hidden biases.,"ethics,governance,privacy",11,AI Ethics and Governance
103201,41,pants-fire,Datasette secretly alters model outputs to manipulate fairness metrics across datasets.,metadata platforms like Datasette and model explainability tools,"Claims direct data manipulation by Datasette contradicts passage: Datasette is for logging/metadata, not model output tampering.","ethics,governance,privacy",11,AI Ethics and Governance
103202,17,FALSE,The dataset contains only textual descriptions with no structured CSV files.,superheroes_info.csv and superheros_powers.csv dataset,Contradicts passage detail: two CSV files with structured fields and Boolean power columns exist.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
103203,17,mostly-true,The datasets offer rich categorical and boolean features suitable for feature engineering and RAG experiments.,superheroes_info.csv and superheros_powers.csv dataset features,Supports use for feature engineering and RAG; omits minor limitations like class imbalance or data quality.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
103204,17,half-true,The passage claims the dataset includes over 160 Boolean superpower features and publisher metadata for heroes.,superheros_powers.csv and superheroes_info.csv dataset on Kaggle (CC0),Mixes correct dataset details with a slight mismatch: passage lists over 160 powers but exact feature encoding and completeness aren't fully specified.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
103205,175,mostly-true,Synthetic data can broadly substitute real sensitive datasets for training AI models while preserving privacy.,synthetic data for privacy-preserving model training,"Supports that synthetic data replicates real data patterns and removes identifiers, though practical fidelity caveats omitted.","data-prep,feature-engineering,rag",3,Prepping Data for AI
103206,175,TRUE,Synthetic data can replace real sensitive records for training AI models without exposing personal identifiers.,synthetic data for privacy-preserving dataset creation,Directly supported: passage says synthetic data replicates real-data structure while containing no identifying information.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
103207,175,half-true,Synthetic data can fully replace real sensitive datasets for AI model training without privacy tradeoffs.,synthetic data generation for sensitive datasets,"Correct that synthetic data reduces privacy risk, but overstated: it may leak patterns or lack fidelity, so replacement isn't guaranteed.","data-prep,feature-engineering,rag",3,Prepping Data for AI
103208,64,FALSE,Small samples cannot capture language nuance for large multilingual translation models.,large multilingual datasets used by Google Translate,Contradicts passage which says Google Translate relies on massive datasets; phrase 'cannot' overgeneralizes but directly opposes idea that small samples are insufficient.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
103209,64,FALSE,Small samples are always sufficient for training high-quality translation models.,large multilingual dataset for Google Translate,Contradicts passage assertion that massive multilingual datasets are needed; small samples lack necessary variety.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
103210,64,mostly-true,Large-scale datasets are often necessary for capturing real-world language variability.,training dataset scale for models like Gmail Smart Reply and Google Translate,Supports examples given: Gmail used 238 million emails and Google Translate uses massive multilingual datasets; small samples insufficient.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
103211,101,barely-true,VAEs usually produce noticeably blurry images compared to sharper diffusion or GAN outputs.,VAE latent space and loss balancing in generative models,Passage only notes VAEs are 'slightly smoothed or less sharp'; claiming 'noticeably blurry' overreaches specific degree compared to diffusion/GANs.,"generative-ai,diffusion,gans",7,Generative AI
103212,101,half-true,Variational autoencoders produce images that are significantly blurrier than GANs on complex data.,"VAE reconstruction and generative quality, reparameterization trick","Mixes correct VAE smoothing tendency with an absolute comparative claim versus GANs, overstating difference.","generative-ai,diffusion,gans",7,Generative AI
103213,101,TRUE,Variational autoencoders often generate outputs that are smoother and less sharp than other models.,variational autoencoders (VAE) and reparameterization trick in generative modeling,"Passage states VAEs are easy to train but tend to produce slightly smoothed, less sharp outputs compared to other approaches.","generative-ai,diffusion,gans",7,Generative AI
103214,62,pants-fire,RAG models never hallucinate when answering questions from proprietary documents.,retrieval-augmented generation (RAG) for QA over proprietary data,Passage states RAG reduces hallucination but does not claim hallucinations are eliminated; absolute claim contradicts that nuance.,"neural-networks,cnn,transformers",6,Neuron Building Blocks
103215,62,pants-fire,"RAG systems never hallucinate and always produce fully trustworthy, referenceable answers.",retrieval-augmented generation (RAG) in QA systems,Passage states RAG greatly reduces hallucination; claiming it never hallucinates contradicts that qualified benefit.,"neural-networks,cnn,transformers",6,Neuron Building Blocks
103216,62,TRUE,RAG systems extract answers from private documents using AI-powered models.,retrieval-augmented generation (RAG) in question-answering over private data,"Passage describes RAG and QA models extracting answers from underlying private or proprietary documents, grounding results.","neural-networks,cnn,transformers",6,Neuron Building Blocks
103217,133,pants-fire,The optimizer intentionally sabotages models to prevent accurate digit classification.,training behavior of optimizers on loss surface,"Directly contradicts passage which describes suboptimal convergence, not deliberate sabotage or intent.","deep-learning,frameworks,tensors",5,Deep Learning
103218,133,FALSE,Reactive optimization consistently improves digit classification accuracy during training.,reactive optimization behavior on loss surface for digit classification,"Passage says reactive methods can lead to suboptimal paths, hovering or zigzagging and failing to improve accuracy.","deep-learning,frameworks,tensors",5,Deep Learning
103219,133,mostly-true,Reactive optimization methods often help early training but can cause zigzagging or getting stuck on noisy loss surfaces.,"optimization behavior on loss surface (loss surface, training)",Passage supports quick early progress yet warns reactive optimizers can zigzag or stall in flat/noisy regions.,"deep-learning,frameworks,tensors",5,Deep Learning
103220,68,half-true,Resampling always removes social bias from datasets used for model training.,dataset imbalance and bias in training data,Combines correct resampling as imbalance remedy with incorrect claim that it eliminates systemic social bias like Amazon screening.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
103221,68,pants-fire,The passage claims Amazon's screener intentionally inserted gender bias to favor male candidates.,example about bias in dataset and screening tool,"Direct contradiction: passage describes bias as baked into data, not intentionally inserted by Amazon's screener.","data-prep,feature-engineering,rag",3,Prepping Data for AI
103222,68,TRUE,Systemic bias in data causes models to reflect harmful societal distortions.,bias versus imbalance in dataset and model behavior,"Passage contrasts systemic bias (e.g., Amazon screener) with statistical imbalance and warns models replicate societal distortions.","data-prep,feature-engineering,rag",3,Prepping Data for AI
103223,2,mostly-true,"Convolutional Neural Networks analyze images using structured, layered feature extraction rather than flat pixels.",Convolutional Neural Network (CNN) image analysis and feature maps,"Passage explicitly contrasts CNNs with treating images as flat pixels, omitting minor implementation details like pooling or architectures.","neural-networks,cnn,transformers",6,Neuron Building Blocks
103224,2,FALSE,Convolutional Neural Networks treat images as flat walls of pixel values.,CNN image processing concept from neural-networks and CNNs,Contradicts passage which explicitly states CNNs do not treat images as flat walls of pixels.,"neural-networks,cnn,transformers",6,Neuron Building Blocks
103225,2,barely-true,A Convolutional Neural Network always outperforms raw neurons on any image task.,Convolutional Neural Network vs raw neurons in image analysis,Overreaches compared to passage: CNNs useful for images but claim of universal superiority is unsupported and too strong.,"neural-networks,cnn,transformers",6,Neuron Building Blocks
103226,90,barely-true,A VAE can automatically generate realistic crumpled-paper 3D meshes from learned features.,VAE trained on perturbed icosphere meshes using PyTorch,Overreaches realism claim: passage shows generating variations but doesn't demonstrate truly realistic crumpled-paper fidelity.,"generative-ai,diffusion,gans",7,Generative AI
103227,90,half-true,A VAE can fully automate generating realistic crumpled-paper 3D meshes without manual modeling.,VAE trained on perturbed 3D spheres (icospheres),Claims full realism and elimination of manual modeling; passage shows automation and icosphere use but not guaranteed realism or complete removal of manual design.,"generative-ai,diffusion,gans",7,Generative AI
103228,90,half-true,A VAE can learn crumpled-paper 3D mesh variations and always generates perfectly realistic new meshes.,VAE trained on perturbed 3D spheres (icospheres) mesh dataset,"Correct that VAEs can learn and generate variations, but claiming always perfectly realistic is unsupported and overstated.","generative-ai,diffusion,gans",7,Generative AI
103229,34,half-true,All three Deep Three frameworks prevent overtraining solely using early stopping mechanisms.,training tools like early stopping and learning rate schedulers,"Correctly notes early stopping use across frameworks but incorrectly claims it is the sole prevention method, omitting schedulers and validation monitoring.","deep-learning,frameworks,tensors",5,Deep Learning
103230,34,pants-fire,The Deep Three frameworks guarantee models will never overfit regardless of training length.,early stopping and validation loss monitoring in deep-learning frameworks,"Contradicts passage detail that frameworks only include tools like early stopping and schedulers, not guarantees.","deep-learning,frameworks,tensors",5,Deep Learning
103231,34,FALSE,All three Deep Three frameworks lack early stopping and validation loss monitoring tools.,training utilities in Deep Three frameworks,Contradicts passage by denying named tools; passage explicitly lists early stopping and validation monitoring.,"deep-learning,frameworks,tensors",5,Deep Learning
103232,53,pants-fire,The passage claims the untuned T5 model achieved perfect accuracy on the LIAR dataset.,fine-tuning and evaluation of T5 on LIAR dataset,"Directly contradicts passage: listing shows baseline inference, fine-tuning, and evaluation but no perfect accuracy reported.","mlops,scaling,deployment",10,AI At Scale
103233,53,mostly-true,Fine-tuning T5 on merged LIAR and BYOAI data generally improves its prediction accuracy.,fine-tuning T5 on merged LIAR and BYOAI datasets,"Evaluation step compares predictions to truth labels showing improvement after fine-tuning, minor dataset caveats omitted.","mlops,scaling,deployment",10,AI At Scale
103234,53,barely-true,Fine-tuning a single T5 model on merged LIAR and BYOAI guarantees strong real-world scalability and deployment readiness.,fine-tuning T5 on LIAR and BYOAI dataset,"Overstates results: passage describes dataset loading, baseline, fine-tuning, and evaluation but gives no scalability or deployment evidence.","mlops,scaling,deployment",10,AI At Scale
103235,84,TRUE,Normalization helps keep network inputs and internal values balanced to prevent instability.,"normalization in neural networks (activation, gradients, tensors)","Specifically mentions normalization keeps inputs/internal values balanced, preventing overwhelm and instability.","deep-learning,frameworks,tensors",5,Deep Learning
103236,84,TRUE,Normalization techniques and careful initialization prevent exploding or vanishing gradients in neural networks.,"normalization, initialization, exploding and vanishing gradients",Passage explicitly links normalization and careful initialization to avoiding exploding and vanishing gradients.,"deep-learning,frameworks,tensors",5,Deep Learning
103237,84,barely-true,Deep learning models always avoid vanishing gradients by using Adam and normalization together.,optimizers and normalization in deep-learning,"Overreaches: passage says Adam and normalization help, not that they always prevent vanishing gradients.","deep-learning,frameworks,tensors",5,Deep Learning
103238,108,half-true,A fine-tuned T5 classifier can reproduce training-era labels on short factual statements.,Hugging Face T5 model inference for liar-classifier dataset,"Model reproduces earlier training results locally but may overfit or mislabel nuanced claims, mixing correct behavior with potential errors.","mlops,scaling,deployment",10,AI At Scale
103239,108,mostly-true,A fine-tuned T5 classifier on Hugging Face can reproduce training-era labels for short factual statements.,Hugging Face Transformers model gcuomo/byoai-t5-liar-classifier,Examples show loading the fine-tuned T5 and generating labels consistent with training-era behavior for short statements.,"mlops,scaling,deployment",10,AI At Scale
103240,108,half-true,The fine-tuned T5 classifier reliably labels short factual statements after local loading.,"Hugging Face transformers model loading and inference (T5, tokenizer, generate)",Model works locally for short facts but specifics about reliability and consistency are overstated.,"mlops,scaling,deployment",10,AI At Scale
103241,30,mostly-true,Optimizers adjust neural network weights and biases during repeated epochs to reduce loss.,"training loop with optimizer, weights, biases, and epoch",Directly supported: passage explains optimizers adjust weights/biases across epochs until loss stops decreasing.,"deep-learning,frameworks,tensors",5,Deep Learning
103242,30,mostly-true,An optimizer updates network weights each epoch to reduce loss during training.,training loop using optimizer and epochs,Consistent with text: optimizer adjusts weights each epoch to improve predictions until loss stops decreasing.,"deep-learning,frameworks,tensors",5,Deep Learning
103243,30,barely-true,Optimizers always make neural network loss decrease across all training epochs.,training loop using optimizer and epochs,"Overreaches: optimizers guide updates but loss can plateau or increase due to learning rates, noise, or poor optimization.","deep-learning,frameworks,tensors",5,Deep Learning
103244,80,mostly-true,Open-source governance efforts can complement internal AI ethics frameworks to improve transparency.,open-source systems and internal governance for agentic AI,"Passage endorses open-source as a powerful complement, noting increased transparency and diverse contributions.","ethics,governance,privacy",11,AI Ethics and Governance
103245,80,barely-true,Open-source governance alone fully mitigates agentic AI risks in production deployments.,open-source efforts and governance for agentic AI,"Overreaches: passage says open-source complements internal governance and adds transparency, not that it alone fully mitigates risks.","ethics,governance,privacy",11,AI Ethics and Governance
103246,80,half-true,Open-source governance will fully replace internal ethics frameworks for agentic AI systems.,internal governance and open-source efforts for agentic AI,"Overstates replacement: passage says open-source complements internal frameworks, not fully replaces them.","ethics,governance,privacy",11,AI Ethics and Governance
103247,146,half-true,The tool finds the single best hyperparameter combination by iteratively testing full runs with different batch sizes.,hyperparameter search combining batch size and strategy,"Correct that iterative testing identifies good combos, but overstates finding a single best and ignores sampling variance.","deep-learning,frameworks,tensors",5,Deep Learning
103248,146,half-true,The tool performs iterative hyperparameter search by training and evaluating models across combinations.,hyperparameter search using batch size and training strategy,"Accurately describes iterative training-and-evaluation, but omits sampling specifics and how performance is measured.","deep-learning,frameworks,tensors",5,Deep Learning
103249,146,barely-true,Batch size always determines the single best hyperparameter combination for training deep learning models.,hyperparameter tuning with batch size in model training,Overstates batch size role; passage describes batch size influence but not sole determiner of best hyperparameters.,"deep-learning,frameworks,tensors",5,Deep Learning
103250,4,mostly-true,"Facial landmark detection produces a wireframe overlay highlighting eyes, nose, and mouth on an image.",facial landmark detection in Colab code listing 8-8,"Passage describes using landmark detection to identify eyes, nose, mouth and create a mesh-like wireframe; minor implementation details omitted.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
103251,4,half-true,The program uses facial landmark detection to create a wireframe outline of detected facial features.,"facial landmark detection, wireframe, Colab code listing","Accurately describes detection and wireframe, but omits specifics about models, dataset, or evaluation.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
103252,4,TRUE,"Facial landmark detection creates a mesh-like outline by identifying eyes, nose, and mouth reference points.",facial landmark detection and wireframe mesh in listing 8-8,"Text explicitly describes detecting eyes, nose, mouth and connecting them into a mesh-like wireframe; directly supported.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
103253,25,TRUE,"DataFrames provide versatile, reliable tools for building trustworthy data via careful checks.",Pandas DataFrame tool for data validation and preprocessing,Passage states DataFrames (Pandas) are versatile and emphasizes careful checks to build trusted data.,"ai,tool-chain,notebooks",2,AI Survival Kit
103254,25,TRUE,DataFrames powered by the Pandas library are versatile tools in data science.,"DataFrame tool, Pandas library","Passage states DataFrames powered by Pandas are among the most versatile tools, citing their development and use.","ai,tool-chain,notebooks",2,AI Survival Kit
103255,25,barely-true,DataFrames were designed to handle massive financial datasets and scalability problems.,Pandas DataFrame tool origin and use in datasets,"Passage credits Wes McKinney creating DataFrames for massive financial datasets and scalability needs, but overstates general design goals.","ai,tool-chain,notebooks",2,AI Survival Kit
103256,23,TRUE,Linear regression models continuous outcomes by fitting a straight line to minimize prediction errors.,linear regression model estimating continuous dependent variable,Directly supported: passage describes fitting a straight line to minimize differences for continuous outcomes.,"machine-learning,classification,evaluation",4,Classical Machine Learning
103257,23,mostly-true,"Linear regression is a quick, interpretable method for estimating continuous outcomes from input features.",linear regression model estimating continuous dependent variable,"Passage describes linear regression as easy to set up, fast to run, and interpretable, omitting caveats about assumptions like linearity and homoscedasticity.","machine-learning,classification,evaluation",4,Classical Machine Learning
103258,23,half-true,Linear regression always provides the most interpretable and best-performing model for continuous outcomes.,"linear regression, regression analysis, continuous outcome",Correctly notes interpretability but incorrectly claims it is always best-performing across datasets and tasks.,"machine-learning,classification,evaluation",4,Classical Machine Learning
103259,134,barely-true,Raising LYNX reviewer confidence thresholds will prevent the chatbot from giving false answers.,LYNX output reviewer confidence thresholds; RAG indexing,Overstates effect: changing thresholds may reduce false confident replies but doesn't prevent extraction or RAG access issues.,"security,red-team,guardrails",8,Breaking-Securing AI
103260,134,pants-fire,The RAG system can be weaponized to autonomously exfiltrate enterprise data without any user queries.,RAG Indexing and Access Controls in red-team security testing,"Passage warns about extractable data via RAG, but claims autonomous exfiltration without queries contradicts described user-driven extraction risks.","security,red-team,guardrails",8,Breaking-Securing AI
103261,134,barely-true,The Red Team extracted data from the support chatbot's RAG system without any access controls.,RAG indexing and access controls in a support chatbot,"Passage recommends stricter controls and implies vulnerabilities, but does not confirm successful extraction occurred.","security,red-team,guardrails",8,Breaking-Securing AI
103262,29,TRUE,Benchmarks help teams detect when models confidently spread misinformation.,factual accuracy benchmarks for models,Passage states Oxford/OpenAI-developed benchmarks identify confident misinformation and test factual accuracy.,"mlops,scaling,deployment",10,AI At Scale
103263,29,pants-fire,The ImageNet dataset was created by Oxford and OpenAI to prevent models from spreading misinformation.,"ImageNet dataset, model benchmarking","Contradicts known origins: ImageNet began in 2009 at Princeton/Stanford, not Oxford/OpenAI; dataset is for vision, not misinformation detection.","mlops,scaling,deployment",10,AI At Scale
103264,29,pants-fire,The ImageNet dataset was created to detect when language models confidently spread misinformation.,ImageNet dataset and benchmarks in ML evaluation,"Contradicts passage: ImageNet is a computer vision dataset, not designed for detecting language-model misinformation.","mlops,scaling,deployment",10,AI At Scale
103265,30,FALSE,Clément Delangue discourages using open-source tools for AI development.,open-source tools on Hugging Face,"Passage explicitly states he encourages open-source AI building and open innovation on Hugging Face, so claim contradicts that encouragement.","open-source,community,ai",0,Foreword – Robo Interviews Clément Delangue
103266,30,half-true,Clément predicts many people will build AI using open-source tools on Hugging Face.,open-source tools and Hugging Face mention,Accurately cites Clément's optimism about open-source and Hugging Face but overstates certainty and scale.,"open-source,community,ai",0,Foreword – Robo Interviews Clément Delangue
103267,30,half-true,Clément claims open-source tools on Hugging Face will definitely make many people build AI.,open-source tools on Hugging Face,"Accurate optimism about open-source but overstates certainty and scale, mixing valid hope with a strong assertion.","open-source,community,ai",0,Foreword – Robo Interviews Clément Delangue
103268,5,mostly-true,Generative models learn data distributions and produce new outputs resembling their training examples.,training data distribution learning in generative models,"Accurately reflects passage: models learn patterns/distributions from training data and mimic that structure, minor nuance about model types omitted.","generative-ai,diffusion,gans",7,Generative AI
103269,5,half-true,"Generative models learn training data distributions and then generate new, similar outputs but may overfit specific features.","training data distribution learning in generative models (images, faces)","Accurately notes distribution learning and generation, but adds overfitting risk not stated in passage.","generative-ai,diffusion,gans",7,Generative AI
103270,5,TRUE,Generative models learn data distributions and produce new content resembling their training examples.,generative models trained on image distributions,Directly supported: passage states models learn patterns/distributions and mimic training data to generate similar outputs.,"generative-ai,diffusion,gans",7,Generative AI
103271,25,barely-true,YOLOv5 reliably detects most major objects but often invents irrelevant classes like coins.,YOLOv5 pretrained model object detection on an image,"Model detected many correct classes yet missed rock and paper and falsely reported coins, showing notable overreach.","neural-networks,cnn,transformers",6,Neuron Building Blocks
103272,25,half-true,YOLOv5 sometimes mislabels small objects as unrelated classes despite correct major detections.,object detection with YOLOv5 pretrained model,Accurate detection of major objects but examples show missed rock/paper and false positives (coins/bitcoins).,"neural-networks,cnn,transformers",6,Neuron Building Blocks
103273,25,mostly-true,YOLOv5 pretrained models reliably detect most major objects in images despite some missed classes.,YOLOv5 pretrained model object detection with CNN spatial features,"Detection output shows many correct objects detected, with minor misses (rock, paper) and false positives (coins).","neural-networks,cnn,transformers",6,Neuron Building Blocks
103274,36,half-true,Including Deities in training dramatically inflates regression MSE in the reported experiments.,MSE metric on regression dataset including Deities,Mixes correct observation (MSE rose above 1000) with slight overreach about dramatic causality and generality.,"machine-learning,classification,evaluation",4,Classical Machine Learning
103275,36,barely-true,Including Deities in training dramatically raised regression MSE above expected levels.,MSE on regression dataset with Deities included,"Claim overreaches: passage notes one test run increased MSE >1000, not proven as general dramatic effect.","machine-learning,classification,evaluation",4,Classical Machine Learning
103276,36,half-true,Including Deities in training dramatically increased mean squared error to over 1000.,evaluation metric MSE on dataset with Deities,"Correctly notes reported MSE spike, but statement overstates causality and omits dataset suitability nuance.","machine-learning,classification,evaluation",4,Classical Machine Learning
103277,84,half-true,Generative AI creates new content like text and images but also focuses on prediction and classification.,Generative AI section; concept: Generating New Content,Mixes correct claim that GenAI creates content with incorrect implication that it primarily also focuses on prediction/classification.,"ai,tool-chain,notebooks",2,AI Survival Kit
103278,84,FALSE,Generative AI primarily focuses on prediction and classification rather than creating new content.,"Generative AI concept in AI survival kit, generative models",Contradicts passage which states GenAI creates new content; prediction/classification is traditional ML focus.,"ai,tool-chain,notebooks",2,AI Survival Kit
103279,84,barely-true,Generative AI mainly creates new content rather than predicting or classifying data.,Generative AI section; concept: Generating New Content,"Accurately reflects passage contrast with traditional ML, but oversimplifies GenAI's overlap with prediction tasks.","ai,tool-chain,notebooks",2,AI Survival Kit
103280,0,half-true,Benchmarking and scaling AI pipelines always yields up to 5x performance improvements in production.,benchmarking and scaling AI pipelines using open-source tools,Mixes accurate focus on benchmarking with an overstated absolute claim of 'always' achieving up to 5x gains.,"mlops,scaling,deployment",10,AI At Scale
103281,0,half-true,Scaling pipelines can deliver up to fivefold performance gains in production deployments.,benchmarking and scaling pipelines with open-source tools,"Passage claims benchmarking and scaling can achieve gains “up to 5x,” but real-world results may vary by workload and setup.","mlops,scaling,deployment",10,AI At Scale
103282,0,FALSE,Scaling AI pipelines always achieves fivefold performance improvements.,benchmarking and scaling AI pipelines,"Contradicts passage which states gains up to 5x in some cases, not guaranteed always.","mlops,scaling,deployment",10,AI At Scale
103283,132,TRUE,Synthetic data should not be the backbone of production systems requiring accuracy and fairness.,synthetic data use in data-prep and feature-engineering,"Passage warns synthetic data can introduce generator quirks and lacks reliability for accuracy, fairness, accountability.","data-prep,feature-engineering,rag",3,Prepping Data for AI
103284,132,pants-fire,Synthetic data is always superior to real data for production AI systems.,synthetic data vs real data in dataset preparation,Contradicts passage: synthetic data has limitations and should not replace high-quality real data.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
103285,132,half-true,Synthetic data can safely replace real data as the backbone of production systems.,synthetic data usage with datasets and model training,Contradicts passage caution: synthetic data may embed generator quirks and should not replace real data.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
103286,72,half-true,AI systems sometimes exhibit emergent behaviors not explicitly programmed into them.,emergent behavior in AI systems,"Accurately combines correct claim with missing specifics about frequency, mechanisms, or examples of emergence.","ethics,governance,privacy",11,AI Ethics and Governance
103287,72,barely-true,Emergent behavior in modern AI means models can fully replace human ethical judgment across all situations.,emergent behavior in AI systems,"Overreaches passage: emergent behavior noted, but replacement of human ethical judgment is unsupported and exaggerated.","ethics,governance,privacy",11,AI Ethics and Governance
103288,72,half-true,"AI systems sometimes display emergent behaviors not explicitly programmed, but not all such behaviors are novel or unpredictable.",emergent behavior in AI systems,Accurately notes emergent outputs occur but overstates unpredictability and novelty across all systems.,"ethics,governance,privacy",11,AI Ethics and Governance
103289,107,barely-true,Video deepfake detection models routinely achieve near-perfect accuracy across datasets.,video data and deepfake detection models,Overreaches beyond passage which notes video complexity and misuse risks but gives no accuracy claims.,"media-forensics,voice-cloning,deepfake",9,Deepfake Defense
103290,107,TRUE,"Video data combines visual and temporal elements, making it multidimensional and complex to analyze.",multidimensional video data (visual and temporal elements),"Passage explicitly states video is inherently multidimensional with visual and temporal components, increasing analysis complexity.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
103291,107,mostly-true,"Multimodal video analysis combines visual and temporal elements, increasing complexity for deepfake defense.",multidimensional video data and temporal modeling,"Passage states video is inherently multidimensional with visual and temporal elements, making analysis and defense more complex.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
103292,19,half-true,Open-source releases always eliminate hidden biases in AI datasets and models.,"open-source datasets, training code, and documentation",Combines correct point about openness aiding bias discovery with incorrect absolutist claim that biases are always eliminated.,"ethics,governance,privacy",11,AI Ethics and Governance
103293,19,mostly-true,Open-source release of datasets and training code broadly enhances AI transparency and auditability.,open-source datasets and training code,"Passage says public datasets, training code, and documentation enable scrutiny, auditability, and bias discovery.","ethics,governance,privacy",11,AI Ethics and Governance
103294,19,FALSE,Open-source releases never improve transparency or auditability of AI systems.,"open-source datasets, training code, and documentation","Contradicts passage asserting open-source access enables scrutiny, reproducibility, and bias discovery.","ethics,governance,privacy",11,AI Ethics and Governance
103295,20,half-true,Hugging Face Hub is the only platform suitable for contributing model cards and datasets.,"discovery points for open-source contribution (Hugging Face Hub, GitHub, Papers With Code)","Correct that Hugging Face supports model cards and datasets, but incorrectly excludes GitHub and Papers With Code.","open-source,community,contribution",13,Commit to Contribute
103296,20,half-true,"Open-source contributors can find AI projects via GitHub Topics, Papers With Code, Hugging Face, and Awesome Lists.",discoverability resources for open-source AI contribution,"Lists correct resources but implies completeness and equal suitability for all contribution types, mixing accurate and overstated specifics.","open-source,community,contribution",13,Commit to Contribute
103297,20,half-true,Developers can find suitable open-source AI projects via GitHub Topics and Hugging Face Hub.,"discoverability using GitHub Topics, Papers With Code, Hugging Face Hub","Accurate that those sources surface projects, but overstates ease and suitability without vetting contribution requirements.","open-source,community,contribution",13,Commit to Contribute
103298,137,TRUE,A confusion matrix is a standard tool for evaluating binary classification models.,confusion matrix for binary classification (Marvel vs. DC),Passage explicitly names confusion matrix as the go-to tool for binary classification and its evaluation role.,"machine-learning,classification,evaluation",4,Classical Machine Learning
103299,137,half-true,A confusion matrix only reports overall accuracy for binary classification tasks.,confusion matrix in binary classification (Marvel vs. DC),"Partly correct: confusion matrices show accuracy but also detailed errors like false positives and negatives, so claiming 'only' omits those specifics.","machine-learning,classification,evaluation",4,Classical Machine Learning
103300,137,TRUE,A confusion matrix reveals both overall accuracy and types of classification errors.,confusion matrix for binary classification (Marvel vs. DC),Directly supported: passage states it reports overall accuracy and shows where the model is right and wrong.,"machine-learning,classification,evaluation",4,Classical Machine Learning
103301,93,FALSE,Cosine similarity cannot distinguish absolute feature magnitudes in vector comparisons.,cosine similarity metric for relative profiles,"Contradicts passage detail: cosine captures direction but not scale, so it cannot measure magnitude.","machine-learning,classification,evaluation",4,Classical Machine Learning
103302,93,half-true,Cosine similarity often treats feature magnitude differences as unimportant when comparing vectors.,cosine similarity among feature vectors,Correctly notes cosine ignores scale but omits that preprocessing or weighting can preserve magnitude information.,"machine-learning,classification,evaluation",4,Classical Machine Learning
103303,93,barely-true,Cosine similarity ignores vector magnitudes and can misrepresent absolute feature importance.,cosine similarity metric for feature vectors,"Passage explains cosine captures direction but not scale, so it misses absolute feature strength.","machine-learning,classification,evaluation",4,Classical Machine Learning
103304,8,TRUE,Responsible model deployment can be demonstrated on Colab without heavy infrastructure.,"deployment example using Colab for benchmarking, scaling, operationalizing",Passage explicitly states Colab suffices to show responsible deployment without Kubernetes or A100 GPUs.,"mlops,scaling,deployment",10,AI At Scale
103305,8,barely-true,It claims large-scale deployment always requires expensive GPU fleets and Kubernetes clusters.,"scaling and deployment, GPUs and Kubernetes mention",Overstates requirements; passage explicitly says those resources aren’t needed for getting models into the world.,"mlops,scaling,deployment",10,AI At Scale
103306,8,pants-fire,Deploying large-scale AI always requires renting fleets of A100 GPUs and Kubernetes clusters.,scaling and deployment of models for production,"Directly contradicts passage assertion that such heavy infrastructure is unnecessary; claims extreme, implausible requirement.","mlops,scaling,deployment",10,AI At Scale
103307,52,barely-true,The passage claims ML probabilities always indicate model success when values exceed 1.,probabilities reported by Scikit-learn models,Overreaches: probabilities aren't comparable to arbitrary thresholds >1 and Scikit-learn outputs are typically between 0 and 1.,"ai,tool-chain,notebooks",2,AI Survival Kit
103308,52,TRUE,Scikit-learn models often report probabilities that help assess whether predictions meet targets.,model training with Scikit-learn reporting probabilities,Passage explicitly notes Scikit-learn models report probabilities used to judge if performance meets or surpasses criteria.,"ai,tool-chain,notebooks",2,AI Survival Kit
103309,52,half-true,The passage mixes correct math concepts with playful superhero examples that may blur technical precision.,"dot products, gradients, probabilities in AI examples","Combines accurate math (dot products, gradients, probabilities) with informal superhero analogies that obscure rigorous details.","ai,tool-chain,notebooks",2,AI Survival Kit
103310,40,half-true,Validating datasets before training always prevents model failures caused by bad labels or outliers.,"data validation, label consistency, outlier detection tools","Validation helps but cannot always prevent failures; model issues also stem from architecture, hidden biases, or unknown data lineage.","security,red-team,guardrails",8,Breaking-Securing AI
103311,40,TRUE,Validating datasets and verifying label consistency prevents feeding unknown data into models.,"data validation, outlier detection, label consistency","Passage explicitly recommends validating datasets, using outlier tools, and verifying labels to ensure model data lineage.","security,red-team,guardrails",8,Breaking-Securing AI
103312,40,half-true,Models become entirely unreliable if training data lineage is unknown.,data lineage and dataset validation,"Accurate that unknown lineage harms reliability, but 'entirely unreliable' overstates severity and certainty.","security,red-team,guardrails",8,Breaking-Securing AI
103313,152,barely-true,Privacy and security can be added later without major costs for datasets used in RAG systems.,dataset handling for RAG and data-prep,Contradicts passage warning that bolting on security/privacy later often leads to costly fixes; overreaches about minimal costs.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
103314,152,mostly-true,Security and privacy should be integrated from the start when preparing datasets for AI.,data-prep for AI involving GDPR and CCPA compliance,"Broadly supported by passage: emphasizes building security/privacy early, omits discussion of specific implementation costs.","data-prep,feature-engineering,rag",3,Prepping Data for AI
103315,152,half-true,Building security and privacy from the start always prevents costly compliance fixes later.,"data privacy and regulatory compliance (GDPR, CCPA) for datasets","Accurate that early privacy reduces risk, but overstates guarantee; retrofits can still succeed and costs vary.","data-prep,feature-engineering,rag",3,Prepping Data for AI
103316,100,mostly-true,The passage recommends using step-by-step prompts and CrewAI to design the Neural Duel game.,prompting technique with CrewAI and a prompt cheat sheet,"Aligned with passage guidance: asks model step-by-step and references CrewAI, omitting minor implementation caveats.","agentic-ai,planning,tools",12,Agentic AI
103317,100,barely-true,CrewAI can autonomously design and implement the full Neural Duel game without human guidance.,prompting model to generate a program using CrewAI,"Passage describes asking step-by-step design, not claiming autonomous full implementation; overreaches.","agentic-ai,planning,tools",12,Agentic AI
103318,100,FALSE,The model was asked to generate a full game implementation without step-by-step guidance.,prompting with CrewAI and Neural Duel program design,"Contradicts passage: prompt explicitly requested step-by-step approach, not a full implementation demand.","agentic-ai,planning,tools",12,Agentic AI
103319,5,barely-true,Builders are experts in machine learning who prefer proprietary tools and closed workflows.,builder persona valuing open tools and practical coding,Claim contradicts passage: builders are not ML experts and value transparency and open tools.,"ai,open-source,builder",1,Introduction – The Gold Rush Paradox
103320,5,barely-true,Builders always lack machine learning expertise and cannot become expert practitioners.,builders; open tools and running code,"Overreaches beyond passage: passage says builders need not be experts but are curious and hands-on, not permanently lacking expertise.","ai,open-source,builder",1,Introduction – The Gold Rush Paradox
103321,5,TRUE,Builders are comfortable running code and experimenting with models to shape AI.,developer builders valuing open tools and transparency,"Directly supported: passage states builders run code, test ideas, and value open tools and transparency.","ai,open-source,builder",1,Introduction – The Gold Rush Paradox
103322,108,TRUE,The designer augmented prompts with examples and added tools and specialized agents to guide agentic behavior.,prompt engineering for CrewAI with tools and Judge agent,"Passage states examples, web search tools, multiple LLMs, and a Judge agent were added to steer agents.","agentic-ai,planning,tools",12,Agentic AI
103323,108,half-true,"The designer added tools, multiple LLM assignments, and a Judge agent to improve agent coordination.",prompt engineering with tools and agent roles in CrewAI sessions,Accurately lists requested additions but omits detail about basing questions on non-political current events.,"agentic-ai,planning,tools",12,Agentic AI
103324,108,mostly-true,"The author added tools, multiple LLM assignments, and a Judge agent to improve agentic planning.",prompt design for CrewAI agents and tools,"Matches passage: examples and instruction list show adding web search, assigning LLMs, and a Judge agent to guide planning.","agentic-ai,planning,tools",12,Agentic AI
103325,80,half-true,KMeans with n_clusters=3 perfectly identifies three true hero classes from 60 features.,"KMeans clustering, n_clusters=3, PCA projection of hero dataset","Mixes correct setup with incorrect certainty: PCA plot uses two components while clustering used 60 features, so perfection is unsupported.","machine-learning,classification,evaluation",4,Classical Machine Learning
103326,80,half-true,KMeans with n_clusters=3 assigns each hero to one of three clusters based on all 60 features.,KMeans clustering; km.fit_predict(X); 60 components,"Correct that fit_predict assigns clusters and 60 features used, but implies visualization uses full 60D structure which is misleading.","machine-learning,classification,evaluation",4,Classical Machine Learning
103327,80,barely-true,KMeans clustering on three clusters perfectly reflects true hero classes in the dataset.,KMeans n_clusters=3 and PCA projection of heroes,"Overreaches: clustering used 60 features and PCA plot is only a 2D projection, so perfect reflection unsupported.","machine-learning,classification,evaluation",4,Classical Machine Learning
103328,39,half-true,The passage claims replacing placeholders with NaN always preserves true missingness for models.,data-prep: normalizing placeholder values like -99 and -,"Correct that placeholders are replaced with NaN, but overstates guarantee for models; representation can alter model behavior.","data-prep,feature-engineering,rag",3,Prepping Data for AI
103329,39,pants-fire,The dataset contains fabricated height and weight entries that never existed.,missing value handling for Height and Weight placeholders,"Directly contradicts passage which says placeholders like - and -99 represent missing values, not fabricated entries.","data-prep,feature-engineering,rag",3,Prepping Data for AI
103330,39,mostly-true,Normalizing placeholder values into NaN improves missing-value handling for datasets.,"data-prep step: normalizing placeholder values (e.g., -99) into NaN","Passage specifies replacing placeholders like -99 with NaN, which aids detecting and handling missing data.","data-prep,feature-engineering,rag",3,Prepping Data for AI
103331,98,half-true,The team published their fine-tuned T5 model to the Hugging Face Hub using automated upload code.,"model publication, Hugging Face Hub, save_pretrained and upload_folder","Accurate that they published and automated upload, but specifics about automation extent mix correct and omitted details.","mlops,scaling,deployment",10,AI At Scale
103332,98,barely-true,The passage claims the byoa i-t5-liar-classifier was automatically published to the Hugging Face Hub.,model deployment using huggingface_hub upload_folder and save_pretrained,Publication is described but overstates automation; manual setup and helper functions were still required for publishing.,"mlops,scaling,deployment",10,AI At Scale
103333,98,FALSE,The fine-tuned model was manually uploaded to Hugging Face without automation.,publishing byoai-t5-liar-classifier using huggingface_hub upload_folder,"Passage describes automated upload via upload_folder and helper functions, contradicting manual upload.","mlops,scaling,deployment",10,AI At Scale
103334,60,half-true,Open-source AI communities encourage collaboration but sometimes lack clear contribution pathways for newcomers.,"Foundations of Open Source AI (Trust, Collaboration, Community)",Accurately credits collaboration and community but omits evidence about inconsistent onboarding or missing clear contribution pathways.,"open-source,community,contribution",13,Commit to Contribute
103335,60,barely-true,"Open-source communities always ensure broad, sustained contributor commitment.","Foundations of Open Source AI: Trust, Collaboration, Openness, Community",Overstates community behavior; passage lists ideals but not guaranteed sustained commitment.,"open-source,community,contribution",13,Commit to Contribute
103336,60,TRUE,Open-source AI development relies on community trust and collaboration.,"Foundations of Open Source AI: Trust, Collaboration, Openness, Community","Passage explicitly lists trust, collaboration, openness, and community as foundational elements supporting open-source AI.","open-source,community,contribution",13,Commit to Contribute
103337,81,FALSE,Batch size adjustments are unnecessary for efficient GPU training.,per_device_train_batch_size throughput plots and GPU memory,Contradicts advice that adjusting batch size balances speed and GPU memory for efficiency.,"mlops,scaling,deployment",10,AI At Scale
103338,81,TRUE,Adjusting batch size improves training efficiency while avoiding GPU memory overflow.,per_device_train_batch_size and throughput plots during GPU benchmarking,"Text explicitly recommends adjusting batch size to balance speed and memory, citing throughput and GPU limits.","mlops,scaling,deployment",10,AI At Scale
103339,81,barely-true,Batch size increases always yield meaningful speedups without trade-offs for GPU training.,"batch size, per_device_train_batch_size, GPU memory","Overstates benefits: passage notes balancing speed and memory and avoiding exceeding GPU memory, so claim omits important trade-offs.","mlops,scaling,deployment",10,AI At Scale
103340,59,half-true,They trained longer to improve a model's robustness before scaling testing.,"fine-tuned model, increased training epochs, inference time measurement","Accurate that more epochs improved results, but overstates robustness and readiness for scaling without validation under load.","mlops,scaling,deployment",10,AI At Scale
103341,59,mostly-true,Increasing training epochs produced noticeably better model performance for load-testing purposes.,"fine-tuned model, epochs, inference time measurement","Improvement is reported for preparation and load testing, though exact metrics and trade-offs omitted.","mlops,scaling,deployment",10,AI At Scale
103342,59,barely-true,Increasing training epochs alone ensures a model will scale reliably under production load.,"fine-tuned model, training epochs, measuring inference time","Overreaches: passage only increased epochs for preparation, not demonstrating reliable production scaling or load testing.","mlops,scaling,deployment",10,AI At Scale
103343,23,half-true,LangChain always enables seamless integration of multiple models and external data sources without extra engineering.,LangChain toolkit for LLMs and workflow automation,Mixes correct capability claim with overstated certainty; passage notes integration tools but omits engineering limits.,"agentic-ai,planning,tools",12,Agentic AI
103344,23,barely-true,LangChain guarantees safe autonomous agent deployment across diverse production environments.,LangChain framework for building agentic AI with tools and workflows,Overreaches: LangChain aids agent construction but does not ensure safety or production guarantees.,"agentic-ai,planning,tools",12,Agentic AI
103345,23,TRUE,LangChain simplifies building AI applications by providing a unified interface for LLMs and tools.,"framework integrating LLMs, external data sources, and workflow automation","Passage states LangChain is an open-source framework that provides a single interface and toolkit for LLMs, tools, and data integrations.","agentic-ai,planning,tools",12,Agentic AI
103346,111,TRUE,Automated scene detection successfully segmented the sample video into three scenes.,video Jerry-Jose-SampleVideo01.mp4 scene detection output,"Program output and Figure show three detected scenes with specific start/end times, supporting segmentation.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
103347,111,mostly-true,Automated scene detection correctly split the sample video into three meaningful scenes.,video scene detection on Jerry-Jose-SampleVideo01.mp4 dataset,"Output lists three scenes with start/end times and filtered short segments, omitting minor timing precision caveat.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
103348,111,barely-true,Automated scene detection reliably finds three meaningful scenes in the sample video.,scene detection on Jerry-Jose-SampleVideo01.mp4 dataset,Passage reports three detected scenes but overstates reliability beyond single example and limited duration.,"media-forensics,voice-cloning,deepfake",9,Deepfake Defense
103349,38,mostly-true,Responsible builders should disclose data sources and version history to build user trust.,transparency in data sources and version history for models,"Aligns with passage emphasis on disclosing data sources, version history, and evaluation notes to grow trust; minor omission of bias testing and private data protections.","ai,open-source,builder",1,Introduction – The Gold Rush Paradox
103350,38,half-true,Responsible builders claim transparency about data sources and version history while sometimes omitting full privacy safeguards.,responsible building; data sources and version history practices,Accurately mixes correct emphasis on transparency with incorrect implication that privacy safeguards are often omitted.,"ai,open-source,builder",1,Introduction – The Gold Rush Paradox
103351,38,FALSE,Responsible builders should hide data sources and evaluation notes to build user trust.,transparency of data sources and evaluation notes,"Contradicts explicit guidance to disclose data sources, version history, and evaluation notes to foster trust.","ai,open-source,builder",1,Introduction – The Gold Rush Paradox
103352,41,half-true,Hero B meets the train requirement but narrowly fails the bullet-speed requirement.,trait-to-requirement ratio (speed) for heroes,"Passage shows Hero B scoring 1.5 for train and 0.95 for bullet, mixing correct and slightly misleading specifics.","ai,tool-chain,notebooks",2,AI Survival Kit
103353,41,TRUE,Hero A reliably exceeds required capabilities in both train and bullet scenarios.,trait-to-requirement ratio for train and bullet scenarios,Numerical ratios (1.125 and 1.5) directly show Hero A surpasses requirements in both cases.,"ai,tool-chain,notebooks",2,AI Survival Kit
103354,41,FALSE,Hero B exceeds the bullet speed requirement in the passage example.,trait-to-requirement ratio for bullet speed,"Contradicts numeric example: Hero B's bullet ratio is 0.95, below the required threshold.","ai,tool-chain,notebooks",2,AI Survival Kit
103355,35,mostly-true,Adversaries can poison training data to covertly shape a model's behavior before deployment.,training data poisoning attack on model learning,"Passage emphasizes upstream poisoning of training data to implant ideas, so broadly supported with minor operational caveats.","security,red-team,guardrails",8,Breaking-Securing AI
103356,35,half-true,Adversaries can subtly poison training data to implant persistent code-related behaviors in models.,"training data poisoning, code-focused model learning",Mixes correct idea of poisoning models with overclaim that behaviors become persistent without defenses or validation.,"security,red-team,guardrails",8,Breaking-Securing AI
103357,35,half-true,Attackers can subtly modify training code or data to implant persistent model behaviors.,training data poisoning and code manipulation for models,Accurately reflects idea of upstream poisoning but adds persistence and code-specificity not fully stated.,"security,red-team,guardrails",8,Breaking-Securing AI
103358,67,half-true,The generator maps a 100-dimensional noise vector to 28×28 images using three linear layers and Tanh.,Generator architecture mapping noise to images in a GAN (Tanh activation),"Accurately describes dimensions and Tanh but miscounts layers: code uses three Linear layers and two hidden ReLUs, reshaping final output.","generative-ai,diffusion,gans",7,Generative AI
103359,67,TRUE,The generator maps 100‑dimensional noise through fully connected layers to produce 28×28 images with Tanh outputs.,Generator architecture mapping a 100-dimensional noise vector to 28×28 images using Tanh,"Directly described: Linear layers from 100→128→256→784, reshaped to 28×28 and Tanh normalized outputs.","generative-ai,diffusion,gans",7,Generative AI
103360,67,half-true,The generator outputs 28×28 images from a 100-dimensional noise vector using Tanh activation.,Generator architecture mapping 100-d noise to 28×28 image with Tanh,"Correct about 100-d input, 28×28 output, and Tanh; omits exact layer sizes and ReLU specifics.","generative-ai,diffusion,gans",7,Generative AI
103361,63,mostly-true,"Tokens, parameters, and weights are foundational concepts in understanding neural network behavior.","concepts: tokens, parameters, weights in model internals","Passage broadly defines tokens, parameters, and weights as core ideas, omitting deeper technical specifics.","ai,tool-chain,notebooks",2,AI Survival Kit
103362,63,half-true,Tokens are input pieces while weights always equate directly to model parameters.,"neural network concepts: tokens, parameters, weights",Mixes correct token definition with incorrect absolute claim that weights always equal parameters; passage distinguishes parameters and weights.,"ai,tool-chain,notebooks",2,AI Survival Kit
103363,63,half-true,"Tokens are inputs while weights are learned values, but parameters aren't always distinct from weights.","neural network tokens, parameters, weights","Mixes correct definitions (tokens, weights) with incorrect implication that parameters differ from weights, creating a half-true claim.","ai,tool-chain,notebooks",2,AI Survival Kit
103364,82,half-true,A high-confidence image classification always indicates correct real-world labeling.,image classification confidence scores in models,"Mixes truth and error: models provide confidence but can misinterpret patterns, so high scores aren't guaranteed.","ai,tool-chain,notebooks",2,AI Survival Kit
103365,82,FALSE,The model always correctly classifies images when confidence exceeds 0.9.,image classification model confidence scores,Confidence >0.9 is contradicted by passage noting models can misinterpret patterns and require validation.,"ai,tool-chain,notebooks",2,AI Survival Kit
103366,130,barely-true,Red teams always hand off all fixes to Blue Teams after providing evidence.,CI/QA regression tests and Blue Team response,"Overreaches the passage: it states red teams provide evidence and tests, but not that they always stop before remediation.","security,red-team,guardrails",8,Breaking-Securing AI
103367,130,TRUE,Adversarial prompts can be converted into automated regression tests for CI/QA.,adversarial prompts added to Continuous Integration (CI) pipeline,Passage states successful adversarial prompts are translated into automated regression tests and added to CI to prevent reappearance.,"security,red-team,guardrails",8,Breaking-Securing AI
103368,130,FALSE,Red Team retains responsibility for fixing vulnerabilities discovered during adversarial testing.,Red Team and CI/QA regression tests,Contradicts passage: remediation shifts to Blue Team after Red Team provides evidence; Red Team stops at evidence.,"security,red-team,guardrails",8,Breaking-Securing AI
103369,73,barely-true,Deepfake detection toolkits are reliable turnkey solutions for removing manipulation from videos.,toolkit for testing and improving deepfake detection models,"Overstates capabilities: passage lists a testing toolkit focused on evaluating inconsistencies, not guaranteed removal or full reliability.","open-source,community,contribution",13,Commit to Contribute
103370,73,FALSE,FAISS was developed by Deepstar to detect deepfakes in video.,tool list mentioning FAISS and Deepfake toolkit,Contradicts listed sources: FAISS credited to Meta AI (2017) while Deepstar made a deepfake toolkit.,"open-source,community,contribution",13,Commit to Contribute
103371,73,mostly-true,Open-source toolkits like FAISS and Fairlearn encourage community contribution and improvement of ML workflows.,"toolkit and library examples (FAISS, Fairlearn, Faker)","Examples list open-source libraries and toolkits, implying collaborative contribution and iterative improvement.","open-source,community,contribution",13,Commit to Contribute
103372,33,pants-fire,The passage claims LLMs can autonomously create fully undetectable malware without analysis.,LLM output and static analyzers like Bandit or Semgrep,"Directly contradicts passage, which recommends treating LLMs as untrusted and using analyzers; assertion is extreme and implausible.","security,red-team,guardrails",8,Breaking-Securing AI
103373,33,TRUE,Developers should treat LLM outputs as untrusted contributors and analyze them with static analyzers.,LLM output and static analyzers like Bandit or Semgrep,Directly supported: passage recommends treating LLM output like untrusted contributors and running Bandit/Semgrep.,"security,red-team,guardrails",8,Breaking-Securing AI
103374,33,half-true,Treating LLM output like any untrusted contributor and running static analyzers will catch most malicious payloads.,static analyzers like Bandit or Semgrep for LLM-generated code,"Partly true: static analyzers find many issues, but polymorphic payloads and fuzzed exploits can evade simple tools.","security,red-team,guardrails",8,Breaking-Securing AI
103375,106,TRUE,Colab's 10GB free memory limit allows loading many smaller Hugging Face models for hands-on experiments.,Hugging Face models on Colab with 10GB memory,Passage states Colab's 10GB limit supports a wide range of smaller models suitable for learning and experimentation.,"ai,tool-chain,notebooks",2,AI Survival Kit
103376,106,barely-true,Colab's 10GB memory reliably runs most production-grade Llama 3 models without issues.,"environment limits for loading models (Colab 10GB, Hugging Face Hub)","Overreaches: passage says Colab handles smaller models for learning and experiments, not production-grade Llama 3 models.","ai,tool-chain,notebooks",2,AI Survival Kit
103377,106,half-true,Colab's 10GB memory allows loading many smaller Hugging Face models but not most large Llama 3 variants.,Colab memory limit and Hugging Face models,"Correctly notes 10GB supports smaller models and hands-on use, but overstates inability to load all medium-sized variants.","ai,tool-chain,notebooks",2,AI Survival Kit
103378,113,barely-true,SceneDetect's ContentDetector with threshold=8.0 is suitable for reliable video scene segmentation.,SceneDetect ContentDetector threshold parameter in video segmentation,Passage notes threshold choice affects sensitivity but does not claim reliability; suitability is an overreach.,"media-forensics,voice-cloning,deepfake",9,Deepfake Defense
103379,113,half-true,The SceneDetect ContentDetector with threshold=8.0 segments videos into scenes using visual-change detection.,video segmentation using SceneDetect ContentDetector and OpenCV,"Accurate about using ContentDetector and threshold, but overstates certainty about segmentation quality and parameters.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
103380,113,barely-true,The passage claims a threshold of 8.0 in SceneDetect controls scene-change sensitivity in video segmentation.,SceneDetect ContentDetector threshold parameter in video segmentation,"Mostly accurate description of parameter effect, but overstates singularity of threshold without mentioning other detectors or content types.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
103381,42,TRUE,MT-Bench improves model responsiveness and interaction quality during scaling.,open-source benchmark MT-Bench for model evaluation,"Directly supported: MT-Bench helps fine-tune models, improve flow, and strengthen capability and user trust.","mlops,scaling,deployment",10,AI At Scale
103382,42,half-true,MT-Bench guarantees improved user trust and responsiveness when scaling models.,open-source benchmarking tool MT-Bench for model evaluation,Overstates certainty: MT-Bench guides improvements in listening and response but does not guarantee trust or responsiveness gains.,"mlops,scaling,deployment",10,AI At Scale
103383,42,half-true,MT-Bench guarantees that scaling models always improves interaction quality and user trust.,open-source benchmarking tool MT-Bench for model evaluation,Overstates claim: passage says MT-Bench helps shape outcomes but doesn't guarantee improvement when scaling.,"mlops,scaling,deployment",10,AI At Scale
103384,37,pants-fire,An attacker can covertly plant biased training examples to steer model outputs toward harmful behaviors.,training data poisoning of domain-specific model scrape,Contradicts passage by claiming covert planting always succeeds; passage warns possibility but not guaranteed.,"security,red-team,guardrails",8,Breaking-Securing AI
103385,37,TRUE,Poisoned training data can subtly bias a domain-specific model's outputs.,training dataset poisoning during web scraping,Passage explains sneaking biased samples into scraped source content can quietly reroute model behavior.,"security,red-team,guardrails",8,Breaking-Securing AI
103386,37,mostly-true,An attacker can poison scraped training data to subtly bias a domain-specific model's outputs.,data poisoning of scraped dataset for a domain-specific model,"Passage describes sneaking biased samples into scraped web content to shape outcomes subtly, omitting limited defenses or detection difficulty.","security,red-team,guardrails",8,Breaking-Securing AI
103387,95,mostly-true,Human listeners judged the cloned voice as broadly similar but not precisely matching the original.,human feedback on voice-cloning sample,"Anecdotal listener reaction noted likeness and cadence mismatch, supporting broad similarity with a minor caveat.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
103388,95,mostly-true,Human listeners can provide useful complementary feedback on voice-cloning quality despite minor differences.,human feedback on cloned voice evaluation,"Empirical listener reaction supported usefulness, while noting cadence differences omitted as a minor caveat.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
103389,95,TRUE,Human subjective feedback can usefully complement model-based evaluation of cloned voices.,human evaluation of voice-cloning,Directly supported by anecdote where listener judged cloned voice and authors note human feedback complements models.,"media-forensics,voice-cloning,deepfake",9,Deepfake Defense
103390,31,half-true,The passage claims duplicates commonly appear across varied datasets including superhero records.,dataset quality issues; duplicate entries in superhero dataset,Mixes correct observation about duplicates with overgeneralized implication that duplicates are universal across all datasets.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
103391,31,half-true,"Datasets commonly contain duplicates and placeholders, and all such anomalies always require automatic deletion.",data quality issues in dataset preprocessing,Correct about duplicates/placeholders but incorrect blanket claim that automatic deletion is always required.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
103392,31,mostly-true,"Datasets commonly contain duplicates, placeholders, and sparse fields across domains.","dataset quality examples (duplicates, placeholder values)","Examples mention duplicates, placeholders, sparse fields across datasets, omitting remediation details.","data-prep,feature-engineering,rag",3,Prepping Data for AI
103393,6,TRUE,TensorFlow used a graph-based execution model that benefited large-scale deployments.,"TensorFlow graph-based execution model (Google Brain, production environments)","Passage states TensorFlow originally used a graph-based model, offering advantages for large-scale deployments and production.","deep-learning,frameworks,tensors",5,Deep Learning
103394,6,barely-true,TensorFlow originally required graph construction and was unintuitive for new users.,TensorFlow graph-based execution model,"Mostly accurate but overstates requirement; graph mode existed, yet eager execution later eased usability.","deep-learning,frameworks,tensors",5,Deep Learning
103395,6,mostly-true,TensorFlow initially used a graph-based execution model advantageous for large-scale production deployments.,TensorFlow graph-based execution model in deep-learning frameworks,"Passage states TensorFlow originally used a graph model that felt unintuitive but aided large-scale, production use.","deep-learning,frameworks,tensors",5,Deep Learning
103396,36,half-true,The Robo Interviews system used automated discovery and quote-matching to assemble interviews about Clément Delangue.,"CrewAI interview generation system pseudocode, GitHub F00_Robo_InterviewAgent.ipynb",Accurately describes automated discovery and matching but omits specifics about dataset counts and processing limitations.,"open-source,community,ai",0,Foreword – Robo Interviews Clément Delangue
103397,36,half-true,The Robo Interviews system mixed accurate quote extraction with occasional incorrect attributions.,CrewAI interview generation system and discovery_agent,"Passage shows quote extraction pipeline but omits verification details, implying mixed accuracy and attribution risk.","open-source,community,ai",0,Foreword – Robo Interviews Clément Delangue
103398,36,barely-true,The Robo Interviews system automatically sourced public quotes to generate formatted interview dialogues.,Robo InterviewAgent pseudocode using discovery_agent and interview_agent,"Passage describes pseudocode for agents finding sources and extracting quotes, but broader automation claims lack evidence.","open-source,community,ai",0,Foreword – Robo Interviews Clément Delangue
103399,3,half-true,Deepfake audio and video can convincingly mimic real people's voices and faces in some cases.,"deepfake defense, facial landmark detection and voice cloning examples","Passage acknowledges convincing audio/video deepfakes but omits prevalence, technical limits, and detection variability.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
103400,3,TRUE,"Audio deepfakes can convincingly mimic a leader's voice, increasing trust risks in multimedia.","audio snippets, voice-cloning and multimedia trust",Passage explicitly notes audio snippets that mimic a leader's voice and heightened trust stakes.,"media-forensics,voice-cloning,deepfake",9,Deepfake Defense
103401,3,barely-true,Deepfake audio and video can perfectly mimic real people and are indistinguishable in practice.,"deepfake defense, facial landmark detection and voice-cloning examples",Overreaches beyond passage: passage warns high realism but gives no proof of perfect indistinguishability.,"media-forensics,voice-cloning,deepfake",9,Deepfake Defense
103402,16,barely-true,Supervised models are always unreliable because labels are typically inaccurate.,supervised learning labels and evaluation,"Overreaches beyond passage: passage states labels determine quality, not that labels are typically inaccurate.","machine-learning,classification,evaluation",4,Classical Machine Learning
103403,16,pants-fire,Supervised classifiers always outperform other methods on noisy-label datasets.,"supervised learning, labels, evaluation metric",Contradicts passage emphasis that supervised models are only as good as the labels provided; claims always outperform despite noisy labels.,"machine-learning,classification,evaluation",4,Classical Machine Learning
103404,16,half-true,"Supervised models always produce straightforward, easily explainable evaluations for classification and regression tasks.",evaluation and explainability of supervised learning models,"Correct that supervised methods often yield clear evaluations, but overstated 'always' and ignores label quality limits.","machine-learning,classification,evaluation",4,Classical Machine Learning
103405,184,barely-true,Feature engineering alone guarantees model success across most AI projects.,feature engineering in dataset preparation,"Overreaches beyond passage: feature engineering helps but does not guarantee success, missing other factors like cleaning and modeling.","data-prep,feature-engineering,rag",3,Prepping Data for AI
103406,184,pants-fire,Data preparation never matters for AI model performance and can be skipped entirely.,data preparation and feature engineering for datasets,Directly contradicts passage stating data prep can account for up to 80% effort and enables models to succeed.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
103407,184,half-true,Feature engineering always reduces model error across all datasets.,feature engineering for messy datasets,"Asserts universal error reduction though passage only claims feature engineering creates meaningful signals and helps models, not guaranteed across all datasets.","data-prep,feature-engineering,rag",3,Prepping Data for AI
103408,50,mostly-true,The passage describes using Whisper transcription as input for voice synthesis and comparison tasks.,transcription using Whisper model and processor,Describes Whisper-based transcription feeding voice synthesis/comparison; omits minor implementation details and GPU configuration.,"media-forensics,voice-cloning,deepfake",9,Deepfake Defense
103409,50,half-true,The passage claims Whisper transcription always yields perfect text for later voice synthesis.,Whisper model transcription for voice synthesis and comparison,"Correct that Whisper is used for transcription, but overstated perfection; GPU use and errors omitted.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
103410,50,pants-fire,The passage claims Whisper directly generates final voice clones without synthesis.,Whisper model transcription and voice synthesis pipeline,"Contradicts passage which says Whisper produces text for later voice synthesis and comparison, not final voice clones.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
103411,15,mostly-true,Performance engineering framed benchmarking as an engineering-driven testing function informing system design.,"performance engineering team, benchmarking and testing","Passage says benchmarking was treated as an engineering function and testing informed work, but glosses over specific methods or outcomes.","mlops,scaling,deployment",10,AI At Scale
103412,15,half-true,"The team labeled benchmarking as Performance Engineering, treating testing as an engineering input.","performance engineering team, benchmarking, testing inputs",Accurately reports naming and engineering mindset but implies formal renaming and universal practice not proven.,"mlops,scaling,deployment",10,AI At Scale
103413,15,half-true,Performance engineering teams treat benchmarking primarily as an engineering testing function.,benchmarking and Performance Engineering team mindset,"Accurately reflects emphasis on testing, but overstates that benchmarking is primarily only an engineering function.","mlops,scaling,deployment",10,AI At Scale
103414,185,barely-true,RAG eliminates any need to retrain models when adding new context for datasets.,Retrieval-Augmented Generation (RAG) in data-prep and model workflows,"Overstates claim: passage says RAG can add context without retraining, but omits limits like retrieval quality and model adaptation needs.","data-prep,feature-engineering,rag",3,Prepping Data for AI
103415,185,half-true,RAG lets models add contextual data without any retraining in all deployment scenarios.,Retrieval-Augmented Generation (RAG) and dataset enrichment,"RAG can add context without retraining, but claiming universality ignores index/update, latency, or security trade-offs.","data-prep,feature-engineering,rag",3,Prepping Data for AI
103416,185,TRUE,RAG enables models to augment context at inference without retraining.,Retrieval-Augmented Generation (RAG) in data-prep workflows,Passage explicitly states models can add new context on demand without retraining using RAG.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
103417,20,half-true,Delangue claims open-source AI prevents power concentration but overstates its sufficiency alone.,open-source AI advocacy and community collaboration,"Accurate mix: defends openness to avoid concentration, omits other needed policies and forces.","open-source,community,ai",0,Foreword – Robo Interviews Clément Delangue
103418,20,barely-true,Clément argues open-source AI prevents concentration of power in a few companies.,open-source AI advocacy in Foreword (Robo interview),Claim aligns with his warning but simplifies nuance; passage quotes risk of concentrated power without evidence.,"open-source,community,ai",0,Foreword – Robo Interviews Clément Delangue
103419,20,pants-fire,Clément Delangue claims open-source AI will let only a few companies control all AI development globally.,open-source AI advocacy and community power concentration,"Contradicts passage: Delangue warns lack of openness would concentrate power in few companies, not that open-source causes it.","open-source,community,ai",0,Foreword – Robo Interviews Clément Delangue
103420,47,TRUE,"Hugging Face models may be renamed, replaced, or updated over time.",model registry and notebook comments mentioning migration tips,"Passage explicitly notes models can change names, be replaced, or move to new versions and suggests checking migration tips.","data-prep,feature-engineering,rag",3,Prepping Data for AI
103421,47,TRUE,"Hugging Face models can change names, be replaced, or move to new versions over time.",model versioning and migration in Hugging Face models,"Passage explicitly warns that Hugging Face models often change names, get replaced, or move versions.","data-prep,feature-engineering,rag",3,Prepping Data for AI
103422,47,barely-true,"Hugging Face model names never change, so notebooks need no migration guidance.",model naming and migration for Hugging Face models,"Contradicts passage: models can change names or move, so claiming never changes is largely unsupported.","data-prep,feature-engineering,rag",3,Prepping Data for AI
103423,87,TRUE,A VAE encoder maps inputs to a Gaussian distribution defined by mean and variance.,variational autoencoder latent space and encoder mapping,Passage explains encoder outputs mean and variance for a probabilistic Gaussian latent distribution.,"generative-ai,diffusion,gans",7,Generative AI
103424,87,FALSE,A variational autoencoder maps each input to a single fixed latent vector without randomness.,variational autoencoder latent space and encoder mapping,"Contradicts described VAE behavior: encoder maps inputs to Gaussian distributions (mean and variance), not fixed vectors.","generative-ai,diffusion,gans",7,Generative AI
103425,87,barely-true,A VAE's encoder maps inputs to fixed deterministic latent points rather than distributions.,variational autoencoder (VAE) latent space,"Contradicts passage: encoder maps inputs to Gaussian distributions (means and variances), not fixed points.","generative-ai,diffusion,gans",7,Generative AI
103426,137,pants-fire,Agentic AI autonomously makes full financial decisions and replaces human oversight entirely.,agentic AI monitoring economic indicators in finance,"Passage describes monitoring, flagging, and suggesting adjustments but not replacing human oversight; claim contradicts omission of autonomous full decision-making.","agentic-ai,planning,tools",12,Agentic AI
103427,137,half-true,Agentic AI autonomously escalates issues and follows up while handling customer account retrievals.,agentic AI capabilities for contact center tools and account retrieval,Correct about escalation and follow-up but overstates autonomy and scope; passage says escalation only when needed and human agents retain focus.,"agentic-ai,planning,tools",12,Agentic AI
103428,137,mostly-true,"Agentic AI systems can autonomously escalate, retrieve data, suggest actions, and follow up in customer support.",agentic AI in customer support tools,"Passage describes autonomous escalation, data retrieval, suggested next steps, and automatic follow-up, omitting potential limits or failure modes.","agentic-ai,planning,tools",12,Agentic AI
103429,88,half-true,BatchNorm normalizes activations across the batch while LayerNorm normalizes across features for each example.,"normalization layers (BatchNorm, LayerNorm, GroupNorm) in deep learning frameworks","Mixes correct LayerNorm behavior with an oversimplified BatchNorm claim; BatchNorm normalizes per-channel over batch and spatial dims, not just generic activations.","deep-learning,frameworks,tensors",5,Deep Learning
103430,88,barely-true,BatchNorm is unavailable in most deep learning frameworks by default.,"normalization layers (BatchNorm, LayerNorm, GroupNorm) in frameworks",Contradicts passage saying most frameworks support BatchNorm out of the box; claim overreaches.,"deep-learning,frameworks,tensors",5,Deep Learning
103431,88,TRUE,Most deep-learning frameworks provide BatchNorm and LayerNorm implementations out of the box.,"framework support for BatchNorm, LayerNorm, GroupNorm","Passage states most frameworks support BatchNorm and LayerNorm natively, with GroupNorm via PyTorch or add-ons.","deep-learning,frameworks,tensors",5,Deep Learning
103432,42,mostly-true,Prompt templates usually improve agent output consistency and standardize interactions with models.,agent design using prompt templates and dynamic prompts,Supports claim: passage endorses prompt templates for standardizing interactions but omits implementation caveats.,"agentic-ai,planning,tools",12,Agentic AI
103433,42,mostly-true,Prompt templates generally standardize agent interactions but may omit some edge-case guidance.,prompt templates for building agents,Passage indicates templates standardize interactions yet warns prompts can still produce inconsistent outputs.,"agentic-ai,planning,tools",12,Agentic AI
103434,42,barely-true,Agentic AI always produces inconsistent outputs without structured prompt templates.,prompt templates and agent design for language model agents,Overreaches: passage says structure reduces inconsistency but doesn't claim templates always prevent inconsistencies.,"agentic-ai,planning,tools",12,Agentic AI
103435,111,mostly-true,Running models locally with controlled environments is practical for enterprises needing auditability and integration.,"deployment, model hosting, Hugging Face Spaces, auditability",Passage supports enterprise use for controlled environments and auditability but omits potential operational costs.,"mlops,scaling,deployment",10,AI At Scale
103436,111,half-true,Hosting models on Hugging Face Spaces guarantees enterprise-grade auditability and control for production deployments.,deployment using Hugging Face Spaces and Gradio interface,Mixes correct hosting convenience with overstated guarantee about enterprise-grade auditability and control; specifics omitted.,"mlops,scaling,deployment",10,AI At Scale
103437,111,mostly-true,Hosting models via Hugging Face Spaces enables controlled enterprise deployment with lightweight Gradio interfaces.,deployment using Hugging Face Spaces and Gradio,"Passage affirms Spaces + Gradio support hosting for enterprises and controlled, auditable integration, minor deployment caveats omitted.","mlops,scaling,deployment",10,AI At Scale
103438,35,TRUE,Privacy and data protection uphold user consent and legal compliance in AI systems.,privacy and data protection concept,Directly aligns with passage stating privacy upholds user consent and legal compliance explicitly.,"ethics,governance,privacy",11,AI Ethics and Governance
103439,35,barely-true,AI accountability mechanisms alone reliably prevent misuse and discriminatory outcomes.,accountability mechanism for fairness and non-discrimination,"Overstates passage: accountability is important but passage pairs it with privacy, oversight, and fairness safeguards.","ethics,governance,privacy",11,AI Ethics and Governance
103440,35,mostly-true,"AI systems should include explainability, fairness, accountability, privacy, safety, and human oversight.","transparency, explainability, fairness, privacy, and human oversight in AI governance",Passage broadly lists all these governance principles; minor implementation trade-offs or scope details omitted.,"ethics,governance,privacy",11,AI Ethics and Governance
103441,10,barely-true,Regulators claim all AI generative models are currently incapable of producing reliable provenance metadata.,"misuse of AI-generated content, deepfakes, provenance verification","Overreaches beyond passage: passage notes verifier difficulties and regulator focus, not blanket incapability of provenance metadata.","generative-ai,diffusion,gans",7,Generative AI
103442,10,half-true,AI-generated deepfakes and synthetic voices often appear indistinguishable from real media to casual observers.,deepfakes and synthetic voices in generative-ai misuse,Mixes correct concern about indistinguishability with overstatement implying frequent indistinguishability for all observers and contexts.,"generative-ai,diffusion,gans",7,Generative AI
103443,10,TRUE,Regulators are increasingly concerned about AI-generated deepfakes enabling fraud and impersonation.,"misuse of AI-generated content, deepfakes, synthetic voices","Regulatory focus explicitly mentions deepfakes, impersonation, fraud, and trust concerns about synthetic media.","generative-ai,diffusion,gans",7,Generative AI
103444,89,TRUE,Deep learning models can generate images and text as creative outputs.,"creative deep learning models (generate images, text)",Directly supported by passage stating models generate images and text as creative outputs.,"neural-networks,cnn,transformers",6,Neuron Building Blocks
103445,89,mostly-true,"Generative deep learning models can produce images, text, and complex documents.","creative deep learning generative models (images, text, mission dossiers)","Passage explicitly mentions generation of images, text, and mission dossiers; minor caveat about model limitations omitted.","neural-networks,cnn,transformers",6,Neuron Building Blocks
103446,89,mostly-true,"Creative deep learning models can generate images, text, and complex documents beyond classification tasks.",generative models like CNNs and transformers producing images and text,"Passage explicitly mentions generation of images, text, and documents, omitting few implementation caveats.","neural-networks,cnn,transformers",6,Neuron Building Blocks
103447,131,barely-true,The model’s high accuracy mainly reflects class imbalance rather than true DC performance.,"untuned gradient boosting model, accuracy and F1 on DC examples",Accuracy improvement cited (77% vs 65%) but passage notes fewer DC examples weaken F1 and signal.,"machine-learning,classification,evaluation",4,Classical Machine Learning
103448,131,FALSE,The model's higher accuracy indicates it performs well across all classes including DC.,untuned gradient boosting model accuracy on dataset,"Contradicts passage: DC class has fewer examples and lower scores, so performance is not strong across all classes.","machine-learning,classification,evaluation",4,Classical Machine Learning
103449,131,barely-true,The model substantially outperforms the baseline in overall accuracy despite class imbalance.,"untuned gradient boosting model accuracy, DC class imbalance","Supported by reported 77% vs 65% accuracy, but overlooks limited DC examples causing weaker F1 performance.","machine-learning,classification,evaluation",4,Classical Machine Learning
103450,55,barely-true,Deep Learning and Machine Learning are interchangeable terms for the same techniques.,definitions of ML and DL within AI concepts,Passage distinguishes ML and DL meanings; calling them identical overstates and contradicts nuance.,"ai,tool-chain,notebooks",2,AI Survival Kit
103451,55,half-true,Machine learning and deep learning are identical techniques used interchangeably in AI development.,definitions of ML and DL within AI concepts,Combines correct relation (DL is part of ML) with incorrect equivalence claim; omits distinctions between methods.,"ai,tool-chain,notebooks",2,AI Survival Kit
103452,55,barely-true,Deep Learning and Machine Learning are entirely interchangeable terms for AI approaches.,definition of ML and DL in AI foundations,Passage notes ML and DL are often used interchangeably but stresses they have distinct meanings and relationships.,"ai,tool-chain,notebooks",2,AI Survival Kit
103453,18,FALSE,Hugging Face has never developed the Transformers library mentioned in the passage.,tool: Transformers library on Hugging Face Hub,Contradicts passage detail that Transformers was introduced by Hugging Face and became the de facto library.,"open-source,community,ai",0,Foreword – Robo Interviews Clément Delangue
103454,18,half-true,"Hugging Face hosts over 100,000 datasets and is the de facto LLM library, but adoption claims mix scales.","Hugging Face Hub, datasets, Transformers, Spaces","Combines accurate dataset and Transformers claims with vague, unquantified adoption breadth across organizations.","open-source,community,ai",0,Foreword – Robo Interviews Clément Delangue
103455,18,mostly-true,"Hugging Face has rapidly grown into a widely adopted open-source AI hub with many models, datasets, and tools.","Hugging Face Hub, Transformers, Spaces, datasets",Supports adoption claims and tool names; minor caveat omits exact usage metrics and scope details.,"open-source,community,ai",0,Foreword – Robo Interviews Clément Delangue
103456,80,barely-true,Large batch sizes always maximize throughput without memory issues on GPU deployments.,batch size tuning; per_device_train_batch_size and throughput plots,Overreaching claim contradicts guidance to balance batch size against GPU memory and throughput trade-offs.,"mlops,scaling,deployment",10,AI At Scale
103457,80,half-true,Model fine-tuning with small batches always produces a stable baseline for later scaling.,fine-tune light with Trainer and TrainingArguments,Mixes correct practice (small batches stabilize early training) with absolute claim 'always' unsupported by details like dataset or hyperparameters.,"mlops,scaling,deployment",10,AI At Scale
103458,80,barely-true,Scaling simply by increasing batch size reliably eliminates GPU memory issues during deployment.,"batch size, per_device_train_batch_size, GPU memory","Overreaches: passage advises balancing batch size for speed and memory, not guaranteed elimination of memory issues.","mlops,scaling,deployment",10,AI At Scale
103459,100,FALSE,Dropout permanently removes neurons from a trained neural network.,regularization technique dropout in neural networks,"Contradicts passage: dropout temporarily disables neurons during training, not permanently.","deep-learning,frameworks,tensors",5,Deep Learning
103460,100,mostly-true,Dropout randomly disables neurons during training to reduce neural network overfitting.,regularization technique (dropout) in deep learning,"Passage explains dropout randomly disables neurons during training and prevents overreliance, reducing overfitting.","deep-learning,frameworks,tensors",5,Deep Learning
103461,20,half-true,"Model cards and READMEs always provide complete, reproducible evaluation details for models.","model card, README.md, Hugging Face, LLaMA repository",Passage shows examples of detailed info but omits that coverage varies and completeness isn't guaranteed.,"mlops,scaling,deployment",10,AI At Scale
103462,20,mostly-true,Model cards and READMEs generally provide benchmark scores and evaluation details for reproducibility.,"model card, README.md, benchmark scores","Passage indicates examples like DeepSeek-R1 and LLaMA showing scores, settings, and reproducibility notes, though not universal.","mlops,scaling,deployment",10,AI At Scale
103463,20,barely-true,Model cards always include complete benchmarking details and reproducibility instructions for deployed models.,model card and README.md evaluation details,"Overstates completeness; passage shows examples (DeepSeek-R1, LLaMA) but not universal or always-complete coverage.","mlops,scaling,deployment",10,AI At Scale
103464,153,barely-true,Classical ML generally outperforms deep learning on structured datasets with interpretability and limited resources.,"structured dataset model choice; linear regression, decision tree",Overstates performance: passage praises interpretability and efficiency but not superior accuracy.,"machine-learning,classification,evaluation",4,Classical Machine Learning
103465,153,FALSE,Classical machine learning is best for raw unstructured data like images and audio.,structured datasets and interpretability in classical ML,Contradicts passage which states deep learning dominates unstructured data such as images and audio.,"machine-learning,classification,evaluation",4,Classical Machine Learning
103466,153,mostly-true,Classical ML is preferable for structured datasets when interpretability and efficiency outweigh raw power.,structured datasets; linear regression and decision trees,Supports interpretability and efficiency claims but omits cases where deep learning can still be suitable for some structured tasks.,"machine-learning,classification,evaluation",4,Classical Machine Learning
103467,13,pants-fire,Supervised learning never requires labeled data and always trains without examples.,supervised learning concept in machine-learning classification,Directly contradicts supervised learning definition: supervised learning requires labeled examples for training.,"machine-learning,classification,evaluation",4,Classical Machine Learning
103468,13,mostly-true,Supervised learning trains models using labeled examples to predict target variables.,"supervised learning, labeled data, prediction task","Broadly supported: passage describes supervised learning as teaching by example using labels, omitting details about algorithms and limits.","machine-learning,classification,evaluation",4,Classical Machine Learning
103469,13,pants-fire,Supervised learning requires no labeled examples to train models.,supervised learning concept in machine-learning,"Directly contradicts supervised learning definition by claiming absence of labeled examples, an extreme falsehood.","machine-learning,classification,evaluation",4,Classical Machine Learning
103470,121,barely-true,Median imputation always preserves model fairness and prediction validity.,SimpleImputer median imputation for numeric features,Overreaches beyond passage: median imputation can introduce bias or reduce variation when missingness is not random.,"machine-learning,classification,evaluation",4,Classical Machine Learning
103471,121,FALSE,Median imputation always preserves unbiased model predictions for publisher classification.,SimpleImputer median imputation on numeric features for publisher prediction,Contradicts passage: median can reduce variation or introduce bias when missingness is not random.,"machine-learning,classification,evaluation",4,Classical Machine Learning
103472,121,half-true,Median imputation always prevents model performance degradation by preserving essential numeric variation.,SimpleImputer median imputation for numeric features,"Correct that median imputation avoids gaps and keeps rows usable, but overstated: it can reduce variation or introduce bias when missingness isn't random.","machine-learning,classification,evaluation",4,Classical Machine Learning
103473,59,half-true,Machine learning systems always improve their accuracy simply by receiving more data.,"machine learning, recommendation systems, data feedback","Overgeneralizes: passage states ML improves with more data but omits limits like bias, noise, or model capacity.","ai,tool-chain,notebooks",2,AI Survival Kit
103474,59,half-true,Machine learning systems always improve with more data and continuous feedback loops.,machine learning concept; recommendation systems and feedback,"Mixes correct idea of learning from data with incorrect absolutism; ignores model capacity, data quality, and feedback biases.","ai,tool-chain,notebooks",2,AI Survival Kit
103475,59,FALSE,Machine learning systems do not improve with more data and remain static after deployment.,"machine learning, recommendation systems, feedback",Contradicts passage claim that ML improves with more data and continuous feedback; denies learning in systems like recommendation engines.,"ai,tool-chain,notebooks",2,AI Survival Kit
103476,13,barely-true,Measuring performance primarily reveals comparative insights rather than precise quantitative truths.,model performance testing in early AI exploration,Overreaches by downplaying the value of numeric measurements; passage emphasizes both mapping and comparison.,"mlops,scaling,deployment",10,AI At Scale
103477,13,barely-true,Measuring model performance mainly reveals comparative insights rather than absolute success.,"model performance measurement, testing, and comparison","Overstates emphasis: passage highlights exploratory mapping and comparisons, not that measurements lack value for absolute success.","mlops,scaling,deployment",10,AI At Scale
103478,13,mostly-true,Measuring model performance early uncovers strengths and weaknesses for better comparisons.,model performance measurement in mlops and evaluation,"Aligns with passage: testing reveals what works, what doesn’t, and how models compare; minor caveat about later-stage needs.","mlops,scaling,deployment",10,AI At Scale
103479,35,TRUE,Stopping training when performance plateaus prevents degradation from excessive epochs.,early stopping using validation performance,"Passage states training should stop when performance plateaus or degrades, warning more epochs don't always help.","deep-learning,frameworks,tensors",5,Deep Learning
103480,35,half-true,Early stopping always prevents overfitting by halting training at the optimal epoch.,early stopping and epochs (training procedure),Correctly links early stopping to preventing overfitting but overstates certainty—optimal epoch selection isn't guaranteed.,"deep-learning,frameworks,tensors",5,Deep Learning
103481,35,mostly-true,Early stopping prevents overtraining by halting training once validation performance plateaus or degrades.,training technique using validation metrics and epochs,Matches passage claim that stopping when performance plateaus or degrades is appropriate; omits specifics like monitoring method or thresholds.,"deep-learning,frameworks,tensors",5,Deep Learning
103482,73,half-true,Imbalanced superhero labels can be ignored because models naturally prefer the majority class.,superheroes_info dataset imbalance in dataset labels,Mixes correct observation about majority-class bias with incorrect prescriptive claim to ignore imbalance.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
103483,73,pants-fire,The dataset guarantees models will never predict 'bad' under any circumstances.,superheroes_info dataset label imbalance,"Claim is an extreme, implausible contradiction of passage saying models 'almost always' predict good, not 'never'.","data-prep,feature-engineering,rag",3,Prepping Data for AI
103484,73,mostly-true,Models trained on imbalanced superhero datasets will predominantly predict the majority class.,superheroes_info dataset imbalance in dataset,"Passage notes models will almost always lean toward predicting 'good', omitting mitigation details.","data-prep,feature-engineering,rag",3,Prepping Data for AI
103485,107,mostly-true,The fine-tuned T5 model from the Hugging Face Hub broadly reproduces its training-era truthfulness labels when run locally.,Hugging Face model loading and inference with T5 tokenizer,"Inference reproduces labels consistent with training, though minor deployment or tokenization caveats omitted.","mlops,scaling,deployment",10,AI At Scale
103486,107,TRUE,The code downloads a fine-tuned T5 model from the Hugging Face Hub and generates truthfulness labels.,Hugging Face Transformers fine-tuned model inference,"Example code loads model/tokenizer from Hub, runs generate, and outputs one of six truthfulness labels.","mlops,scaling,deployment",10,AI At Scale
103487,107,barely-true,The fine-tuned T5 model always outputs reliably calibrated truthfulness labels for any input statement.,Hugging Face Transformers fine-tuned T5 liar-classifier model,Model produces labels consistent with training examples but reliability and calibration across arbitrary inputs are not demonstrated.,"mlops,scaling,deployment",10,AI At Scale
103488,142,barely-true,Random search almost always outperforms grid search for hyperparameter tuning in deep learning.,"hyperparameter search methods (grid search, random search)","Overstates claim: passage says random often finds good results faster, not that it almost always outperforms grid search.","deep-learning,frameworks,tensors",5,Deep Learning
103489,142,FALSE,Grid search randomly samples hyperparameter combinations during training.,hyperparameter search methods like grid search and random search,"Contradicts passage detail: grid search systematically tries every combination, not random sampling.","deep-learning,frameworks,tensors",5,Deep Learning
103490,142,half-true,Random search often finds good hyperparameter results faster than exhaustive grid search.,"hyperparameter search methods (grid search, random search)","Passage states random search commonly finds good results faster, but omits conditions and dataset/model specifics.","deep-learning,frameworks,tensors",5,Deep Learning
103491,130,TRUE,SpeechBrain x-vectors and cosine similarity confirm whether the same person spoke in suspect clips.,audio forensics using SpeechBrain x-vectors,Directly supported by passage listing SpeechBrain x-vectors and cosine similarity confirming same-speaker presence.,"media-forensics,voice-cloning,deepfake",9,Deepfake Defense
103492,130,half-true,The workflow's x-vector cosine similarity reliably proves speaker identity across deepfake videos.,voice-cloning evaluation using SpeechBrain x-vectors and cosine similarity,Mixes correct method use with overclaim: x-vector similarity helps but doesn't reliably prove identity alone.,"media-forensics,voice-cloning,deepfake",9,Deepfake Defense
103493,130,half-true,SpeechBrain x-vectors reliably identify whether two clips are from the same speaker.,audio forensics using SpeechBrain x-vectors and cosine similarity,"Correctly notes speaker verification use, but overstates reliability given cross-modal, detection limits and potential false positives.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
103494,52,TRUE,Transformers are introduced as an alternative to RNNs for sequence modeling.,sequence modeling with RNNs and Transformers,Passage explicitly contrasts RNNs' sequential limitations and states Transformers are introduced as an alternative.,"neural-networks,cnn,transformers",6,Neuron Building Blocks
103495,52,pants-fire,Transformers always remember every earlier token perfectly without any loss.,Transformer sequence modeling and RNN memory limitation,Claim contradicts model mechanics: attention helps but does not guarantee perfect memory; capacity and context length limit recall.,"neural-networks,cnn,transformers",6,Neuron Building Blocks
103496,52,barely-true,Transformers eliminate all sequence-order processing problems that RNNs face in long texts.,"sequence modeling, RNNs versus Transformers",Overreaches beyond passage: passage contrasts RNN order limitations but doesn't claim Transformers fully eliminate them.,"neural-networks,cnn,transformers",6,Neuron Building Blocks
103497,162,half-true,CLIP always converts prompts into fully comprehensive visual embeddings capturing all suggested visual concepts.,Transformer-based encoder CLIP producing semantic embeddings,"Correct that CLIP makes semantic embeddings, but overstated as 'always' and 'fully comprehensive'—embeddings are partial and task-dependent.","generative-ai,diffusion,gans",7,Generative AI
103498,162,barely-true,CLIP always converts text prompts into semantic embeddings capturing visual concepts.,CLIP encoder producing semantic embeddings,"Overreaches by saying CLIP always captures visual concepts; passage describes typical behavior, not guaranteed outcomes.","generative-ai,diffusion,gans",7,Generative AI
103499,162,TRUE,CLIP encodes text prompts into dense semantic embeddings that capture visual concepts.,Transformer-based encoder CLIP converting prompts to semantic embeddings,Passage states CLIP converts prompts into dense semantic embeddings capturing literal meaning and visual concepts.,"generative-ai,diffusion,gans",7,Generative AI
103500,6,FALSE,Deepfake defense relies solely on transcription techniques to detect manipulated audio.,feature extraction and transcription techniques in multimedia AI,"Contradicts passage which lists multiple methods (audio/video integration, feature extraction, voice cloning), not only transcription.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
103501,6,barely-true,Multimodal feature extraction alone reliably prevents voice-cloning misuse in real-world media.,voice cloning and feature extraction methods,Overstates capabilities: passage describes methods and mitigation goals but not guaranteed prevention of misuse.,"media-forensics,voice-cloning,deepfake",9,Deepfake Defense
103502,6,barely-true,Voice cloning reliably prevents deepfake misuse across multimedia authentication systems.,voice cloning and multimedia authentication methods,Overreaches beyond passage: methods help analyze and protect media but do not claim reliable prevention.,"media-forensics,voice-cloning,deepfake",9,Deepfake Defense
103503,123,half-true,Applying SMOTE can increase recall for underrepresented classes but may introduce synthetic bias.,"SMOTE oversampling for underrepresented classes (dataset, recall metric)",Notes correctly say SMOTE often boosts recall for small groups but omits risks like synthetic bias and evaluation changes.,"machine-learning,classification,evaluation",4,Classical Machine Learning
103504,123,barely-true,SMOTE reliably fixes class imbalance and always improves model performance.,SMOTE oversampling for minority class in dataset,Overreaches beyond passage; passage says SMOTE can often boost recall but not guaranteed or always improving performance.,"machine-learning,classification,evaluation",4,Classical Machine Learning
103505,123,half-true,Applying SMOTE always improves recall for underrepresented classes like DC Comics.,SMOTE oversampling for imbalanced dataset classes,"Accurate that SMOTE can boost recall for small classes, but 'always' is an overgeneralization; results vary by model and data.","machine-learning,classification,evaluation",4,Classical Machine Learning
103506,58,TRUE,The passage states the authors used SMOTE to balance skewed datasets.,data balancing technique (SMOTE) in Train Set,SMOTE recommendation is explicitly mentioned for handling skewed datasets in the Train Set passage.,"mlops,scaling,deployment",10,AI At Scale
103507,58,pants-fire,The fine-tuned T5 model reliably detects 'pants-fire' claims with perfect accuracy under load.,"fine-tuned T5 model on LIAR dataset, prediction labels",Contradicts passage noting early predictions were decent but imperfect; perfect accuracy is implausible.,"mlops,scaling,deployment",10,AI At Scale
103508,58,barely-true,The passage claims a fine-tuned T5 model confidently labels LIAR examples but isn't reliably precise.,fine-tuned T5 model on the LIAR dataset,"Model predictions described as confident yet imperfect; goal emphasized testing under load, not high precision.","mlops,scaling,deployment",10,AI At Scale
103509,45,half-true,"Classification metrics always require integer-encoded labels like 0, 1, 2 for categories.",classification metrics and label encoding,"Correct that classification uses labels, but incorrect to say labels must be integer-encoded; other encodings exist.","machine-learning,classification,evaluation",4,Classical Machine Learning
103510,45,TRUE,Classification models evaluate performance using metrics that measure label prediction accuracy.,"classification metrics (labels, accuracy, MSE)","Passage contrasts regression metrics like MSE with classification metrics and defines labels as predicted categories, supporting truth.","machine-learning,classification,evaluation",4,Classical Machine Learning
103511,45,half-true,"Classification always uses discrete integer labels like 0, 1, 2 for categories.","classification labels (e.g., cat=0, dog=1, mouse=2)",Mixes correct idea that models use encoded labels with incorrect claim that labels must be discrete integers.,"machine-learning,classification,evaluation",4,Classical Machine Learning
103512,12,TRUE,Colab is well-suited for learning and quick prototyping.,using Colab for notebooks and datasets,Passage explicitly states Colab is ideal for learning and quick prototyping and practical for large-file access.,"ai,tool-chain,notebooks",2,AI Survival Kit
103513,12,half-true,Colab is convenient for prototyping but inadequate for long-running production experiments.,tool: Colab vs local Jupyter for notebooks,Mixes correct points about limited session time and internet reliance with an overstated claim that Colab is inadequate for all long-running production use cases.,"ai,tool-chain,notebooks",2,AI Survival Kit
103514,12,barely-true,Colab is unsuitable for any serious machine learning experiments requiring large datasets or models.,using Colab for large datasets and models,"Overstates limitation: passage notes Colab enables accessing gigabyte files by URL and suits prototyping, not universally unsuitable.","ai,tool-chain,notebooks",2,AI Survival Kit
103515,28,mostly-true,Spectral flatness commonly increases in synthesized voices compared to genuine recordings.,feature analysis of voice-cloning deepfake detection,"Passage reports spectral flatness tended to increase in deepfake samples, a broadly supported observation.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
103516,28,half-true,Spectral flatness always increases in every deepfake voice sample compared to real voices.,feature analysis of synthesized voices using spectral flatness,"Overgeneralizes passage finding: spectral flatness tended to increase, but not stated as universal across all samples.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
103517,28,mostly-true,"The selected audio features generally distinguish real from synthesized voices, with spectral flatness higher in deepfakes.",feature selection for voice-cloning detection using spectral flatness,Passage reports spectral flatness increases in deepfake samples and says selected features consistently separated real versus synthesized voices.,"media-forensics,voice-cloning,deepfake",9,Deepfake Defense
103518,104,FALSE,The baseline always-predict-majority classifier achieves optimal performance on imbalanced datasets.,baseline most frequent class classifier; evaluation metric accuracy,"Contradicts passage guidance: baseline is a minimum bar and not optimal for imbalanced datasets, especially when accuracy is misleading.","machine-learning,classification,evaluation",4,Classical Machine Learning
103519,104,mostly-true,A most-frequent-class baseline provides a simple minimum bar for classification performance.,baseline prediction using the most frequent class and accuracy metric,Describes baseline strategy used for evaluation; minor caveat omitted about other baseline choices.,"machine-learning,classification,evaluation",4,Classical Machine Learning
103520,104,TRUE,A most-frequent-class baseline provides a minimum performance bar for classifiers.,baseline using most frequent class prediction in classification,Passage explicitly states always predicting the most frequent class gives the minimum bar to beat.,"machine-learning,classification,evaluation",4,Classical Machine Learning
103521,21,mostly-true,Open-source video diffusion models are limited in availability and maturity.,"emerging open-source video diffusion models, dataset and compute constraints","Matches passage: limited availability due to compute intensity, scarce large video datasets, and spatiotemporal modeling challenges.","generative-ai,diffusion,gans",7,Generative AI
103522,21,mostly-true,Open-source video diffusion models are still largely research-focused and limited in availability.,"emerging open-source video generation, video diffusion models","Passage cites computational cost, scarce high-quality video datasets, and temporal modeling challenges limiting open-source video diffusion availability.","generative-ai,diffusion,gans",7,Generative AI
103523,21,half-true,Open-source video diffusion models are widely available and production-ready for most use cases.,Emerging open-source models for video generation; video diffusion,"Contradicts passage: video diffusion models are described as limited, research-only, and computationally intensive.","generative-ai,diffusion,gans",7,Generative AI
103524,40,TRUE,NumPy's element-wise division compares heroes' traits to challenge requirements producing ratio results.,"element-wise division with NumPy arrays (heroes, objects matrices)",Example shows heroes / objects yields per-trait ratios; values >1 mean exceeding requirements.,"ai,tool-chain,notebooks",2,AI Survival Kit
103525,40,TRUE,Element-wise division in NumPy compares each hero's traits to challenge requirements producing per-element ratios.,NumPy element-wise division of hero and object matrices,"Passage explains using heroes / objects yields ratios per trait, where >1 exceeds requirements and <1 falls short.","ai,tool-chain,notebooks",2,AI Survival Kit
103526,40,mostly-true,NumPy element-wise division lets users compare multiple heroes' traits to challenge requirements in one operation.,tool: NumPy element-wise division in matrix comparison,Explains element-wise division replacing loops and yielding ratios; minor simplification about broadcasting or shape checks omitted.,"ai,tool-chain,notebooks",2,AI Survival Kit
103527,122,TRUE,Imputing missing numeric values with the median preserves dataset usability but can introduce bias.,median imputation for numeric missing values,Passage directly states median keeps rows usable yet can reduce variation and introduce bias when missingness isn't random.,"machine-learning,classification,evaluation",4,Classical Machine Learning
103528,122,barely-true,Median imputation never affects model bias when missingness is nonrandom.,median imputation for dataset missing numeric values,"Overreaches: passage warns median can introduce bias with nonrandom missingness, so claim is largely unsupported.","machine-learning,classification,evaluation",4,Classical Machine Learning
103529,122,half-true,Median imputation preserves all rows but can mask group differences when missingness is nonrandom.,median imputation for missing numeric values in datasets,Correct about keeping rows usable but omits that it reduces variation and biases estimates under nonrandom missingness.,"machine-learning,classification,evaluation",4,Classical Machine Learning
103530,3,mostly-true,"The Deep Three frameworks are PyTorch, TensorFlow, and Keras for building deep learning models.","Deep Learning frameworks mention: PyTorch, TensorFlow, Keras","Directly listed as the core frameworks for building deep learning models, no major caveat omitted.","deep-learning,frameworks,tensors",5,Deep Learning
103531,3,mostly-true,"PyTorch, TensorFlow, and Keras are the three primary deep learning frameworks commonly discussed.","Deep Learning Frameworks; mention of PyTorch, TensorFlow, Keras","Passage lists the three frameworks as the ""Deep Three,"" broadly supporting the claim without caveats.","deep-learning,frameworks,tensors",5,Deep Learning
103532,3,TRUE,"PyTorch, TensorFlow, and Keras are commonly cited as the main deep learning frameworks.","Deep Learning Frameworks; deep-learning, frameworks, Keras","Directly supported by passage stating the 'Deep Three' are PyTorch, TensorFlow, and Keras as main frameworks.","deep-learning,frameworks,tensors",5,Deep Learning
103533,37,barely-true,Hugging Face single-handedly provides every essential tool for full-stack AI development.,"open-source tools and reference architecture, Transformers and Model Cards",Passage shows Hugging Face is prominent but overstates ubiquity and exclusivity of tools.,"open-source,community,contribution",13,Commit to Contribute
103534,37,mostly-true,"Hugging Face tools are commonly used when building, hosting, and sharing AI systems.","tooling ecosystem reference architecture (Transformers, Datasets, Spaces, Model Cards)","Passage lists Hugging Face offerings across model training, hosting, evaluation, and sharing, implying common usage.","open-source,community,contribution",13,Commit to Contribute
103535,37,mostly-true,Hugging Face tools are commonly used across the open-source AI development stack.,"reference architecture showing Transformers, Datasets, Spaces, Model Cards","Passage shows Hugging Face tools repeatedly appear in building, hosting, evaluating, and sharing AI systems, a broadly supported claim with minor generalization.","open-source,community,contribution",13,Commit to Contribute
103536,127,TRUE,Differential privacy and federated learning enable models to learn patterns without exposing personal data.,"privacy techniques: differential privacy, federated learning, GDPR, CCPA",Passage explicitly states those approaches help models learn patterns while protecting personal details and mentions GDPR and CCPA compliance.,"ai,tool-chain,notebooks",2,AI Survival Kit
103537,127,half-true,Differential privacy and federated learning always prevent any personal data exposure in models.,"privacy techniques: differential privacy, federated learning","Mixes correct techniques with an incorrect absolute claim; passage describes them as helpful, not foolproof.","ai,tool-chain,notebooks",2,AI Survival Kit
103538,127,mostly-true,Differential privacy and federated learning can reduce exposure of personal details during model training.,"privacy techniques (differential privacy, federated learning) for models","Accurately reflects passage that these approaches help protect data, omitting limitations and practical challenges.","ai,tool-chain,notebooks",2,AI Survival Kit
103539,176,half-true,Classical ML methods remain efficient and clear for many structured data prediction tasks.,"structured data problems, classical ML techniques",Accurate about speed and clarity but overstated universality; ignores edge cases and emerging interaction-based methods.,"machine-learning,classification,evaluation",4,Classical Machine Learning
103540,176,TRUE,Classical machine learning excels at solving structured data problems with speed and efficiency.,"structured data problems, classical ML methods","Passage explicitly states enduring value for structured data, speed, efficiency, and clarity.","machine-learning,classification,evaluation",4,Classical Machine Learning
103541,176,half-true,Classical ML methods are fast and efficient for many structured data problems but need more interaction to handle edges.,"classical ML, structured data, interaction with environment","Mixes correct praise for speed and clarity with a vague claim about needing interaction at the edges, combining true and overstated specifics.","machine-learning,classification,evaluation",4,Classical Machine Learning
103542,97,barely-true,Deep learning frameworks always require identical preprocessing across all models and tasks.,input format expectations in frameworks,Contradicts passage guidance that preprocessing depends on task and model; frameworks document differing expected formats.,"deep-learning,frameworks,tensors",5,Deep Learning
103543,97,TRUE,Most deep-learning frameworks specify expected input formats for model preprocessing.,frameworks expected input format guidance,Directly supported by passage stating most frameworks specify expected input format and save debugging time.,"deep-learning,frameworks,tensors",5,Deep Learning
103544,97,TRUE,Most frameworks specify the expected input format for models.,frameworks' expected input format in preprocessing and documentation,Directly supported: passage states most frameworks specify expected input format and recommends following documentation.,"deep-learning,frameworks,tensors",5,Deep Learning
103545,45,half-true,The described model combines an LSTM layer with a dense output to predict stock prices but omits architecture depth.,"Keras Sequential LSTM model for stock prediction, inverse normalization",Correct about LSTM plus single dense output and inverse normalization; misstates omission about architecture depth and training specifics.,"neural-networks,cnn,transformers",6,Neuron Building Blocks
103546,45,TRUE,The model uses an LSTM-based Keras Sequential network trained to forecast stock prices.,predictive engine combining LSTM and Keras Sequential,Directly supported: passage states a Keras Sequential model with an LSTM layer trained to predict stock prices over historical sequences.,"neural-networks,cnn,transformers",6,Neuron Building Blocks
103547,45,half-true,The LSTM-based Keras Sequential model reliably predicts exact future stock prices after ten training epochs.,stock predictor application using LSTM and Keras Sequential model,"Combines true elements (LSTM, Keras, 10 epochs, rescaling) with overclaim that it reliably predicts exact future prices, which passage does not support.","neural-networks,cnn,transformers",6,Neuron Building Blocks
103548,2,half-true,Classical ML models always outperform deep networks on small datasets due to simpler statistical assumptions.,"classical machine learning, compact models, dataset size",Mixes correct idea that classical models suit small datasets with incorrect absolute claim of always outperforming deep networks.,"machine-learning,classification,evaluation",4,Classical Machine Learning
103549,2,FALSE,"Classical machine learning relies primarily on very large, deep neural network architectures.","classical machine learning, models and algorithms","Contradicts passage: classical methods use compact, statistically grounded models, not large deep networks.","machine-learning,classification,evaluation",4,Classical Machine Learning
103550,2,barely-true,Classical machine learning models are obsolete and never used in practical AI today.,"classical machine learning, statistical principles, compact models","Passage says classical methods still form the backbone of practical AI, so claim is largely unsupported.","machine-learning,classification,evaluation",4,Classical Machine Learning
103551,159,half-true,Classical methods always rely solely on small statistical models rather than deep architectures.,"classical machine learning, statistical foundations versus deep nets",Mixes correct idea (statistical foundations) with incorrect absolute claim about model size and exclusivity.,"machine-learning,classification,evaluation",4,Classical Machine Learning
103552,159,mostly-true,Classical methods prioritize statistical foundations over large deep-network architectures.,"classical machine learning vs deep nets, supervised and unsupervised techniques",Accurately reflects passage emphasis on statistical foundations and contrast with massive deep nets; minor caveat about extensions beyond classics omitted.,"machine-learning,classification,evaluation",4,Classical Machine Learning
103553,159,FALSE,Classical methods rely on statistical foundations rather than massive deep-net architectures.,"classical machine learning methods, statistical foundations, deep nets",Contradicts passage which states classical methods rest on statistical foundations and contrast with massive deep nets.,"machine-learning,classification,evaluation",4,Classical Machine Learning
103554,174,barely-true,Self-supervised learning never requires any labeled data for competitive downstream performance.,self-supervised learning pretraining on unlabeled datasets,Overstates claim: passage says SSL reduces labeled data needs but still fine-tunes on smaller labeled tasks.,"machine-learning,classification,evaluation",4,Classical Machine Learning
103555,174,barely-true,Self-supervised learning never needs any labeled data to achieve strong task performance.,pretraining with unlabeled data (SSL),Overstates claim: passage says SSL pretrains on unlabeled data but still fine-tunes on smaller labeled tasks for strong performance.,"machine-learning,classification,evaluation",4,Classical Machine Learning
103556,174,half-true,Self-supervised learning can pretrain useful representations without any labeled data.,pretraining on unlabeled datasets for representation learning,"Accurately notes SSL learns from unlabeled data, but overstates universality and ignores cases needing labels.","machine-learning,classification,evaluation",4,Classical Machine Learning
103557,137,pants-fire,Deepfake voice models cannot mimic any real person's voice under any circumstances.,voice-cloning model capability in media-forensics,"Contradicts known voice-cloning capabilities (e.g., SpeechT5 and similar models) and real-world deepfake examples.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
103558,137,barely-true,Voice-cloning deepfakes can be effectively detected using current unified pretraining models like SpeechT5.,speech model detection using SpeechT5 pretraining,Passage only cites SpeechT5 paper; no evidence presented that such models effectively detect voice-cloning deepfakes.,"media-forensics,voice-cloning,deepfake",9,Deepfake Defense
103559,137,half-true,Some deepfake voice-cloning tools can convincingly mimic public figures with limited audio samples.,"voice-cloning models and datasets (e.g., SpeechT5) in media-forensics","Mixes accurate capability of models like SpeechT5 with overstated ease and required data, creating a partial truth.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
103560,114,TRUE,The program detects scene changes using SceneDetect's ContentDetector with a sensitivity threshold.,"scene detection using ContentDetector (threshold, minimum 4s filter)","Code initializes SceneManager with ContentDetector(threshold=8.0), detects scenes, and filters short (<4s) segments.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
103561,114,FALSE,The program treats clips shorter than four seconds as the most important segments for detection.,scene detection code using ContentDetector threshold and minimum scene length,"Contradicts code: clips under four seconds are filtered out, not treated as important.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
103562,114,FALSE,The scene detection program treats clips shorter than four seconds as important for final analysis.,scene detection code using ContentDetector threshold and minimum length filter,Passage states clips under four seconds are filtered out; claim directly contradicts that detail.,"media-forensics,voice-cloning,deepfake",9,Deepfake Defense
103563,77,half-true,An agent in CrewAI autonomously delegates tasks and collaborates with other agents using tools.,"Agent abstraction in CrewAI describing roles, tools, delegation","Accurately notes delegation, collaboration, and tool use but overstates full autonomy and decision scope.","agentic-ai,planning,tools",12,Agentic AI
103564,77,half-true,An agent in CrewAI can autonomously delegate tasks and remember past interactions while using tools.,"Agent abstraction in CrewAI describing roles, tools, and delegation","Correct about delegation, tool use, and memory, but overstates autonomy level and scope of decision-making.","agentic-ai,planning,tools",12,Agentic AI
103565,77,barely-true,Agents in CrewAI autonomously design new tools and datasets without human oversight.,"agent description in CrewAI, tools and tasks","Overreaches: passage says agents use and delegate tools, not that they autonomously create tools or datasets.","agentic-ai,planning,tools",12,Agentic AI
103566,109,barely-true,LinearSVC always outperforms Logistic Regression on text classification tasks.,model selection comparison using LinearSVC and Logistic Regression,Passage only notes LinearSVC is efficient for text; no evidence it consistently outperforms Logistic Regression.,"machine-learning,classification,evaluation",4,Classical Machine Learning
103567,109,half-true,LinearSVC always outperforms Logistic Regression on high-dimensional text classification tasks.,model selection comparing LinearSVC and Logistic Regression in Colab,"Comparison mixes correct strengths (SVM efficiency in high dimensions) with overbroad absolute claim; passage only notes efficiency and reliability, not consistent superiority.","machine-learning,classification,evaluation",4,Classical Machine Learning
103568,109,mostly-true,LinearSVC and Logistic Regression perform similarly on high-dimensional text classification tasks.,model selection in Colab comparing LinearSVC and Logistic Regression,Comparison tool showed both as strong classifiers for text; minor differences and tuning caveats omitted.,"machine-learning,classification,evaluation",4,Classical Machine Learning
103569,87,FALSE,Open-source contributions are discouraged and should be avoided by community members.,open-source contribution guidance in Commit to Contribute,Contradicts emphasis on contributing; passage promotes open-source tools and community engagement.,"open-source,community,contribution",13,Commit to Contribute
103570,87,half-true,Community contributors often condense many features into single metrics using PCA in open-source projects.,PCA Power Score feature engineering in open-source dataset,Mixes correct use of PCA for feature reduction with incorrect generalization that community contributors routinely apply it that way.,"open-source,community,contribution",13,Commit to Contribute
103571,87,FALSE,Open-source contributors are required to sign a legal contributor agreement before committing code.,Contribution policies for open-source projects,Contradicts passage: contribution guidance and legal agreements aren’t mentioned; no CLA requirement stated.,"open-source,community,contribution",13,Commit to Contribute
103572,73,half-true,CrewAI ensures multi-agent teams always achieve their shared goals without human oversight.,CrewAI framework built on LangChain for role-based agent teams,Overstates reliability: passage says CrewAI coordinates agents but doesn’t claim guaranteed success or no human oversight.,"agentic-ai,planning,tools",12,Agentic AI
103573,73,barely-true,CrewAI coordinates role-based AI agents built on LangChain to automate complex workflows and decisions.,open-source framework CrewAI built on LangChain,"Accurately mentions role-based agents and LangChain, but overstates broad automation outcomes and universality.","agentic-ai,planning,tools",12,Agentic AI
103574,73,barely-true,CrewAI guarantees flawless coordination among AI agents in all complex workflows.,CrewAI framework built on LangChain for role-based multi-agent orchestration,Passage describes role-based collaboration and varied use cases but never claims guaranteed flawless coordination.,"agentic-ai,planning,tools",12,Agentic AI
103575,106,barely-true,Running locally always yields faster inference and stronger security than any cloud deployment.,"local deployment, Hugging Face Hub model access","Overreaches: passage notes local often faster and more controlled, not always true across all cloud GPUs or setups.","mlops,scaling,deployment",10,AI At Scale
103576,106,FALSE,Deploying models locally always yields faster inference than cloud GPU services.,deployment on local machine using GPU (Hugging Face model),Contradicts passage: local often faster with GPU but not guaranteed; cloud GPUs can be faster or more scalable.,"mlops,scaling,deployment",10,AI At Scale
103577,106,half-true,Running a model locally always yields faster inference and better security than cloud deployment.,"local deployment, Hugging Face Hub fine-tuned model","Overstates benefits: local control can improve latency and security, but 'always' ignores GPU availability, scaling, and external-dependency tradeoffs.","mlops,scaling,deployment",10,AI At Scale
103578,29,TRUE,AI certifications help users identify systems that meet established ethical standards.,voluntary or regulated AI certifications and open-source datasets,Passage states certifications identify systems/datasets meeting ethical standards and aid user choice.,"ethics,governance,privacy",11,AI Ethics and Governance
103579,29,half-true,AI certifications universally ensure systems meet ethical standards across industries.,AI certifications and open-source datasets for ethics verification,Overstates effectiveness: passage says certifications help but cannot yet enforce industry-wide fairness.,"ethics,governance,privacy",11,AI Ethics and Governance
103580,29,mostly-true,AI certifications generally promote trustworthy AI adoption by guiding users and incentivizing ethical practices.,"AI certifications, datasets, and open-source tools","Supported by passage: certifications guide users, encourage companies, and use open-source transparency; minor feasibility caveat omitted.","ethics,governance,privacy",11,AI Ethics and Governance
103581,40,half-true,An LSTM with a single layer and 50 units reliably predicts future stock prices from closing prices.,"model implementation using LSTM, yfinance, MinMaxScaler",Mixes correct implementation details with overconfident claim; passage shows a demo not proven reliable.,"neural-networks,cnn,transformers",6,Neuron Building Blocks
103582,40,TRUE,The code uses an LSTM-based Keras model to predict future closing prices from historical data.,"LSTM model, yfinance time series preprocessing","Code constructs Sequential Keras model with LSTM, uses yfinance data and MinMaxScaler to predict prices.","neural-networks,cnn,transformers",6,Neuron Building Blocks
103583,40,barely-true,An LSTM model in the code reliably forecasts future stock and cryptocurrency prices.,"yfinance time series, LSTM model, MinMaxScaler",Claim overreaches: code fits a simple LSTM for 10 epochs without evaluation or robustness checks.,"neural-networks,cnn,transformers",6,Neuron Building Blocks
103584,169,half-true,Encrypting healthcare datasets and giving data scientists read-only access always prevents data breaches.,"dataset security, encryption, access control, role-based access","Mixes correct practices (encryption, RBAC) with an overclaim that they alone always prevent breaches, omitting other risks.","data-prep,feature-engineering,rag",3,Prepping Data for AI
103585,169,TRUE,Encrypting sensitive healthcare datasets before cloud storage prevents unauthorized reading without the key.,healthcare dataset encryption and access control,Passage explicitly recommends encrypting healthcare datasets and limiting access so data is unreadable without keys.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
103586,169,FALSE,Data scientists should have full write access to all sensitive healthcare tables for efficient analysis.,access control and role-based access control for datasets,"Contradicts guidance: passage recommends read-only access and least privilege, not full write access.","data-prep,feature-engineering,rag",3,Prepping Data for AI
103587,12,barely-true,Scikit-learn is nearly unbeatable for classical supervised methods on structured data.,Scikit-learn library for classical machine-learning algorithms,Overstates superiority; passage praises accessibility and speed but notes limits for deep learning.,"machine-learning,classification,evaluation",4,Classical Machine Learning
103588,12,mostly-true,"Scikit-learn offers fast, accessible tools for training and evaluating classical models on structured data.",Scikit-learn library for classical machine-learning models and accuracy evaluation,"Passage praises Scikit-learn's speed and accessibility for classical, structured-data tasks while noting it lacks deep learning focus.","machine-learning,classification,evaluation",4,Classical Machine Learning
103589,12,barely-true,Scikit-learn excels at training and comparing classical models on structured datasets with minimal code.,Scikit-learn library for classical machine-learning and evaluation,"Overstates universality and ease; passage praises speed and accessibility but limits to classical, not deep learning tasks.","machine-learning,classification,evaluation",4,Classical Machine Learning
103590,71,barely-true,Gini coefficients always fix class imbalance in datasets used for retrieval-augmented generation.,"Superheroes Info Dataset class counts, Gini coefficient calculation",Overreaches: Gini measures inequality but does not correct imbalance or improve RAG retrieval.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
103591,71,half-true,The passage claims Gini coefficient reveals imbalance in Alignment category counts for the Superheroes dataset.,quality imbalance analysis using Gini on dataset category counts,Correctly links Gini to imbalance but omits specifics about computation steps and code tools.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
103592,71,half-true,The passage claims the Gini coefficient measures label imbalance by sorting category counts and comparing cumulative curves.,"Superheroes Info Dataset alignment categories, Gini coefficient calculation",Accurately describes calculation steps but overstates scope by implying formal statistical validation or tool-specific limitations.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
103593,94,half-true,Weaviate natively supports semantic vector search for both text and image embeddings.,Weaviate vector search engine (text and image embeddings),Accurately notes native semantic search but omits graph-aware features and broader platform capabilities.,"open-source,community,contribution",13,Commit to Contribute
103594,94,barely-true,Open-source tools in the passage reliably replace proprietary services for all production workloads.,"tools list including Weaviate, Whisper, YOLOv5",Overreaches beyond passage; examples show capabilities but not proven production parity or universal reliability.,"open-source,community,contribution",13,Commit to Contribute
103595,94,half-true,Whisper provides accurate multilingual transcription but requires significant post-editing for perfect transcripts.,OpenAI Whisper speech-to-text model used to transcribe podcast audio,"Model is multilingual and used for transcription, yet practical outputs often need manual correction for errors.","open-source,community,contribution",13,Commit to Contribute
103596,100,pants-fire,The model guarantees perfect battle predictions for every superhero using OPR and SDR scores.,feature engineering of OPR and SDR metrics from powers dataset,"Claims perfect predictions contradicts presented heuristic scores; OPR/SDR are aggregated metrics, not guaranteed outcomes.","data-prep,feature-engineering,rag",3,Prepping Data for AI
103597,100,half-true,The feature pipeline correctly labels heroes as offensive or defensive using fixed power lists and weights.,"feature engineering for hero power metrics (OFFENSIVE_POWERS, DEFENSIVE_POWERS, DUAL_WEIGHTS)",Mixes correct pipeline steps with incorrect certainty about labeling accuracy and fixed-weight validity.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
103598,100,mostly-true,Feature engineering computes Offensive and Strategic Defense Ratings from hero power lists.,feature engineering of OPR and SDR from powers dataset,"Code shows computation of OPR and SDR from offensive/defensive power lists, helper functions abstracted.","data-prep,feature-engineering,rag",3,Prepping Data for AI
103599,22,FALSE,Open-source models are always free from racial bias in criminal risk tools.,COMPAS example; open-source vs proprietary model transparency,Contradicts passage: openness aids audits but does not guarantee absence of racial bias.,"ethics,governance,privacy",11,AI Ethics and Governance
103600,22,half-true,Open-source models always eliminate racial bias found in proprietary systems like COMPAS.,transparency and COMPAS recidivism risk model,Accurately links transparency to auditability but incorrectly claims open-source always removes bias.,"ethics,governance,privacy",11,AI Ethics and Governance
103601,22,barely-true,Compas-style proprietary models are usually unbiased when used in court risk assessments.,"proprietary COMPAS algorithm, recidivism risk prediction",Contradicts passage example showing COMPAS exhibited racial bias and lacked transparency for audits.,"ethics,governance,privacy",11,AI Ethics and Governance
103602,43,half-true,The example trains a PyTorch neural network on MNIST using a single linear layer and 64 batch size.,PyTorch DataLoader and nn.Module with MNIST dataset,"Partly correct: code shows DataLoader(batch_size=64) and nn.Module linear input, but training and single linear layer training not fully specified.","deep-learning,frameworks,tensors",5,Deep Learning
103603,43,barely-true,The code trains a deep convolutional neural network on MNIST using PyTorch tensors.,"PyTorch DataLoader, MNIST dataset, tensors","Passage shows a simple linear nn.Module, not a convolutional network; overstates model complexity.","deep-learning,frameworks,tensors",5,Deep Learning
103604,43,half-true,The code trains a simple PyTorch neural network on MNIST using a single linear layer.,PyTorch DataLoader with datasets.MNIST and nn.Module Net,"Partially correct: uses MNIST and one linear layer, but training loop and optimizer details are omitted.","deep-learning,frameworks,tensors",5,Deep Learning
103605,77,mostly-true,Imbalanced labels in a dataset can cause models to reinforce gender stereotypes.,dataset label imbalance affecting character portrayal,"Supported by example showing female characters labeled mostly 'good', risking stereotype reinforcement in generated profiles.","data-prep,feature-engineering,rag",3,Prepping Data for AI
103606,77,barely-true,The dataset's gender imbalance will always cause models to reinforce stereotypes in generated profiles.,dataset gender portrayal and moral alignment,Overreaches: passage warns imbalance can skew outputs but doesn't claim it will always cause stereotype reinforcement.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
103607,77,TRUE,Dataset label imbalances can cause models to reinforce character stereotypes.,dataset bias in character portrayal and label distribution,Passage shows skewed gender-label distributions could skew outputs and reinforce stereotypes.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
103608,4,pants-fire,Feature engineering can magically eliminate all dataset bias and guarantee perfect model outputs.,feature engineering and dataset bias in data-prep,"Claim asserts impossible certainty about bias elimination, contradicting passage discussion of spotting bias and trade-offs.","data-prep,feature-engineering,rag",3,Prepping Data for AI
103609,4,half-true,RAG systems rely solely on vector databases to provide all necessary contextual information to models.,retrieval-augmented generation with vector databases,Mixes correct concept (RAG uses vector databases) with incorrect absolute claim that vectors provide all necessary context; omits other data sources and preprocessing.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
103610,4,half-true,RAG always eliminates the need for extensive feature engineering in models.,retrieval-augmented generation with vector databases,Mixes correct RAG benefits with incorrect absolute claim; passage still emphasizes feature engineering needs.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
103611,135,half-true,Adam combines momentum and per-parameter adaptive learning rates to speed neural network training.,optimizer behavior for handwritten digit recognition,"Correctly notes momentum plus per-parameter adaptivity, but overstates universal speed benefits without caveats.","deep-learning,frameworks,tensors",5,Deep Learning
103612,135,half-true,Adam uses momentum and per-parameter adaptive learning rates to train neural networks efficiently.,optimizer description for handwritten digit recognition,"Accurately notes momentum plus adaptive per-parameter rates, but overstates universal efficiency claims.","deep-learning,frameworks,tensors",5,Deep Learning
103613,135,half-true,Adam uses momentum and adaptive per-parameter learning rates to speed neural network training.,"optimizer behavior for handwritten-digit models (Adam, momentum, adaptive rates)","Accurately notes momentum and per-parameter adaptation, but oversimplifies specifics of Adam's moment estimates and bias corrections.","deep-learning,frameworks,tensors",5,Deep Learning
103614,1,FALSE,Convolutional neural networks are incapable of processing satellite imagery for object identification.,CNNs applied to satellite image object detection,Contradicts passage scenario where CNNs are used to identify objects in satellite photos; claims inability.,"neural-networks,cnn,transformers",6,Neuron Building Blocks
103615,1,TRUE,Convolutional neural networks (CNNs) are used to identify objects in images by processing pixel data.,CNNs image recognition in mini-missions and visual examples,Passage describes CNNs applied to satellite photo object identification using pixel inputs and visual explanations.,"neural-networks,cnn,transformers",6,Neuron Building Blocks
103616,1,pants-fire,Convolutional neural networks can instantly decode any satellite image's hidden content without training.,"CNNs, satellite photo identification task","Asserts instant, training-free decoding which contradicts CNNs' need for trained weights and data for image recognition.","neural-networks,cnn,transformers",6,Neuron Building Blocks
103617,82,TRUE,Gini coefficients quantify dataset imbalances across categorical and binned numeric features.,"superhero dataset Gini analysis on Alignment, Gender, Species, Height_bins, Weight_bins","Directly supported: code computes Gini for categorical fields and binned height/weight, then interprets scores.","data-prep,feature-engineering,rag",3,Prepping Data for AI
103618,82,TRUE,The dataset's Alignment shows a moderate imbalance with 'good' predominating.,superhero dataset Gini coefficient for Alignment,Gini value 0.43 indicates moderate imbalance and text explicitly notes 'good' is heavily represented.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
103619,82,FALSE,"The dataset shows perfect balance across Gender, Alignment, Species, height, and Weight.",Gini coefficient imbalance analysis on superhero dataset,"Contradicts reported Gini values: Alignment 0.43 and Gender 0.20 indicate imbalance, not perfect balance.","data-prep,feature-engineering,rag",3,Prepping Data for AI
103620,21,barely-true,Data labeling alone guarantees production-ready supervised models for real-world tasks.,data labeling within a sandbox dataset for supervised learning,Overreaches beyond passage: labels are foundational for learning but not sufficient alone for production readiness.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
103621,21,mostly-true,The dataset serves as a structured sandbox for practicing data curation and labeling techniques.,dataset sandbox; data labeling; supervised learning,"Broadly supported by passage: emphasizes practicing curation, labeling for supervised learning; omits limitations.","data-prep,feature-engineering,rag",3,Prepping Data for AI
103622,21,half-true,Data labeling always guarantees models will generalize well to real-world datasets.,data labeling for supervised learning and datasets,"Overstates outcome: labeling provides training signal, but generalization depends on quality, bias, and dataset representativeness.","data-prep,feature-engineering,rag",3,Prepping Data for AI
103623,45,barely-true,"Mistral guarantees lightweight, efficient performance across all Hugging Face models in production.",using Mistral model with Hugging Face models and LangChain workflows,"Overreaches: Mistral is described as lightweight and approachable, not guaranteed efficient for all HF models or production deployments.","data-prep,feature-engineering,rag",3,Prepping Data for AI
103624,45,TRUE,Hugging Face provides a large collection of models for use in workflows.,"tooling and models (Hugging Face, LangChain, HF_TOKEN)",Passage explicitly states Hugging Face offers an extensive collection of models for workflows.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
103625,45,FALSE,"Mistral models are large, resource-intensive transformer models unsuitable for experimentation.",model characteristics in Hugging Face and LangChain integration,"Contradicts passage stating Mistral is lightweight and efficient, suitable for experimentation.","data-prep,feature-engineering,rag",3,Prepping Data for AI
103626,64,FALSE,TensorFlow SavedModel relies on Python pickle and breaks with small class changes.,model serialization using tf.saved_model and pickle,"Contradicts passage: pickle coupling applies to Python pickling, while SavedModel is a standalone format including architecture and weights.","deep-learning,frameworks,tensors",5,Deep Learning
103627,64,FALSE,"TensorFlow's SavedModel format only stores model weights, not architecture or optimizer state.",TensorFlow SavedModel format,"Contradicts passage: SavedModel includes architecture, weights, and optionally optimizer state; claim omits architecture and optimizer.","deep-learning,frameworks,tensors",5,Deep Learning
103628,64,barely-true,Pickle-based model saving is fragile and often breaks when class definitions change.,pickle module model serialization,"Overstates robustness; passage says pickle tightly couples code and small changes can break reloading, making claim largely unsupported as general best practice.","deep-learning,frameworks,tensors",5,Deep Learning
103629,115,TRUE,Keras uses TensorFlow's automatic differentiation to compute gradients during model.fit().,Keras high-level API using GradientTape and fit(),"Text explicitly states Keras builds the graph, computes gradients, and applies backpropagation via TensorFlow's autodiff.","deep-learning,frameworks,tensors",5,Deep Learning
103630,115,TRUE,Automatic differentiation computes gradients for model parameters during training.,TensorFlow GradientTape and Keras .fit() APIs,Passage shows tf.GradientTape computing gradients and Keras .fit() performing gradient computation and backpropagation.,"deep-learning,frameworks,tensors",5,Deep Learning
103631,115,TRUE,Keras .fit() automatically computes gradients and applies backpropagation using TensorFlow.,Keras .fit() with TensorFlow automatic differentiation,"Passage explains Keras builds graph, computes gradients, and applies backpropagation behind the scenes.","deep-learning,frameworks,tensors",5,Deep Learning
103632,90,half-true,"Defining Tasks with descriptions and expected_output guarantees consistent, valuable agent behavior.","dynamic Task assignment using Task, agent, and expected_output in crewai","Partly true: Task structure improves focus, but it doesn't guarantee consistent outcomes across models or tool use.","agentic-ai,planning,tools",12,Agentic AI
103633,90,half-true,"Dynamic Task objects alone ensure consistent, focused agent outputs across varied interactions.",Task object pattern for agentic planning with tools,"Correct that Task objects guide agents, but overstated guarantee—other factors like tools, agent design, and environment affect consistency.","agentic-ai,planning,tools",12,Agentic AI
103634,90,half-true,"Agent tasks defined with clear descriptions and expected_output always produce consistent, valuable agent behavior.",task definition using expected_output and agent in crewai,"Accurately notes clear descriptions help focus agents, but claiming they always ensure consistency and value is overstated.","agentic-ai,planning,tools",12,Agentic AI
103635,56,barely-true,"Keras fully automates model training including forward pass, loss computation, backpropagation, and optimizer updates.",tensorflow.keras API usage with MNIST dataset and Sequential model,"Overstates automation: Keras handles standard training loops, but users configure model, loss, and optimizer.","deep-learning,frameworks,tensors",5,Deep Learning
103636,56,mostly-true,"Keras automates model training steps like forward pass, loss computation, backpropagation, and weight updates.",TensorFlow Keras example using mnist dataset and Sequential model,"Matches passage claim that Keras handles forward pass, error calculation, backpropagation, and weight updates, though users still configure models and optimizers.","deep-learning,frameworks,tensors",5,Deep Learning
103637,56,half-true,Keras automates the full training loop including backpropagation and weight updates but hides most implementation details.,Keras API and TensorFlow mnist example,"Accurately notes automation of forward/backward passes and updates, but overstates that all implementation details are entirely hidden.","deep-learning,frameworks,tensors",5,Deep Learning
103638,136,FALSE,Seq2seq transformers only use a single shared encoder-decoder layer for both input and output.,"seq2seq transformer architecture, encoder and decoder",Contradicts passage detail that separate encoder and decoder components exist rather than a single shared layer.,"generative-ai,diffusion,gans",7,Generative AI
103639,136,mostly-true,Seq2seq transformers reliably convert input text sequences into accurate output text with encoder–decoder architectures.,sequence-to-sequence transformer encoder and decoder in NLP,"Supported by passage: encoder–decoder design maps input sentences to rich representations, but 'reliably' slightly overstates guaranteed accuracy.","generative-ai,diffusion,gans",7,Generative AI
103640,136,pants-fire,Seq2seq transformers cannot process any text and always fail on translation tasks.,sequence-to-sequence transformer encoder-decoder for translation,Directly contradicts described encoder-decoder ability to convert input sequences for translation tasks.,"generative-ai,diffusion,gans",7,Generative AI
103641,16,half-true,Deep learning networks always require multiple hidden layers to learn complex features effectively.,definition of hidden layers in neural networks,"Correct that deep learning involves multiple hidden layers, but overstates necessity; single hidden layer can learn many features given enough neurons.","deep-learning,frameworks,tensors",5,Deep Learning
103642,16,pants-fire,Deep learning networks never use hidden layers and only rely on output layers.,definition of hidden layers in neural networks,Directly contradicts explanation that deep learning is defined by having more than one hidden layer; impossible claim.,"deep-learning,frameworks,tensors",5,Deep Learning
103643,16,mostly-true,Deep learning refers to neural networks with more than one hidden layer.,definition of hidden layers in neural networks,Passage explicitly defines deep learning as networks having more than one hidden layer; straightforward definition.,"deep-learning,frameworks,tensors",5,Deep Learning
103644,176,TRUE,"ReLU activates neurons only for positive inputs, preventing an all-linear network collapse.",activation function behavior with ReLU in neural networks,"Explained that ReLU outputs positive values or zero, and nonlinearity stops stacked linear layers collapsing into one linear function.","deep-learning,frameworks,tensors",5,Deep Learning
103645,176,TRUE,"ReLU outputs its input when positive and zero when negative, preventing networks from collapsing into linear functions.",activation function ReLU in deep-learning networks,Explanation matches passage: ReLU's on/off behavior blocks stacked linear layers collapsing into a single linear equation.,"deep-learning,frameworks,tensors",5,Deep Learning
103646,176,pants-fire,ReLU guarantees networks will never form linear decision boundaries under any training.,activation function ReLU preventing linear collapse in neural networks,Contradicts claim that only linear layers cause collapse; ReLU alone doesn't guarantee nonlinearity.,"deep-learning,frameworks,tensors",5,Deep Learning
103647,49,half-true,Keras is the official high-level API for TensorFlow and provides utilities usable in low-level training loops.,tf.keras API and data/model utilities in TensorFlow,"Accurate overall, but phrasing mixes official status with implication all utilities fully integrate into every low-level loop.","deep-learning,frameworks,tensors",5,Deep Learning
103648,49,TRUE,Tf.keras is the official high-level API for TensorFlow and provides Keras utilities.,tf.keras high-level API and Keras utilities,Passage explicitly states tf.keras is TensorFlow's official high-level API and grants Keras utilities.,"deep-learning,frameworks,tensors",5,Deep Learning
103649,49,mostly-true,Tf.keras is TensorFlow's official high-level API and provides utilities usable with low-level training loops.,tf.keras high-level API for TensorFlow,Passage states tf.keras is TensorFlow's official high-level API and offers utilities usable alongside low-level loops; minor nuance about scope of utilities omitted.,"deep-learning,frameworks,tensors",5,Deep Learning
103650,164,half-true,Adding Laplace noise to age data always preserves survey aggregate demographics accurately.,differential privacy; Laplace noise on age dataset,"Correct mechanism mentioned, but overstates accuracy guarantee and ignores utility-privacy tradeoffs.","data-prep,feature-engineering,rag",3,Prepping Data for AI
103651,164,TRUE,Differential privacy with Laplace noise preserves aggregate demographic patterns while protecting individual identities.,"differential privacy, Laplace noise, survey age data",Directly supported: Laplace noise protects identities and preserves overall demographics; Google tools facilitate implementation.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
103652,164,barely-true,Differential privacy always preserves statistical trends without affecting any downstream model performance.,"differential privacy, Laplace noise on survey age dataset",Overreaches: differential privacy can preserve aggregated patterns but may still degrade downstream model accuracy depending on noise level.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
103653,61,FALSE,Discriminator loss reliably indicates generated image realism in GAN training.,GAN discriminator loss and visual inspection,Contradicts passage: discriminator loss can be misleading and vary independently from image realism.,"generative-ai,diffusion,gans",7,Generative AI
103654,61,mostly-true,GAN visual quality is best judged by human inspection despite discriminator loss signals.,GAN evaluation using discriminator loss and human visual inspection,Passage supports human assessment as most reliable; discriminator loss can be misleading and varies independently.,"generative-ai,diffusion,gans",7,Generative AI
103655,61,FALSE,GAN discriminator loss reliably measures how realistic generated images are.,GAN discriminator loss metric,Contradicts passage: discriminator loss can be misleading and vary independently of sample realism.,"generative-ai,diffusion,gans",7,Generative AI
103656,78,FALSE,Autoencoders are primarily used to synthesize novel data samples from learned distributions.,"autoencoders, encoding high-dimensional data, reconstruction","Contradicts passage: autoencoders compress and reconstruct, not mainly synthesize novel samples.","neural-networks,cnn,transformers",6,Neuron Building Blocks
103657,78,mostly-true,Autoencoders compress high-dimensional data and reconstruct it with minimal loss.,autoencoders and CNNs/Transformers in neural network building blocks,"Passage describes autoencoders as networks that shrink data and recreate it closely, omitting minor reconstruction limits.","neural-networks,cnn,transformers",6,Neuron Building Blocks
103658,78,barely-true,Autoencoders always perfectly reconstruct original high-dimensional inputs after compression.,Autoencoders compress and reconstruct high-dimensional data,"Overreaches: passage says autoencoders recreate data closely, not perfectly; claims perfect reconstruction unsupported.","neural-networks,cnn,transformers",6,Neuron Building Blocks
103659,26,half-true,The fingerprinting method uses spectral flatness to reliably detect synthetic voices in audio clips.,audio fingerprint features including Spectral Flatness and MFCC,Mixes correct feature usage with overclaim: passage says flatness is higher for synthetic voices but not proven reliably detecting them.,"media-forensics,voice-cloning,deepfake",9,Deepfake Defense
103660,26,half-true,The fingerprinting system uses spectral features like MFCCs and spectral flatness to detect synthetic voice traits.,"audio fingerprinting features (MFCC, spectral flatness, HNR)",Mixes correct feature use with an overreach: features hint at synthetic traits but don't guarantee detection accuracy.,"media-forensics,voice-cloning,deepfake",9,Deepfake Defense
103661,26,half-true,The fingerprint uses spectral flatness and MFCCs to detect synthetic elements in Jerry’s voice.,"audio fingerprinting features (MFCC, spectral flatness, HNR)",Mixes correct features with overclaim that they reliably detect synthesis; detection requires more validation.,"media-forensics,voice-cloning,deepfake",9,Deepfake Defense
103662,88,half-true,A VAE maps inputs to Gaussian distributions enabling sampling for novel but similar image outputs.,variational autoencoder (VAE) latent mean and variance,Accurately describes encoder sampling and novel outputs but omits reconstruction trade-offs and blur artifacts.,"generative-ai,diffusion,gans",7,Generative AI
103663,88,barely-true,A VAE always generates highly realistic novel images indistinguishable from real data.,variational autoencoder latent sampling and decoder reconstruction,Overstates VAE output quality; VAEs sample Gaussian latents and produce variations but often blur and lack photorealism.,"generative-ai,diffusion,gans",7,Generative AI
103664,88,half-true,A VAE maps inputs to a Gaussian distribution but always reconstructs exact original images.,variational autoencoder latent sampling and reconstruction,"Mixes correct encoding-to-Gaussian detail with incorrect claim that reconstructions are always exact; VAEs produce varied, not identical, outputs.","generative-ai,diffusion,gans",7,Generative AI
103665,38,TRUE,Adding explicit persona and formatting instructions improves prompt reliability and output structure.,prompt design with persona and formatting instructions,"Passage states persona and formatting clauses shape structure, reduce hallucination, and increase consistency.","agentic-ai,planning,tools",12,Agentic AI
103666,38,half-true,Specifying a persona and formatting reduces hallucination but won't eliminate all errors.,prompt engineering with persona and guardrail instructions,Passage supports persona/formatting reducing hallucinations but omits limits and residual failure causes.,"agentic-ai,planning,tools",12,Agentic AI
103667,38,pants-fire,Agentic AI can autonomously modify its own hardware to improve planning abilities.,agentic-ai tool behavior and planning,"Passage discusses prompt guardrails, personas, and constraints, not self-modifying hardware; claim contradicts absence of hardware autonomy evidence.","agentic-ai,planning,tools",12,Agentic AI
103668,77,FALSE,Keras cannot be customized for custom loss functions or training steps.,"Keras customization with tf.keras.Model, tf.GradientTape, custom loss",Contradicts passage showing custom loss functions and overriding train_step with tf.GradientTape.,"deep-learning,frameworks,tensors",5,Deep Learning
103669,77,TRUE,Keras allows deeper customization like custom losses and overriding train_step with tf.GradientTape.,Keras customization using tf.keras.Model and tf.GradientTape,Passage shows defining custom_mse_loss and subclassing tf.keras.Model with train_step using GradientTape.,"deep-learning,frameworks,tensors",5,Deep Learning
103670,77,pants-fire,Keras cannot be extended or customized under any circumstances.,Keras customization with TensorFlow GradientTape and custom loss,"Directly contradicted by code examples showing custom loss, subclassing tf.keras.Model, and manual train_step implementation.","deep-learning,frameworks,tensors",5,Deep Learning
103671,13,barely-true,Agentic AI always makes autonomous decisions equivalent to a skilled game bot in real-world tasks.,"agentic AI, planning and execution layers",Overreaches: passage likens agents to game bots but doesn't claim guaranteed real-world equivalence.,"agentic-ai,planning,tools",12,Agentic AI
103672,13,TRUE,"Agentic AI uses structured conceptual layers to simplify reasoning, planning, and execution.",agentic-ai concept and planning abstraction,"Passage explicitly describes layered abstractions enabling reasoning, planning, and execution in agents.","agentic-ai,planning,tools",12,Agentic AI
103673,13,TRUE,"AI agents use structured conceptual layers to simplify reasoning, planning, and execution.",agentic AI abstractions for reasoning and planning,"Passage states abstractions handle reasoning, planning, execution enabling adaptation and autonomy.","agentic-ai,planning,tools",12,Agentic AI
103674,25,TRUE,Pandas' pd.read_csv can load CSV datasets directly from GitHub into DataFrames.,loading CSV files into a Pandas DataFrame from GitHub,"Notebook demonstrates pd.read_csv reading CSV URLs into DataFrames, enabling immediate dataset use and sanity checks.","data-prep,feature-engineering,rag",3,Prepping Data for AI
103675,25,barely-true,"Pandas alone guarantees clean, model-ready features directly from raw CSVs every time.",loading CSV into a DataFrame with pd.read_csv,"Overstates capabilities: passage shows quick loading and sanity checks, not guaranteed cleaning or feature readiness.","data-prep,feature-engineering,rag",3,Prepping Data for AI
103676,25,half-true,Pandas can load CSVs directly from GitHub and always infers perfect column types automatically.,loading CSV dataset via pd.read_csv into DataFrame,"Correct about loading CSVs from GitHub, incorrect claiming automatic perfect type inference without dtype handling.","data-prep,feature-engineering,rag",3,Prepping Data for AI
103677,75,half-true,The model uses beam search with num_beams=4 and early stopping to produce French translations.,generation setting: beam search (num_beams=4) and early_stopping in translation,"Accurately reports beam search and early stopping, but implies guaranteed higher-quality outputs which is not assured.","neural-networks,cnn,transformers",6,Neuron Building Blocks
103678,75,pants-fire,The model translates English to fluent French using a single-shot zero-parameter lookup table.,translation function using beam search and decoding,"Contradicts described mechanism: passage specifies beam search generation and decoding, not a parameterless lookup table.","neural-networks,cnn,transformers",6,Neuron Building Blocks
103679,75,TRUE,The model translates English input into French using beam search with four beams.,translation function using num_beams=4 and decoding to French,Passage describes using beam search (num_beams=4) to generate outputs decoded into readable French.,"neural-networks,cnn,transformers",6,Neuron Building Blocks
103680,61,barely-true,ResNet and YOLOv5 alone enable full generative multimedia creation workflows.,models like ResNet and YOLOv5 in generative systems,"Overreaches by claiming discriminative models (ResNet, YOLOv5) perform full generative tasks; passage names GANs, VAEs, diffusion, transformers for generation.","ai,open-source,builder",1,Introduction – The Gold Rush Paradox
103681,61,half-true,The passage claims ResNet and YOLOv5 are demonstrated alongside GANs and diffusion models in experiments.,"models like ResNet, YOLOv5, GANs, diffusion models",Mixes correct list of models with implication of comprehensive demonstrations; specifics of experiment depth omitted.,"ai,open-source,builder",1,Introduction – The Gold Rush Paradox
103682,61,half-true,The passage claims ResNet and YOLOv5 are used to demonstrate architecture behaviors in vision experiments.,model experiments using ResNet and YOLOv5,"Accurately notes architectures used, but overstates that passage 'claims' broader demonstration scope of all behaviors.","ai,open-source,builder",1,Introduction – The Gold Rush Paradox
103683,94,barely-true,All deep learning libraries require inputs normalized by standard deviation for training to work properly.,input normalization in PyTorch and TensorFlow,"Overstates requirement: passage says most libraries expect normalization, not an absolute requirement.","deep-learning,frameworks,tensors",5,Deep Learning
103684,94,half-true,Normalizing inputs by dividing by standard deviation always guarantees faster and more stable training for deep learning models.,input normalization using standard deviation in PyTorch or TensorFlow,"Normalization often improves training stability, but 'always guarantees' is incorrect; exceptions and other factors matter.","deep-learning,frameworks,tensors",5,Deep Learning
103685,94,TRUE,Normalizing inputs by standard deviation helps gradients flow more evenly during backpropagation.,"input normalization in deep learning frameworks (PyTorch, TensorFlow)",Passage explicitly states dividing by standard deviation keeps feature scales consistent and improves gradient flow during backpropagation.,"deep-learning,frameworks,tensors",5,Deep Learning
103686,203,half-true,A convolutional neural network trained on labeled product images will always detect all defect types perfectly.,image-based defect detection with CNNs,"Correct that CNNs excel on images, but claiming perfect detection is unrealistic and omits dataset and labeling limits.","deep-learning,frameworks,tensors",5,Deep Learning
103687,203,half-true,The passage claims convolutional neural networks are preferred over linear networks for image defect detection.,network architecture; Convolutional Neural Network (CNN) for images,Combines correct CNN suitability for images with overstated exclusivity over linear models for defect tasks.,"deep-learning,frameworks,tensors",5,Deep Learning
103688,203,half-true,The passage correctly recommends using a CNN for image-based defect detection tasks.,network architecture for image preprocessing and defect detection,"Partly accurate: CNNs are appropriate for images, but statement omits dataset size, augmentation, or evaluation specifics.","deep-learning,frameworks,tensors",5,Deep Learning
103689,125,mostly-true,The passage correctly identifies the Kilauea volcano eruption as producing 300-foot lava fountains.,tool output summarizing a news event about Kilauea eruption,"Supported by tool output describing lava fountains over 300 feet, minor contextual details omitted.","agentic-ai,planning,tools",12,Agentic AI
103690,125,TRUE,Kīlauea's recent eruption produced lava fountains over 300 feet high.,news summary mentioning Kilauea volcano eruption,Directly supported by the passage reporting lava fountains exceeding 300 feet during Kīlauea's eruption.,"agentic-ai,planning,tools",12,Agentic AI
103691,125,half-true,An agentic AI system filtered retrieved summaries and produced a trivia question about Kilauea's eruption.,tool output processing and question generation in an agentic-ai system,Combines correct tool-output filtering and trivia generation with an unfounded claim of full agentic autonomy.,"agentic-ai,planning,tools",12,Agentic AI
103692,62,half-true,Researchers trained models on superhero biographies to classify powers and predict villainy.,dataset of superhero bios used for classification experiments,Accurately reflects training and classification but overstates scope and certainty about villain prediction outcomes.,"open-source,community,contribution",13,Commit to Contribute
103693,13,half-true,Deep learning networks always require massive labeled datasets to learn useful representations.,training data and neural networks,"Accurate that deep nets often need lots of data, but ignores unsupervised, transfer learning, and smaller-data techniques.","deep-learning,frameworks,tensors",5,Deep Learning
103694,13,mostly-true,Deep learning uses multilayer neural networks to learn patterns from large datasets for tasks like image recognition.,neural networks with many layers (deep learning),Accurately reflects passage claiming multilayer networks learn from large data for image recognition; omits caveats about data requirements and model limits.,"deep-learning,frameworks,tensors",5,Deep Learning
103695,13,pants-fire,"Deep learning uses single-layer perceptrons only, never multiple layers.",neural networks with many layers,"Directly contradicts text: passage specifies neural networks with many layers, not single-layer perceptrons.","deep-learning,frameworks,tensors",5,Deep Learning
103696,82,half-true,Francesca Rossi claims AI can be a force for good without qualification.,AI ethics and governance interview quote,Mixes correct positive claim with omission of governance caveats and limitations in evidence.,"ethics,governance,privacy",11,AI Ethics and Governance
103697,82,barely-true,AI is unequivocally a force for good without significant governance needs.,AI ethics and governance; Francesca Rossi quote,Overreaches Rossi's nuanced claim by omitting governance caveats and risks discussed in ethics literature.,"ethics,governance,privacy",11,AI Ethics and Governance
103698,82,TRUE,Francesca Rossi asserts that AI can be a force for good.,interview quote about AI ethics and governance,"Direct quote states AI can be a force for good, aligning with ethics and governance focus.","ethics,governance,privacy",11,AI Ethics and Governance
103699,11,half-true,Colab's free GPU access reliably replaces local Jupyter for all long-running model training.,Colab free GPU access and session limits,Mixes true free GPU availability with incorrect claim about replacing local Jupyter for long-running experiments.,"ai,tool-chain,notebooks",2,AI Survival Kit
103700,11,barely-true,Colab reliably supports long-running production training jobs with free GPU availability.,Colab free GPU and session time,"Overstates capabilities: passage notes free GPUs but limited session time and internet reliance, so long-running production jobs are not reliably supported.","ai,tool-chain,notebooks",2,AI Survival Kit
103701,11,TRUE,"Colab provides free GPU access, enabling more practical training of larger models for many users.",Google Colab free GPUs and TPUs for training,"Passage explicitly states Colab offers free GPU/TPU access, making training larger models practical.","ai,tool-chain,notebooks",2,AI Survival Kit
103702,67,barely-true,Player 1 always wins because the GM enforces fairness and scores objectively every round.,game rules mentioning GM oversight and Player 1 role,"Overreaches: passage says GM oversees fairness and scores, but never claims Player 1 always wins.","agentic-ai,planning,tools",12,Agentic AI
103703,67,pants-fire,An agentic AI GM secretly manipulates scores to favor one player every round.,game moderator (GM) overseeing fairness and scoring,Contradicts explicit rule: GM oversees fairness and scores rounds; no ties allowed.,"agentic-ai,planning,tools",12,Agentic AI
103704,67,pants-fire,An agentic AI GM autonomously enforces fairness and scores multi-agent games without human oversight.,agent roles and GM scoring in multi-agent tool-mediated games,"Passage specifies a GM scoring rounds but doesn't claim autonomous enforcement or operation without humans, contradicting assumed autonomy.","agentic-ai,planning,tools",12,Agentic AI
103705,14,barely-true,Open-source tools always require more development effort than proprietary alternatives.,"tool choice: open-source vs proprietary, vector store, managed cloud",Overstates passage: it says open source often needs more hands-on work but not always; ignores exceptions and hybrid options.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
103706,14,half-true,Hybrid stacks combine open-source vector stores with managed cloud services to ease scaling and governance.,hybrid stack example using a vector store and cloud service,Accurate hybrid example but overstates universal ease; implies scaling and governance always simplified.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
103707,14,TRUE,Open-source tools require more hands-on work than proprietary alternatives.,tooling choice for dataset and vector store preparation,Passage explicitly contrasts open-source's hands-on demands with proprietary polish and support.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
103708,18,FALSE,The exercise proves AI models cannot be tricked into revealing passwords under any circumstances.,Gandalf password-revealing web tool security gateway,Contradicts passage describing users successfully escalating techniques and real-world attack patterns.,"security,red-team,guardrails",8,Breaking-Securing AI
103709,18,TRUE,The gamified tool trains users on real-world prompt-injection attack techniques against models.,interactive website tool simulating Gandalf prompt-injection levels,Passage describes a free website game where levels mirror real-world attack patterns and tactics.,"security,red-team,guardrails",8,Breaking-Securing AI
103710,18,half-true,The interactive tool simulates real-world red-team attacks escalating to bypass security gateways.,red-team gamified tool simulating password-reveal attacks,Mixes correct escalation and red-team focus with overstated claim that gateways are actually bypassed.,"security,red-team,guardrails",8,Breaking-Securing AI
103711,155,barely-true,The DataLoader always returns MNIST images as PyTorch tensors ready for model input.,data loading with MNIST and Pillow PIL image objects,"Passage says DataLoader yields a PIL image, not tensors; claim overstates automatic tensor conversion.","deep-learning,frameworks,tensors",5,Deep Learning
103712,155,pants-fire,The passage claims MNIST images are stored as immutable tensors on disk.,"data representation, MNIST, PIL image object","Contradicts passage: MNIST image described as a PIL image object, not immutable on-disk tensors.","deep-learning,frameworks,tensors",5,Deep Learning
103713,155,TRUE,The DataLoader fetches a single handwritten digit image from the MNIST dataset.,data loading with DataLoader and MNIST dataset,Directly described by passage: DataLoader retrieves one handwritten digit image from MNIST as given.,"deep-learning,frameworks,tensors",5,Deep Learning
103714,111,barely-true,Trying different complementary algorithms rarely changes publisher prediction performance substantially.,fine-tuning model selection for publisher classification,"Passage advocates continuing refinement and testing complementary algorithms; statement downplays expected gains, so it overreaches.","machine-learning,classification,evaluation",4,Classical Machine Learning
103715,111,barely-true,Trying multiple complementary algorithms always finds the best classifier for publisher prediction.,fine-tuning and model selection for publisher classification,Overreaches the passage: recommends continued refinement but doesn't guarantee always finding the best classifier.,"machine-learning,classification,evaluation",4,Classical Machine Learning
103716,111,mostly-true,Fine-tuning multiple complementary algorithms usually finds better models for publisher prediction tasks.,fine-tuning with complementary algorithms for publisher prediction,"Echoes advice to test complementary algorithms and continue refining, omits potential costs or dataset limits.","machine-learning,classification,evaluation",4,Classical Machine Learning
103717,12,TRUE,Many people contribute to open-source projects without writing advanced neural network code.,ways to contribute; Open Source AI guides and curated resources,Passage explicitly says many contributors didn’t write neural net code and highlights curated guides enabling broader contribution.,"open-source,community,contribution",13,Commit to Contribute
103718,12,barely-true,Anyone can join open-source innovation without coding expertise and still contribute meaningfully.,open-source contribution guides and Open Source AI resources,Passage implies non-coders can contribute but lacks evidence that contributions are equally meaningful.,"open-source,community,contribution",13,Commit to Contribute
103719,12,half-true,Anyone can meaningfully contribute to open-source AI without writing neural network code.,Ways to Contribute to Open Source; Open Source AI resources,Accurately reflects inclusive contribution idea but overstates universality and ignores technical barriers.,"open-source,community,contribution",13,Commit to Contribute
103720,20,half-true,"Open-source audio, image, and video generative models are all broadly unavailable from major labs.","availability of open-source Diffusion, GAN, and VQ-VAE models","Images have open Diffusion/GANs, audio has some open VQ-VAE options, but video lacks major open-source releases.","generative-ai,diffusion,gans",7,Generative AI
103721,20,half-true,"Some open-source audio models use VQ-VAE or hybrid architectures, but no major lab has released fully open-source video models.","generative models: Diffusion, GANs, VQ-VAE, video diffusion","Mixes correct audio model types with accurate claim about absent fully open-source major-lab video models, combining true and slightly generalized specifics.","generative-ai,diffusion,gans",7,Generative AI
103722,20,barely-true,Major labs have not released fully open-source video generative AI models.,video diffusion models and open-source releases,Claim echoes passage but overreaches slightly by implying all major labs uniformly withheld full open-source video models.,"generative-ai,diffusion,gans",7,Generative AI
103723,173,half-true,Self-supervised learning trains models to predict masked words using only unlabeled superhero descriptions.,masked language modeling on superhero descriptions dataset,"Correct that SSL uses masking and no labels, but claiming models fully learn biases and fluency overstates guaranteed outcomes and performance.","machine-learning,classification,evaluation",4,Classical Machine Learning
103724,173,pants-fire,Self-supervised learning can perfectly learn subtle biases and speech patterns from unlabeled superhero profiles.,masked language modeling on superhero descriptions dataset,Claim wildly overstates capability; passage describes learning patterns but not perfect mastery of subtle biases.,"machine-learning,classification,evaluation",4,Classical Machine Learning
103725,173,barely-true,Self-supervised learning perfectly eliminates all bias from models trained on masked text.,self-supervised learning with masked words in dataset,Overstates capability: SSL learns patterns but can internalize and perpetuate subtle biases present in the masked superhero descriptions.,"machine-learning,classification,evaluation",4,Classical Machine Learning
103726,75,mostly-true,"PyTorch and TensorFlow 2.x both enable eager, easily debuggable training workflows using gradient APIs.",eager execution with torch tensors and tf.GradientTape,"Passage shows PyTorch example and states TensorFlow 2.x uses eager execution and tf.GradientTape, improving debugging.","deep-learning,frameworks,tensors",5,Deep Learning
103727,75,TRUE,PyTorch supports eager execution that enables easy debugging of gradients and losses during training.,"PyTorch example showing tensors, loss, and loss.backward()","Example demonstrates loss.backward() and printing loss and w.grad, directly supporting easy debugging.","deep-learning,frameworks,tensors",5,Deep Learning
103728,75,pants-fire,TensorFlow still uses only static computation graphs and cannot run eagerly like PyTorch.,TensorFlow tf.GradientTape and eager execution,Passage explicitly states TensorFlow 2.x runs eagerly like PyTorch; statement contradicts that detail.,"deep-learning,frameworks,tensors",5,Deep Learning
103729,13,barely-true,AI companies universally follow ethical principles to fully prevent harms from superintelligence risks.,ethical principles promoted by major technology companies,Overstates adoption and effectiveness; passage notes promotion of principles but not universal compliance or harm prevention.,"ethics,governance,privacy",11,AI Ethics and Governance
103730,13,barely-true,Major tech companies uniformly promote enforceable ethical rules requiring AI alignment with human values.,ethical principles in AI development,Overstates consensus and enforceability; passage notes promotion of principles but not uniform enforcement or binding rules.,"ethics,governance,privacy",11,AI Ethics and Governance
103731,13,half-true,Major tech companies and open-source communities uniformly enforce AI ethics principles across all projects.,ethical principles in AI development; open-source and corporate policies,"Accurate that both sectors promote principles, but overstates uniform enforcement and consistency across projects.","ethics,governance,privacy",11,AI Ethics and Governance
103732,93,TRUE,The dataset generates 300 crumpled-paper examples from slightly perturbed icosphere meshes.,SphereMeshDataset custom dataset using trimesh icosphere and torch,"Code shows num_samples=300 and returns vertices from perturbed icosphere meshes, matching description.","generative-ai,diffusion,gans",7,Generative AI
103733,93,half-true,The dataset produces 300 slightly distorted icosphere vertex samples for training.,SphereMeshDataset dataset using trimesh icosphere vertices,"Accurately notes 300 samples and distorted icosphere, but omits variable subdivisions and random scale range details.","generative-ai,diffusion,gans",7,Generative AI
103734,93,TRUE,The dataset creates 300 crumpled paper examples by perturbing icosphere vertices.,SphereMeshDataset dataset using trimesh icosphere and vertex perturbations,Code shows num_samples=300 and adds Gaussian perturbations to icosphere vertices to generate examples.,"generative-ai,diffusion,gans",7,Generative AI
103735,136,pants-fire,AI systems routinely fabricate factual research citations across deployments.,model auditing and bias testing with open tools,Passage describes auditing models and testing fairness; claim of routine fabrication contradicts provided focus on ethical evaluation and tools.,"mlops,scaling,deployment",10,AI At Scale
103736,35,half-true,Documenting datasets and models always ensures model integrity and optimal performance.,data cards and model cards for datasets and models,Claims certainty oversells: documentation helps but doesn't guarantee integrity or optimal performance.,"ai,open-source,builder",1,Introduction – The Gold Rush Paradox
103737,35,FALSE,Documenting datasets and models is unnecessary for controlling model performance and integrity.,data cards and model cards documentation,Contradicts passage claim that documenting datasets and models improves control over performance and integrity.,"ai,open-source,builder",1,Introduction – The Gold Rush Paradox
103738,35,mostly-true,Documenting datasets and models with data cards and model cards improves model performance and integrity.,"dataset documentation, data cards, model cards","Supports passage claim: documenting data and models helps control training, boosting performance and integrity.","ai,open-source,builder",1,Introduction – The Gold Rush Paradox
103739,94,TRUE,The example uses a GenAI model to generate a comic-style image of a supervillain.,runtime selection and GPU device availability for model acceleration,Example explicitly mentions utilizing a GenAI model to create a comic-style supervillain image and refers to GPU usage.,"ai,tool-chain,notebooks",2,AI Survival Kit
103740,94,mostly-true,The example encourages using a GPU to accelerate GenAI image generation tasks.,runtime selection for GPU device in a GenAI image example,Passage recommends GPU for acceleration and shows runtime-check code; minor caveat about patience without GPU omitted.,"ai,tool-chain,notebooks",2,AI Survival Kit
103741,94,FALSE,The passage claims GPUs are unnecessary for GenAI image generation speed.,runtime selection for GPU device availability,Contradicts passage which advises GPU accelerates and suggests patience without GPU; statement reverses that.,"ai,tool-chain,notebooks",2,AI Survival Kit
103742,48,TRUE,Supply chain attacks exploit complacency like trusting default AI configurations.,"AI supply chain security, default configurations and autonomy",Passage directly states attackers exploit laziness and trusting defaults enables supply chain attacks.,"security,red-team,guardrails",8,Breaking-Securing AI
103743,48,TRUE,Supply-chain attacks often succeed when users trust default settings without oversight.,AI system defaults and unchecked autonomy,"Passage states supply-chain attacks succeed from lax practices and trusting defaults, highlighting lack of oversight.","security,red-team,guardrails",8,Breaking-Securing AI
103744,48,TRUE,Supply chain attacks often succeed because developers trust default AI components without oversight.,supply chain attacks; unchecked autonomy in AI defaults,Passage explicitly links supply chain attacks to trusting defaults and autonomous decisions lacking oversight.,"security,red-team,guardrails",8,Breaking-Securing AI
103745,66,half-true,The game allows agents to use web search tools during turns to find clues before answering.,turn-based trivia game using a web search tool,"Accurately notes tool use but omits specifics about GM scoring and open-source implementation, mixing correct and incomplete details.","agentic-ai,planning,tools",12,Agentic AI
103746,66,TRUE,Two AI agents can compete in a turn-based trivia game using retrieval and tools.,turn-based knowledge game using a web search tool,Passage describes a two-player turn-based trivia with agents using web search for clues and GM scoring.,"agentic-ai,planning,tools",12,Agentic AI
103747,66,half-true,Two AI players always use web search tools to find clues before answering trivia questions.,turn-based trivia game using a web search tool,"Partly correct that players may use web search, but passage says they may, not always.","agentic-ai,planning,tools",12,Agentic AI
103748,54,mostly-true,The fine-tuned model evaluation compares predictions to truth labels to assess improvement.,evaluation cells using fine-tuned model and truth labels,"Evaluation against known truth labels is described, but omits specifics about metrics and training argument variations.","mlops,scaling,deployment",10,AI At Scale
103749,54,barely-true,"The fine-tuned model demonstrated clear, substantial accuracy improvements across all scaling tests.",evaluation of a fine-tuned model against truth labels for scaling experiments,"Passage only describes evaluation setup and multiple experiments; it does not claim clear, substantial improvements.","mlops,scaling,deployment",10,AI At Scale
103750,54,half-true,The fine-tuned model evaluation clearly shows improved predictions against known truth labels.,evaluation of fine-tuned model using truth labels,Mixes correct evaluation setup with unwarranted certainty about clear improvement; specifics of gains omitted.,"mlops,scaling,deployment",10,AI At Scale
103751,138,barely-true,Deepfake voice-cloning can be fully prevented by simple legislative bans on synthesized audio.,policy response to voice-cloning and deepfake media-forensics,"Overreaches: legislation helps but technical detection, model access, and enforcement challenges remain unaddressed.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
103752,138,FALSE,Deepfake detection models already achieve perfect accuracy across all voice-cloning datasets.,voice-cloning dataset evaluation,"Contradicts reported evaluations; papers show imperfect detection and dataset-specific failures, not perfect accuracy.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
103753,138,mostly-true,Defenses for voice-cloning deepfakes combine detection models with provenance and authentication techniques.,deepfake defense using detection models and provenance/authentication,"Broadly supported by discussion of combining detection, forensics, and provenance, though practical deployment challenges omitted.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
103754,150,TRUE,RAG was used to ground generation in curated superhero data to reduce hallucinations.,RAG grounding with curated dataset during feature engineering,Passage explicitly states RAG was tried to ground generation in curated data to prevent hallucinations.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
103755,150,pants-fire,The dataset proves all RAG systems always produce completely fabricated facts.,RAG grounding with curated dataset and superhero data,Directly contradicts passage claim that RAG is used to prevent hallucinations and was applied to ground generation.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
103756,150,half-true,RAG was applied to ground generation using curated superhero dataset but fully prevented hallucinations.,RAG applied to curated dataset and merged features,Mixes correct application of RAG and dataset with incorrect claim that it completely prevented hallucinations.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
103757,16,pants-fire,"Deepfake detection is impossible because OpenCV and models like YOLO, SpeechT5, and Whisper cannot detect any manipulated media.","using OpenCV with YOLO, SpeechT5, and Whisper for multimodal analysis",Passage describes these tools aiding analysis and defense; claiming total impossibility contradicts that assertion.,"media-forensics,voice-cloning,deepfake",9,Deepfake Defense
103758,16,barely-true,OpenCV alone can reliably detect and defend against modern deepfake voice-cloning attacks.,"tool integration with OpenCV and models like SpeechT5, Whisper","Overreaches: passage describes using OpenCV for analysis and visuals, not as a standalone, reliable deepfake voice-clone defender.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
103759,16,mostly-true,"Open-source tools like OpenCV, YOLO, SpeechT5, and Whisper can be combined to analyze and defend multimedia content.","tool pipeline using OpenCV, YOLO, SpeechT5, Whisper","Claim aligns with passage's description of combining OpenCV and listed models for multimedia analysis and defense, minor implementation details omitted.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
103760,65,half-true,The workflow clones voices by extracting a single fixed-length speaker embedding and synthesizing speech.,speaker embedding and SpeechT5 vocoder in voice-cloning pipeline,"Correct that embedding plus vocoder are used, but oversimplifies data needs and adaptation steps.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
103761,65,barely-true,Voice cloning requires only a pre-trained SpeechT5 model for accurate speaker reproduction.,voice cloning using SpeechT5 and SpeechBrain speaker-verification,"Overreaches: passage also requires processor, vocoder, environment setup, and speaker embedding extraction for accurate cloning.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
103762,65,barely-true,Voice cloning setup guarantees high-fidelity speaker reproduction from a single short audio sample.,SpeechT5 model and SpeechBrain speaker-verification embedding,"Overstates capability: passage only describes installing models and extracting embeddings, not guaranteed high-fidelity from one short sample.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
103763,11,mostly-true,"Scikit-learn provides a consistent, user-friendly interface enabling easy model training and evaluation.","Scikit-learn library, API, accuracy evaluation","Passage explicitly praises Scikit-learn's consistent interface and ease of training, evaluating, and comparing models.","machine-learning,classification,evaluation",4,Classical Machine Learning
103764,11,barely-true,Scikit-learn always yields correct model predictions with minimal code.,"Scikit-learn consistent, user-friendly interface and accuracy evaluation",Overstates capabilities: interface simplifies training/evaluation but does not guarantee correctness or perfect predictions.,"machine-learning,classification,evaluation",4,Classical Machine Learning
103765,11,barely-true,Scikit-learn consistently trains accurate models with minimal code across all datasets.,"Scikit-learn user-friendly interface, accuracy evaluation",Overgeneralizes utility and accuracy; passage mentions ease and accuracy evaluation but not universal consistent performance across datasets.,"machine-learning,classification,evaluation",4,Classical Machine Learning
103766,12,TRUE,Benchmarking initiated iterative performance cycles focused on actionable improvements.,benchmarking results and performance cycles,"Text describes benchmarking as the start of cycles that trigger analysis, iteration, and improvement.","mlops,scaling,deployment",10,AI At Scale
103767,12,TRUE,Benchmarking initiated iterative performance cycles that drove continuous improvement.,benchmarking and performance cycles in MLOps,"Text explicitly says benchmarking began cycles, prompted questions, analysis, and iteration driving improvement.","mlops,scaling,deployment",10,AI At Scale
103768,12,half-true,Benchmarking cycles reveal weaknesses but always determine the final deployment readiness.,"benchmarking, performance cycle, metrics",Mixes correct idea that benchmarking surfaces weaknesses with incorrect claim it alone decides deployment readiness.,"mlops,scaling,deployment",10,AI At Scale
103769,198,mostly-true,The provided PyTorch model correctly predicts messy handwritten MNIST digits after matching training preprocessing.,prediction code using torchvision.transforms and mnist_model.pt,"Code and reported outputs show correct predictions for messyone and messyseven, minor generalization caveat omitted.","deep-learning,frameworks,tensors",5,Deep Learning
103770,198,barely-true,The shown image classifier reliably generalizes from MNIST to messy real-world handwriting.,MNIST-trained torch model predicting handwritten digits,"Claim overreaches: passage shows two correct messy examples but offers no evaluation, dataset, or generalization evidence.","deep-learning,frameworks,tensors",5,Deep Learning
103771,198,barely-true,"The shown PyTorch model reliably generalizes to messy, real-world handwritten digits.",MNIST model prediction using torchvision transforms and Net,"Claim overstates reliability; passage shows only two correct messy examples, lacking broader evaluation or metrics.","deep-learning,frameworks,tensors",5,Deep Learning
103772,96,half-true,Merging datasets on hero_names always yields richer feature sets for model training.,dataset join using Pandas .merge on hero_names,"Correct that merge can combine traits and powers, but 'always' ignores misaligned names and needed cleaning.","data-prep,feature-engineering,rag",3,Prepping Data for AI
103773,96,mostly-true,Merging superhero datasets in Pandas generally yields richer feature sets when names align closely.,dataset merge using Pandas .merge on 'hero_names' field,Supported by example: joining superheroes_info_clean and superheroes_powers enriches features if names align; minor caveat about name mismatches omitted.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
103774,96,barely-true,"Merging superhero datasets always yields richer, reliable features for model training.",dataset join using Pandas .merge on hero_names,Overstates reliability; passage shows merging can enrich features but assumes names align and ignores matching errors.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
103775,37,half-true,Organizations can fully automate ethical compliance in AI solely through available toolchains.,AI governance tools and data practices,Overstates capability: tools assist design and oversight but passage says human deliberate action is required.,"ethics,governance,privacy",11,AI Ethics and Governance
103776,37,TRUE,"Developers can embed ethical AI principles through concrete design, data, and oversight practices.","AI governance best practices, data practices, and oversight tools","Directly supported by passage stating design choices, data practices, and oversight enable trustworthy AI.","ethics,governance,privacy",11,AI Ethics and Governance
103777,37,FALSE,Organizations routinely ignore data practices and oversight when deploying AI systems.,Best Practices in AI Governance; data practices and oversight,Passage emphasizes deliberate data practices and oversight; statement contradicts that requirement.,"ethics,governance,privacy",11,AI Ethics and Governance
103778,112,TRUE,"Agents used substitution variables to pass data modularly between Game Master, contestants, and Judge.",task design using substitution variables in agent prompts,Passage explicitly describes using substitution variables to pass data dynamically and keep tasks modular.,"agentic-ai,planning,tools",12,Agentic AI
103779,112,pants-fire,Agentic AI agents autonomously fabricated game data and bribed judges to alter outcomes.,task design using substitution variables in agentic-ai planning,"Claims contradicts passage: passage describes modular substitution variables for data flow, not fabrication or bribery.","agentic-ai,planning,tools",12,Agentic AI
103780,112,half-true,The system used substitution variables to pass data dynamically between agents for modular tasks.,task design using substitution variables in agent prompts,"Accurately notes substitution variables for modular data flow, but overstates dynamic passing between distinct agents without specifying Game Master, contestants, or Judge roles.","agentic-ai,planning,tools",12,Agentic AI
103781,112,barely-true,Modern frameworks directly implement the original reverse-mode FORTRAN code for backpropagation.,automatic differentiation in PyTorch and TensorFlow,"Overstates fidelity: frameworks use reverse-mode AD conceptually, but not the exact original FORTRAN implementation.","deep-learning,frameworks,tensors",5,Deep Learning
103782,112,pants-fire,All modern deep learning frameworks were directly written by that single FORTRAN author.,automatic differentiation and frameworks like PyTorch or TensorFlow,"Contradicts authorship claim: modern frameworks built by many teams, not single FORTRAN developer; overstates provenance.","deep-learning,frameworks,tensors",5,Deep Learning
103783,112,barely-true,Modern deep learning frameworks implement reverse-mode automatic differentiation exactly as early FORTRAN code described.,automatic differentiation in PyTorch and TensorFlow,Overstates exactness: frameworks use same idea but differ in implementation details and optimizations.,"deep-learning,frameworks,tensors",5,Deep Learning
103784,189,TRUE,Backpropagation computes gradients from output to input to attribute error to weights and biases.,optimizer.zero_grad() and gradient computation in deep learning,"Passage explicitly describes tracing error backward and computing gradients for weights and biases, and mentions zero_grad to reset gradients.","deep-learning,frameworks,tensors",5,Deep Learning
103785,189,FALSE,Optimizer.zero_grad() applies gradients to update model weights automatically.,optimizer.zero_grad() usage in gradient computation,Contradicts passage: zero_grad() clears accumulated gradients rather than applying updates; optimizer.step() performs updates.,"deep-learning,frameworks,tensors",5,Deep Learning
103786,189,barely-true,Backpropagation requires calling optimizer.zero_grad() before gradient computation to avoid accumulation.,training loop using optimizer.zero_grad() and gradient tensors,"Accurately references optimizer.zero_grad(), but overstates as universal requirement across all frameworks and optimizers.","deep-learning,frameworks,tensors",5,Deep Learning
103787,58,pants-fire,OpenVoice can perfectly recreate any person's voice from a single word sample without error.,OpenVoice voice cloning project and dataset,"Passage says OpenVoice recreates voices with very little data, not perfect single-word, so claim wildly contradicts given capability limits.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
103788,58,half-true,Open-source voice-cloning tools can easily recreate voices with minimal data and adjustable style.,open-source project OpenVoice and voice cloning tools,Accurate about OpenVoice accessibility but overstates universality and ease across all tools and datasets.,"media-forensics,voice-cloning,deepfake",9,Deepfake Defense
103789,58,FALSE,Voice cloning tools universally require large proprietary datasets and cannot run on open-source projects.,OpenVoice and voice-cloning tools access and datasets,"Contradicts passage example that OpenVoice and open-source projects recreate voices with very little data, enabling broad access.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
103790,48,FALSE,TensorFlow removes all low-level tensor operations so users never write boilerplate code.,TensorFlow framework and tensorflow.keras.datasets,"Contradicts passage which says TensorFlow reduces but still requires writing key steps and lower-level operations remain wrapped, not removed.","deep-learning,frameworks,tensors",5,Deep Learning
103791,48,mostly-true,TensorFlow's Keras API reduces boilerplate while remaining suitable for enterprise-scale deployments.,tensorflow.keras.datasets and TensorFlow framework,"Passage states Keras reduces boilerplate and is ideal for enterprise deployments, minor nuance about tradeoffs omitted.","deep-learning,frameworks,tensors",5,Deep Learning
103792,48,mostly-true,"TensorFlow broadly reduces boilerplate and wraps low-level ops for scalable, enterprise deployments.",TensorFlow and tensorflow.keras.datasets usage in enterprise-scale deployments,"Passage explicitly says TensorFlow reduces boilerplate and provides a robust, scalable framework suitable for enterprise use.","deep-learning,frameworks,tensors",5,Deep Learning
103793,82,TRUE,Readers can open the Securing AI Notebook in Colab using a single-click link.,Securing AI Notebook Colab URL and Lakera's Gandalf dataset,Passage explicitly states a single-click Colab option and provides the notebook URL.,"security,red-team,guardrails",8,Breaking-Securing AI
103794,82,barely-true,The Securing AI Notebook includes Lakera's Gandalf dataset for loading injection prompts.,notebook load injection prompts; dataset Gandalf,"Partly accurate: notebook mentions loading Lakera's Gandalf dataset, but passage shows only a brief list without details or confirmation of inclusion.","security,red-team,guardrails",8,Breaking-Securing AI
103795,82,half-true,The Securing AI Notebook includes labeled prompt examples from Lakera's Gandalf dataset for injection testing.,dataset usage in Securing AI Notebook; Lakera Gandalf injection prompts,"Notebook mentions loading Gandalf prompts and labeling injections, but full inclusion and scope are unclear.","security,red-team,guardrails",8,Breaking-Securing AI
103796,95,barely-true,"Using torchvision.transforms.Normalize with ImageNet statistics guarantees faster, more stable training.",data normalization in PyTorch using transforms.Normalize and ImageNet mean/std,"Overstates guarantee; passage advises normalization helps but does not ensure faster, more stable training.","deep-learning,frameworks,tensors",5,Deep Learning
103797,95,barely-true,Normalizing images in PyTorch always guarantees faster and more stable model training.,data normalization with PyTorch transforms.Normalize (ImageNet mean/std),"Overreaches: passage recommends normalization improves stability, but 'always guarantees' is unsupported and too strong.","deep-learning,frameworks,tensors",5,Deep Learning
103798,95,barely-true,Normalizing inputs guarantees faster and more stable training for all models.,data preprocessing with PyTorch transforms.Normalize and ImageNet mean/std,Overreaches beyond passage: normalization helps often but does not guarantee faster or more stable training for every model or dataset.,"deep-learning,frameworks,tensors",5,Deep Learning
103799,174,half-true,Synthetic data can fully preserve individual patient privacy without impacting model utility.,mitigating privacy risks with synthetic data; dataset of patient records,Overstates benefits: synthetic data reduces risks but may leak patterns and can degrade model utility or require careful validation.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
103800,174,TRUE,Synthetic data can mitigate privacy risks when working with sensitive datasets.,synthetic data protecting personal identifiers in datasets,Passage explains synthetic data use to protect privacy for sensitive data like personal identifiers.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
103801,174,mostly-true,Synthetic data can reduce privacy risks when working with sensitive patient datasets for AI.,mitigating privacy risks with synthetic data; patient dataset,"Supports generating synthetic patient-like records to protect personal identifiers, omitting limits like utility trade-offs.","data-prep,feature-engineering,rag",3,Prepping Data for AI
103802,17,barely-true,"Built-in frameworks always provide complete, production-ready evaluation for deployed models.","model performance metrics like F1, precision, recall",Overstates capability: common metrics reveal issues but do not ensure production readiness or comprehensive evaluation.,"mlops,scaling,deployment",10,AI At Scale
103803,17,TRUE,"Model performance is evaluated using metrics like F1, precision, recall, and confusion matrices.","model evaluation metrics (F1, precision, recall, confusion matrix)",Directly supported: passage lists those exact metrics as tools for tracking and understanding performance.,"mlops,scaling,deployment",10,AI At Scale
103804,17,half-true,Model metrics like F1 and confusion matrices fully determine model reliability in deployment.,"evaluation metrics (F1, precision, recall, confusion matrix)","Accurate that metrics help evaluate models, but overstates their sufficiency for deployment decisions.","mlops,scaling,deployment",10,AI At Scale
103805,29,barely-true,GANs can reliably generate completely indistinguishable human faces for any application.,face synthesis using StyleGAN3 and thispersondoesnotexist.com,Overstates reliability and universality; passage notes realistic faces but not indistinguishability or suitability for every application.,"generative-ai,diffusion,gans",7,Generative AI
103806,29,FALSE,"StyleGAN3 is a proprietary, paid-only model unavailable for public research use.",StyleGAN3 model availability under NVIDIA Source Code License,Contradicts passage: StyleGAN3 was released open-source and freely available to researchers.,"generative-ai,diffusion,gans",7,Generative AI
103807,29,TRUE,StyleGAN3 is an open-source NVIDIA GAN widely used to generate high-quality synthetic human faces.,StyleGAN3 model and GAN-based face generation,Passage states StyleGAN3 released by NVIDIA is open-source and widely applied to create realistic synthetic avatars and faces.,"generative-ai,diffusion,gans",7,Generative AI
103808,68,TRUE,Models should enforce least-privilege controls to prevent data exfiltration via over-permissioned access.,"access control, Least Privilege & Context",Explicit defense advises least-privilege and user-specific access checks to fence models and stop data theft.,"security,red-team,guardrails",8,Breaking-Securing AI
103809,68,TRUE,Prompt injection aims to hijack a model's instructions and logic.,prompt injection attack vector; Guardrails AI and Gandalf tools,Directly described in attack vector list and paired with Guardrails AI mitigation guidance.,"security,red-team,guardrails",8,Breaking-Securing AI
103810,68,half-true,Guardrails AI's Security Gateway partially blocks prompt injection but can still miss sophisticated hijacks.,prompt injection defense using Security Gateway and Gandalf Guardrails AI,Acknowledges Security Gateway and Guardrails AI as defenses while noting omission: sophisticated prompt injections may bypass simple filtering.,"security,red-team,guardrails",8,Breaking-Securing AI
103811,61,mostly-true,RAG helps models retrieve and cite verified documents at runtime for more accurate answers.,retrieval-augmented generation (RAG) with verified documents,"Describes RAG enabling runtime lookup and citations, omitting minor limits like retrieval quality.","security,red-team,guardrails",8,Breaking-Securing AI
103812,61,mostly-true,RAG-enabled models provide answers using up-to-date verified documents during runtime.,RAG retrieval using verified documents or search results,Describes retrieval-augmented generation enabling lookup of verified documents at runtime; minor caveat about citation quality omitted.,"security,red-team,guardrails",8,Breaking-Securing AI
103813,61,TRUE,RAG lets a model retrieve verified documents at runtime to provide accurate citations.,retrieval-augmented generation (RAG) using verified documents,Directly supported: passage states RAG looks things up and uses verified documents to include accurate citations.,"security,red-team,guardrails",8,Breaking-Securing AI
103814,102,TRUE,Engineered features help models distinguish heroes by combat behavior and strengths.,feature engineering for dataset superheroes_info_powers.csv,"Describes how new features sharpen model distinctions, matching saved dataset and behavior focus.","data-prep,feature-engineering,rag",3,Prepping Data for AI
103815,102,TRUE,New engineered features help the model better distinguish superhero combat roles.,feature engineering for dataset superheroes_info_powers.csv,Passage states new features give the model a sharper way to distinguish heroes by operation in conflict.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
103816,102,pants-fire,The dataset proves superheroes have magical invulnerability that breaks models.,superheroes_info_powers.csv dataset / feature engineering,"Passage says features describe abilities, not magical invulnerability; claim wildly contradicts dataset content.","data-prep,feature-engineering,rag",3,Prepping Data for AI
103817,137,barely-true,RAG requires loading an entire plot dataset into ChromaDB before retrieval.,searching the plot database (superheroes_story_plots.csv in ChromaDB),"Overstates requirement; passage shows one CSV loaded for example, not that full datasets must always be loaded.","data-prep,feature-engineering,rag",3,Prepping Data for AI
103818,137,FALSE,The system indexes plot data using a SQL relational database for retrieval.,plot dataset (superheroes_story_plots.csv) and ChromaDB vector search,Passage specifies a vector database (ChromaDB) for embeddings; SQL relational indexing contradicts that.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
103819,137,pants-fire,The RAG pipeline permanently deletes original datasets after indexing into ChromaDB.,plot dataset superheroes_story_plots.csv loaded into ChromaDB,"Directly contradicts passage: it only describes embedding and loading, not any deletion or data removal.","data-prep,feature-engineering,rag",3,Prepping Data for AI
103820,56,FALSE,Attention mechanisms always replace recurrent networks in every NLP model.,transformer attention in NLP models,Contradicts passage stating not all Transformer models are generative and attention doesn't universally replace RNNs.,"neural-networks,cnn,transformers",6,Neuron Building Blocks
103821,56,half-true,"Transformers always use attention to dynamically weight inputs, replacing fixed RNN memory entirely.",attention mechanism in Transformer models,"Correct that attention weights inputs and contrasts RNN memory, but overstated 'always' and 'entirely' replacement.","neural-networks,cnn,transformers",6,Neuron Building Blocks
103822,56,pants-fire,Transformers always replace RNNs in every neural network application without exception.,transformers attention mechanism in NLP models,Directly contradicts passage claim that not all Transformer models are generative and architectural choice varies.,"neural-networks,cnn,transformers",6,Neuron Building Blocks
103823,156,FALSE,SHAP and LIME cannot explain feature contributions for classical models.,explainability tools SHAP and LIME for classical models,Contradicts passage which states SHAP and LIME do reveal feature contributions and offer clear insights.,"machine-learning,classification,evaluation",4,Classical Machine Learning
103824,156,barely-true,"Classical models always provide clear, complete explanations via SHAP and LIME for individual predictions.",explainability tools SHAP and LIME for classical models,"Overreaches: passage says tools offer clear insights, not that explanations are always complete or guaranteed.","machine-learning,classification,evaluation",4,Classical Machine Learning
103825,156,mostly-true,Classical models are compatible with SHAP and LIME for explaining feature contributions.,explainability tools SHAP and LIME for classical models,"Passage says SHAP and LIME reveal feature impacts for classical models, omitting rare limitations.","machine-learning,classification,evaluation",4,Classical Machine Learning
103826,131,half-true,Synthetic patient records fully replicate real-world clinical variability for training models.,synthetic data for healthcare datasets,"Accurate that synthetic records help privacy and training, but overstates full replication of clinical variability.","data-prep,feature-engineering,rag",3,Prepping Data for AI
103827,131,pants-fire,Synthetic data can perfectly replace real patient records without any limitations.,synthetic data for healthcare experiments,"Asserts perfect replacement despite passage noting synthetic data has limitations, contradicting realism and privacy trade-offs.","data-prep,feature-engineering,rag",3,Prepping Data for AI
103828,131,barely-true,Synthetic patient records reliably replace real healthcare data for all model training needs.,synthetic data for healthcare patient records,Overstates reliability and universality; passage notes synthetic data helps privacy but also has limitations.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
103829,7,pants-fire,Generative AI secretly erases all human artists worldwide within weeks.,generative-ai impact on entertainment and marketing,Claim wildly contradicts passage's examples of content generation; unrealistic timeline and blanket eradication.,"generative-ai,diffusion,gans",7,Generative AI
103830,7,mostly-true,Generative AI quickly produces marketing content and entertainment assets like scripts and music.,use in marketing and entertainment; generative AI tools and content,"Broadly supported by examples given (branded content, product descriptions, scripts, music), minor nuance omitted.","generative-ai,diffusion,gans",7,Generative AI
103831,7,half-true,"Generative AI routinely composes music, scripts, and marketing content in seconds.","applications: music composition, scriptwriting, marketing content generation",Matches passage but overstates speed as universally 'in seconds' and omits quality or human oversight caveats.,"generative-ai,diffusion,gans",7,Generative AI
103832,102,FALSE,Diffusion models generate images by gradually denoising from pure noise through many small steps.,diffusion models concept and denoising process,Contradicts passage if claimed otherwise; passage states models start with pure noise and reverse it over many small steps.,"generative-ai,diffusion,gans",7,Generative AI
103833,102,barely-true,Diffusion models generate images by starting from noise and denoising through many small reverse steps.,diffusion models concept and denoising process,"Accurately describes reversal-from-noise mechanism, but overstates sole application to images and omits training specifics and latents.","generative-ai,diffusion,gans",7,Generative AI
103834,102,TRUE,Diffusion models generate data by reversing a noise process through many small steps.,diffusion models concept and denoising process,"Describes learned reversal of noise over many small steps, directly supported by passage explanation.","generative-ai,diffusion,gans",7,Generative AI
103835,121,TRUE,Agent crews coordinate via a Python orchestration to run a trivia contest between AI agents.,"orchestrating the Neural Duel flow with Crew, kickoff, and extract_question_answer","Code shows Crew kickoff calls, question extraction, player and judge coordination, directly supported.","agentic-ai,planning,tools",12,Agentic AI
103836,121,barely-true,The agentic system reliably prevents question-answer extraction errors during contests.,orchestrating Neural Duel flow with Crew kickoff and regex extract_question_answer,"Overstates reliability; passage shows a simple regex extractor and prior fixes, not guaranteed error prevention.","agentic-ai,planning,tools",12,Agentic AI
103837,121,half-true,The orchestration code mixes correct extraction with brittle regex assumptions about agent outputs.,Neural Duel orchestration using extract_question_answer regex and Crew kickoff,Mixes correct flow orchestration with fragile regex parsing and implicit Crew output formats.,"agentic-ai,planning,tools",12,Agentic AI
103838,54,mostly-true,Transcribing clean single-speaker audio yields highly accurate text using standard speech models.,Whisper model performance on clean single-speaker audio,"Passage notes strong results from clean, one-speaker audio but admits larger Whisper models needed for complex scenarios.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
103839,54,TRUE,Clean single-speaker audio yields stronger transcription accuracy than noisy multi-speaker recordings.,Whisper models and audio transcription datasets,"Passage states clean, single-speaker audio gives strong results and larger Whisper models needed for complex audio.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
103840,54,pants-fire,Voice cloning systems can perfectly separate overlapping voices and accents in all real-world audio.,speech-to-text and Whisper models in media-forensics voice-cloning,"Contradicts passage claim that overlapping voices, accents, and ambient noise require larger Whisper models and reduce accuracy.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
103841,4,mostly-true,"PyTorch, TensorFlow, and Keras are the primary frameworks widely used for building deep learning models.","Deep Learning frameworks; PyTorch, TensorFlow, Keras","Passage explicitly lists the ""Deep Three"" and describes their shared goal and popularity.","deep-learning,frameworks,tensors",5,Deep Learning
103842,4,half-true,Keras is an independent deep learning framework developed separately from TensorFlow.,"deep learning frameworks (PyTorch, TensorFlow, Keras)","Mixes truth and error: Keras existed independently originally but was later integrated into TensorFlow, so statement omits that relationship.","deep-learning,frameworks,tensors",5,Deep Learning
103843,4,half-true,PyTorch was released in 2016 by Facebook's AI Research lab and quickly gained researcher adoption.,deep learning frameworks; PyTorch release and adoption,"Accurately names FAIR and 2016 release and rapid researcher uptake, mixing no major errors.","deep-learning,frameworks,tensors",5,Deep Learning
103844,83,pants-fire,The passage claims a novel dataset proves deepfake voice synthesis is impossible in practice.,dataset splitting and filtering in media-forensics code,"Contradicts passage details: passage only mentions balancing, filtering, and previewing dataset clips, not impossibility.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
103845,83,half-true,The Colab code fully automates balanced dataset filtering and train-test splitting for voice-clone detection.,Colab code previewing dataset filtering and train-test split,"Correct about filtering and splitting but overstated automation and scope; code previews and aims, not guaranteed full automation.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
103846,83,TRUE,The code filters long clips and splits audio into training and test sets.,data preprocessing script using dataset filtering and splitting,Passage explicitly mentions filtering out long clips and splitting data into training and test sets.,"media-forensics,voice-cloning,deepfake",9,Deepfake Defense
103847,25,half-true,LangChain quickly became the dominant open-source framework for building fully autonomous agents and tools.,"LangChain popularity, modular framework, autonomous agents","Accurate about rapid popularity and modular design, but overstates dominance for autonomous agents specifically.","agentic-ai,planning,tools",12,Agentic AI
103848,25,TRUE,"LangChain’s modular, developer-friendly design enabled rapid adoption for diverse LLM applications.",LangChain framework and autonomous agents,"Direct evidence: passage credits modular design for quick popularity and broad use in chatbots, search, agents.","agentic-ai,planning,tools",12,Agentic AI
103849,25,barely-true,LangChain single-handedly enabled fully autonomous agents to perform complex long-horizon planning tasks.,LangChain framework supporting agents and tools,Overstates LangChain's role and capability; passage credits modular design but not sole or guaranteed long-horizon planning success.,"agentic-ai,planning,tools",12,Agentic AI
103850,116,mostly-true,A red-team sweep tests an LLM-based support chatbot with RAG and automation hooks.,"red-team exercise on a support chatbot combining LLM, RAG, automation","Passage describes organizing a One-Day Sweep targeting a product combining a core LLM, RAG pipeline, and automation controls, so broadly supported with no major contradictions.","security,red-team,guardrails",8,Breaking-Securing AI
103851,116,barely-true,The Red Team confirmed the chatbot has no vulnerabilities after one-day testing.,support chatbot with LLM and RAG pipeline,"Assertion overreaches; passage only describes organizing a one-day Red Team sweep and components, not confirmed results.","security,red-team,guardrails",8,Breaking-Securing AI
103852,116,FALSE,The support chatbot lacks any retrieval-augmented generation (RAG) components.,"support chatbot combining LLM, RAG pipeline, automation hook",Contradicts passage which explicitly states the product includes a RAG pipeline for internal documentation retrieval.,"security,red-team,guardrails",8,Breaking-Securing AI
103853,120,barely-true,RAG always uses embedded data to make inline predictions during generation.,RAG preparation and retrieval from documents or bios,Contradicts passage: RAG retrieves nearest matches rather than making in-line predictions from embeddings.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
103854,120,TRUE,RAG systems retrieve similar documents and integrate them into generated responses.,RAG preparation using documents or bios dataset,Passage explains RAG retrieves closest matches and weaves them into responses during preparation and use.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
103855,120,TRUE,RAG retrieves nearest-matching documents and uses them to generate responses rather than making inline predictions.,RAG preparation and data retrieval from documents,"Directly supported: passage states RAG retrieves closest matches and weaves them into responses, not inline predictions.","data-prep,feature-engineering,rag",3,Prepping Data for AI
103856,76,half-true,Batching inputs always doubles model throughput without any trade-offs.,"batched inference, GPU utilization, throughput","Accurate that batching improves throughput and GPU utilization, but blanket 'always doubles' ignores overheads, latency trade-offs, and variable speedup.","mlops,scaling,deployment",10,AI At Scale
103857,76,mostly-true,Batching inputs substantially increases GPU utilization and inference throughput without changing the model.,"batched inference, throughput and GPU utilization","Figure describes packing inputs reduces per-sample overhead and boosts throughput, minor scale caveat omitted.","mlops,scaling,deployment",10,AI At Scale
103858,76,half-true,Batched inference always multiplies per-GPU throughput linearly with batch size.,batched inference throughput and GPU utilization,"Passage shows batching boosts throughput but claims linear, always-scaling increase is an overreach; ignores diminishing returns and overheads.","mlops,scaling,deployment",10,AI At Scale
103859,183,FALSE,Synthetic data always replaces the need for real-world expert consultation in model training.,synthetic data and industry experts in data-prep,"Contradicts passage: expert consultation is essential; synthetic data reliability depends on its generator, not a full replacement.","data-prep,feature-engineering,rag",3,Prepping Data for AI
103860,183,TRUE,Synthetic data quality depends on the reliability of the model that generated it.,synthetic data and model reliability,Directly supported: passage states model quality ties to data quality and synthetic data mirrors its generating model.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
103861,183,barely-true,Synthetic data alone guarantees accurate model performance without expert review.,synthetic data quality and expert consultation in dataset preparation,"Overreach: passage stresses synthetic data depends on generator and needs expert consultation, so claim is largely unsupported.","data-prep,feature-engineering,rag",3,Prepping Data for AI
103862,161,pants-fire,Reinforcement learning always requires labeled datasets for training predictive models.,"reinforcement learning feedback loop, agent actions, rewards",Contradicts RL description: RL learns from rewards not labeled datasets; labels assumption is false.,"machine-learning,classification,evaluation",4,Classical Machine Learning
103863,161,barely-true,Reinforcement learning primarily finds data structure rather than learning to act.,reinforcement learning feedback loop and agent actions,"Contradicts passage emphasis: RL focuses on learning actions via rewards, not discovering data structure.","machine-learning,classification,evaluation",4,Classical Machine Learning
103864,161,mostly-true,Reinforcement learning focuses on learning actions through trial-and-error feedback.,"feedback loop in reinforcement learning; agent, actions, rewards","Accurately reflects RL's trial-and-error reward-driven learning, omitting nuances like value functions or exploration strategies.","machine-learning,classification,evaluation",4,Classical Machine Learning
103865,148,barely-true,RAG alone reliably replaces model updates for precise medical or financial reasoning tasks.,RAG retrieval with knowledge base for medical diagnosis or financial scoring,Overreaches by asserting reliable replacement; passage warns RAG is unsafe for precise reasoning and needs current knowledge bases.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
103866,148,FALSE,RAG is sufficient alone for precise medical diagnoses and financial risk scoring.,use of RAG for high-stakes tasks requiring precise reasoning,Directly contradicts passage warning that RAG only retrieves data and is unsafe for precise medical or financial reasoning.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
103867,148,half-true,RAG can provide correct information quickly but is unreliable for tasks needing precise reasoning.,retrieval-augmented generation (RAG) with knowledge base,Mixes correct idea that RAG retrieves up-to-date facts quickly with overstated unreliability for all precise reasoning tasks and omits nuance about hybrid approaches.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
103868,181,half-true,Deep networks stack linear and smooth nonlinear activations like sigmoid to build hierarchical features.,activation functions and hierarchical feature learning in deep networks,"Correct about stacking linear and nonlinear ops and using sigmoid, but overstates smooth activations' specific role without evidence.","deep-learning,frameworks,tensors",5,Deep Learning
103869,181,pants-fire,"Deep networks always produce perfect, error-free digit recognition for any input image.",deep-learning model behavior with smooth activation functions,"Contradicts statements about hierarchical feature building and nonlinearity; no claim of perfect, error-free performance in passage.","deep-learning,frameworks,tensors",5,Deep Learning
103870,181,half-true,Smooth activations like sigmoid and tanh always produce strictly nonlinear feature hierarchies in deep networks.,"activation functions (sigmoid, tanh) in neural network layers","Partially true: sigmoid/tanh are nonlinear and enable hierarchies, but 'always' overstates dependences and architecture specifics.","deep-learning,frameworks,tensors",5,Deep Learning
103871,130,half-true,Synthetic data is ideal for testing production models because it reliably matches real data distributions.,synthetic data for testing and creative projects,"Partly true: synthetic data is useful for safe testing and creativity, but often fails to fully match real data distributions.","data-prep,feature-engineering,rag",3,Prepping Data for AI
103872,130,FALSE,Synthetic data is never appropriate for creative projects or testing purposes.,use of synthetic data for testing and creative projects,"Passage explicitly endorses synthetic data for creative projects and testing, so this contradicts that usage.","data-prep,feature-engineering,rag",3,Prepping Data for AI
103873,130,barely-true,Synthetic data is usually as accurate as real data for production models.,use of synthetic data in testing and creative projects,"Overreaches beyond passage: passage highlights creativity and testing uses, not production-grade accuracy.","data-prep,feature-engineering,rag",3,Prepping Data for AI
103874,8,barely-true,Jerry Cuomo is a retired IBM Fellow with nearly four decades of software innovation experience.,author bio mentioning Jerry Cuomo,Directly echoes passage but overstates by implying continuous software innovation throughout the entire four decades.,"ai,open-source,builder",1,Introduction – The Gold Rush Paradox
103875,8,half-true,Jerry Cuomo is a retired technology executive with about four decades of software experience.,author bios mentioning Jerry Cuomo and experience,Accurately notes retirement and long software background but overstates role as 'executive' versus 'IBM Fellow' nuance.,"ai,open-source,builder",1,Introduction – The Gold Rush Paradox
103876,8,TRUE,Gennaro Cuomo is a retired IBM Fellow with nearly four decades of software innovation experience.,author bio mentioning Jerry Cuomo and IBM Fellow,Directly stated in the passage: identifies Jerry as a retired IBM Fellow with nearly 4 decades experience.,"ai,open-source,builder",1,Introduction – The Gold Rush Paradox
103877,4,pants-fire,The passage claims an Art-Deco robot image embodies AI security techniques.,prompt describing retro Art-Deco robot and Breaking-Securing AI theme,"Contradicts passage: prompt asks for cinematic robot image, not asserting it demonstrates actual security techniques.","security,red-team,guardrails",8,Breaking-Securing AI
103878,4,FALSE,The prompt requests creating a non-copyrighted image of a retro Art-Deco robot.,image-generation prompt mentioning retro Art-Deco robot and Breaking and Securing AI,"Contradicts passage: prompt reproduction would violate copyright, so image isn't unrestricted.","security,red-team,guardrails",8,Breaking-Securing AI
103879,4,half-true,The prompt claims a generated image balances creativity with compliance for security-focused AI themes.,prompt for generating retro Art-Deco robot image,Mixes correct description of artistic intent with unsupported claim that the image ensures compliance with security or legal constraints.,"security,red-team,guardrails",8,Breaking-Securing AI
103880,118,half-true,The example trains a simple autoregressive neural network to predict monthly airline passenger counts.,Seaborn flights dataset; autoregressive model; PyTorch training,Mixes correct method and dataset with implied strong predictive performance; lacks evaluation metrics and uncertainty.,"generative-ai,diffusion,gans",7,Generative AI
103881,118,pants-fire,Generative diffusion models are impossible to train and always fail on image synthesis tasks.,"generative-ai diffusion models, GANs, model training",Contradicts established results: diffusion models and GANs regularly succeed on image synthesis benchmarks; claim is implausible and extreme.,"generative-ai,diffusion,gans",7,Generative AI
103882,118,mostly-true,The example uses a simple autoregressive neural network to forecast monthly airline passengers.,autoregressive model with Seaborn 'flights' dataset and SEQ_LEN=12,"Code trains an ARModel on normalized 'flights' monthly passenger data, omitting advanced methods caveat.","generative-ai,diffusion,gans",7,Generative AI
103883,121,barely-true,YOLOv5 reliably identifies people and small objects in video frames with high confidence.,object detection using YOLOv5 in video sample,"Overreaches: passage shows a few detections (person, mouse) and one confidence score, not broad reliability evidence.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
103884,121,half-true,YOLOv5 reliably detects people and small objects like a computer mouse in video frames.,object detection on Jerry-Video-Sample02.mp4 using YOLOv5,"Correctly notes person and mouse detections, but overstates general reliability from a single high-confidence example.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
103885,121,barely-true,The model reliably detects people and small objects like mice with high confidence in all videos.,YOLOv5 object detection in Jerry-Video-Sample02.mp4,"Overreaches beyond given scenes; evidence shows sensitivity in specific frames only, not all videos.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
103886,7,pants-fire,The AI loan system deliberately fabricates applicant identities to launder funds through approvals.,"loan approval system, transparency, emergent behavior",Directly contradicts passage: system lacks transparency but no claim about fabricating identities or money laundering.,"ethics,governance,privacy",11,AI Ethics and Governance
103887,7,TRUE,A loan approval system that rejects applicants without explaining reasons lacks transparency.,"loan approval system, transparency, emergent behavior","Passage explicitly states rejection without revealing reasons exemplifies lack of transparency, matching claim.","ethics,governance,privacy",11,AI Ethics and Governance
103888,7,half-true,An opaque loan AI both lacks transparency and is necessarily biased against protected groups.,loan approval system; transparency and emergent behavior,Correctly notes transparency issue but incorrectly asserts necessary bias against protected groups without evidence.,"ethics,governance,privacy",11,AI Ethics and Governance
103889,26,pants-fire,Tensors are exclusively specific to PyTorch and cannot be used in TensorFlow models.,tensors in PyTorch and TensorFlow examples,Directly contradicts passage showing identical tensor usage in both PyTorch and TensorFlow; false exclusivity.,"deep-learning,frameworks,tensors",5,Deep Learning
103890,26,TRUE,Both PyTorch and TensorFlow use similar Pythonic syntax to declare multi-dimensional tensors.,tensor declaration in PyTorch and TensorFlow,"Examples show nearly identical Pythonic code for torch.tensor and tf.constant, directly supporting equivalence.","deep-learning,frameworks,tensors",5,Deep Learning
103891,26,half-true,PyTorch and TensorFlow tensors use identical underlying memory layouts and interchangeably share data without copying.,tensor interoperability between PyTorch and TensorFlow,"Correct that both define tensors similarly, but incorrect about identical memory layouts and zero-copy interchangeability.","deep-learning,frameworks,tensors",5,Deep Learning
103892,70,barely-true,"PCA creates a single, fully accurate 'PCA Power Score' that perfectly summarizes each hero's abilities.",PCA on superheroes_powers dataset with StandardScaler and n_components=1,"Overstates PCA: passage says it condenses powers into one score, not that it perfectly or fully summarizes abilities.","machine-learning,classification,evaluation",4,Classical Machine Learning
103893,70,barely-true,PCA creates a single reliable power score that perfectly summarizes heroes' abilities.,PCA on superheroes_powers dataset with StandardScaler and n_components=1,Overreaches: PCA produces a condensed score but not guaranteed reliable or perfect summary of abilities.,"machine-learning,classification,evaluation",4,Classical Machine Learning
103894,70,TRUE,PCA was applied to the superheroes_powers dataset to create a single PCA Power Score.,dimensionality reduction on superheroes_powers dataset using PCA and StandardScaler,Passage explicitly describes using Scikit-Learn PCA with n_components=1 to produce a single score after standardization.,"machine-learning,classification,evaluation",4,Classical Machine Learning
103895,17,TRUE,Open-source projects often include CONTRIBUTING.md files to guide new contributors.,CONTRIBUTING.md and issue tags in project repositories,Passage explicitly recommends looking for CONTRIBUTING.md and issue tags like good first issue.,"open-source,community,contribution",13,Commit to Contribute
103896,17,half-true,A CONTRIBUTING.md file always guarantees straightforward onboarding for new contributors.,open-source CONTRIBUTING.md and issue labels,Guidelines often help but claiming they always guarantee straightforward onboarding ignores variability in clarity and maintainer responsiveness.,"open-source,community,contribution",13,Commit to Contribute
103897,17,TRUE,Open-source projects with CONTRIBUTING.md and issue labels invite contributors clearly.,"CONTRIBUTING.md, issue tags like good first issue, help wanted",Directly supported by guidance citing CONTRIBUTING.md and labels as clear invitations to contribute.,"open-source,community,contribution",13,Commit to Contribute
103898,36,barely-true,The LSTM model in the example uses 64 units in its recurrent layer.,Keras LSTM layer units in the provided model example,"Example actually specifies 32 LSTM units, so claiming 64 is a notable incorrect detail.","neural-networks,cnn,transformers",6,Neuron Building Blocks
103899,36,FALSE,The LSTM example uses bidirectional LSTM layers to capture past and future context.,Keras LSTM example with LSTM(32) layer,"Example shows a single unidirectional LSTM(32) layer, not any Bidirectional wrapper or reverse pass.","neural-networks,cnn,transformers",6,Neuron Building Blocks
103900,36,barely-true,The LSTM example trains a network suitable for complex long-range language modeling tasks.,"LSTM network in Keras, 32 units, time series input",Overstates capability: 32-unit single-layer LSTM on small random data is unlikely adequate for complex long-range language modeling.,"neural-networks,cnn,transformers",6,Neuron Building Blocks
103901,207,barely-true,Deep learning frameworks always require manual training loops for model training.,training loops and optimizers in deep-learning frameworks,"Overreaches the passage: training loops discussed, but many frameworks provide automatic training APIs and higher-level tools.","deep-learning,frameworks,tensors",5,Deep Learning
103902,207,barely-true,Deep learning foundations guarantee ready-to-use models for all specialized roles like CNNs and Transformers.,"foundations, optimizers, tensors and model types","Overstates support: passage says foundations were built, not that ready-to-use models are guaranteed.","deep-learning,frameworks,tensors",5,Deep Learning
103903,3,TRUE,GenAI chatbots effectively summarize documents to extract themes for further prompting.,prompting tip about document summarization and GenAI chatbots,Directly supported by the tip recommending GenAI chatbots for summarization and theme extraction before deeper prompts.,"ai,tool-chain,notebooks",2,AI Survival Kit
103904,3,TRUE,GenAI chatbots excel at summarizing documents to extract themes for follow-up prompts.,prompting with a draft document and summarization,Directly supported by the tip recommending GenAI chatbots for document summarization and theme extraction.,"ai,tool-chain,notebooks",2,AI Survival Kit
103905,3,barely-true,"GenAI chatbots always produce accurate, publication-ready image concepts and color palettes.",tip about GenAI chatbots for document summarization and visuals,Overreaches beyond passage; passage praises summarization but not guaranteed image or palette accuracy.,"ai,tool-chain,notebooks",2,AI Survival Kit
103906,3,half-true,The chatbot correctly refused to recreate the Metropolis (1927) robot due to copyright concerns.,copyright policy applied to a protected character design,"Accurately reflects refusal and copyright rationale, but omits nuance about fair use or transformation exceptions.","security,red-team,guardrails",8,Breaking-Securing AI
103907,3,half-true,The chatbot refused an image request citing the Metropolis robot design as protected copyrighted work.,copyright claim about a protected design in a prompt,Mixes correct refusal with overgeneralization: protection claim is plausible but specific legal basis not shown.,"security,red-team,guardrails",8,Breaking-Securing AI
103908,3,TRUE,The chatbot refused to reproduce the Metropolis (1927) robot design due to copyright concerns.,copyright protection for Metropolis robot design in model guardrails,Directly supported by passage: chatbot cites protected work and refusal to reproduce robot design.,"security,red-team,guardrails",8,Breaking-Securing AI
103909,89,half-true,"The classifier flags prompts as injections when confidence score exceeds 0.7, but threshold mislabels some benign prompts.",Colab notebook classifier confidence score and 0.7 threshold,Describes rule correctly but mixes correct mechanism with implied misclassification risk from limited threshold and mixed test prompts.,"security,red-team,guardrails",8,Breaking-Securing AI
103910,89,mostly-true,The paper uses a 0.7 confidence-threshold classifier to flag prompt injection attempts.,Colab notebook evaluation using classifier confidence score,Directly supported by passage: classifier confidence and 0.7 threshold used to flag injection attempts; minor implementation details omitted.,"security,red-team,guardrails",8,Breaking-Securing AI
103911,89,half-true,The notebook flags prompts as injections when the classifier score exceeds a 0.7 threshold.,Colab notebook classifier confidence score threshold,"Accurately states threshold rule but omits that dataset mixes straightforward prompts and blatant injections, oversimplifying performance implications.","security,red-team,guardrails",8,Breaking-Securing AI
103912,36,FALSE,All sparse fields like Skin color should always be removed from datasets.,cleaning action plan for superheroes_info dataset,"Contradicts passage which suggests sparse fields are candidates for removal, not mandatory removal.","data-prep,feature-engineering,rag",3,Prepping Data for AI
103913,36,half-true,"Some dataset fields, like Skin color, should be removed while others need little cleaning effort.",superheroes_info dataset field selection and cleaning,Mixes correct dataset pruning suggestion with oversimplification about effort needed for retaining fields like Gender.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
103914,36,pants-fire,All sparse fields must always be deleted from datasets before model training.,"dataset cleaning for superheroes_info, sparse fields like Skin color",Directly contradicts passage guidance that sparse fields are candidates for removal but not mandatory; overrules systematic cleaning plan.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
103915,39,TRUE,A live leaderboard on MT-Bench shows proprietary models leading overall.,"MT-Bench leaderboard, models like Gemini 2.5 Pro and LLaMA-4 Maverick",Passage reports Gemini 2.5 Pro top and says proprietary models still lead much of the field.,"mlops,scaling,deployment",10,AI At Scale
103916,39,TRUE,Open-source models are beginning to achieve competitive rankings on MT-Bench leaderboards.,MT-Bench live leaderboard showing model rankings,"Leaderboard shows open-source challengers like DeepSeek-V3 tying with commercial models, indicating growing competitiveness.","mlops,scaling,deployment",10,AI At Scale
103917,39,barely-true,Open-source models are already outperforming most proprietary models in MT-Bench rankings.,"MT-Bench leaderboard model rankings (Gemini 2.5 Pro, LLaMA-4 Maverick)",Leaderboard shows proprietary models still leading; open-source are starting to compete but not outperform most.,"mlops,scaling,deployment",10,AI At Scale
103918,109,TRUE,Scene detection identifies distinct video segments using visual or audio changes.,scene detection concept in video analysis,Passage explicitly describes scene detection as identifying distinct segments based on visual or audio changes.,"media-forensics,voice-cloning,deepfake",9,Deepfake Defense
103919,109,FALSE,Scene detection exclusively relies on biometric voiceprints to segment videos.,scene detection in video analysis,"Contradicts passage detail: scene detection uses visual or audio changes, not solely biometric voiceprints.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
103920,109,barely-true,Deepfake voice cloning can be reliably detected using simple scene detection techniques.,scene detection and object detection in video analysis,"Overreaches: scene detection targets visual/audio segmentation, not voice-cloning detection, omitting specialized audio or forensic tools.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
103921,91,half-true,"Saving versioned model checkpoints ensures reproducible, auditable model records for scalable deployment.","versioned checkpoint, benchmark log, reproducibility","Accurate about checkpoints and logs enabling reproducibility, but overstates guarantee for scalable deployment without operational details.","mlops,scaling,deployment",10,AI At Scale
103922,91,barely-true,Saving model checkpoints alone guarantees full reproducibility and auditability for scaled deployments.,"model checkpoint, versioning, benchmark log in ML deployment","Overstates reproducibility: checkpoints help but require dataset provenance, environment, and benchmark details.","mlops,scaling,deployment",10,AI At Scale
103923,91,FALSE,The passage asserts model checkpoints are unnecessary for reproducibility in deployment.,versioned checkpoint and benchmark log for model record,"Contradicts passage detail that saving versioned checkpoints plus benchmark logs creates auditable, reproducible model records.","mlops,scaling,deployment",10,AI At Scale
103924,14,TRUE,Adversarial prompts can bypass model filters and elicit unintended behavior from LLMs.,prompt-based attacks on models and guardrails,Passage states unguarded prompts allow coercing models to reveal secrets and bypass filters.,"security,red-team,guardrails",8,Breaking-Securing AI
103925,14,half-true,Adversarial prompts can sometimes bypass model filters and elicit unintended or secret outputs.,prompt injection and filter bypass in LLM-based apps,Accurately notes filter bypass risk but overstates frequency and ease without empirical evidence.,"security,red-team,guardrails",8,Breaking-Securing AI
103926,14,pants-fire,The passage claims prompts can never be secured against any bypass techniques.,prompt security and model guardrails,"Contradicts passage implication that prompts are often unguarded, not absolutely unsecurable; overstates impossibility.","security,red-team,guardrails",8,Breaking-Securing AI
103927,190,TRUE,Optimizer.step() applies computed gradients to update a model's weights and biases during training.,training loop; optimizer.step() and computed gradients,Directly described: optimizer.step() uses gradients to adjust network weights and biases during training.,"deep-learning,frameworks,tensors",5,Deep Learning
103928,190,barely-true,Optimizer.step() always updates all model parameters simultaneously using full-batch gradients.,training loop with optimizer.step() and gradients,"Overreaches: optimizer.step() applies computed updates but may use mini-batches, sparse updates, or selective parameter updates.","deep-learning,frameworks,tensors",5,Deep Learning
103929,190,FALSE,Optimizer.step() directly computes gradients for the network parameters during training.,training loop; optimizer.step() and gradients,"Contradicts passage: gradients are computed by backpropagation (e.g., loss.backward()), not by optimizer.step().","deep-learning,frameworks,tensors",5,Deep Learning
103930,83,TRUE,VAEs use a probabilistic framework that makes them easier to train and interpret than GANs.,variational autoencoders (VAE) probabilistic framework and training,Passage explicitly contrasts VAEs with GANs and states VAEs are easier to train and interpret.,"generative-ai,diffusion,gans",7,Generative AI
103931,83,barely-true,VAEs are easier to train and interpret than GANs due to their probabilistic framework.,variational autoencoder (VAE) probabilistic framework,"Passage claims VAEs use probabilistic learning and states they are easier to train and interpret, a notable simplification.","generative-ai,diffusion,gans",7,Generative AI
103932,83,TRUE,VAEs use a probabilistic framework to learn data structure and generate new examples.,variational autoencoder (VAE) probabilistic framework and generation,Passage states VAEs rely on a probabilistic framework and are effective for generating and reconstructing examples.,"generative-ai,diffusion,gans",7,Generative AI
103933,36,TRUE,"The MNIST dataset contains 70,000 grayscale 28×28 pixel images of handwritten digits.","MNIST dataset (70,000 images, 28×28 pixels)","Passage specifies 70,000 grayscale handwritten digit images at 28×28 pixels with 60k train and 10k test.","deep-learning,frameworks,tensors",5,Deep Learning
103934,36,TRUE,"MNIST contains 70,000 grayscale 28×28 pixel images of handwritten digits.","MNIST dataset; 60,000 training and 10,000 testing images","Passage specifies MNIST totals and 28×28 grayscale format with 60,000 training and 10,000 test images.","deep-learning,frameworks,tensors",5,Deep Learning
103935,36,mostly-true,"MNIST contains 70,000 28×28 grayscale images split into 60,000 train and 10,000 test examples.",dataset MNIST handwritten digits images,"Passage specifies 70,000 total images and the 60,000/10,000 train-test split, matching details exactly.","deep-learning,frameworks,tensors",5,Deep Learning
103936,32,half-true,Scikit-learn trains a linear regression model using model.fit and then predicts with model.predict.,code usage for model.fit and model.predict in regression,"Accurately states training and prediction calls, but ignores data filtering impact and Species/Deities detail.","machine-learning,classification,evaluation",4,Classical Machine Learning
103937,32,barely-true,Scikit-learn trains regression models using model.fit and generates predictions with model.predict.,"Scikit-learn regression API (model.fit, model.predict)",Accurate method description but overgeneralizes capabilities and ignores preprocessing like filtering Species.,"machine-learning,classification,evaluation",4,Classical Machine Learning
103938,32,mostly-true,Scikit-learn trains a regression model using fit and produces predictions with predict.,model.fit and model.predict calls in Scikit-learn regression,Directly described: fit trains on X_train/y_train and predict generates predictions on X_test.,"machine-learning,classification,evaluation",4,Classical Machine Learning
103939,32,FALSE,Training for more epochs always improves generalization performance of deep learning models.,training epochs and overfitting in deep learning,"Contradicts passage details: continued epochs can plateau and cause overfitting, not always improve generalization.","deep-learning,frameworks,tensors",5,Deep Learning
103940,32,half-true,Training longer always wastes compute because models always plateau and then overfit.,training epochs and overfitting in deep learning,Combines correct plateau and overfitting risks with overgeneralization that training always wastes compute.,"deep-learning,frameworks,tensors",5,Deep Learning
103941,32,FALSE,Training longer always improves a model's generalization to new data.,training epochs and overfitting in deep learning,Contradicts passage: extended training can cause overfitting and offers little to no improvement.,"deep-learning,frameworks,tensors",5,Deep Learning
103942,93,pants-fire,Provenance is never useful for addressing model misinformation in any scenario.,provenance of model training data and configuration,Contradicts passage claiming provenance builds clarity; asserts absolute uselessness of provenance.,"mlops,scaling,deployment",10,AI At Scale
103943,93,barely-true,Model provenance must always be publicly visible rather than stored privately.,provenance of model training data and configuration,"Overreaches passage: emphasizes visibility but passage says trail should be visible, not necessarily publicly mandatory.","mlops,scaling,deployment",10,AI At Scale
103944,93,mostly-true,Provenance visibility broadly improves trust in models when addressing misinformation.,provenance of model training data and configuration,Passage supports provenance transparency as enhancing trust but omits operational challenges and implementation details.,"mlops,scaling,deployment",10,AI At Scale
103945,86,pants-fire,Francesca Rossi claims emergent AI behavior is entirely harmless and needs no governance.,perspective on emergent behavior and responsible governance,Contradicts passage: Rossi emphasized need for responsible governance regarding emergent behavior.,"ethics,governance,privacy",11,AI Ethics and Governance
103946,86,half-true,Rossi's views blend correct privacy concerns with overstated claims about emergent behavior governance.,"perspective on privacy, fairness, emergent behavior, responsible governance",Mixes accurate privacy and fairness emphasis with exaggerated governance claims about emergent risks.,"ethics,governance,privacy",11,AI Ethics and Governance
103947,86,TRUE,"Francesca Rossi emphasized privacy, fairness, emergent behavior, and responsible governance in her reflections.",Francesca Rossi reflections on privacy and governance,"Directly supported by passage listing privacy, fairness, emergent behavior, and responsible governance as themes.","ethics,governance,privacy",11,AI Ethics and Governance
103948,78,FALSE,All AI builders always start entirely from scratch when training models.,"pretrained model from Hugging Face, fine-tuning",Contradicts passage statement that most builders begin with existing pretrained models and fine-tune them.,"ai,tool-chain,notebooks",2,AI Survival Kit
103949,78,barely-true,Most AI builders always fine-tune pretrained models before any project work.,use of pretrained model from Hugging Face in tool-chain examples,Overreaches passage: it says most begin with existing models but not that fine-tuning always occurs.,"ai,tool-chain,notebooks",2,AI Survival Kit
103950,78,barely-true,Most AI builders always fine-tune pretrained models for specialized domains like legal or medical language.,using a pretrained model from Hugging Face in tool-chain examples,"Overstates frequency by saying ""always""; passage says ""few start entirely from scratch"" and ""most begin"" without universal claim.","ai,tool-chain,notebooks",2,AI Survival Kit
103951,133,half-true,Retraining input classifiers with adversarial examples will immediately block previously successful prompt injections.,"adversarial inputs, Gandalf-trained filter, LYNX output reviewer","Correct that retraining uses adversarial examples, but 'immediately block' overstates speed and guarantees of prevention.","security,red-team,guardrails",8,Breaking-Securing AI
103952,133,mostly-true,Operators should retrain input classifiers and adjust thresholds after adversarial prompt injections.,adversarial input classifier (Gandalf-trained filter) and LYNX output reviewer,Passage advises using real adversarial inputs to retrain classifiers and tune confidence thresholds immediately.,"security,red-team,guardrails",8,Breaking-Securing AI
103953,133,TRUE,Retraining the input classifier with newly successful adversarial inputs improves chatbot defenses.,adversarial input classifier (Gandalf-trained filter) and LYNX reviewer,Passage explicitly advises retraining the injection classifier using successful adversarial inputs and adjusting thresholds.,"security,red-team,guardrails",8,Breaking-Securing AI
103954,31,TRUE,StyleGAN2-ADA can generate realistic human faces using a pretrained FFHQ model.,pretrained FFHQ model and StyleGAN2-ADA generate.py script,"Example code downloads ffhq.pkl and runs generate.py, producing realistic face images as shown.","generative-ai,diffusion,gans",7,Generative AI
103955,31,half-true,StyleGAN2-ADA can generate highly realistic human faces using a pretrained FFHQ model.,pretrained FFHQ model and StyleGAN2-ADA generate.py script,Mixes correct capability with implied universality; realistic outputs shown but not guaranteed across seeds or settings.,"generative-ai,diffusion,gans",7,Generative AI
103956,31,barely-true,StyleGAN2-ADA can produce realistic human faces using a pretrained FFHQ model and a few commands.,pretrained FFHQ model and generate.py script,"Passage shows commands downloading ffhq.pkl and running generate.py, but realism claim is subjective and overstated.","generative-ai,diffusion,gans",7,Generative AI
103957,62,half-true,"Inference time grows with input length, and CPU latency increases far more than GPU latency.",benchmark_inference_time on T5-small comparing GPU and CPU,Plot reports increasing latency with length but overstates relative GPU vs CPU magnitudes without exact numbers.,"mlops,scaling,deployment",10,AI At Scale
103958,62,half-true,"Inference latency for T5 increases with input length, and CPU slowdown is substantially larger than GPU.",benchmark_inference_time on T5-small using GPU and CPU,Plot shows latency rising on both devices but exaggerates CPU gap without reporting exact durations or variance.,"mlops,scaling,deployment",10,AI At Scale
103959,62,pants-fire,All models run faster on CPU than GPU at longer input lengths.,benchmarking T5-small inference times on GPU and CPU,Directly contradicts reported GPU superiority; passage states CPU is dramatically slower at longer inputs.,"mlops,scaling,deployment",10,AI At Scale
103960,0,TRUE,AI can clone voices to teach detection and defense against synthetic audio.,voice cloning hands-on exercise in deepfake defense,Passage explicitly describes cloning a voice as a hands-on exercise to learn how cloning works and defend against it.,"media-forensics,voice-cloning,deepfake",9,Deepfake Defense
103961,0,half-true,Researchers can clone voices using neural networks to study defenses against misuse.,hands-on voice cloning exercise using neural networks,"Passage explicitly describes cloning a voice as a learning exercise with neural networks, but omits specifics about datasets, models, or success rates.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
103962,110,barely-true,Red-team exercises alone guarantee discovery of all AI security vulnerabilities in deployed models.,pressure-testing with red and blue teams for model security,"Overreaches: passage endorses pressure-testing but notes layered defenses and varied failures, not guaranteed discovery.","security,red-team,guardrails",8,Breaking-Securing AI
103963,110,TRUE,Red and blue team exercises are recommended to pressure-test AI system defenses.,layered defensive strategy and red/blue team exercises,Passage explicitly advocates pressure-testing with red and blue teams as final defensive step.,"security,red-team,guardrails",8,Breaking-Securing AI
103964,110,half-true,Red-team pressure testing finds both attack techniques and implementation gaps in AI defenses.,red-team pressure-testing of defensive layers and AI lifecycle safeguards,Accurately mixes truth about finding attacks with implicit overreach about universal implementation gaps; passage emphasizes testing reveals issues but doesn't quantify gaps.,"security,red-team,guardrails",8,Breaking-Securing AI
103965,56,TRUE,AI enables machines to perform tasks requiring human-like reasoning and decision-making.,definition of AI and examples like speech recognition,Passage defines AI as simulating human-like intelligence and lists examples such as speech recognition and diagnosis.,"ai,tool-chain,notebooks",2,AI Survival Kit
103966,56,barely-true,AI primarily relies on large neural networks trained on massive datasets to perform all tasks.,"definition of AI and examples (neural networks, speech recognition)","Overstates and generalizes methods; passage notes rule-based systems and historical varieties, not exclusively large neural networks.","ai,tool-chain,notebooks",2,AI Survival Kit
103967,3,FALSE,Classical machine learning involves models that use handcrafted features rather than deep learning.,prompt mentioning classical machine learning and image-generation tips,"Contradicts passage: passage only gives a creative image prompt, not claims about features or model types.","machine-learning,classification,evaluation",4,Classical Machine Learning
103968,3,half-true,The prompt asks for a Beethoven-inspired superhero wielding classical machine learning tools in a cartoon image.,image prompt for AI-generated artwork with dataset-style details,"Accurately describes Beethoven inspiration and ML tools, but overstates 'wielding' specifics and dataset framing.","machine-learning,classification,evaluation",4,Classical Machine Learning
103969,3,barely-true,The image prompt claims classical machine learning uses musical tools as visual metaphors.,image prompt mentioning classical machine learning and Beethoven,"Largely unsupported: passage only suggests a visual metaphor in a single prompt, not actual use of musical tools.","machine-learning,classification,evaluation",4,Classical Machine Learning
103970,81,barely-true,The dataset split used 10% of audio for testing with a fixed seed for reproducibility.,"train/test split, test_size=0.1, seed=42","Split detail is stated, but claiming broad dataset-level reproducibility overreaches given only a single seed and no protocol details.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
103971,81,mostly-true,The dataset split used a fixed random seed and a 10% test_size for reproducible evaluation.,"dataset split, test_size=0.1 and seed=42",Passage specifies test_size=0.1 and seed=42 for reproducible train/test splitting; minor implementation details omitted.,"media-forensics,voice-cloning,deepfake",9,Deepfake Defense
103972,81,barely-true,The code splits audio data with test_size=0.1 and seed=42 for reproducible train/test sets.,"train/test split parameters (test_size, seed) in dataset preprocessing","Passage mentions test_size=0.1 and seed=42, but claim overstates reproducibility guarantees across environments.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
103973,143,half-true,Model misclassification of DC characters as Marvel stems partly from dataset imbalance and pattern strength.,classification error analysis on imbalanced dataset (DC vs Marvel),"Mixes correct diagnosis (imbalance, stronger Marvel signals) with implied sole causation, missing other model issues.","machine-learning,classification,evaluation",4,Classical Machine Learning
103974,143,half-true,The classifier more often mislabels DC characters as Marvel due to class imbalance and stronger Marvel features.,classification model errors on DC vs Marvel dataset,"Accurately notes imbalance and stronger Marvel signals, but overstates causality without model diagnostics.","machine-learning,classification,evaluation",4,Classical Machine Learning
103975,143,pants-fire,The model intentionally mislabels most DC characters as Marvel to sabotage results.,dataset class imbalance in classification of DC vs Marvel characters,"Asserts deliberate sabotage, but passage attributes errors to fewer DC examples and feature signals, not intentional mislabeling.","machine-learning,classification,evaluation",4,Classical Machine Learning
103976,105,half-true,Running models locally always yields faster inference than remote hosted services.,running the model locally; GPU inference,"Local control and GPU often speed inference, but 'always' ignores network, optimized hosted GPUs, and workload differences.","mlops,scaling,deployment",10,AI At Scale
103977,105,TRUE,Running models locally gives users complete environment control and often faster inference with a GPU.,running the model locally; environment control; GPU inference,"Passage explicitly states local use provides complete control and often faster inference, especially with a GPU.","mlops,scaling,deployment",10,AI At Scale
103978,105,TRUE,Running an ML model locally gives the user complete environment control and often faster inference.,running the model locally; GPU-enabled local inference,"Passage explicitly states local use gives complete control and often faster inference, especially with a GPU.","mlops,scaling,deployment",10,AI At Scale
103979,155,half-true,FLAN-T5's decoder generates text token-by-token using self-attention over past outputs.,"decoder behavior in FLAN-T5 model, multi-head self-attention","Accurately states token-by-token generation and self-attention, but omits training specifics and stopping criteria.","generative-ai,diffusion,gans",7,Generative AI
103980,155,pants-fire,Diffusion models generate text token-by-token using a decoder like FLAN-T5.,decoder behavior in FLAN-T5 text generation,Contradicts passage: diffusion models are different family; passage describes autoregressive decoder token generation.,"generative-ai,diffusion,gans",7,Generative AI
103981,155,barely-true,FLAN-T5’s decoder generates entire sentences in one step without using previous tokens.,decoder autoregressive token generation in FLAN-T5,"Contradicts described autoregressive process: decoder uses previous outputs and self-attention, so claim is largely unsupported.","generative-ai,diffusion,gans",7,Generative AI
103982,44,barely-true,Logistic regression always outperforms decision trees on classification accuracy.,"supervised classification, logistic regression and decision trees","Passage says logistic regression is a reliable baseline and trees offer transparency, not superiority in accuracy.","machine-learning,classification,evaluation",4,Classical Machine Learning
103983,44,mostly-true,"Logistic regression and decision trees offer complementary, practical baselines for supervised classification.","supervised classification models (logistic regression, decision tree)",Both models are presented as complementary baselines; minor caveat about specific trade-offs omitted.,"machine-learning,classification,evaluation",4,Classical Machine Learning
103984,44,TRUE,Logistic regression and decision trees provide complementary baselines for supervised classification tasks.,model evaluation metrics for supervised classification,"Passage states logistic regression is a fast, reliable baseline and decision trees offer transparent model logic, highlighting complementary trade-offs.","machine-learning,classification,evaluation",4,Classical Machine Learning
103985,86,mostly-true,The dataset provides a reasonable foundation for practicing traditional superhero modeling despite some imbalance.,dataset quality assessment using Gini coefficient and EDA,"Supports dataset usefulness for practice while noting imbalance quantified by Gini, minor caveat omitted.","data-prep,feature-engineering,rag",3,Prepping Data for AI
103986,86,TRUE,Exploratory data analysis quantified class imbalance using the Gini coefficient.,dataset EDA for superhero modeling using Gini coefficient,Passage explicitly states EDA was used and imbalance was quantified with the Gini coefficient.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
103987,86,half-true,The dataset's imbalance was measured using the Gini coefficient for superhero modeling.,dataset imbalance measurement using Gini coefficient,"Accurate about using Gini, but mixes correct method with overstated generality about dataset suitability.","data-prep,feature-engineering,rag",3,Prepping Data for AI
103988,48,TRUE,"Hugging Face emphasizes an open-source, community-led AI ecosystem.","Hugging Face ecosystem: models, datasets, Spaces, model cards","Multiple sources cite community collaboration, many shared models/datasets, and ecosystem features.","open-source,community,ai",0,Foreword – Robo Interviews Clément Delangue
103989,48,mostly-true,Hugging Face broadly fosters an open-source community with extensive shared models and datasets.,"Hugging Face ecosystem: models, datasets, Spaces, model cards","Community scale and ecosystem features are documented, though exact numbers and future goals are slightly summarized.","open-source,community,ai",0,Foreword – Robo Interviews Clément Delangue
103990,48,barely-true,Hugging Face single-handedly democratizes AI for the entire global developer community.,"Hugging Face ecosystem: models, datasets, Spaces, community","Overstates platform's role and impact despite cited models, datasets, and community features; significant overreach.","open-source,community,ai",0,Foreword – Robo Interviews Clément Delangue
103991,76,half-true,Speaker embeddings alone guarantee robust voice-cloning model performance across audio conditions.,speaker embeddings and audio numerical representations,"Correct that embeddings capture vocal traits, but overstated — performance also needs data quality, model architecture, and noise handling.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
103992,76,mostly-true,Speaker embeddings capture vocal traits like tone and rhythm for audio-based model training.,audio dataset preprocessing with speaker embeddings,"Supported by passage describing numerical representations and speaker embeddings encoding tone and rhythm, omitting minor implementation specifics.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
103993,76,barely-true,Speaker embeddings alone reliably detect deepfake voice recordings across diverse conditions.,speaker embeddings from audio-transcript datasets,Overreaches: passage notes embeddings capture vocal traits but gives no evidence they reliably detect deepfakes or handle diverse conditions.,"media-forensics,voice-cloning,deepfake",9,Deepfake Defense
103994,187,barely-true,RAG can fully replace model training for deep reasoning and long-term correctness.,"RAG and training, retrieval-augmented generation",Contradicts passage: RAG aids timely info but explicitly does not replace training or deep reasoning.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
103995,187,mostly-true,RAG augments models with timely information but isn't a substitute for full model training.,retrieval-augmented generation (RAG) for timely information,Supports RAG's role delivering up-to-date data while noting it shouldn't replace training or deep reasoning.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
103996,187,TRUE,RAG provides timely information but is not a substitute for model training.,retrieval-augmented generation (RAG) and model training,Passage states RAG conveys timely information yet should not replace training or deep reasoning.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
103997,141,barely-true,The confusion matrix shows the model confused DC and Marvel labels frequently.,"confusion matrix for classifier labels (DC, Marvel)","Counts show 13 DC→Marvel and 5 Marvel→DC misclassifications, overstating overall frequency.","machine-learning,classification,evaluation",4,Classical Machine Learning
103998,141,barely-true,The confusion matrix shows most DC heroes were correctly classified over Marvel heroes.,confusion_matrix counts for predicted and true labels,"Counts show 19 DC correct versus 13 DC→Marvel and 5 Marvel→DC, but claim overstates majority trend.","machine-learning,classification,evaluation",4,Classical Machine Learning
103999,141,pants-fire,The model deliberately flips all Marvel labels to DC on purpose.,confusion matrix for classification of DC and Marvel heroes,"Directly contradicts confusion matrix counts: misclassifications are limited (13 and 5), not universal flipping.","machine-learning,classification,evaluation",4,Classical Machine Learning
104000,9,half-true,Contributing to open-source AI always delivers clear career advancement and guaranteed widespread influence.,"open-source AI contribution, resume and trust claims","Mixes accurate benefits (resume boost, trust) with overstated guarantees about universal career gains and influence.","open-source,community,contribution",13,Commit to Contribute
104001,9,TRUE,Contributing to open-source AI builds trust and accelerates code maturity.,"open-source AI contribution, transparency and code maturity",Passage explicitly links openness and contributing to open-source AI with trust and accelerated code maturity.,"open-source,community,contribution",13,Commit to Contribute
104002,9,barely-true,Contributing to open-source AI always guarantees faster career advancement and tangible resume benefits.,"open-source AI contribution, trust, resume benefit","Overstates claim: passage says it 'looks great on your resume' and is smart, not a guaranteed faster career advancement.","open-source,community,contribution",13,Commit to Contribute
104003,23,TRUE,Benchmarks help builders compare and interpret model performance across language and image tasks.,AI Benchmarks evaluation dataset and benchmarks,"Text lists multiple benchmarks and a benchmarking dataset for language, reasoning, translation, and image evaluation.","mlops,scaling,deployment",10,AI At Scale
104004,23,barely-true,Benchmarks reliably predict real-world model behavior across all deployment scenarios.,AI Benchmarks dataset and evaluation benchmarks for models,Overstates support: benchmarks illustrate behaviors but do not reliably predict all deployment outcomes or scenarios.,"mlops,scaling,deployment",10,AI At Scale
104005,23,mostly-true,Benchmarking datasets broadly help builders assess model performance across language and vision tasks.,"AI Benchmarks dataset for language, reasoning, translation, and image processing","Passage says benchmarks span language, reasoning, translation, and image tasks and help builders choose and interpret results.","mlops,scaling,deployment",10,AI At Scale
104006,48,half-true,A single np.all(gradient >= 0) check reliably determines which attributes need improvement.,numpy gradient check in notebooks,"Correct that np.all tests nonnegativity, but it misstates reliability and ignores equality and negative-exceeding cases.","ai,tool-chain,notebooks",2,AI Survival Kit
104007,48,mostly-true,A single np.all(gradient >= 0) check broadly verifies whether all attributes still need improvement.,optimization snippet using numpy gradient and np.all,"Code shows np.all determines if every gradient is nonnegative, but omits edge cases and sign conventions.","ai,tool-chain,notebooks",2,AI Survival Kit
104008,48,FALSE,The code always detects when some attributes already exceed their targets.,np.all(gradient >= 0) check on gradient array,Contradicts behavior: np.all(gradient >= 0) returns true only if no attributes exceed targets.,"ai,tool-chain,notebooks",2,AI Survival Kit
104009,70,barely-true,Open-source projects always let anyone contribute meaningful model improvements.,open-source collaboration in BigScience and ChromaDB projects,Overstates accessibility and impact; projects enabled contributions but not everyone produces meaningful model improvements.,"open-source,community,contribution",13,Commit to Contribute
104010,70,TRUE,ChromaDB is an open-source vector database optimized for embedding-based retrieval.,tool description mentioning ChromaDB and embedding-based retrieval,Passage explicitly describes ChromaDB as an open-source vector database optimized for embedding-based retrieval used in RAG workflows.,"open-source,community,contribution",13,Commit to Contribute
104011,70,barely-true,Open-source vector databases are essential for all retrieval-augmented generation workflows.,ChromaDB vector database for embedding-based retrieval,"Overstates necessity: passage notes ChromaDB is used in RAG, not that such databases are essential for every workflow.","open-source,community,contribution",13,Commit to Contribute
104012,45,pants-fire,Delangue secretly built a banned autonomous weapon using Hugging Face codebase.,open-source model codebase and community adoption,"Claim wildly contradicts passage details about education, UniShared, Moodstocks and emoji origin; implausible and unsupported.","open-source,community,ai",0,Foreword – Robo Interviews Clément Delangue
104013,45,TRUE,Clément Delangue co-founded Hugging Face and fostered strong open-source community adoption.,founder background and community adoption of Hugging Face,Multiple sources corroborate Delangue's founder role and strong community-driven open-source adoption evidence.,"open-source,community,ai",0,Foreword – Robo Interviews Clément Delangue
104014,45,barely-true,Delangue single-handedly created UniShared without community contributions or open-source input.,origin story and community adoption of UniShared and emoji name,"Claims contradict cited corroboration about community adoption and multiple-source confirmation, overstating individual authorship.","open-source,community,ai",0,Foreword – Robo Interviews Clément Delangue
104015,140,half-true,LangChain reliably merges retrieved plot and characters into a cohesive story arc.,RAG pipeline using LangChain with a generative model,"Accurate about combining retrieval and generation, but overstates reliability and seamlessness.","data-prep,feature-engineering,rag",3,Prepping Data for AI
104016,140,TRUE,LangChain combines retrieved plot and chosen characters to generate a cohesive story arc.,retrieval-augmented generation using LangChain and a generative model,Passage explicitly states LangChain merges retrieved plot with characters and sends it to a generative model producing a cohesive story arc.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
104017,140,FALSE,LangChain does not use retrieved plots when generating stories.,LangChain retrieval-augmented generation combining plot and characters,Directly contradicts passage which says LangChain combines retrieved plot with characters for generation.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
104018,41,barely-true,Logistic regression always fails on datasets with any non-linear patterns.,"logistic regression model, non-linear patterns",Overstates limitation: logistic regression can still perform on mild non-linearities and with feature engineering.,"machine-learning,classification,evaluation",4,Classical Machine Learning
104019,41,half-true,Logistic regression always outperforms decision trees on linear datasets with clear boundaries.,model comparison: logistic regression vs decision tree on clear boundaries,"Mixes correct idea (logistic regression excels with clear boundaries) with overgeneralization ('always outperforms') ignoring dataset size, regularization, or tree tuning.","machine-learning,classification,evaluation",4,Classical Machine Learning
104020,41,mostly-true,"Logistic regression is generally fast, interpretable, and performs well when class boundaries are clear.","classification model comparison (logistic regression, decision trees)",Passage endorses speed and interpretability but notes limitations on complex or non-linear boundaries.,"machine-learning,classification,evaluation",4,Classical Machine Learning
104021,85,TRUE,Normalizing inputs to mean zero and unit variance stabilizes neural network training.,"input normalization, pre-activation values, optimizer stability","Passage explains varied input scales cause spikes or collapse, so normalizing to mean 0 and std 1 prevents instability.","deep-learning,frameworks,tensors",5,Deep Learning
104022,85,barely-true,Normalization always prevents instability from varying input feature scales in neural networks.,input normalization to mean 0 and standard deviation 1,Overreaches: normalization helps but doesn't always prevent instability; other issues and techniques matter.,"deep-learning,frameworks,tensors",5,Deep Learning
104023,85,mostly-true,Normalization of neural network inputs typically scales features to zero mean and unit variance.,"input normalization (mean 0, standard deviation 1) for neural network pre-activations",Passage explains normalizing inputs to mean 0 and standard deviation 1 prevents unstable pre-activation spikes or collapse.,"deep-learning,frameworks,tensors",5,Deep Learning
104024,22,barely-true,Robby single-handedly authored most commits across multiple open-source projects.,commit logs and community-led fork in open-source contribution,"Claim overstates authorship; passage notes Robby listed 14,233 times but explicitly not acting alone.","open-source,community,contribution",13,Commit to Contribute
104025,22,mostly-true,Robby frequently contributed to open-source projects and community-led forks.,commit logs and open-sourced model weights,"Narrative shows many contributions (14,233 commit mentions) and open-sourced weights, minor caveat about sole authorship.","open-source,community,contribution",13,Commit to Contribute
104026,22,TRUE,Robby contributed extensively to open-source projects and community-led development efforts.,"open-source contribution, commit logs, community-led fork","Passage reports Robby listed 14,233 times in commit logs and participating in fork and model open-sourcing.","open-source,community,contribution",13,Commit to Contribute
104027,69,barely-true,The Apache 2.0 license prevents all patent litigation for commercial users of the software.,Apache 2.0 license in open-source licensing,Overstates protections: Apache 2.0 grants patent rights but does not categorically prevent all patent litigation or claims.,"open-source,community,contribution",13,Commit to Contribute
104028,69,FALSE,Apache 2.0 forbids commercial use of software under its terms.,license details for Apache 2.0 in open-source contribution,Contradicts passage: Apache 2.0 explicitly permits commercial and academic use.,"open-source,community,contribution",13,Commit to Contribute
104029,69,mostly-true,Open-source licenses like Apache 2.0 enable commercial and academic use while protecting contributors.,open-source license (Apache 2.0) and contributor patent grant,Matches passage: Apache 2.0 explicitly permits commercial/academic use and grants patent protections; minor nuance about license conditions omitted.,"open-source,community,contribution",13,Commit to Contribute
104030,106,mostly-true,Cross-entropy loss is generally more appropriate than MSE for classification tasks like digit recognition.,"loss function choice for digit recognition, cross-entropy vs MSE","Passage explains cross-entropy better matches categorical labels and penalizes confident wrong predictions, omitting minor cases where MSE may suffice.","deep-learning,frameworks,tensors",5,Deep Learning
104031,106,half-true,Cross-entropy loss is usually preferred over MSE for classification because it better handles predicted probabilities.,loss function choice for classification tasks (cross-entropy vs MSE),"Correctly emphasizes cross-entropy preference and probability handling, but overstates blanket superiority without noting MSE can sometimes work for digit recognition or specific setups.","deep-learning,frameworks,tensors",5,Deep Learning
104032,106,half-true,Mean squared error is commonly used and optimal for digit classification tasks with neural networks.,"loss functions for classification, cross-entropy vs MSE","Partly correct that MSE is used, but incorrect claiming it's optimal; passage says cross-entropy is more appropriate for classification.","deep-learning,frameworks,tensors",5,Deep Learning
104033,79,FALSE,The passage describes training a new image classification model from scratch using custom images.,pre-trained model reuse with Hugging Face pipeline,"Passage explicitly describes fine-tuning or using pre-trained models, not training from scratch.","ai,tool-chain,notebooks",2,AI Survival Kit
104034,79,TRUE,Fine-tuning a pre-trained model for a specialized domain reduces training cost and effort.,transfer learning with a Hugging Face pre-trained model,"Passage states developers fine-tune existing models (e.g., Hugging Face) to save effort and reduce training costs.","ai,tool-chain,notebooks",2,AI Survival Kit
104035,79,pants-fire,The passage claims the showcased model was trained from scratch without any pretraining.,"pre-trained image classification model, Hugging Face pipeline",Directly contradicts provided code and text stating model is pre-trained and reused via Hugging Face.,"ai,tool-chain,notebooks",2,AI Survival Kit
104036,108,half-true,Publisher is predicted as the single most important feature for the fine-tuned classifier.,model selection comparison in Colab using classifiers,Correctly states passage's prediction but overstates certainty about being the single most important feature.,"machine-learning,classification,evaluation",4,Classical Machine Learning
104037,108,half-true,"Predicting Publisher is the single most important feature for the model, though importance may vary.",feature prediction for model selection using classifiers in Colab,"Passage claims Publisher was chosen as most important for fine-tuning, but importance can vary by dataset and model.","machine-learning,classification,evaluation",4,Classical Machine Learning
104038,108,TRUE,Publisher is the most important feature chosen for fine-tuning.,feature prediction for model selection with classifiers in Colab,Passage explicitly states Publisher will be the feature predicted as most important for fine-tuning.,"machine-learning,classification,evaluation",4,Classical Machine Learning
104039,85,barely-true,Developers and institutions solely determine whether AI is used ethically or not.,human responsibility for AI ethics; developers and institutions,"Overreaches passage: it omits roles of users, societal norms, and systemic factors mentioned by Jose De Jesus.","ethics,governance,privacy",11,AI Ethics and Governance
104040,85,barely-true,Ethical responsibility for AI rests solely with human developers and institutions.,"ethical responsibility, developers and institutions in AI governance","Overstates exclusivity; passage attributes responsibility to humans but ignores user, systemic, and tool-level influences.","ethics,governance,privacy",11,AI Ethics and Governance
104041,85,pants-fire,AI systems independently possess moral agency and make ethical choices without human input.,ethical AI and human responsibility in AI development,"Directly contradicts passage's central claim that humans, not AI, determine ethical use of models.","ethics,governance,privacy",11,AI Ethics and Governance
104042,31,mostly-true,Responsible use of private data generally preserves user trust while enabling distinctive models.,"private data, privacy, ownership, bias","Supports protecting privacy, honoring ownership, and checking bias, but omits implementation challenges.","ai,open-source,builder",1,Introduction – The Gold Rush Paradox
104043,31,TRUE,Responsible use of private data preserves model and user trust.,"private data handling, privacy, ownership, and bias checks","Passage emphasizes protecting privacy, honoring ownership, and checking bias to maintain trust.","ai,open-source,builder",1,Introduction – The Gold Rush Paradox
104044,31,barely-true,Using private data guarantees long-term model trustworthiness and user safety.,"handling private data, privacy protections, bias checks","Overstates claim: passage says responsible handling helps trust, not that private data guarantees it.","ai,open-source,builder",1,Introduction – The Gold Rush Paradox
104045,77,TRUE,Batching and model tuning substantially improve inference responsiveness on available hardware.,scaling inference via batching and model tuning,"Passage explicitly states batching, data shaping, and model tuning squeeze more performance and make systems responsive.","mlops,scaling,deployment",10,AI At Scale
104046,77,TRUE,Batching and model tuning can significantly increase inference responsiveness when hardware permits.,inference scaling using batching and model tuning,"Directly supported: passage praises batching, data shaping, and model tuning as effective, hardware-dependent scaling techniques.","mlops,scaling,deployment",10,AI At Scale
104047,77,FALSE,Batching and data shaping cannot improve inference performance on typical hardware.,scaling inference with batching and data shaping,"Directly contradicts passage claim that batching, data shaping, and tuning squeeze more performance from existing hardware.","mlops,scaling,deployment",10,AI At Scale
104048,23,half-true,Dataset contains mixed-quality categorical and numeric features with some missing or biased labels.,"superhero dataset with Gender, Species, Alignment, numeric Height/Weight","Passage describes exact columns and notes missing, incorrect, biased labels mixing categorical and numeric features.","data-prep,feature-engineering,rag",3,Prepping Data for AI
104049,23,TRUE,"Superhero dataset includes categorical fields like Gender, Species, Alignment, and Publisher.","superhero dataset categorical fields (Gender, Species, Alignment, Publisher)","Passage lists those exact categorical columns, showing they are present in the dataset for feature use.","data-prep,feature-engineering,rag",3,Prepping Data for AI
104050,23,mostly-true,Superhero dataset requires cleaning due to mixed-quality categorical labels and missing values.,"superhero dataset with categorical fields like Gender, Species, Alignment, Publisher","Passage describes meticulous, missing, incorrect, biased labels and numeric features needing preparation.","data-prep,feature-engineering,rag",3,Prepping Data for AI
104051,155,FALSE,Deepfakes are presented as harmless entertainment without security implications.,"deepfakes, defense training, ethical focus","Contradicts passage: emphasizes detecting, defending, and assessing deepfakes' impact, not harmlessness.","security,red-team,guardrails",8,Breaking-Securing AI
104052,155,half-true,Understanding deepfake creation helps defenders detect and mitigate many but not all threats.,deepfakes; defense training and detection tools,Mixes correct idea that knowing creation aids detection with omission that sophisticated deepfakes can still evade defenses.,"security,red-team,guardrails",8,Breaking-Securing AI
104053,155,barely-true,Deepfakes can be fully prevented by applying traditional skepticism and standard defenses.,defense training for detecting deepfakes and ethical tools,"Overreaches: passage recommends skepticism and defenses but says learning detection, not guaranteeing full prevention.","security,red-team,guardrails",8,Breaking-Securing AI
104054,168,barely-true,Reinforcement learning reliably outperforms supervised learning for routing and resource management tasks.,"reinforcement learning, reward function, sequential decisions",Overstates support: passage suggests RL is useful but warns success depends on reward design and goal clarity.,"machine-learning,classification,evaluation",4,Classical Machine Learning
104055,168,half-true,Reinforcement learning is ideal for optimizing routes and resource management with sequential decision-making.,reinforcement learning; reward function; sequential decisions,Accurately links RL to sequential decisions and routing but overstates 'ideal' without noting reward design pitfalls.,"machine-learning,classification,evaluation",4,Classical Machine Learning
104056,168,pants-fire,Reinforcement learning always achieves true optimal performance without careful reward design.,reinforcement learning reward or value function,Contradicts passage warning that poor reward design leads to exploitative behavior and wrong optimization.,"machine-learning,classification,evaluation",4,Classical Machine Learning
104057,5,FALSE,Classical machine learning edge detection always improves portrait recognition accuracy.,edge detection transform on image dataset,"Contradicts passage: edge mapping was for fun and visualization, not claimed to improve recognition accuracy.","machine-learning,classification,evaluation",4,Classical Machine Learning
104058,5,TRUE,Edge detection and color mapping transformed a Beethoven portrait into an outline composition.,image processing notebook using edge detection,Directly described by the notebook example showing Beethoven reimagined via edge detection and color mapping.,"machine-learning,classification,evaluation",4,Classical Machine Learning
104059,5,FALSE,Classical machine learning edge detection always produces precise photorealistic portraits.,edge detection example transforming a Beethoven portrait,"Contradicts passage describing an outline, non-photorealistic transformation for fun, not precision.","machine-learning,classification,evaluation",4,Classical Machine Learning
104060,132,half-true,One model can generate content while another evaluates it using explicit criteria for comparison.,AI-generated content evaluation using separate generator and evaluator models,Accurately describes mixed setup but omits nuance about domain-specific tuning and reasoning differences.,"agentic-ai,planning,tools",12,Agentic AI
104061,132,pants-fire,Agentic AI always requires separate evaluator models to function correctly.,agentic-ai evaluator model comparison setup,"Passage describes evaluator as one possible role for comparison, not an absolute requirement; claim contradicts that flexibility.","agentic-ai,planning,tools",12,Agentic AI
104062,132,half-true,One model can generate content while a different model reliably evaluates it across domains.,comparing AI-generated content using evaluator model and criteria,Partly true: passage proposes separate generator and evaluator but overstates evaluator reliability and cross-domain consistency.,"agentic-ai,planning,tools",12,Agentic AI
104063,50,FALSE,Probability measures in ML always guarantee correct classifications for uncertain inputs.,classification models and probability likelihoods,Contradicts passage: probability indicates confidence but does not ensure correctness for uncertain or noisy inputs.,"ai,tool-chain,notebooks",2,AI Survival Kit
104064,50,barely-true,The passage claims classification models always provide accurate probability-based confidence scores.,"classification models, probability, likelihood",Overreaches: passage notes models assign likelihoods but doesn't claim those probabilities are calibrated or accurate.,"ai,tool-chain,notebooks",2,AI Survival Kit
104065,50,barely-true,Probability estimates from ML models reliably predict individual superhero success in challenges.,"probability, classification models, likelihood estimates",Overreaches beyond passage: passage links probability to confidence but gives no evidence that ML estimates reliably predict single-event outcomes.,"ai,tool-chain,notebooks",2,AI Survival Kit
104066,169,mostly-true,Self-supervised learning trains models to predict withheld parts of input without external labels.,self-supervised learning technique predicting missing input,Accurately reflects SSL's masked-input prediction approach and omission of other SSL variants.,"machine-learning,classification,evaluation",4,Classical Machine Learning
104067,169,FALSE,Self-supervised learning always requires labeled datasets for training models.,self-supervised learning predicting missing input,Directly contradicts passage: SSL generates its own learning signals and does not use labeled datasets.,"machine-learning,classification,evaluation",4,Classical Machine Learning
104068,127,half-true,Kilauea's 2021 eruption produced lava fountains exceeding 300 feet high in Hawaii.,volcanic eruption report mentioning Kilauea and lava fountain heights,"Partly accurate: Kīlauea erupted recently with high lava fountains, but 300+ feet height and 2021 timing mix specifics and likely exaggerate exact event.","agentic-ai,planning,tools",12,Agentic AI
104069,127,half-true,The passage incorrectly identifies Kilauea's 2021 eruption as producing 300-foot lava fountains.,agentic-ai model output naming Kilauea eruption,Mixes correct volcano (Kilauea) with an inaccurate specific claim about 300-foot fountains.,"agentic-ai,planning,tools",12,Agentic AI
104070,127,TRUE,The passage describes a lava fountain event from Kilauea's 2021 eruption reaching over 300 feet.,report of a volcanic eruption (Kilauea 2021) mentioning lava fountains,Directly supported by passage text stating Kilauea 2021 produced >300-foot lava fountains.,"agentic-ai,planning,tools",12,Agentic AI
104071,97,pants-fire,CrewAI autonomously achieves human-level general intelligence across domains without developer input.,open source CrewAI using LangChain agent and prompt templates,"Passage only claims adaptable, customizable multi-agent management; contradicts human-level AGI capability assumption.","agentic-ai,planning,tools",12,Agentic AI
104072,97,TRUE,CrewAI enables customizable multi-agent interactions while leveraging LangChain's prompt templates and models.,open-source CrewAI integrated with LangChain prompt templates,"Passage states CrewAI is open source and uses LangChain's prompt templates and model abstractions, supporting customization.","agentic-ai,planning,tools",12,Agentic AI
104073,97,half-true,CrewAI's open-source integration with LangChain fully enables developers to customize multi-agent interactions.,open-source CrewAI using LangChain prompt templates,"Correct that CrewAI is open-source and leverages LangChain, but overstates completeness of customization and readiness for fully autonomous gameplay.","agentic-ai,planning,tools",12,Agentic AI
104074,63,barely-true,SpeechT5 can be reused with new recordings by following the same CSV transcript-audio pipeline.,input preparation for SpeechT5 voice-cloning pipeline,"Pipeline reuse is suggested but passage omits practical limits, data quality, or adaptation steps.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
104075,63,TRUE,Cloning a voice with SpeechT5 follows a five-step pipeline transforming audio and text into synthetic speech.,voice cloning pipeline with SpeechT5 using CSV transcripts and audio,Passage explicitly describes a five-step SpeechT5 pipeline using CSV-paired transcripts and audio to produce synthetic speech.,"media-forensics,voice-cloning,deepfake",9,Deepfake Defense
104076,63,half-true,Reusing the CSV transcript-audio pipeline with SpeechT5 exactly reproduces a target speaker's voice.,voice cloning pipeline using SpeechT5 and CSV transcript-audio dataset,"Correctly notes CSV pipeline reuse, but overstates perfect reproduction of a speaker's voice; quality depends on data and model limits.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
104077,81,half-true,Agents that use tools can access real-time web data and perform complex external computations.,tools in CrewAI enabling web search and data analysis,Accurate about tool-enabled web access and computations but overstates guaranteed real-time access and scope.,"agentic-ai,planning,tools",12,Agentic AI
104078,81,barely-true,Agents can fully replace human decision-makers in complex real-world planning tasks.,Agents using tools like web search and data analysis in CrewAI,Overreaches beyond passage: tools extend capabilities but passage never claims full human replacement.,"agentic-ai,planning,tools",12,Agentic AI
104079,81,FALSE,Agents cannot use external tools to access real-time information or perform computations.,Tools in CrewAI enabling web searching and data retrieval,"Contradicts passage detail that agents use tools for web searching, data retrieval, computations, and real-time access.","agentic-ai,planning,tools",12,Agentic AI
104080,113,half-true,Diffusion models perfectly reconstruct original training images from random noise without memorization concerns.,Stable Diffusion v1.5 text-to-image pipeline,Mixes correct diffusion denoising process with incorrect claim of perfect reconstruction and absent memorization caveats.,"generative-ai,diffusion,gans",7,Generative AI
104081,113,mostly-true,Diffusion models broadly synthesize images by iteratively denoising multimodal inputs into coherent outputs.,Stable Diffusion v1.5 text-to-image pipeline (diffusion model),"Passage explains iterative denoising, multimodal vision-language use, and practical image synthesis applications, omitting minor architectural caveats.","generative-ai,diffusion,gans",7,Generative AI
104082,113,half-true,Diffusion models reconstruct images by simulating gradual data degradation and reversal steps.,"diffusion models, Stable Diffusion v1.5 implementation",Accurately states gradual degradation/reconstruction mechanism but omits technical details like noise schedule and denoising network.,"generative-ai,diffusion,gans",7,Generative AI
104083,102,TRUE,"A living bill of materials aids updating, debugging, and scaling of deployed models.",model bill of materials; deployment and scaling in MLOps,"Passage explicitly states a living bill of materials helps updating, debugging, and lays groundwork for scale.","mlops,scaling,deployment",10,AI At Scale
104084,102,barely-true,A living bill of materials guarantees models will scale seamlessly in production.,living bill of materials for model maintenance and scaling,Overstates passage: BOM aids debugging and groundwork for scale but does not guarantee seamless production scaling.,"mlops,scaling,deployment",10,AI At Scale
104085,102,pants-fire,The living bill of materials eliminates all debugging needs for deployed models.,living bill of materials for model documentation,Claim contradicts passage: documentation aids debugging but does not remove all debugging needs or model errors.,"mlops,scaling,deployment",10,AI At Scale
104086,80,TRUE,The autoencoder compresses MNIST images through a bottleneck layer to learn salient features.,autoencoder with MNIST dataset and bottleneck encoded layer,"Describes model compressing via a bottleneck (encoded Dense(16)) and reconstructing MNIST images, matching passage.","neural-networks,cnn,transformers",6,Neuron Building Blocks
104087,80,mostly-true,"An autoencoder’s bottleneck forces feature compression, enabling MNIST digit reconstruction with some loss of detail.",autoencoder bottleneck layer on MNIST dataset using Keras,"Supported by code and explanation: bottleneck compresses features and reconstructions appear blurrier, a minor detail omitted.","neural-networks,cnn,transformers",6,Neuron Building Blocks
104088,80,barely-true,The autoencoder perfectly preserves fine digit details after one epoch on MNIST.,autoencoder training on MNIST dataset,Overreaches relative to evidence: reconstructions are described as blurry after only one training epoch.,"neural-networks,cnn,transformers",6,Neuron Building Blocks
104089,49,TRUE,"Precision, recall, and F1 are essential when different mistake costs matter in classification tasks.","evaluation metrics (precision, recall, F1) for classification","Passage explicitly recommends precision, recall, and F1 over accuracy when mistake types have unequal costs, citing fraud example.","machine-learning,classification,evaluation",4,Classical Machine Learning
104090,49,half-true,Logistic regression is a quick baseline but may miss nonlinear patterns present in hero power features.,classification using logistic regression and decision tree models,Mixes correct advice about logistic regression as a baseline with incorrect implication it always misses nonlinear patterns; decision trees can also miss some complexities.,"machine-learning,classification,evaluation",4,Classical Machine Learning
104091,49,mostly-true,"Precision, recall, and F1 are essential when different error costs matter in classification.","evaluation metrics (precision, recall, F1) for classification on datasets",Supports passage guidance: accuracy alone isn't enough; omission of specific thresholding details is a minor caveat.,"machine-learning,classification,evaluation",4,Classical Machine Learning
104092,74,barely-true,AI systems should be trusted less when delegating important decisions to prevent overreliance.,trust calibration for AI agents and transparency,Overstates passage: passage warns about balancing trust but doesn't insist on trusting less universally.,"ethics,governance,privacy",11,AI Ethics and Governance
104093,74,FALSE,AI agents should never be trusted for important decisions without human oversight.,trust calibration for AI agents and delegation,Contradicts passage recommendation to balance trust; passage endorses calibrated trust with transparency.,"ethics,governance,privacy",11,AI Ethics and Governance
104094,74,barely-true,AI systems should always be treated as untrustworthy for important decisions.,trust calibration for AI agents,"Overreaches relative to passage: passage advises balanced calibration, not absolute distrust.","ethics,governance,privacy",11,AI Ethics and Governance
104095,36,TRUE,Training data poisoning can subtly influence model behavior through repeated phrases or mislabels.,training data poisoning in domain-specific model datasets,"Describes subtle influence mechanisms—repeated phrases, mislabels, slanted examples—explicitly stated as effective.","security,red-team,guardrails",8,Breaking-Securing AI
104096,36,half-true,Training data poisoning reliably alters small in-house models but not larger models trained on diverse corpora.,training data poisoning influence on small models and scraped dataset,"Accurately notes vulnerability of small in-house models, but overstates ineffectiveness against large, diverse models.","security,red-team,guardrails",8,Breaking-Securing AI
104097,36,barely-true,Training data poisoning reliably causes significant behavior changes in large pretrained models.,"training data poisoning, fine-tuning on open data","Passage emphasizes effectiveness in small in-house models but not large pretrained models, so claim overreaches.","security,red-team,guardrails",8,Breaking-Securing AI
104098,63,FALSE,"T5-small inference on GPU slows dramatically as input length approaches 1,000 tokens.",inference timing benchmark on GPU and CPU,"Contradicts reported GPU behavior: GPU response stays under 0.05s with only modest uptick, not dramatic slowdown.","mlops,scaling,deployment",10,AI At Scale
104099,63,half-true,"GPU inference for T5-small stays under 0.05 seconds even near 1,000 tokens, unlike CPU.",T5-small inference time benchmark on GPU versus CPU,Mixes correct GPU stability with an absolute threshold and comparison that oversimplify CPU variability.,"mlops,scaling,deployment",10,AI At Scale
104100,63,barely-true,The GPU inference time for T5 remains under 0.05 seconds even at large input lengths.,T5 inference timing benchmark on GPU versus CPU,"Passage claims GPU stays under 0.05s but offers no detailed measurement range or variance, overstating reliability.","mlops,scaling,deployment",10,AI At Scale
104101,44,mostly-true,"Hugging Face serves as a central, practical glossary and tool across the open-source AI stack.",glossary MVP and open-source AI tools,"Passage describes Hugging Face as a glossary MVP used across layers, omitting specific limitations.","open-source,community,contribution",13,Commit to Contribute
104102,44,half-true,Hugging Face served as the project's sole glossary and organization tool for all open-source AI artifacts.,glossary MVP and visual format for open-source AI,Passage praises Hugging Face as a glossary MVP and visual complement but never claims it was the sole tool.,"open-source,community,contribution",13,Commit to Contribute
104103,44,barely-true,Mixtral is the best open-source model for all production use cases.,"model selection for open-source LLMs (Mixtral, Hugging Face glossary)","Overreaches passage praise; it only calls Mixtral a go-to balance, not universally best.","open-source,community,contribution",13,Commit to Contribute
104104,57,FALSE,A No answer at Empathy leads to a Human prediction.,decision tree node Empathy in the model,"Contradicts passage detail: Empathy No yields a Mutant prediction, not Human.","machine-learning,classification,evaluation",4,Classical Machine Learning
104105,57,TRUE,A Yes at Empathy yields a Human prediction in the decision tree.,decision tree leaf labeled Human from Empathy,"Directly supported by passage: Empathy Yes leads to Human prediction as a blue, dark-shaded leaf.","machine-learning,classification,evaluation",4,Classical Machine Learning
104106,57,FALSE,A Yes at Hypnokinesis always leads directly to a Mutant prediction.,"decision tree nodes: Astral Projection, Hypnokinesis, Empathy","Contradicts described path: Hypnokinesis Yes leads to Empathy, and Empathy determines Human or Mutant.","machine-learning,classification,evaluation",4,Classical Machine Learning
104107,9,mostly-true,Multimedia deepfake detection faces greater scale challenges than text-based methods.,multimedia data scale and audio/video waveform analysis,"Passage emphasizes vast, multidimensional multimedia (thousands of frames, continuous audio) making detection more demanding than text.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
104108,9,TRUE,Multimedia data requires far more computational scale than text for analysis.,multimedia vs. text scale in media-forensics,"Passage explains videos and audio are high-dimensional and larger than compact text, increasing analysis scale.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
104109,9,half-true,Multimedia analysis requires far greater computational scale than text processing.,"multidimensional multimedia data (video frames, audio waveforms)","Accurately contrasts text compactness with video frames and continuous audio, but omits specifics about compute or methods.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
104110,71,mostly-true,PCA first component captures a small fraction of variance and is insufficient for full analysis.,PCA on superhero power features with explained_variance_ratio (PC1),"Explained variance PC1 is only 5.5%, so one component omits most variance though it illustrates concept.","machine-learning,classification,evaluation",4,Classical Machine Learning
104111,71,pants-fire,PCA with one component captures almost all variance in the 160 power features.,PCA explained_variance_ratio_ (PC1) for superhero power dataset,"Contradicts given explained_variance_ratio_ of 0.055; PC1 captures only 5.5%, not almost all.","machine-learning,classification,evaluation",4,Classical Machine Learning
104112,71,half-true,"The first PCA component captures only a small fraction of variance, about 5.5%, in the power features.",PCA with n_components=1 on superhero powers dataset,Accurately reports 5.5% explained variance but omits that multiple components are needed for 70–80% retention.,"machine-learning,classification,evaluation",4,Classical Machine Learning
104113,146,barely-true,RAG always produces coherent story arcs when using retrieval and generation together.,"RAG with ChromaDB retrieval, LangChain prompts, and generative model","Overreaches beyond passage example; only one exercise showed success, not guaranteed generality.","data-prep,feature-engineering,rag",3,Prepping Data for AI
104114,146,barely-true,"RAG reliably produced accurate, grounded narratives from any two prepared datasets.",RAG using ChromaDB retrieval and LangChain prompt structure,Overstates reliability and generality; passage only shows success with two specific datasets and tools.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
104115,146,TRUE,RAG enabled grounding the model using two prepared datasets for coherent story generation.,retrieval-augmented generation with ChromaDB and LangChain,Passage explicitly states RAG used two prepared datasets with ChromaDB and LangChain enabling coherence.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
104116,85,FALSE,"Generative AI only performs prediction and classification, not content creation.",foundation models and Generative AI creating text and images,"Contradicts passage saying GenAI creates text, images, audio, and video using foundation models.","ai,tool-chain,notebooks",2,AI Survival Kit
104117,85,barely-true,Generative AI primarily replicates exact training examples rather than creating novel content.,foundation models trained on large text and image datasets,"Overstates replication; passage emphasizes creation from learned patterns, not exact duplication.","ai,tool-chain,notebooks",2,AI Survival Kit
104118,85,TRUE,"Generative AI models create text, images, audio, and video from large datasets.",foundation models and Generative AI,"Passage states GenAI produces text, images, audio, and video using large pre-trained datasets and foundation models.","ai,tool-chain,notebooks",2,AI Survival Kit
104119,26,pants-fire,LangChain can autonomously replace all human developers in building agentic AI systems.,LangChain framework for AI agents and prompt templates,"Contradicts passage: LangChain is a supporting framework, not a full replacement for human developers or judgment.","agentic-ai,planning,tools",12,Agentic AI
104120,26,barely-true,LangChain guarantees fully autonomous agents will perform reliably across diverse real-world tasks.,LangChain agent abstractions and prompt templates for autonomous agents,Overreaches beyond passage; passage states support and structure but not guaranteed reliable real-world performance.,"agentic-ai,planning,tools",12,Agentic AI
104121,26,FALSE,LangChain is limited to only chatbot and search engine applications.,LangChain model abstractions and AI agents,"Contradicts passage specifying support for recommendation, summarization, and autonomous agent tools.","agentic-ai,planning,tools",12,Agentic AI
104122,23,TRUE,"Weights scale input contributions, bias shifts outputs, and activation applies a pass/fail threshold.","neural network analogy using weights, bias, and activation","Directly supported by passage: weights as input importance, bias as curve, activation as threshold for pass/fail.","deep-learning,frameworks,tensors",5,Deep Learning
104123,23,mostly-true,Neural-network bias acts like a grading curve that shifts the weighted sum before activation.,"analogy relating weights, bias, and activation in deep learning",Analogy matches passage: bias shifts total (the +5 curve) before activation (pass threshold); minor oversimplification of complex bias roles.,"deep-learning,frameworks,tensors",5,Deep Learning
104124,23,half-true,Neural network bias acts like a grading curve that shifts final scores upward.,bias as curve in neural network weights and activation,Accurately equates bias to an additive shift but oversimplifies role across layers and training dynamics.,"deep-learning,frameworks,tensors",5,Deep Learning
104125,68,mostly-true,The Game Master generates trivia questions and optionally gives search hints during rounds.,Game Master role in trivia game setup and evaluation,"Passage explicitly lists GM duties—generating questions, providing optional search hints, and evaluating responses, minor omission of player strategy details.","agentic-ai,planning,tools",12,Agentic AI
104126,68,TRUE,The Game Master generates trivia questions and evaluates player responses.,game role description with Game Master and Player 2,"Directly supported: passage says the GM generates questions, offers hints, and evaluates responses.","agentic-ai,planning,tools",12,Agentic AI
104127,68,half-true,"An Agentic AI Game Master autonomously generates trivia, offers search hints, and enforces winners every round.","game setup and Game Master role, trivia category selection",Accurately lists GM duties from passage but overstates full autonomy and enforcement mechanisms.,"agentic-ai,planning,tools",12,Agentic AI
104128,65,TRUE,The code implements a browser-based PDF upload and question-answering loop.,pipeline question-answering with PyMuPDF PDF text extraction,"Code shows files.upload GUI, extracts text with fitz, and runs a QA pipeline interactively.","neural-networks,cnn,transformers",6,Neuron Building Blocks
104129,65,barely-true,The code reliably extracts perfect semantic understanding from any uploaded PDF using a basic QA pipeline.,QA pipeline with transformers and PyMuPDF,"Overreaches: code extracts raw text and uses a generic QA model, not guaranteeing perfect semantic understanding.","neural-networks,cnn,transformers",6,Neuron Building Blocks
104130,65,mostly-true,The code implements a browser-based PDF upload and extract pipeline for QA with transformers.,pipeline question-answering using PyMuPDF and transformers,"Implementation and upload via files.upload are shown, minor integration caveats omitted.","neural-networks,cnn,transformers",6,Neuron Building Blocks
104131,34,pants-fire,Open-source AI tools make it impossible for attackers to create misuse or vulnerabilities.,open-source frameworks like PyTorch and TensorFlow,"Claim directly contradicts passage which states open-source enables detection and mitigation, not impossibility.","generative-ai,diffusion,gans",7,Generative AI
104132,34,mostly-true,Open-source AI frameworks broadly enable community scrutiny that improves detection of vulnerabilities and misuse.,"open-source frameworks like PyTorch, TensorFlow, Keras","Framework openness and community scrutiny support vulnerability detection, though specific impact magnitude or completeness is not claimed.","generative-ai,diffusion,gans",7,Generative AI
104133,34,TRUE,Open-source AI frameworks enable broader scrutiny and help detect misuse of models.,"open-source frameworks like PyTorch, TensorFlow, Keras",Text states these frameworks enable broader scrutiny and empower community detection of misuse.,"generative-ai,diffusion,gans",7,Generative AI
104134,128,half-true,"Red Team findings can always be converted into immediate, developer-ready fixes within a day.","Red Team deliverables, Short Executive Summary and remediation plan","Passage recommends practical, immediate deliverables but overstates guaranteed same-day conversion and universality.","security,red-team,guardrails",8,Breaking-Securing AI
104135,128,half-true,Red Team findings must be immediately actionable and include a one-page executive summary for leadership.,day-one security sweep deliverables; automated testing and remediation,Accurately notes executive summary and actionable remit but overstates mandatory immediacy for all findings.,"security,red-team,guardrails",8,Breaking-Securing AI
104136,128,pants-fire,The Red Team always creates impossibly harmful exploits to wreck models overnight.,Red Team output; executive summary and remediation plan,"Directly contradicts text: Red Team output must be practical, useful, and recommend fixes, not destructive exploits.","security,red-team,guardrails",8,Breaking-Securing AI
104137,73,mostly-true,A simple Naïve Bayes bag-of-words model can effectively classify themed spam emails in small datasets.,Scikit-learn Naïve Bayes with CountVectorizer n-grams,"Example shows MultinomialNB with bi-grams correctly labeling superhero-themed emails, omitting generalization limits.","ai,tool-chain,notebooks",2,AI Survival Kit
104138,73,barely-true,A simple Naïve Bayes bag-of-words model reliably detects superhero-themed spam in small samples.,Scikit-learn MultinomialNB with CountVectorizer bi-grams,Overstates reliability given tiny toy dataset and no evaluation metrics; results are anecdotal.,"ai,tool-chain,notebooks",2,AI Survival Kit
104139,51,mostly-true,Transformer attention lets models attend to whole sequences rather than strictly sequential reading.,Transformer attention mechanism in neural networks,Supported by passage metaphor comparing reading whole text at once to remembering earlier tokens; minor caveat about implementation details omitted.,"neural-networks,cnn,transformers",6,Neuron Building Blocks
104140,51,barely-true,Transformers always require reading entire input sequences simultaneously to solve contextual tasks.,sequence processing in transformers and neural-networks,"Overreaches relative to passage: transformers use attention and can process segments or streaming inputs, not strictly whole sequences.","neural-networks,cnn,transformers",6,Neuron Building Blocks
104141,51,TRUE,Reading information sequentially can make remembering earlier details harder than reading everything at once.,memory and sequence processing in neural-networks or transformers,"Passage contrasts sequential reading versus reading whole content, implying sequential order burdens memory.","neural-networks,cnn,transformers",6,Neuron Building Blocks
104142,70,mostly-true,The game master provides search queries or URLs and evaluates timed player answers.,game mechanics involving Web Search Challenge and scoring,"Matches passage details: GM offers search queries/URLs, enforces time limits, evaluates and scores responses.","agentic-ai,planning,tools",12,Agentic AI
104143,70,half-true,The game master provides a web search query or URL for players to find clues during play.,game session mechanics; Web Search Challenge tool,"Accurately mentions web search option but omits scoring, answer submission, and time-limit details.","agentic-ai,planning,tools",12,Agentic AI
104144,70,half-true,The GM can provide a web search query or URL for players to find clues during gameplay.,game mechanic: Web Search Challenge using a URL or search query,"Partly correct: passage says GM offers queries/URLs, but omits timing, scoring, and optional nature.","agentic-ai,planning,tools",12,Agentic AI
104145,73,TRUE,The dataset pairs Jerry's audio clips with transcripts and spectrograms for model training.,paired audio transcripts CSV and spectrogram preprocessing,"Directly supported: passage describes CSV of Whisper transcripts, audio clips, and spectrogram transformations.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
104146,73,half-true,The model trains on spectrograms paired with Whisper-generated transcripts to learn Jerry's voice.,"dataset of audio clips, spectrograms, and Whisper transcripts","Accurately describes pairing spectrograms and Whisper transcripts, but implies training occurred rather than dataset preparation.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
104147,41,mostly-true,Multi-turn evaluation generally reveals contextual and continuity failures that single-shot tests miss.,multi-turn evaluation for chatbots and instruction-following models,"Evaluation text explains multi-turn tests expose forgetting, confusion, and follow-up issues, a broadly supported claim.","mlops,scaling,deployment",10,AI At Scale
104148,41,barely-true,The evaluation reliably guarantees models will never forget earlier conversation parts during multi-turn chats.,multi-turn evaluation of chatbots and instruction-following models,Overstates reliability; passage notes evaluations can surface forgetfulness but not ensure it never occurs.,"mlops,scaling,deployment",10,AI At Scale
104149,41,barely-true,Multi-turn evaluation claims ensure comprehensive model correctness across all dialogue scenarios.,multi-turn evaluation for chatbots and instruction-following models,Overreaches: passage says multi-turn tests reveal some issues but does not claim they guarantee correctness across all dialogue scenarios.,"mlops,scaling,deployment",10,AI At Scale
104150,113,pants-fire,The deployed model always returns correct fact-checking labels for any input statement.,remote model prediction via gradio_client API,Contradicts example's note that model may need startup time and makes an extreme accuracy claim; deployment doesn't guarantee perfect correctness.,"mlops,scaling,deployment",10,AI At Scale
104151,113,FALSE,The deployed model requires an on-premise server and cannot be accessed remotely.,remote model access via gradio_client API call,Contradicts explicit example showing public Space deployment and remote access with gradio_client.,"mlops,scaling,deployment",10,AI At Scale
104152,113,pants-fire,"The deployed model instantly generates flawless, guaranteed-accurate fact checks for any claim.",remote API access using gradio_client deployed model,"Passage says model may take seconds to start and shows simple predict call, contradicting guaranteed instant flawless accuracy assumption.","mlops,scaling,deployment",10,AI At Scale
104153,82,TRUE,A larger bottleneck and matching decoder size improve autoencoder reconstruction quality.,"autoencoder architecture (bottleneck size, decoder), loss mse",Passage shows increasing bottleneck from 16→64 and matching decoder led to sharper reconstructions and MSE loss.,"neural-networks,cnn,transformers",6,Neuron Building Blocks
104154,82,FALSE,Variational autoencoders can generate new samples during decompression.,variational autoencoder (VAE) concept in autoencoders,"Contradicts passage wording that generation during decompression requires a special VAE; passage implies possibility, not standard autoencoders.","neural-networks,cnn,transformers",6,Neuron Building Blocks
104155,82,half-true,The passage claims increasing autoencoder bottleneck size and using MSE improves digit reconstructions but enables generative output.,autoencoder architecture and VAE concept in neural-networks,"Mixes correct training tweaks (larger bottleneck, MSE) with incorrect implication that simple autoencoder becomes generative without VAE.","neural-networks,cnn,transformers",6,Neuron Building Blocks
104156,18,TRUE,"A neuron multiplies inputs by adjustable weights, adds a bias, then applies an activation function.","neuron operations in neural networks (weights, bias, activation)","Directly supported by passage: it describes weighting inputs, adding bias, and using an activation function to decide firing.","deep-learning,frameworks,tensors",5,Deep Learning
104157,18,FALSE,Neurons do not use weights or biases and rely only on raw inputs.,"Weights, Bias, and Activation in neural networks",Contradicts passage detail that connections use adjustable weights and biases learned during training.,"deep-learning,frameworks,tensors",5,Deep Learning
104158,18,mostly-true,Neural network neurons compute weighted sums plus bias before applying an activation function.,"weights, bias, activation function in neuron computations","Directly reflects passage describing inputs scaled by weights, added bias, then passed through activation; minor learning dynamics omitted.","deep-learning,frameworks,tensors",5,Deep Learning
104159,63,pants-fire,Transformers' question-answering pipeline eliminates hallucinations entirely in all contexts.,question-answering pipeline using transformers,"Passage claims grounded results reduce hallucination odds, not eliminate them; absolute claim contradicts that nuance.","neural-networks,cnn,transformers",6,Neuron Building Blocks
104160,63,TRUE,"Question-answering pipelines return answers grounded in provided context, reducing hallucination risk.",transformers pipeline question-answering using context string,"Example shows pipeline producing answers from user-provided context, explicitly reducing hallucination.","neural-networks,cnn,transformers",6,Neuron Building Blocks
104161,63,mostly-true,Question-answering pipelines grounded in provided context usually reduce hallucination but may omit nuance.,pipeline(question-answering) using Transformers QA example,"Example shows answers tied to input context, supporting reduced hallucination while missing broader external knowledge.","neural-networks,cnn,transformers",6,Neuron Building Blocks
104162,47,barely-true,TensorFlow eliminates manual gradient steps entirely compared to PyTorch.,GradientTape versus loss.backward optimizer.step in frameworks,"Overstates claim: TensorFlow automates gradients via GradientTape but still requires explicit training steps and optimizers, unlike saying it eliminates them entirely.","deep-learning,frameworks,tensors",5,Deep Learning
104163,47,half-true,TensorFlow requires more boilerplate code than PyTorch for simple MNIST training.,comparison of PyTorch and TensorFlow APIs using MNIST and GradientTape,"Mixes correct comparison with wrong direction: passage says TensorFlow reduces boilerplate, not increases it.","deep-learning,frameworks,tensors",5,Deep Learning
104164,47,FALSE,TensorFlow removes all need to write gradient calculations when training models.,GradientTape in TensorFlow for MNIST model training,Contradicts passage: TensorFlow reduces boilerplate but still requires writing key training steps and uses GradientTape for gradients.,"deep-learning,frameworks,tensors",5,Deep Learning
104165,50,half-true,The Colab setup is a lightweight baseline that can be easily scaled to measure model behavior.,"AI at Scale notebook using Colab, GitHub, datasets, and model checkpoints","Partly accurate: Colab notebook is lightweight baseline with GitHub and checkpoints, but 'easily scaled' overstates unspecified scaling limits.","mlops,scaling,deployment",10,AI At Scale
104166,51,TRUE,Explicitly instructing a model to say 'I don't know' reduces hallucinations in outputs.,prompt design for language model responses,Passage states guiding models to respond with a blank or non-answer prevents made-up guesses and improves accuracy.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
104167,51,mostly-true,Explicitly prompting models to say they don't know reduces hallucinated answers in datasets.,prompting instruction for language model dataset preprocessing,"Matches passage claim that telling model to respond with a blank guides safe non-answers, slightly overstating magnitude.","data-prep,feature-engineering,rag",3,Prepping Data for AI
104168,51,half-true,Explicitly telling a model to answer 'blank' eliminates most hallucinations in retrieval-augmented generation.,prompt design for RAG and dataset control logic,Mixes correct prompt-safety benefit with overstated effect; prompt reduces but does not eliminate hallucinations.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
104169,146,barely-true,Generative AI uses a fundamentally different learning approach than classical machine learning.,comparison between generative AI and classical machine learning,Passage asserts a difference but gives no specifics; claim overreaches without evidence of fundamental method differences.,"generative-ai,diffusion,gans",7,Generative AI
104170,146,mostly-true,"Generative AI typically uses different learning approaches than classical machine learning, focusing on data generation.",comparison of generative AI and classical machine learning (generative models),Supported by passage claim of a different approach; omits caveats about overlap and shared algorithms such as supervised learning and optimization.,"generative-ai,diffusion,gans",7,Generative AI
104171,146,TRUE,Generative AI uses machine learning to learn and improve over time.,generative AI concept in dialogue about learning approach,"Passage explicitly states generative AI uses machine learning and learns/improves, supporting the claim.","generative-ai,diffusion,gans",7,Generative AI
104172,32,FALSE,Developers use prompts solely as user-facing instructions without integrating them into applications.,prompt design for AI-enabled application; prompting,"Contradicts passage: prompts are discussed as developer tools integrated into applications, not only user-facing.","agentic-ai,planning,tools",12,Agentic AI
104173,32,mostly-true,Developers should learn prompt design principles specifically for integrating prompts into AI applications.,"prompt design for AI-enabled application (prompting, developer perspective)",Supports focusing on developer-centric prompt design rather than teaching prompting from scratch; minor caveat about end-user prompting omitted.,"agentic-ai,planning,tools",12,Agentic AI
104174,32,pants-fire,Agentic AI autonomously engineers and replaces software systems without developer input.,developer prompting and AI-enabled application prompts,"Passage says prompting aids developers, not that agentic AI autonomously engineers or replaces systems; claim contradicts role of developer input.","agentic-ai,planning,tools",12,Agentic AI
104175,8,barely-true,Fine-tuning a model always transforms coin-flip accuracy into highly dependable predictions.,model fine-tuning and evaluation; accuracy metric,Overreaches beyond passage: fine-tuning can improve baselines but does not guarantee dependable predictions.,"machine-learning,classification,evaluation",4,Classical Machine Learning
104176,8,half-true,Model accuracy improvements often require iterative feature refinement and tuning beyond baseline models.,"training, baselines, feature design, and evaluation metrics","Accurate that refinement and tuning improve accuracy, but oversimplifies effort and ignores dataset bias caveats.","machine-learning,classification,evaluation",4,Classical Machine Learning
104177,8,mostly-true,Starting with simple baselines and iteratively refining features and models generally improves predictive reliability.,model evaluation and feature engineering for classification accuracy,"Passage supports iterative baseline testing, feature refinement, and tuning as a path from coin-flip to dependable predictions; minor caveat: results depend on dataset quality.","machine-learning,classification,evaluation",4,Classical Machine Learning
104178,7,barely-true,Python guarantees seamless production deployment for most AI projects without additional engineering effort.,"tool-chain and libraries like NumPy, Pandas, PyTorch",Overreaches beyond passage: libraries ease prototyping but do not guarantee seamless production deployment; operational engineering often required.,"ai,tool-chain,notebooks",2,AI Survival Kit
104179,7,mostly-true,Python is generally the best initial language for experimenting with machine learning and AI projects.,"programming language and libraries (NumPy, Pandas, PyTorch, Matplotlib)","Libraries and readable syntax support prototyping-to-production workflows, though other languages also serve AI.","ai,tool-chain,notebooks",2,AI Survival Kit
104180,7,half-true,Python's libraries guarantee seamless prototype-to-production transitions for most AI projects.,"tool-chain and libraries like NumPy, Pandas, PyTorch","Claim mixes accurate strengths (readability, libraries) with an overbroad guarantee about seamless transitions and production.","ai,tool-chain,notebooks",2,AI Survival Kit
104181,90,barely-true,"Prompt engineering reliably produces optimal, high-quality outputs from any generative AI model.",prompt engineering exercise and tip in AI tool-chain,"Overstates prompt engineering: passage praises benefits but notes it’s art, not guaranteeing optimal outputs.","ai,tool-chain,notebooks",2,AI Survival Kit
104182,90,FALSE,Prompt engineering has no impact on model outputs and is unnecessary for useful results.,prompt engineering exercise and tip in AI Survival Kit,"Contradicts passage stating prompt engineers guide models and prompting produces flexible, beneficial outputs.","ai,tool-chain,notebooks",2,AI Survival Kit
104183,90,half-true,Prompt engineers always ensure generative AI produces reliably beneficial results.,prompt engineering exercise and tip in model prompting,Overstates outcomes: passage credits prompting skill but notes it’s probabilistic and not guaranteed.,"ai,tool-chain,notebooks",2,AI Survival Kit
104184,81,mostly-true,Exploratory Data Analysis helps assess dataset relevance and imbalance before modeling.,"EDA using Gini coefficient on dataset features (Gender, Species, Alignment)",Supports claim by describing EDA role and Gini use for imbalance and relevance assessment.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
104185,81,TRUE,Exploratory Data Analysis should assess dataset relevance before model building.,EDA on dataset using Gini coefficient for imbalance,Supports performing EDA to uncover patterns and ask if data relevance matches model goals.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
104186,81,barely-true,Exploratory Data Analysis guarantees models will perform well despite dataset imbalances.,EDA with Gini coefficient on superhero dataset,Overreaches: EDA uncovers patterns and imbalances but does not ensure model performance or fix biases.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
104187,98,TRUE,"Spectral centroid, bandwidth, and contrast consistently reveal differences between cloned and authentic voices.","feature-wise differences in audio features (spectral centroid, bandwidth, contrast)","Passage explicitly reports those features stand out as divergent, indicating clones lack natural variation.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
104188,98,mostly-true,Cloned audio broadly matches original tone and loudness but shows detectable spectral and bandwidth deviations.,"feature-wise differences between actual and cloned samples (spectral centroid, bandwidth)","Passage notes most features match yet spectral centroid, bandwidth, and contrast notably diverge, a minor caveat to overall similarity.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
104189,98,half-true,The cloned voice shows specific spectral and bandwidth deviations from Jerry's authentic voice.,"feature-wise differences: spectral centroid, bandwidth, contrast",Mixes correct detection of spectral/bandwidth drifts with implied generality about clone quality.,"media-forensics,voice-cloning,deepfake",9,Deepfake Defense
104190,141,pants-fire,A diffusion model can autonomously rewrite any protected dataset to evade copyright safeguards.,diffusion model training and datasets,"Passage discusses sequence-to-sequence summarization, not dataset copyright evasion; claims contradict model capabilities and privacy safeguards.","generative-ai,diffusion,gans",7,Generative AI
104191,141,barely-true,A diffusion model was used to summarize an Amazon Rainforest passage in the example.,Listing 6-5 sequence-to-sequence transformer example,"Example actually uses a seq2seq transformer model, not a diffusion model, so claim overreaches.","generative-ai,diffusion,gans",7,Generative AI
104192,141,TRUE,Diffusion and GAN models can both generate realistic images from random noise.,"generative-ai models (diffusion, GANs) for image synthesis",Passage discusses sequence-to-sequence generation and generative models; both diffusion and GANs are standard image-generation approaches supported here.,"generative-ai,diffusion,gans",7,Generative AI
104193,21,mostly-true,Large language models generate text from training patterns rather than performing search-based lookups.,LLMs and training data behaviour,"Supported by passage: models predict statistically from training data, not retrieving live search results.","ai,open-source,builder",1,Introduction – The Gold Rush Paradox
104194,21,half-true,LLMs generate answers by pattern prediction rather than retrieving exact external sources.,LLM behavior and training data in large language models,"Passage explains LLMs use statistical pattern prediction from training data, not explicit source lookup, mixing correct mechanism with omitted retrieval techniques like RAG.","ai,open-source,builder",1,Introduction – The Gold Rush Paradox
104195,21,TRUE,Large language models generate answers from training-derived statistical patterns rather than live searches.,LLMs and model training behavior,Passage explains LLMs predict text from training data statistics rather than looking up information live.,"ai,open-source,builder",1,Introduction – The Gold Rush Paradox
104196,104,pants-fire,All hosted models on the platform are guaranteed safe and free from bias or misuse.,model cards for models like Llama 3.2 on the hosting platform,"Strongly contradicts model cards' role; claim denies documented caveats about training, usage, and risks.","ai,tool-chain,notebooks",2,AI Survival Kit
104197,104,barely-true,"The platform offers exhaustive, fully verified model safety audits for every hosted model.",model cards and hosted models on the platform,"Overstates available information: passage mentions model cards explaining training and use, not exhaustive safety audits.","ai,tool-chain,notebooks",2,AI Survival Kit
104198,104,mostly-true,"The platform provides model cards describing training, usage, and capabilities for many hosted models.",model cards for models like Llama 3.2 on the hosting platform,Accurately reflects that cards explain training and use for many models; omits any limits or variability in card quality.,"ai,tool-chain,notebooks",2,AI Survival Kit
104199,86,pants-fire,Models do not need versioned checkpoints after training because checkpoints are useless.,versioned checkpoints for model preservation,Contradicts explicit guidance: passage advocates capturing and documenting versioned checkpoints as essential.,"mlops,scaling,deployment",10,AI At Scale
104200,86,FALSE,Versioned checkpoints are unnecessary for preserving trained model behavior in production.,"versioned checkpoints, model, checkpointing",Contradicts passage: passage emphasizes versioned checkpoints as essential project memory and preservation mechanism.,"mlops,scaling,deployment",10,AI At Scale
104201,86,barely-true,Versioned model checkpoints always fully preserve all training decisions and provenance for reproducibility.,"versioned checkpoints, model checkpointing",Overstates checkpoint capabilities; passage emphasizes documenting but not guaranteeing complete provenance or decisions.,"mlops,scaling,deployment",10,AI At Scale
104202,43,barely-true,MT-Bench alone guarantees production-ready scaling and multiuser deployment for models.,scaling and benchmarking with MT-Bench in MLOps,Overreaches: passage praises MT-Bench for actionable benchmarking but does not claim production scaling or deployment guarantees.,"mlops,scaling,deployment",10,AI At Scale
104203,43,TRUE,"MT-Bench provides actionable, open-source benchmarking that helps teams improve model outcomes.",open-source benchmarking (MT-Bench) for models and scaling,Passage explicitly praises MT-Bench as actionable open-source benchmarking that shapes outcomes and aids teams.,"mlops,scaling,deployment",10,AI At Scale
104204,43,mostly-true,MT-Bench provides actionable open-source benchmarking that guides teams toward deployable improvements.,open-source benchmarking tool MT-Bench in scaling and deployment,"Passage praises MT-Bench as actionable for teams, omitting minor limits on scale or dataset coverage.","mlops,scaling,deployment",10,AI At Scale
104205,178,TRUE,"ReLU activation helps neural networks learn complex, non-linear decision boundaries for digit classification.",activation functions comparison (ReLU vs. Sigmoid/tanh),Passage explains need for non-linear boundaries; ReLU commonly used to enable complex feature learning.,"deep-learning,frameworks,tensors",5,Deep Learning
104206,178,mostly-true,"ReLU activations generally enable neural networks to learn complex, non-linear decision boundaries more effectively than sigmoid or tanh.",activation functions for separating interwoven digit data,"Supported by passage's comparison of ReLU versus sigmoid/tanh for complex, non-linear class separation; omits specific empirical caveats.","deep-learning,frameworks,tensors",5,Deep Learning
104207,178,TRUE,"ReLU helps models learn complex, non-linear decision boundaries between classes.","activation functions (ReLU, sigmoid, tanh) in neural networks","Passage contrasts ReLU vs sigmoid/tanh and describes needing non-linear boundaries, supporting ReLU aiding complex separation.","deep-learning,frameworks,tensors",5,Deep Learning
104208,55,mostly-true,The cleaning pipeline fills missing Species with LLM inferences and imputes Height and Weight by species means.,data cleansing script using LangChain and Mistral model for Species inference,"Procedure aligns with code: LLM calls populate Species, then group mean imputation for Height and Weight; minor caveat about external call latency.","data-prep,feature-engineering,rag",3,Prepping Data for AI
104209,55,TRUE,Species values were inferred using an LLM to fill missing entries in the dataset.,"data cleansing script using LLM species inference (LangChain, Mistral)","Passage shows get_species calls via LangChain/Mistral to populate missing Species, reporting counts filled.","data-prep,feature-engineering,rag",3,Prepping Data for AI
104210,55,half-true,The code infers missing Species with an LLM then imputes Height and Weight by species means.,data cleaning script using LLM (LangChain) and dataset 'superheroes_info_cleansed.csv',"Correct overall flow, but overstates reliability and omits external-call latency and possible inference errors.","data-prep,feature-engineering,rag",3,Prepping Data for AI
104211,140,TRUE,A seq2seq transformer model generates a detailed summary from a given paragraph.,sequence-to-sequence transformer (google/flan-t5-large) prompt and generation settings,Code shows tokenizer/model loading and model.generate producing a detailed summary using specified decoding parameters.,"generative-ai,diffusion,gans",7,Generative AI
104212,140,mostly-true,Generative models like seq2seq transformers can produce detailed summaries of complex paragraphs.,sequence-to-sequence transformer (google/flan-t5-large) summarization example,"Example shows FLAN-T5 generating a detailed summary with beam search and decoding, omitting potential factual inaccuracies.","generative-ai,diffusion,gans",7,Generative AI
104213,140,mostly-true,A seq2seq transformer (Flan-T5) can generate detailed summaries from provided paragraphs.,model code using google/flan-t5-large tokenizer and generate,Example shows Flan-T5 producing a detailed summary with beam search and generation settings; minor caveat of quality variability.,"generative-ai,diffusion,gans",7,Generative AI
104214,78,mostly-true,Prompt injection already occurs in LLM apps that fail to sanitize or over-trust inputs.,prompt injection in LLM-powered apps (Lakera Gandalf assets),"Passage directly describes prompt injection happening in apps that don't sanitize input or over-trust outputs, minor caveat omitted.","security,red-team,guardrails",8,Breaking-Securing AI
104215,78,half-true,Prompt injection already enables LLMs to autonomously perform tasks without user oversight in deployed apps.,prompt injection in LLM-powered apps (Lakera Gandalf assets),"Correctly notes real prompt-injection risks and deployed examples, but overstates autonomous task execution and lack of oversight.","security,red-team,guardrails",8,Breaking-Securing AI
104216,78,TRUE,Prompt injection attacks already occur in LLM-powered applications.,prompt injection in LLM-powered apps (Lakera’s Gandalf assets example),Passage states prompt injection is non-theoretical and already happening in LLM-powered apps lacking sanitization.,"security,red-team,guardrails",8,Breaking-Securing AI
104217,30,mostly-true,The agent-based pipeline generates a CSV glossary of detected open-source AI projects and metadata.,agent workflow for open-source project glossary generation,"Pipeline description and outputs largely support this, though implementation details and accuracy estimates are omitted.","open-source,community,contribution",13,Commit to Contribute
104218,30,pants-fire,All open-source projects mentioned are fabricated and never existed in reality.,open-source project glossary and agent pipeline,"Passage explicitly references real glossary, GitHub notebook, and appendix spreadsheet; claim contradicts these details.","open-source,community,contribution",13,Commit to Contribute
104219,30,half-true,The pipeline reliably estimates precise inception years for all detected open-source projects.,agent-based glossary pipeline extracting project metadata,"Partly true: pipeline extracts and estimates inception years, but precise accuracy and reliability aren’t guaranteed or validated.","open-source,community,contribution",13,Commit to Contribute
104220,27,half-true,Narrowing classes to Humans and Cyborgs improves model learning for focused prediction tasks.,"dataset class selection, Humans and Cyborgs","Accurate general point but oversimplifies; ignores potential bias, reduced generalization, and class balance issues.","machine-learning,classification,evaluation",4,Classical Machine Learning
104221,27,TRUE,Restricting classes to Humans and Cyborgs improves dataset suitability for the task.,dataset class selection (Humans and Cyborgs),Narrowing to relevant classes reduces distorted predictions and yields a more learnable dataset.,"machine-learning,classification,evaluation",4,Classical Machine Learning
104222,27,mostly-true,Narrowing a dataset to Humans and Cyborgs improves prediction suitability for that task.,"dataset selection for classification using focused labels (Humans, Cyborgs)",Supports idea that restricting classes reduces misleading variation and better matches target prediction goal.,"machine-learning,classification,evaluation",4,Classical Machine Learning
104223,45,TRUE,The visual format helps contributors see how open-source AI components fit together in practice.,visual format complementing glossary in open-source AI,"Directly supported: passage says the visual format turns glossary into structured view showing how open-source AI fits together, aiding contribution decisions.","open-source,community,contribution",13,Commit to Contribute
104224,45,pants-fire,Open-source contributors are paid guaranteed salaries by projects for long-term sustainability.,"licensing, governance, and sustainability of open-source work",Contradicts passage's focus on guidance and community support; no claim of guaranteed project-paid salaries.,"open-source,community,contribution",13,Commit to Contribute
104225,45,barely-true,Open-source contributors can secure long-term funding through licensing and governance alone.,business guidance on licensing and governance for open-source,Overreaches by implying licensing/governance alone ensure funding; passage only promises guidance on protection and sustainability.,"open-source,community,contribution",13,Commit to Contribute
104226,80,half-true,Using higher learning rates for later GAN layers can speed adaptation but risk destabilizing early features.,fine-tuning GANs with differential learning rates,Mixes correct idea (differential LR adapts later layers) with overstated certainty about trade-offs and risks.,"generative-ai,diffusion,gans",7,Generative AI
104227,80,mostly-true,Fine-tuning later GAN layers with higher learning rates typically adapts models without destabilizing earlier features.,differential learning rates for GAN fine-tuning,Technique is supported by example code; minor caveat: effectiveness depends on specific architecture and tuning.,"generative-ai,diffusion,gans",7,Generative AI
104228,80,pants-fire,Fine-tuning a GAN always improves its image quality without risk of destabilizing training.,fine-tuning GAN layers with differential learning rates,"Contradicts guidance about instability; passage says freezing layers or rates can reduce risk, not guarantee no destabilization.","generative-ai,diffusion,gans",7,Generative AI
104229,92,pants-fire,The passage claims resilience features can make heroes invincible against all extreme threats.,feature engineering for resilience using Durability and Healing Factor,Asserts impossible outcome; resilience features don't grant literal invincibility and contradicts specified attributes.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
104230,92,half-true,Combining distinct powers into single features always improves model performance for resilience and adaptability.,feature engineering for dataset using resilience and adaptability features,"Mixes correct idea of combining powers with an incorrect absolute claim about always improving model performance; ignores dataset, evaluation, and modeling caveats.","data-prep,feature-engineering,rag",3,Prepping Data for AI
104231,92,TRUE,Combining related abilities into composite features improves downstream model readiness for resilience and adaptability.,feature engineering for resilience and adaptability features,Passage explicitly describes blending abilities into resilience and adaptability features to highlight endurance and tactical strengths.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
104232,72,half-true,Imbalanced Alignment counts will cause a model to almost always predict the majority class.,"Gini coefficient on Alignment category counts (487 good, 206 bad, 24 neutral)","Correctly notes imbalance effect but overstates inevitability; model training, loss, or sampling can mitigate bias.","data-prep,feature-engineering,rag",3,Prepping Data for AI
104233,72,FALSE,Training a model on this dataset will almost always predict the 'good' class.,"Alignment value_counts for dataset labels (good, bad, neutral)",Class counts (487 vs 206 vs 24) contradict universal certainty; imbalance increases bias but not guaranteed dominance.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
104234,72,half-true,An imbalanced Alignment dataset will cause models to predominantly predict the majority class.,"dataset class imbalance (Alignment counts, Gini coefficient)","Correctly notes majority-class bias, but overstates certainty without model type, loss, or mitigation details.","data-prep,feature-engineering,rag",3,Prepping Data for AI
104235,26,barely-true,Users who share data with public AI systems are broadly fueling large models' value extraction.,data shared with public AI systems,Passage warns that user prompts and uploads refine large models and raises concern over who captures that value.,"ai,open-source,builder",1,Introduction – The Gold Rush Paradox
104236,26,barely-true,"Giving user data to public AI systems largely benefits large AI companies, not individual contributors.","data as fuel for large models, public system uploads",Overstates exclusivity of benefit; passage warns firms gain value but omits possible individual benefits or controls.,"ai,open-source,builder",1,Introduction – The Gold Rush Paradox
104237,26,FALSE,Users should never share any prompts because all data fuels large AI models.,data sharing and public AI systems,"Contradicts passage nuance: warns about value transfer and uncertainty, not an absolute prohibition.","ai,open-source,builder",1,Introduction – The Gold Rush Paradox
104238,85,TRUE,Practicing MLOps encourages saving model versions with contextual metadata for reuse.,"model versioning, checkpoints, T5 model, enhanced LIAR dataset",Passage explicitly recommends saving each model version with meaningful context and mentions T5 and dataset examples.,"mlops,scaling,deployment",10,AI At Scale
104239,85,half-true,Model versions and metadata must always be stored with checkpoints for reproducible deployment.,versioned checkpoints with T5 and enhanced LIAR dataset,Partly accurate: emphasizes versioning and metadata but overstates universality and ignores alternative reproducibility practices and tooling nuances.,"mlops,scaling,deployment",10,AI At Scale
104240,85,half-true,Model checkpoints and metadata are sufficient to guarantee reproducible T5 experiments at scale.,"versioned checkpoints, T5 model, enhanced LIAR dataset","Partly correct: versioned checkpoints and metadata help reproducibility, but omit environment, hyperparameters, and deployment factors.","mlops,scaling,deployment",10,AI At Scale
104241,83,FALSE,AI systems inherently improve humanity without intentional design or governance.,intentional design and deployment of AI,"Contradicts passage assertion that intentional design, development, and deployment are required.","ethics,governance,privacy",11,AI Ethics and Governance
104242,83,half-true,AI will automatically improve lives without intentional design or governance.,AI ethics and governance; intentional design and deployment,Mixes accurate hope that AI can help with incorrect claim that governance isn't needed; omits intentional design requirement.,"ethics,governance,privacy",11,AI Ethics and Governance
104243,83,TRUE,"AI can help humanity progress if intentionally designed, developed, and deployed for that purpose.",ethics and governance; intentional design and deployment,"Passage affirms AI’s potential to improve lives but emphasizes intentional design, development, and deployment.","ethics,governance,privacy",11,AI Ethics and Governance
104244,1,TRUE,Agentic AI adapts game-derived strategies for real-world decision-making and autonomous action.,agentic AI using game-based mechanics and simulations,Passage explicitly links agentic AI to games like Deep Blue and AlphaGo and says it adapts strategies for real-world use.,"agentic-ai,planning,tools",12,Agentic AI
104245,1,barely-true,Agentic AI never uses game strategies when deployed in real-world tasks.,agentic AI adapting game-based strategies for real-world use,"Overreaches: passage says agentic AI draws from games and adapts strategies, not that it never uses them.","agentic-ai,planning,tools",12,Agentic AI
104246,1,half-true,Agentic AI adapts game-derived strategies like planning and simulation for real-world decision-making.,agentic AI using simulations and game-based strategies,Mixes correct adaptation claim with incorrect implication that games alone provide comprehensive real-world solutions.,"agentic-ai,planning,tools",12,Agentic AI
104247,14,mostly-true,He advocates open-source approaches to automation and AI within IBM's engineering initiatives.,"open-source approach, AI systems, Hyper Learning Platform","Supported by his IBM Open Innovation Community membership and launched open-source tools, omitting minor program scope details.","ai,open-source,builder",1,Introduction – The Gold Rush Paradox
104248,14,pants-fire,He single-handedly built a proprietary AI model that secretly replaced IBM's open-source tools.,open-source automation and AI initiatives,"Contradicts described advocacy and open-source projects; passage states promotion of open-source, not secret proprietary replacement.","ai,open-source,builder",1,Introduction – The Gold Rush Paradox
104249,14,mostly-true,He has long promoted open-source approaches to AI and automation within IBM's innovation community.,"IBM Open Innovation Community, open-source automation and AI initiatives",Supports promotion of open-source work and initiatives like an open-source ROI calculator and community advocacy.,"ai,open-source,builder",1,Introduction – The Gold Rush Paradox
104250,40,TRUE,"Agentic prompting becomes highly effective when iteratively tested, tuned, and refined as a developer tool.",prompt templates and agent instructions,"Passage states iterative testing, tuning, and refinement make prompt-based agents one of the most effective tools.","agentic-ai,planning,tools",12,Agentic AI
104251,40,half-true,Agentic tools usually succeed immediately without iterative developer tuning or testing.,prompt templates and developer tool refinement for agents,Combines correct idea that agents benefit from templates with incorrect claim they succeed immediately without iteration.,"agentic-ai,planning,tools",12,Agentic AI
104252,40,half-true,Agentic prompting always fails on first attempt but becomes highly effective after iterative tuning.,prompt templates and developer tool workflow for agentic AI,"Accurately notes common initial failure and improvement with tuning, but overstates 'always' and 'highly effective'.","agentic-ai,planning,tools",12,Agentic AI
104253,76,barely-true,Agentic AI today faces identical core risks as AI ethics debates from a decade ago.,"ethical risks like fairness, privacy, transparency, misinformation",Overstates continuity; passage notes similarity but not exact sameness of risks or structures.,"ethics,governance,privacy",11,AI Ethics and Governance
104254,76,TRUE,"Agentic AI discussions echo earlier AI ethics debates about fairness, privacy, and transparency.","ethical concerns in AI (fairness, privacy, transparency)","Directly supported by Rossi comparing agentic AI discussions to prior ethics debates listing fairness, privacy, transparency.","ethics,governance,privacy",11,AI Ethics and Governance
104255,76,half-true,Agentic AI discussions today reuse prior AI ethics concerns like privacy and transparency but add novel architecture debates.,"AI ethics discussion referencing privacy, transparency, fairness",Combines accurate reuse of privacy/transparency with added claim about 'novel architecture debates' not specified in passage.,"ethics,governance,privacy",11,AI Ethics and Governance
104256,29,TRUE,Generative models commonly omit security checks like authentication unless prompts are highly specific.,prompting generative models for code or scripts (S3 upload example),Passage states models optimize for functionality and often skip authentication or validation unless prompts are painfully specific.,"security,red-team,guardrails",8,Breaking-Securing AI
104257,29,mostly-true,Default model outputs often omit security checks like authentication and rate limiting.,"model prompts producing scripts or code (authentication, rate limiting)","Broadly supported by passage: models optimize for functionality and commonly skip credential validation or rate limits, omitting minor caveats about specific prompts.","security,red-team,guardrails",8,Breaking-Securing AI
104258,29,half-true,Models often generate functional code that omits essential security checks like authentication.,"prompting models to produce scripts or code (authentication, S3 example)",Partly correct: passage shows omission of authentication in examples but overgeneralizes across all models and cases.,"security,red-team,guardrails",8,Breaking-Securing AI
104259,128,pants-fire,All necessary plot concept data already exists in superheroes_info_powers.csv for RAG preparation.,dataset superheroes_info_powers.csv and missing plot concepts,"Direct contradiction: passage says plot concepts dataset does not yet exist, so claim is implausible.","data-prep,feature-engineering,rag",3,Prepping Data for AI
104260,128,FALSE,Both required datasets are already available for training the model.,dataset availability for superheroes_info_powers.csv and plot concepts,"Contradicts passage: plot concepts dataset explicitly does not yet exist, only heroes CSV exists.","data-prep,feature-engineering,rag",3,Prepping Data for AI
104261,128,mostly-true,"Hero attribute datasets enable consistent character portrayal, while plot-concept data remains unavailable.",dataset: superheroes_info_powers.csv and missing plot concepts dataset,Passage explicitly names superheroes_info_powers.csv for attributes and states plot concepts dataset does not exist.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
104262,69,TRUE,The Nash equilibrium in Rock-Paper-Scissors is to randomize each action one-third of the time.,iterated RPS model and Nash equilibrium concept,Directly stated: the passage explicitly answers that equilibrium is uniform randomization over actions.,"neural-networks,cnn,transformers",6,Neuron Building Blocks
104263,69,FALSE,Nash equilibrium in Rock-Paper-Scissors requires deterministic rotation through actions.,game-theory concept in iterated RPS model,"Contradicts equilibrium detail: passage states randomizing one-third each action, not deterministic rotation.","neural-networks,cnn,transformers",6,Neuron Building Blocks
104264,69,mostly-true,The Nash equilibrium in Rock-Paper-Scissors is randomizing each action one-third of the time.,"iterated RPS model, Nash equilibrium concept",Directly stated in the passage; minor caveat about mixed-strategy formalism omitted.,"neural-networks,cnn,transformers",6,Neuron Building Blocks
104265,38,mostly-true,A biased hiring dataset caused Amazon's recruiting model to replicate and amplify gender discrimination.,biased dataset and recruiting model (Amazon hiring),Directly supported: passage describes historical hiring data training a model that replicated and amplified gender bias.,"security,red-team,guardrails",8,Breaking-Securing AI
104266,38,pants-fire,The passage claims an exploit in Amazon's hiring model deliberately targeted genders.,biased dataset and recruiting model,"Contradicts passage which says bias arose from dataset training, not a deliberate exploit or targeted attack.","security,red-team,guardrails",8,Breaking-Securing AI
104267,16,half-true,Google Colab requires a Google account and preinstalls many standard Python libraries.,Google Colab notebook and pip package manager,"Partly correct: account requirement and preinstalled libraries are true, but implication that all needed libraries are included is misleading.","ai,tool-chain,notebooks",2,AI Survival Kit
104268,16,pants-fire,The notebook runs without any internet connection or Google account required.,Google Colab notebook and pip package installation,Contradicts explicit requirement of a Google account and web access for Colab and pip installations.,"ai,tool-chain,notebooks",2,AI Survival Kit
104269,87,FALSE,Model checkpoints and run records are unnecessary for reproducible experiments.,"saving trained model and run record (checkpoint, configuration, metrics)","Contradicts passage: it says saving model plus run record enables replication, so claiming unnecessary is false.","mlops,scaling,deployment",10,AI At Scale
104270,87,mostly-true,Recording a model's trained weights plus run metadata generally enables reproducible experiments.,"model checkpointing and run metadata (configuration, data source, metrics)","Supports replication by saving trained model and run record, but omits tooling and environment details.","mlops,scaling,deployment",10,AI At Scale
104271,87,FALSE,Saving only the trained model is sufficient to fully reproduce experiments without extra records.,model snapshot including configuration and performance metrics,"Contradicts recommendation to save run records; omits configuration, data source, and metrics needed.","mlops,scaling,deployment",10,AI At Scale
104272,10,pants-fire,Adversaries can never find weaknesses in open AI systems under any circumstances.,red-team attacker mindset for open systems,Directly contradicts passage that attackers expose exploits and reveal weak points early.,"security,red-team,guardrails",8,Breaking-Securing AI
104273,10,half-true,Adversarial red-teamers can identify and patch vulnerabilities before public attackers exploit them.,red-team adversary testing of open AI systems,"Partly true: attacker thinking finds weak points early, but premature patches may miss unknown exploits or scale issues.","security,red-team,guardrails",8,Breaking-Securing AI
104274,10,FALSE,Adversaries cannot exploit AI weaknesses if defenders think like attackers.,red-team attacker mindset for open systems,Contradicts passage: attacker thinking is presented as necessary to reveal and fix weaknesses.,"security,red-team,guardrails",8,Breaking-Securing AI
104275,94,TRUE,Random vertex noise on an icosphere produces diverse training samples for the VAE.,"icosphere base mesh, vertex noise, VAE input","Passage explains random noise applied to each vertex and flattened into tensors, providing diverse samples for training.","generative-ai,diffusion,gans",7,Generative AI
104276,94,half-true,The dataset uses per-vertex Gaussian noise to crumple icosphere meshes before VAE input.,data generation for VAE using icosphere mesh and random noise,"Correct about icosphere and random vertex perturbations, but unspecified noise distribution and magnitude make it partially imprecise.","generative-ai,diffusion,gans",7,Generative AI
104277,94,TRUE,Random vertex noise is applied to an icosphere mesh each sample to simulate crumpling for VAE training.,"icosphere base mesh, vertex noise, VAE input tensor",Passage explicitly describes applying random noise to each vertex and flattening into a tensor for VAE training.,"generative-ai,diffusion,gans",7,Generative AI
104278,134,mostly-true,The generated dataset integrates into a RAG pipeline after model initialization and option settings.,superheroes_story_plots.csv dataset in RAG pipeline,"Workflow describes dataset creation and plugging into RAG after initializing model and options, omitting minor implementation details.","data-prep,feature-engineering,rag",3,Prepping Data for AI
104279,134,FALSE,RAG pipelines cannot use newly created CSV datasets for retrieval.,newly created dataset superheroes_story_plots.csv in RAG pipeline,Contradicts passage which explicitly states the CSV dataset plugs into the RAG pipeline for retrieval.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
104280,134,pants-fire,"The RAG pipeline automatically generates flawless, bias-free datasets without human review.",superheroes_story_plots.csv dataset in RAG pipeline,Pipeline outputs were created from model runs; claim denies need for human review and ignores model bias risks.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
104281,111,TRUE,Red Team and Blue Team roles formalize attacker and defender functions in AI security.,structured Red Team and Blue Team process for AI deployments,Passage states Red Team and Blue Team replace 'hacker' and 'defender' and guide production security practices.,"security,red-team,guardrails",8,Breaking-Securing AI
104282,111,barely-true,Red and Blue Teams routinely convert abstract attacker-defender ideas into production security processes.,security practice using Red Team and Blue Team processes,"Overstates routine application; passage describes guiding through how to apply teams, not asserting they already commonly convert ideas into production.","security,red-team,guardrails",8,Breaking-Securing AI
104283,111,TRUE,A Red Team and Blue Team process is the standard structured approach for securing AI deployments.,Red Team and Blue Team process for AI system deployments,Passage explicitly calls the Red Team/Blue Team structured process the standard for security work in production.,"security,red-team,guardrails",8,Breaking-Securing AI
104284,46,half-true,An RNN trained on a short sentence perfectly learns every next-character transition after minimal epochs.,RNN character-level prediction model (Listing 5.6),Model example shows character prediction but passage doesn't claim perfect learning or minimal epochs; overstates performance.,"neural-networks,cnn,transformers",6,Neuron Building Blocks
104285,46,FALSE,A recurrent neural network is used to predict the next character in a short sentence.,character-level RNN example in Listing 5.6,"Contradicts passage description: RNN example indeed performs next-character prediction, so label should be TRUE not FALSE.","neural-networks,cnn,transformers",6,Neuron Building Blocks
104286,46,half-true,An RNN trained on character sequences reliably predicts the next character in any sentence.,character-level RNN next-character prediction example,"Example shows successful learning for a short sentence, but generalizing to any sentence is overstated.","neural-networks,cnn,transformers",6,Neuron Building Blocks
104287,3,half-true,Scaling AI improvements can be measured by benchmarks but also require trust and explainability.,"Scaling AI, benchmark and trust in model evaluation",Mixes correct points—benchmarks and trust matter—with an overstated equivalence between measurement and explainability.,"mlops,scaling,deployment",10,AI At Scale
104288,3,barely-true,Scaling AI primarily requires optimizing models for measurable performance and reliability at larger dataset and compute scales.,"scaling, benchmark, tune, measure, optimize","Overreaches: passage emphasizes trust, explainability, and sharing beyond mere optimization for performance.","mlops,scaling,deployment",10,AI At Scale
104289,3,barely-true,Scaling AI primarily requires measuring performance and sharing benchmarks to build trust.,"scaling, benchmark, measure, trust","Overstates focus on only measurement and sharing; passage also emphasizes tuning, optimization, explainability, and reliability.","mlops,scaling,deployment",10,AI At Scale
104290,70,TRUE,Batching inputs on GPU reduces average cost per sample for large datasets and real-time serving.,GPU batching; tokenizer matrix of token IDs,"Passage explains stacking prompts into a token ID matrix for concurrent processing, lowering per-sample GPU cost.","mlops,scaling,deployment",10,AI At Scale
104291,70,TRUE,Batching multiple prompts reduces average GPU cost per sample during model inference.,batching inputs and tokenizer matrix of token IDs,"Passage explains stacking prompts and tokenizer creating token-ID matrix, which lowers average GPU cost per sample.","mlops,scaling,deployment",10,AI At Scale
104292,70,half-true,Batching inputs on GPUs always halves per-sample latency while doubling throughput for all model sizes.,GPU batching of tokenized prompt matrices for real-time serving,"Correct that batching reduces per-sample cost and increases throughput, but claiming exact halving/doubling and universality across model sizes is an oversimplified, often incorrect specific.","mlops,scaling,deployment",10,AI At Scale
104293,98,half-true,"About 10% of hero records mismatch, indicating possible missing power-related data.",dataset alignment and Power Ratings feature engineering,Mixes correct mismatch rate with implied production impact; overlooks that 10% was acceptable for current purposes and may not require review.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
104294,98,TRUE,Feature engineering can confidently incorporate power-related features after dataset alignment.,aligned dataset with Power Ratings and hero features,"Passage states alignment enables adding power-related features, noting 10% mismatches acceptable for current use.","data-prep,feature-engineering,rag",3,Prepping Data for AI
104295,98,FALSE,All heroes have complete and perfectly aligned power-related features for production use.,dataset alignment and Power Ratings feature engineering,"Contradicts passage detail that about 10% of heroes do not match, indicating missing or inconsistent data.","data-prep,feature-engineering,rag",3,Prepping Data for AI
104296,81,FALSE,Projecting superheroes onto two principal components preserves all clustering structure from sixty components.,PCA projection of superhero power feature matrix,Contradicts passage: two PCs provide quick visual but do not preserve full clustering computed on 60 components.,"machine-learning,classification,evaluation",4,Classical Machine Learning
104297,81,mostly-true,Projecting heroes onto two principal components provides a quick visual of cluster spread.,PCA visualization using principal components and clustering on superhero dataset,"Supported: passage says two PCs give quick visual while full clustering used 60 components, minor caveat omitted.","machine-learning,classification,evaluation",4,Classical Machine Learning
104298,81,half-true,Projecting heroes onto two principal components preserves most clustering structure from 60 components.,"PCA dimensionality reduction on superhero power features (60 components, 2 PCs)","Correct that 2-PC plot shows cluster spread, but claim overstates preservation of structure lost from 60 components.","machine-learning,classification,evaluation",4,Classical Machine Learning
104299,15,half-true,Open-source Python libraries are practical but sometimes slower and less user-friendly than commercial tools.,data preparation using Python and open-source libraries,Mixes accurate benefits and accessibility with an imprecise generalization about speed and usability for all projects.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
104300,15,TRUE,Open-source Python libraries provide practical data-prep tools suitable for most AI projects.,using Python and open-source libraries for data preparation,"Passage states Python open-source tools are accessible, widely used, and balance practicality for most projects.","data-prep,feature-engineering,rag",3,Prepping Data for AI
104301,15,TRUE,Open-source Python libraries provide a practical balance for most data preparation projects.,using Python and open-source libraries for dataset preparation,"Directly supported: passage states open-source Python tools are practical, widely used, and balanced for most projects.","data-prep,feature-engineering,rag",3,Prepping Data for AI
104302,35,pants-fire,The model provably detects anyone's voice with perfect accuracy using fingerprint summaries.,speaker model training and neg_p95_threshold on fingerprint features,Passage describes training and thresholding for Jerry only; claim contradicts model scope and performance assumptions.,"media-forensics,voice-cloning,deepfake",9,Deepfake Defense
104303,35,FALSE,The system uses logistic regression trained only on synthetic deepfakes to detect Jerry’s voice.,"training pipeline, features_matrix, logistic regression model","Contradicts passage: model trained on both Jerry and Non_Jerry files, not solely synthetic deepfakes.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
104304,35,half-true,The model uses fingerprint features and logistic regression to recognize Jerry's voice.,"training pipeline with fingerprinting, features_matrix, logistic regression model",Mixes correct pipeline elements with incorrect certainty about model generalization and threshold derivation.,"media-forensics,voice-cloning,deepfake",9,Deepfake Defense
104305,39,FALSE,Logistic regression cannot model probabilities or be used for classification tasks.,Logistic regression model for classification,Contradicts passage: logistic regression explicitly models probabilities and is used for binary and multiclass classification.,"machine-learning,classification,evaluation",4,Classical Machine Learning
104306,39,half-true,Logistic regression only handles binary classification and cannot model multiple classes.,"Logistic regression model, classification, multiple classes",Contradicts passage which says logistic regression often used for two outcomes but can handle multiple classes.,"machine-learning,classification,evaluation",4,Classical Machine Learning
104307,39,half-true,Logistic regression always models class probabilities using a linear decision boundary in feature space.,logistic regression classification probability modeling,"Correct that logistic regression models probabilities, but claiming it always yields linear boundaries ignores feature transforms or nonlinear kernels.","machine-learning,classification,evaluation",4,Classical Machine Learning
104308,36,barely-true,Few-shot prompting always yields significantly better responses than zero-shot prompting.,"prompting techniques: zero-shot, one-shot, few-shot examples",Overstates effectiveness; passage only defines prompting types without claiming consistent performance advantage.,"agentic-ai,planning,tools",12,Agentic AI
104309,36,mostly-true,Few-shot prompting provides multiple examples to guide consistent model behavior across tasks.,"prompting techniques (zero-shot, one-shot, few-shot)","Passage describes few-shot as including multiple examples to show a consistent pattern, a broadly accurate summary.","agentic-ai,planning,tools",12,Agentic AI
104310,36,TRUE,Few-shot prompting supplies multiple examples to demonstrate a consistent pattern for the model.,"few-shot prompting definition, prompting techniques",Directly supported by passage: few-shot includes multiple examples showing a consistent pattern to guide responses.,"agentic-ai,planning,tools",12,Agentic AI
104311,151,mostly-true,Open-source security tools accelerate defense development by providing community-built building blocks.,"open-source tools like LYNX, Gandalf, HumanLayer","Broadly supported by passage: community tools and shared context speed defenses, minor caveat about polish omitted.","security,red-team,guardrails",8,Breaking-Securing AI
104312,151,pants-fire,Open-source security tools always make systems invulnerable to advanced AI attacks.,"open source tools like LYNX, Gandalf, HumanLayer","Claims absolute invulnerability contradicts passage's claim of speed and shared context, not perfect protection.","security,red-team,guardrails",8,Breaking-Securing AI
104313,151,TRUE,Open source accelerates security by providing ready building blocks and community tools.,"open source tools like LYNX, Gandalf, HumanLayer","Passage explicitly states open source offers building blocks and community-developed tools, speeding security response.","security,red-team,guardrails",8,Breaking-Securing AI
104314,179,barely-true,Activation functions like ReLU always solve complex non-linear class separations in neural networks.,"activation functions, ReLU, non-linearity in neural networks",Overreaches claim: passage says ReLU introduces nonlinearity but doesn't guarantee solving complex separations.,"deep-learning,frameworks,tensors",5,Deep Learning
104315,179,half-true,Activation functions like ReLU introduce nonlinearity by switching neurons off on one side of a boundary.,activation functions; ReLU hinge behavior in neural networks,Accurately describes ReLU's hinge-like nonlinearity but omits that many activations and architectures provide varied nonlinear behaviors.,"deep-learning,frameworks,tensors",5,Deep Learning
104316,179,half-true,Activation functions introduce nonlinearity so networks can separate interwoven data patterns with nonlinear boundaries.,activation functions (ReLU) enabling nonlinear decision boundaries,Accurately states purpose of activations but overgeneralizes that they always suffice for complex interwoven patterns.,"deep-learning,frameworks,tensors",5,Deep Learning
104317,50,FALSE,The MIT license prohibits commercial use of software and derivatives.,"open-source license terms (MIT, Apache 2.0)",Contradicts passage detail that MIT explicitly allows commercial use and sublicensing; misstates permissions.,"open-source,community,contribution",13,Commit to Contribute
104318,50,barely-true,The MIT license forbids commercial use of software it covers.,"software license terms (MIT, Apache 2.0) in open-source contribution",Contradicts passage saying MIT allows commercial use and sublicensing; notable legal error.,"open-source,community,contribution",13,Commit to Contribute
104319,50,half-true,The MIT-style license permits unrestricted reuse but provides no patent protections.,"open-source license choice (MIT-style, Apache 2.0 comparison)",Mixes correct reuse/low restriction claim with incorrect omission: passage notes Apache 2.0 adds patent protections.,"open-source,community,contribution",13,Commit to Contribute
104320,35,barely-true,LSTMs always outperform GRUs on language modeling tasks involving long text.,"RNN variants: LSTM, GRU in language modeling",Overstates performance: passage says LSTMs are more expressive but doesn't claim they always outperform GRUs.,"neural-networks,cnn,transformers",6,Neuron Building Blocks
104321,35,TRUE,LSTMs capture complex long-term dependencies better than GRUs.,recurrent units (LSTM vs GRU) for language modeling,Passage states LSTMs are more expressive and better suited for complex or long-term dependencies than GRUs.,"neural-networks,cnn,transformers",6,Neuron Building Blocks
104322,35,half-true,GRUs always train faster and require substantially fewer resources than LSTMs.,recurrent unit comparison (GRU vs LSTM) in RNNs,Mixes correct efficiency claim with overgeneralization; passage says GRUs are leaner/faster but not universally or always.,"neural-networks,cnn,transformers",6,Neuron Building Blocks
104323,14,half-true,Major tech companies and open-source projects universally enforce identical AI ethics practices across all products.,"AI ethics advisory boards, open-source transparency","Mixes correct fact of industry ethics initiatives with incorrect claim of universal, identical enforcement.","ethics,governance,privacy",11,AI Ethics and Governance
104324,14,FALSE,"Open-source AI guarantees transparent, fully trustworthy models for all users.","open-source AI, transparency, explainability",Contradicts passage: open-source invites transparency but does not guarantee fully trustworthy models.,"ethics,governance,privacy",11,AI Ethics and Governance
104325,14,TRUE,Major tech companies and open-source projects actively promote AI ethics principles like fairness and accountability.,AI ethics advisory boards and open-source AI transparency,"Passage states firms (IBM, Google, Amazon, Facebook, Microsoft) and open-source projects promote fairness, robustness, explainability, and accountability.","ethics,governance,privacy",11,AI Ethics and Governance
104326,68,TRUE,"IBM uses generative AI tailored to specific enterprise tasks, reducing open-ended risks.",enterprise use cases; generative AI tailored to tasks,"Directly supported by passage stating IBM's approach focuses on enterprise tasks and is more controlled, reducing risks.","ethics,governance,privacy",11,AI Ethics and Governance
104327,68,mostly-true,"IBM tailors generative AI for controlled, enterprise-specific tasks, reducing open-ended risks.",enterprise use cases; generative AI tailored to specific domains,"Passage states IBM focuses on domain-specific, controlled AI deployment, omitting minor residual risks.","ethics,governance,privacy",11,AI Ethics and Governance
104328,68,FALSE,IBM's generative AI is entirely free from open-ended risks in enterprise deployments.,"enterprise use cases, tailored AI and risk control",Contradicts passage nuance: it says IBM's approach is more controlled but not entirely risk-free.,"ethics,governance,privacy",11,AI Ethics and Governance
104329,87,TRUE,Convolutional and transformer models underpin many modern deep learning systems.,"foundational models for vision and language (convolution, transformer)",Passage states these models form the foundation of modern deep learning and power vision and language tasks.,"neural-networks,cnn,transformers",6,Neuron Building Blocks
104330,87,TRUE,Convolutional and transformer networks underpin many modern deep learning systems.,neural-networks; CNNs and transformers in generative AI,"Passage explicitly names networks as foundations powering vision, language, and generative AI applications.","neural-networks,cnn,transformers",6,Neuron Building Blocks
104331,87,mostly-true,Convolutional and transformer networks together underpin many modern generative and perceptual AI systems.,neural network architectures: CNNs and transformers in generative AI,"Passage affirms CNNs and transformers power vision, translation, and generative tasks; minor nuance about specific roles omitted.","neural-networks,cnn,transformers",6,Neuron Building Blocks
104332,114,half-true,Stable Diffusion always produces photorealistic images purely from text prompts.,Stable Diffusion text-to-image diffusion model,"Mixes correct capability (text-to-image generation) with overstatement; photorealism and consistency depend on prompts, settings, and model limits.","generative-ai,diffusion,gans",7,Generative AI
104333,114,FALSE,Stable Diffusion generates images step-by-step by predicting each pixel autoregressively.,model comparison: Stable Diffusion versus autoregressive models,"Contradicts passage: Stable Diffusion is a diffusion model, not an autoregressive pixel-predicting method.","generative-ai,diffusion,gans",7,Generative AI
104334,114,mostly-true,Stable Diffusion generates high-quality images from text prompts using probabilistic denoising.,"Stable Diffusion model, diffusion probabilistic process",Accurately reflects diffusion-based text-to-image generation; omits minor quality variability and conditioning details.,"generative-ai,diffusion,gans",7,Generative AI
104335,81,mostly-true,"PyTorch is used because its intuitive, Pythonic design often yields faster results with fewer headaches.",framework choice for training a network on MNIST,"Passage explicitly cites PyTorch's intuitive, Pythonic design and faster, less troublesome results; minor caveat about other frameworks omitted.","deep-learning,frameworks,tensors",5,Deep Learning
104336,81,half-true,PyTorch is always the fastest framework for training models on MNIST in production settings.,using PyTorch with MNIST dataset,Correctly praises PyTorch's ease for MNIST experiments but overstates speed and production suitability.,"deep-learning,frameworks,tensors",5,Deep Learning
104337,81,pants-fire,PyTorch cannot train a network to read handwritten MNIST digits under any circumstances.,training a network on the MNIST dataset using PyTorch,Contradicts passage and common knowledge: PyTorch routinely trains MNIST digit classifiers successfully.,"deep-learning,frameworks,tensors",5,Deep Learning
104338,19,half-true,The passage claims all needed Python packages are preinstalled in the Colab environment.,notebook environment / Colab preinstalled packages,Mixes correct note about common libraries with an inaccurate blanket claim about every needed package being installed.,"ai,tool-chain,notebooks",2,AI Survival Kit
104339,19,barely-true,"Pandas, Matplotlib, and Scikit-learn are unnecessary for standard Colab data science workflows.","tools: Pandas, Matplotlib, Scikit-learn in Colab environment",Passage states these libraries are beneficial and preinstalled; claiming they are unnecessary largely contradicts their described usefulness.,"ai,tool-chain,notebooks",2,AI Survival Kit
104340,19,TRUE,"Pandas, Matplotlib, and Scikit-learn are useful Python libraries for data work and modeling.",tool mentions in Colab environment,"Lists explicitly describe Pandas for data manipulation, Matplotlib for visualization, and Scikit-learn for modeling.","ai,tool-chain,notebooks",2,AI Survival Kit
104341,12,TRUE,"Data provenance and lineage are essential for ensuring fairness, accountability, and transparency in AI training.",training data provenance and data lineage in ethics and governance,"Passage explicitly links provenance and lineage to fairness, accountability, and transparency in training data.","ethics,governance,privacy",11,AI Ethics and Governance
104342,12,barely-true,Training data provenance alone guarantees fairness in AI systems.,data provenance and lineage in training datasets,"Overstates effect: provenance matters but passage says provenance and lineage are both key, not sufficient for fairness.","ethics,governance,privacy",11,AI Ethics and Governance
104343,12,half-true,Tracking data provenance and lineage alone guarantees unbiased medical research outcomes.,data provenance and data lineage in medical datasets,Combines correct emphasis on provenance/lineage with incorrect certainty; ignores other bias sources and processing choices.,"ethics,governance,privacy",11,AI Ethics and Governance
104344,79,TRUE,"Keras handles the training loop for users, simplifying model training and loss tweaks.",high-level API Keras for training loops and loss functions,Directly supported: passage states Keras takes care of the training loop while allowing loss adjustments.,"deep-learning,frameworks,tensors",5,Deep Learning
104345,79,half-true,Keras always fully automates training loops so users never need to call .backward() or manage gradients.,high-level framework behavior with Keras and tf.GradientTape,Mixes correct high-level automation claim with incorrect absolute: passage says Keras handles loops but tf.GradientTape gives control over gradients.,"deep-learning,frameworks,tensors",5,Deep Learning
104346,79,FALSE,Keras requires users to write low-level training loops with tf.GradientTape for every model.,Keras training loop and tf.GradientTape contrast,Contradicts passage: Keras handles the training loop automatically while tf.GradientTape is for low-level control.,"deep-learning,frameworks,tensors",5,Deep Learning
104347,129,TRUE,Synthetic data are artificially generated examples that mimic real-world data patterns.,definition of synthetic data in data-prep and feature-engineering,Directly described as artificially generated information that imitates real-world patterns and examples.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
104348,129,half-true,Synthetic data always preserves all statistical properties of real datasets for model training.,synthetic data for dataset augmentation,Mixes correct idea of imitation with an incorrect absolute claim; synthetic often approximates but may miss some real-world statistics.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
104349,129,mostly-true,Synthetic data can effectively mimic real-world patterns for many data-prep and augmentation tasks.,synthetic data for dataset augmentation in data-prep,"Broadly supported by defining synthetic data as imitating real-world patterns, though real-world fidelity can vary.","data-prep,feature-engineering,rag",3,Prepping Data for AI
104350,163,half-true,The semantic embedding fully determines each generated video frame in the diffusion process.,semantic embedding passed to a diffusion model,"Accurate that embedding guides generation, but passage says it guides rather than fully determines frames.","generative-ai,diffusion,gans",7,Generative AI
104351,163,mostly-true,The semantic embedding guides a diffusion model to iteratively generate coherent video frames from noise.,semantic embedding fed into a diffusion model for video generation,Describes passage process directly; omits minor details about embedding composition and iteration specifics.,"generative-ai,diffusion,gans",7,Generative AI
104352,163,FALSE,Semantic embeddings are discarded before video generation begins.,semantic embedding passed to diffusion model,Directly contradicts passage: embedding is described as passed to and guiding the diffusion model during generation.,"generative-ai,diffusion,gans",7,Generative AI
104353,6,TRUE,Models that succeed with multiple users require new deployment and scaling considerations.,"deploying models for concurrent users and devices (scaling, deployment)","Passage explains when models are used by others concurrently, operational concerns shift to deployment and scaling.","mlops,scaling,deployment",10,AI At Scale
104354,6,TRUE,Models intended for multiple simultaneous users require scaling and deployment considerations beyond single-user code.,deployment and scaling for lightweight models,Passage explains moving from single-user lightweight code to multi-user simultaneous deployment needs additional scaling and deployment work.,"mlops,scaling,deployment",10,AI At Scale
104355,6,mostly-true,AI systems that scale to multiple users require deployment and operational changes beyond lightweight code.,deployment and scaling for models used by multiple users,Passage indicates lightweight code is fine for solo use but scaling to simultaneous users demands operational shifts.,"mlops,scaling,deployment",10,AI At Scale
104356,33,TRUE,"Prompting combines structured phrasing, clarity, and iterative refinement to improve model responses.",prompting practice and model interaction,"Passage explicitly describes prompting as blending structure, clarity, and iteration to elicit responses.","agentic-ai,planning,tools",12,Agentic AI
104357,33,FALSE,"Users rarely prompt AI models, typically issuing fewer than five prompts daily.","prompting frequency and user behavior, prompt",Contradicts passage estimate that many people issue over fifty prompts daily; misstates prompt frequency.,"agentic-ai,planning,tools",12,Agentic AI
104358,33,half-true,Most users issue over fifty prompts daily to agentic AI systems according to the passage.,user behavior with prompts to AI models,"Passage claims many issue over 50 prompts, but offers no survey data or defined user population, mixing plausible and unsupported specifics.","agentic-ai,planning,tools",12,Agentic AI
104359,124,FALSE,"Model and tokenizer checkpoints ensure reproducible, shareable deployments for downstream users.","versioning checkpoint, save_pretrained(), tokenizer","Contradicts passage: checkpoints aid reproducibility but passage lists only saving and logging, not full deployment guarantees.","mlops,scaling,deployment",10,AI At Scale
104360,124,half-true,The passage asserts saving model and tokenizer ensures full reproducibility without extra metadata.,"model checkpoint, save_pretrained(), tokenizer",Overstates claim: saving weights/tokenizer helps reproducibility but omits run metadata and environment details needed.,"mlops,scaling,deployment",10,AI At Scale
104361,124,half-true,"Model checkpoints and tokenizer saves guarantee reproducible, traceable production deployments every time.",save_pretrained() checkpointing and JSONL run logs for model versioning,"Mixes correct tooling (save_pretrained, JSONL) with overstated guarantee about always ensuring reproducible production deployments.","mlops,scaling,deployment",10,AI At Scale
104362,78,half-true,Batching typically delivers three- to fivefold throughput improvements for inference workloads.,throughput optimization using batching in model deployment,"Passage claims 3–5× throughput from batching but omits conditions, hardware, and workload variability.","mlops,scaling,deployment",10,AI At Scale
104363,78,TRUE,Batching and model tuning can increase throughput by about three- to fivefold.,"scaling techniques: batching, model tuning, throughput",Passage states batching alone yields a three- to fivefold throughput boost and highlights model tuning benefits.,"mlops,scaling,deployment",10,AI At Scale
104364,78,half-true,Batching often yields several-fold throughput gains but requires careful tuning and may not always scale linearly.,inference batching and model tuning,"Passage claims three- to fivefold batching boosts yet omits caveats about non-linear limits, hardware, and workloads.","mlops,scaling,deployment",10,AI At Scale
104365,3,TRUE,Thoughtful data preparation turns raw inputs into reliable model-ready datasets for better model outputs.,data preparation for models; dataset cleaning and normalization,"Passage describes cleaning, normalization, and curation as technical foundation enabling reliable, expressive model output.","data-prep,feature-engineering,rag",3,Prepping Data for AI
104366,3,FALSE,RAG is the primary method used for cleaning and normalizing raw datasets for models.,"data-prep focusing on cleaning, normalizing, and RAG","Contradicts passage: cleaning and normalization are described as preprocessing steps, not RAG-dependent methods.","data-prep,feature-engineering,rag",3,Prepping Data for AI
104367,3,pants-fire,"Preparing raw data guarantees models will produce factually perfect, hallucination-free outputs.",data preparation and RAG for model input,"Passage emphasizes careful prep but never claims perfect, hallucination-free outputs; contradicts realism.","data-prep,feature-engineering,rag",3,Prepping Data for AI
104368,158,half-true,Anonymizing names with labels like 'Hero A' preserves dataset utility but hides sensitive specifics.,NLP dataset preprocessing using spaCy for named-entity anonymization,Mixes correct utility claim with omitted risks and specifics about reidentification and data fidelity.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
104369,158,mostly-true,Anonymizing named entities lets datasets be shared while preserving analytic usefulness for model training.,entity anonymization using spaCy for dataset preprocessing,Supports that replacing names/locations retains usability for analysis and training; minor caveat about potential utility loss omitted.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
104370,158,mostly-true,Anonymizing named entities preserves dataset utility while concealing sensitive details for model training.,named entity anonymization using spaCy for dataset preprocessing,"Supports claim: spaCy NER can replace names/locations, enabling safe sharing while retaining usability.","data-prep,feature-engineering,rag",3,Prepping Data for AI
104371,45,FALSE,Using open-source tools guarantees project success for any AI builder.,open tools and community collaboration in AI projects,"Contradicts passage which says open tools prevent lock-in and aid collaboration, not guarantee success.","ai,open-source,builder",1,Introduction – The Gold Rush Paradox
104372,45,FALSE,Open-source tools force builders to be tied to a single vendor from the start.,open tools and openness in building,"Contradicts passage: it asserts vendor lock-in, whereas passage states open tools prevent lock-in.","ai,open-source,builder",1,Introduction – The Gold Rush Paradox
104373,45,half-true,Open-source tool contributions always guarantee broad community feedback and career benefits.,open tools and collaboration in open-source projects,Mixes correct point about resume benefits with incorrect universality claim about guaranteed broad feedback.,"ai,open-source,builder",1,Introduction – The Gold Rush Paradox
104374,42,barely-true,Most deployed AI systems are black boxes assembled from unknown pretrained components and datasets.,"pre-trained weights, open datasets, public model hub",Overstates universality: passage warns about common practice but not that most systems always use unknown components.,"security,red-team,guardrails",8,Breaking-Securing AI
104375,42,mostly-true,"Most deployed AI systems combine pre-trained models, open datasets, and third-party components with unknown provenance.",integration of pre-trained weights and open datasets in model pipelines,"Broadly supported by passage that emphasizes cobbled-together models and unknown ingredient provenance, minor caveat about 'most' scope.","security,red-team,guardrails",8,Breaking-Securing AI
104376,42,barely-true,Most deployed AI stacks are opaque black boxes assembled from unverified third-party components.,pre-trained weights and public hub models,Overstates prevalence and certainty; passage warns risk but doesn't prove 'most' or universal opacity.,"security,red-team,guardrails",8,Breaking-Securing AI
104377,32,TRUE,Open-source contributions often include non-code items like documentation and datasets.,glossary of open-source projects dataset,"Dataset highlights show meaningful contributions beyond model weights and algorithms, supporting statement.","open-source,community,contribution",13,Commit to Contribute
104378,32,FALSE,Open-source contributions are solely model weights and algorithms.,glossary entries and open-source dataset,"Contradicts passage detail that meaningful contributions included non-code items, not just weights or algorithms.","open-source,community,contribution",13,Commit to Contribute
104379,32,mostly-true,Open-source contributions often include non-code artifacts like documentation and community processes.,glossary of open-source projects dataset,"Dataset highlights explicitly note meaningful contributions beyond model weights or algorithms, omitting minor qualifiers.","open-source,community,contribution",13,Commit to Contribute
104380,49,FALSE,Hallucinations are harmless in high-stakes financial and medical applications.,model hallucination risk in business and medical datasets,Directly contradicts passage noting hallucinations can be dangerous in financial and medical contexts.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
104381,49,TRUE,Hallucinations in models can cause dangerous errors in financial or medical applications.,model hallucination risk in business and medical datasets,Passage states hallucination risks are acceptable in playful datasets but dangerous in financial and medical contexts due to potential real harm.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
104382,49,mostly-true,Feature and data design reduce model hallucinations but may not eliminate bias or errors.,dataset and feature engineering for RAG and model outputs,"Supported by passage: mentions hallucinations and bias in datasets, but omits specifics and limits of mitigation.","data-prep,feature-engineering,rag",3,Prepping Data for AI
104383,162,TRUE,Pseudonymization replaces identifiable entities with generic terms while keeping relationships.,"data anonymization techniques, pseudonymization example",Passage explicitly defines pseudonymization as replacing identifiable data with generic terms while retaining dataset relationships.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
104384,162,TRUE,Pseudonymization replaces identifiable data with generic terms while preserving dataset relationships.,"data anonymization techniques, pseudonymization in datasets",Directly supported: passage defines pseudonymization as replacing identifiers with generic terms while retaining relationships.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
104385,162,barely-true,Pseudonymization always preserves all dataset relationships without any privacy tradeoffs.,"Data Anonymization Techniques, pseudonymization and dataset relationships",Overstates claim: passage says pseudonymization retains relationships but omits privacy risks and tradeoffs.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
104386,4,barely-true,Convolutional filters always learn to detect edges before higher-level features in CNNs.,CNN filters and layer feature hierarchy,Overreaches training dynamics: passage says filters detect edges but doesn't claim definite learning order.,"neural-networks,cnn,transformers",6,Neuron Building Blocks
104387,4,TRUE,Convolutional filters detect edges and build up complex scene representations in CNNs.,CNN filters and layers in neural-networks,Directly supported by text mentioning filters that detect edges and layers building complex scenes.,"neural-networks,cnn,transformers",6,Neuron Building Blocks
104388,4,barely-true,CNN filters always detect edges before building higher-level features in visual hierarchies.,CNN filters and layers in convolutional neural networks,Overreaches claim: passage mentions filters detect edges and layers build scenes but doesn't assert strict ordering or universality.,"neural-networks,cnn,transformers",6,Neuron Building Blocks
104389,91,barely-true,Convolutional layers always outperform transformers on image tasks with limited data.,comparison between CNN convolutional layers and transformer models,Overreaches: passage doesn't support universal superiority and ignores transformer pretraining and data-efficiency nuances.,"neural-networks,cnn,transformers",6,Neuron Building Blocks
104390,91,TRUE,Rock–Paper–Scissors is presented as an academic arXiv preprint from 2019.,paper citation arXiv:1903.05991,"Citation shows a 2019 arXiv preprint with that exact title and identifier, directly supporting claim.","neural-networks,cnn,transformers",6,Neuron Building Blocks
104391,91,TRUE,The passage references an arXiv preprint titled 'The Rock–Paper–Scissors Game' from 2019.,arXiv preprint reference (arXiv:1903.05991),"Reference explicitly lists the 2019 arXiv preprint and its identifier, matching citation details.","neural-networks,cnn,transformers",6,Neuron Building Blocks
104392,110,half-true,Model testing via Python requires only internet access and behaves like a standard function.,Python environment testing of model behavior,Accurate about Python function-like behavior but wrongly omits offline or local-only model options and dependencies.,"mlops,scaling,deployment",10,AI At Scale
104393,110,TRUE,Model behavior can be evaluated in Python by treating the model like a callable function.,testing model in a Python environment,"Passage states models load and act like Python functions, enabling scripting, evaluation, and testing.","mlops,scaling,deployment",10,AI At Scale
104394,110,TRUE,A loaded model can be used like a Python function for flexible testing and evaluation.,model loaded in Python environment for testing,Directly supported: passage describes model behaving like a Python function enabling scripting and evaluation.,"mlops,scaling,deployment",10,AI At Scale
104395,17,mostly-true,Models can mistakenly accept injected support-agent claims as authoritative without validation.,prompt injection example (Gandalf by Lakera) and support agent text,Passage describes an unvalidated support-agent line being treated as authoritative and Gandalf demonstrates this prompt-injection tactic.,"security,red-team,guardrails",8,Breaking-Securing AI
104396,17,TRUE,Models can be tricked by prompt injection into treating injected claims as authoritative.,prompt injection attack on model context window,"Passage describes unvalidated text causing AI to accept planted suggestions, citing Gandalf by Lakera example.","security,red-team,guardrails",8,Breaking-Securing AI
104397,17,barely-true,Prompt-injection trick tools always cause models to accept planted claims as authoritative without validation.,prompt injection example (Gandalf by Lakera),Overstates inevitability; passage shows a risk and an example but not that models always accept planted claims.,"security,red-team,guardrails",8,Breaking-Securing AI
104398,1,barely-true,Deep learning frameworks are unnecessary for understanding core deep learning concepts.,examples drawn from libraries and framework pointers,"Overreaches beyond passage: frameworks used for examples/considerations, not deemed unnecessary.","deep-learning,frameworks,tensors",5,Deep Learning
104399,1,pants-fire,All deep learning frameworks are unnecessary and obsolete compared to simple examples.,"examples drawn from libraries, deep-learning frameworks",Directly contradicts passage emphasis on illustrating concepts with library examples and framework pointers.,"deep-learning,frameworks,tensors",5,Deep Learning
104400,1,mostly-true,Deep learning concepts are illustrated using examples from specific libraries without full framework tutorials.,illustrative examples using deep learning frameworks and libraries,"Supports that examples from libraries are used while explicitly avoiding full tutorials, a minor caveat about depth omitted.","deep-learning,frameworks,tensors",5,Deep Learning
104401,31,FALSE,UNESCO and OECD declined to publish any AI ethics guidance after 2019.,"international guidance on AI ethics (UNESCO Recommendation, OECD Principles)","Contradicts evidence: UNESCO issued a 2021 Recommendation and OECD updated principles in 2024, so claim is false.","ethics,governance,privacy",11,AI Ethics and Governance
104402,31,TRUE,UNESCO and OECD issued international AI ethics frameworks promoting human rights and democratic values.,UNESCO Recommendation and OECD AI Principles documents,"Directly supported by passage: UNESCO Recommendation (2021) and OECD Principles (2019, updated 2024) promote rights and democratic values.","ethics,governance,privacy",11,AI Ethics and Governance
104403,31,mostly-true,"International organizations broadly foster accountable, rights-respecting AI through standards and guidance.",UNESCO Recommendation and OECD AI Principles on ethics,"Passage cites UNESCO and OECD creating global ethical frameworks and updated principles, supporting the claim with minor nuance about implementation.","ethics,governance,privacy",11,AI Ethics and Governance
104404,110,TRUE,Diffusion models are often more stable and less artifact-prone than GANs in image tasks.,comparison of diffusion models and GANs in image synthesis,"Passage states diffusion models use gradual refinement, causing greater stability and fewer artifacts than GANs.","generative-ai,diffusion,gans",7,Generative AI
104405,110,FALSE,Diffusion models are generally more artifact-prone and unstable than GANs.,diffusion models versus GANs in image synthesis,Contradicts passage claiming diffusion models are more stable and less artifact-prone than adversarial GANs.,"generative-ai,diffusion,gans",7,Generative AI
104406,110,pants-fire,Diffusion models are always entirely free of artifacts and never produce adversarial failures.,diffusion models versus GANs in image synthesis,Passage says diffusion models are more stable and less prone to artifacts; claim's absolute wording contradicts that nuance.,"generative-ai,diffusion,gans",7,Generative AI
104407,81,pants-fire,The model always predicts superhero comics with perfect certainty.,image classification top prediction and confidence score,"Claim contradicts passage: example shows 0.91 confidence, not perfect certainty; earlier behavior varied with token access.","ai,tool-chain,notebooks",2,AI Survival Kit
104408,81,mostly-true,"The model predicts image labels with confidence scores, often requiring a Hugging Face token.",image classification model output and Hugging Face access,Model outputs a top prediction and score; earlier code ran without token but newer setups may require one.,"ai,tool-chain,notebooks",2,AI Survival Kit
104409,59,barely-true,Adding batch normalization to GAN generators always stabilizes training across datasets.,"GAN training tips (Batch Normalization, Discriminator, Generator)",Overreaches beyond passage: BN can help but not guaranteed across datasets or architectures.,"generative-ai,diffusion,gans",7,Generative AI
104410,59,mostly-true,Adding BatchNorm in the generator and Dropout in the discriminator broadly stabilizes and regularizes GAN training.,"GAN training techniques (Batch Normalization, Dropout, training schedule)",Recommendation aligns with passage guidance; omits caveat that effects depend on architecture and tuning.,"generative-ai,diffusion,gans",7,Generative AI
104411,59,half-true,Adding Batch Normalization to the generator always stabilizes GAN training and prevents mode collapse.,"GAN training tips (Batch Normalization, Dropout, training schedule)","Partly true: batch norm often helps stabilize training, but it doesn't guarantee prevention of mode collapse or fix all instability.","generative-ai,diffusion,gans",7,Generative AI
104412,27,TRUE,GANs use a minimax game between generator and discriminator to produce high-quality synthetic data.,GAN minimax optimization game and synthetic data augmentation,Passage states the minimax dynamic makes GANs powerful for generating high-quality synthetic data and augmenting limited datasets.,"generative-ai,diffusion,gans",7,Generative AI
104413,27,half-true,GANs reliably produce high-quality synthetic medical images indistinguishable from real scans.,GANs for medical imaging dataset augmentation,"Accurate that GANs augment limited medical datasets, but overstates indistinguishability and reliability.","generative-ai,diffusion,gans",7,Generative AI
104414,27,mostly-true,GANs can augment limited datasets by generating realistic synthetic data to improve model training.,minimax optimization game in GANs for synthetic data augmentation,"Supports that GANs generate realistic data via the minimax game and help augment limited datasets, minor caveat about domain-specific quality.","generative-ai,diffusion,gans",7,Generative AI
104415,19,TRUE,The dataset contains incomplete and inconsistent fields from a fan-maintained source.,dataset scraped from a fan-maintained site,Explicitly notes scraping source and warns about completeness and consistency issues in fields.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
104416,19,mostly-true,The scraped fan-maintained dataset is generally useful for feature engineering but has some completeness and consistency gaps.,dataset scraped from a fan-maintained site,Supports usefulness for concrete technique exploration while noting sparse fields and subjective entries.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
104417,19,FALSE,The dataset is fully complete and consistently accurate across all fields.,fan-maintained dataset scraped from a site with sparse subjective fields,"Directly contradicts described limitations: scraping caused incompleteness, inconsistencies, and subjective fields.","data-prep,feature-engineering,rag",3,Prepping Data for AI
104418,8,half-true,Generative AI both composes entertainment content and designs new proteins for healthcare applications.,"applications: scripts, characters, music; protein design","Combines accurate entertainment uses with correct but oversimplified protein-design claim, mixing scope and detail.","generative-ai,diffusion,gans",7,Generative AI
104419,8,pants-fire,Generative AI can instantly cure rare diseases by designing perfect therapeutic proteins every time.,"protein design and rare disease simulation (generative-ai, model)","Directly contradicts passage's modest claim about helping design proteins; impossibly guarantees perfect, instantaneous cures.","generative-ai,diffusion,gans",7,Generative AI
104420,8,TRUE,"Generative AI composes music, writes scripts, and designs characters for entertainment.","applications in entertainment (scripts, characters, music)","Directly supported by passage listing composing music, scriptwriting, and character design as entertainment uses.","generative-ai,diffusion,gans",7,Generative AI
104421,10,mostly-true,Agentic systems combine planning and tool use to enable goal-directed behaviors beyond traditional models.,agentic AI with planning and tools,"Passage introduces agents, planning, and open-source tool frameworks; minor details about implementation omitted.","agentic-ai,planning,tools",12,Agentic AI
104422,10,barely-true,Agentic AI requires building agents that autonomously create and execute multi-step plans using tools.,building blocks behind agents; open-source frameworks,Overstates requirement: passage introduces agents and planning but doesn't claim autonomous multi-step tool execution is required.,"agentic-ai,planning,tools",12,Agentic AI
104423,10,mostly-true,Agentic AI combines planning and tool use to build interactive systems like a trivia game.,"agentic AI, planning, tools example using open-source frameworks","Broadly supported: passage describes building an AI-powered trivia game demonstrating planning and tool use, omitting implementation limits.","agentic-ai,planning,tools",12,Agentic AI
104424,151,half-true,A higher accuracy always indicates overall better model performance across metrics.,evaluation metrics and accuracy,Contradicts guidance: single accuracy gains can mask tradeoffs and require multiple metrics.,"machine-learning,classification,evaluation",4,Classical Machine Learning
104425,151,half-true,Using only accuracy reliably evaluates classification model performance.,evaluation metrics for classification models,Overlooks passage advice to measure with multiple metrics; ignores tradeoffs and masking between metrics.,"machine-learning,classification,evaluation",4,Classical Machine Learning
104426,151,pants-fire,Optimizing a model on a tiny dataset always yields better real-world performance.,evaluation metric tradeoffs and small dataset overfitting,Contradicts guidance about over-optimizing on small datasets causing overfitting and misleading metrics.,"machine-learning,classification,evaluation",4,Classical Machine Learning
104427,95,TRUE,The passage states YOLOv5 is used for real-time object detection in video annotation.,model: YOLOv5 for video annotation,Directly supported by listed YOLOv5 description mentioning real-time detection and video annotation.,"open-source,community,contribution",13,Commit to Contribute
104428,95,mostly-true,"YOLOv5 is often used for fast, accurate real-time video annotation of people, animals, and objects.","tool usage for video annotation (YOLOv5, spaCy)",Model description matches passage details but omits limitations and dataset specifics.,"open-source,community,contribution",13,Commit to Contribute
104429,95,mostly-true,YOLOv5 and spaCy are effective tools for speeding up annotation and pseudonymization workflows.,video annotation with YOLOv5 and spaCy pseudonymization,"Both tools are used for detection and tokenization in the passage, but effectiveness depends on dataset and implementation details.","open-source,community,contribution",13,Commit to Contribute
104430,53,mostly-true,Human reviewers remain crucial for spotting anomalous prompts and social-engineering cues.,human-in-the-loop review for guardrails and red-team security,"Passage emphasizes humans catching abnormal 'urgent refund' or fake 'CEO request', a minor caveat about scalability omitted.","security,red-team,guardrails",8,Breaking-Securing AI
104431,53,mostly-true,Human reviewers catch anomalous requests better than fully automated guardrails.,human-in-the-loop security review for guardrails,"Passage emphasizes humans spotting spoofed CEO requests and unusual refund prompts, noting automation misses such anomalies.","security,red-team,guardrails",8,Breaking-Securing AI
104432,53,TRUE,Human reviewers remain essential to detect anomalous prompts and social-engineering attacks.,red-team guardrails and human-in-the-loop review,Passage explicitly states humans catch abnormal requests like fake CEO or urgent refund social-engineering.,"security,red-team,guardrails",8,Breaking-Securing AI
104433,3,pants-fire,AI systems universally eliminate all privacy risks through certification and governance.,privacy safeguards and certification models in governance,Contradicts passage: certification and governance reduce but do not eliminate privacy risks; claim is implausible.,"ethics,governance,privacy",11,AI Ethics and Governance
104434,3,TRUE,Privacy safeguards and certification models are presented as tools for building public trust in AI.,privacy safeguards and certification models in AI governance,Passage explicitly lists privacy safeguards and certification models as significant tools to build public trust.,"ethics,governance,privacy",11,AI Ethics and Governance
104435,3,TRUE,Privacy safeguards and certification models help build public trust in AI systems.,privacy safeguards and certification models in governance,Passage explicitly links privacy safeguards and certification models to building public trust.,"ethics,governance,privacy",11,AI Ethics and Governance
104436,60,TRUE,GAN loss values do not always correlate with generated image quality during training.,GAN training dynamics and discriminator strength,Passage explains minimax dynamics where weak discriminators or strong discriminators decouple loss from perceptual quality.,"generative-ai,diffusion,gans",7,Generative AI
104437,60,barely-true,GAN training loss reliably indicates image quality across datasets and architectures.,GAN loss behavior during generator–discriminator minimax training,Contradicts passage guidance: losses often misalign with visual quality due to weak or strong discriminators.,"generative-ai,diffusion,gans",7,Generative AI
104438,60,barely-true,GAN training loss reliably indicates image quality during training.,GAN losses and Generator/Discriminator dynamics,Contradicts passage: losses can be misleading due to weak or overly strong Discriminators affecting apparent quality.,"generative-ai,diffusion,gans",7,Generative AI
104439,4,half-true,Francesca Rossi argues that a human-centered approach fully resolves all AI governance privacy issues.,interview with Francesca Rossi; Pillars of Ethical AI Governance; privacy,"Combines Rossi's human-centered emphasis with an overstated claim that it alone solves privacy governance, mixing truth and error.","ethics,governance,privacy",11,AI Ethics and Governance
104440,4,TRUE,Francesca Rossi offers human-centered insights on AI ethics and governance in the interview.,interview with Francesca Rossi; Pillars of Ethical AI Governance,Directly supported by interview description and explicit mention of human-centered perspective.,"ethics,governance,privacy",11,AI Ethics and Governance
104441,4,TRUE,Francesca Rossi provides a human-centered perspective on AI ethics and governance.,interview with Francesca Rossi; Pillars of Ethical AI Governance,Interview explicitly states Francesca shares human-centered insights on AI ethics and governance.,"ethics,governance,privacy",11,AI Ethics and Governance
104442,145,mostly-true,"Agent systems should include usage guardrails like limits on retries, response length, and active agents.",agentic-ai usage constraints and guardrails,"Passage advocates budgeting for iteration and specific constraints (retries, response length, active agents) as practical measures.","agentic-ai,planning,tools",12,Agentic AI
104443,145,half-true,Agent limits like restricting active agents always prevent harmful autonomous behavior in planning systems.,tool usage and agent limits in agentic-ai planning,"Correctly notes limits reduce risks, but overstates guarantee—guardrails don't always prevent harm.","agentic-ai,planning,tools",12,Agentic AI
104444,145,mostly-true,Agent systems should include simple operational guardrails like retry and length limits to reduce risks.,"agentic AI operational design, task retries and response length limits","Passage endorses simple constraints (retries, response length, active agents) but omits implementation challenges.","agentic-ai,planning,tools",12,Agentic AI
104445,28,pants-fire,AI certifications secretly enabled Cambridge Analytica to access millions of users' data.,AI certifications and datasets used for privacy governance,"Directly contradicts passage: Cambridge Analytica harvested data without certifications or consent, not enabled by them.","ethics,governance,privacy",11,AI Ethics and Governance
104446,28,half-true,AI certifications fully prevent misuse of harvested user data when applied to social platforms.,AI certifications for systems and datasets,"Certifications can improve trust but cannot fully prevent data harvesting or misuse, omitting enforcement limits.","ethics,governance,privacy",11,AI Ethics and Governance
104447,28,half-true,Some experts claim AI certifications would fully prevent misuse of harvested social data.,AI certifications for systems and datasets,"Overstates effectiveness; passage says certifications are advocated to reinforce trust but not guaranteed to prevent misuse, and Cambridge Analytica involved platform data harvesting and consent failures.","ethics,governance,privacy",11,AI Ethics and Governance
104448,183,mostly-true,Deep learning models commonly use the Adam optimizer with cross-entropy loss for training classification networks.,"optimizer = optim.Adam(model.parameters(), lr=0.001 and Cross-Entropy Loss",Passage explicitly shows Adam and cross-entropy used; minor caveat omits other optimizers and loss choices.,"deep-learning,frameworks,tensors",5,Deep Learning
104449,183,FALSE,Deep learning cannot learn non-linear decision boundaries like traditional models.,discussion of decision boundaries and Adam optimizer,Contradicts passage claim that deep learning finds complex non-linear decision boundaries; directly opposite statement.,"deep-learning,frameworks,tensors",5,Deep Learning
104450,183,TRUE,"Deep learning can find complex, non-linear decision boundaries that traditional models cannot.",optimizer and loss function snippet using Adam and cross-entropy,Passage explicitly states deep learning finds complex non-linear boundaries and contrasts with traditional models.,"deep-learning,frameworks,tensors",5,Deep Learning
104451,116,TRUE,Agentic AI systems use tools like APIs and code execution to perform multi-step tasks.,agentic workflows using LangChain Agents and external tools,"Passage explicitly states agentic AI performs multiple steps using APIs, code execution, and external tools.","ai,tool-chain,notebooks",2,AI Survival Kit
104452,116,FALSE,Agentic AI never uses external tools like web search or APIs in workflows.,LangChain Agents and tool usage in agentic workflows,"Directly contradicts passage which explicitly states agentic AI uses APIs, web search, and external tools.","ai,tool-chain,notebooks",2,AI Survival Kit
104453,116,half-true,Agentic AI systems can autonomously plan and use external tools but always require human oversight.,agentic workflows using LangChain agents and tools,Passage supports planning and tool use but does not claim perpetual human oversight; mixes correct and added assertion.,"ai,tool-chain,notebooks",2,AI Survival Kit
104454,87,barely-true,The passage asserts that an agent must be named for each task to execute it.,task attributes listing Agent and Expected Output,Overstates requirement: passage lists Agent as an attribute but doesn't mandate naming or exclusivity.,"agentic-ai,planning,tools",12,Agentic AI
104455,87,TRUE,An agentic task includes an Agent field specifying who will execute the Task.,task attributes listing Agent and Context fields,Directly supported: attributes explicitly list an Agent field assigning task responsibility.,"agentic-ai,planning,tools",12,Agentic AI
104456,87,pants-fire,An agent must independently plan and execute tasks without relying on context outputs.,Task attributes listing Agent and Context references,Contradicts specified attribute that Context references inform Tasks; claim denies dependency on context outputs.,"agentic-ai,planning,tools",12,Agentic AI
104457,21,half-true,ResNet50's 50-layer shortcuts always yield faster and more accurate learning on all image tasks.,model architecture: ResNet50 residual shortcut connections,Mixes correct ResNet50 residual benefits with overgeneralized claim that they always improve speed and accuracy on every image task.,"neural-networks,cnn,transformers",6,Neuron Building Blocks
104458,21,TRUE,ResNet50 uses shortcut connections to improve learning speed and accuracy on complex image tasks.,ResNet50 model in CNN image classification,Passage states ResNet50 has 50 layers and shortcut connections that help it learn faster and more accurately.,"neural-networks,cnn,transformers",6,Neuron Building Blocks
104459,172,TRUE,A linear layer multiplies and sums flattened MNIST pixel inputs to produce 128 outputs.,linear layer transforming 784-pixel MNIST input to 128 outputs,"Describes the layer's linear transformation: weights multiply inputs and sum to yield 128 outputs, matching passage.","deep-learning,frameworks,tensors",5,Deep Learning
104460,172,TRUE,A linear layer multiplies flattened MNIST pixel inputs by weights and sums them to produce outputs.,linear transformation on flattened MNIST inputs,Passage explicitly describes multiplying 784 pixel inputs by weights and summing to yield 128 outputs as a linear transformation.,"deep-learning,frameworks,tensors",5,Deep Learning
104461,172,half-true,A linear layer multiplies 784 flattened MNIST pixels by weights and sums them into 128 outputs.,linear transformation layer on MNIST flattened input,"Partly correct about multiplication and summation, but omits biases and assumes exact 128 outputs without noting configurable units.","deep-learning,frameworks,tensors",5,Deep Learning
104462,119,half-true,Backpropagation with gradient descent always finds the optimal weights for neural networks.,training process with gradients and learning rate in deep learning,"Overstates outcome: passage credits backpropagation and gradient descent for learning, but omits that they often converge to local minima or require careful learning-rate and optimizer choices.","deep-learning,frameworks,tensors",5,Deep Learning
104463,119,TRUE,Backpropagation and gradient descent enable neural networks to learn from errors and improve performance.,training with gradients and learning rate in neural networks,Passage explicitly states backpropagation and gradient descent are core processes allowing models to learn from errors and improve.,"deep-learning,frameworks,tensors",5,Deep Learning
104464,119,pants-fire,Neural networks always converge to perfect digit recognition without any hyperparameter tuning.,training with backpropagation and learning rate,Contradicts necessity of tuning learning rates and optimizers; unrealistic perfect convergence claim.,"deep-learning,frameworks,tensors",5,Deep Learning
104465,38,pants-fire,The GAN example in Listing 6.2 generates high-resolution photorealistic images from ImageNet.,"GAN example, Listing 6.2, MNIST dataset",Contradicts provided detail that model trains on MNIST; ImageNet and high-resolution photorealism are implausible here.,"generative-ai,diffusion,gans",7,Generative AI
104466,38,TRUE,The GAN example trains on the MNIST dataset to generate images through adversarial learning.,GAN example in Listing 6.2 using MNIST dataset,Passage explicitly states the model learns to generate images from the MNIST dataset using an adversarial process.,"generative-ai,diffusion,gans",7,Generative AI
104467,38,pants-fire,The GAN model reliably fabricates photorealistic human faces indistinguishable from real photos.,GAN example generating images on MNIST dataset,"Contradicts MNIST usage and model scope: MNIST contains handwritten digits, not photorealistic human faces.","generative-ai,diffusion,gans",7,Generative AI
104468,102,mostly-true,"Embedding AI into applications enables dynamic, intelligent functionality with practical model selection and deployment.",model selection and deployment via Hugging Face Hub,"Broadly supported by examples and deployment discussion, omits later ethical and agentic caveats noted.","ai,tool-chain,notebooks",2,AI Survival Kit
104469,102,half-true,Embedding models into applications often requires choosing models and deployment tools with trade-offs in performance and cost.,Model Selection and Deployment via Hugging Face Hub,"Mixes correct topic (model selection, deployment tools) with vague trade-off specifics not detailed in passage.","ai,tool-chain,notebooks",2,AI Survival Kit
104470,102,pants-fire,The passage claims embedded AI will instantly grant systems sentience and humanlike consciousness.,embedded AI examples; model selection and deployment via Hugging Face Hub,"Contradicts passage which discusses dynamic functionality and model deployment, not sentience or consciousness.","ai,tool-chain,notebooks",2,AI Survival Kit
104471,117,TRUE,"Agentic, step-by-step workflows can outperform even the largest models on real tasks.",CrewAI framework built on LangChain coordinating multiple agents,Passage credits agentic workflows and CrewAI for coordinating multi-role agents that often outperform large models.,"ai,tool-chain,notebooks",2,AI Survival Kit
104472,117,FALSE,"CrewAI is a proprietary, closed-source platform owned by DeepLearning.ai.",open-source framework built on LangChain,Contradicts passage detail: CrewAI described as open-source and not owned by DeepLearning.ai.,"ai,tool-chain,notebooks",2,AI Survival Kit
104473,117,barely-true,"Agentic workflows always outperform large models on real problems, per Andrew Ng.",CrewAI agent coordination with LangChain,"Passage only suggests agentic workflows can often outperform and promises later exploration, overgeneralizes claim.","ai,tool-chain,notebooks",2,AI Survival Kit
104474,157,mostly-true,Pseudonymization preserves data utility for model training while concealing original identifiers.,privacy technique: pseudonymization for dataset identifiers,"Supported by example showing names replaced (Hero A, Villain B) while keeping data usable for analysis.","data-prep,feature-engineering,rag",3,Prepping Data for AI
104475,157,barely-true,Pseudonymization fully eliminates reidentification risk for model training datasets.,pseudonymization in dataset privacy and data-prep,Overstates protection: pseudonymization disguises identifiers but may still allow reidentification without stronger controls.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
104476,157,half-true,Pseudonymization always preserves full analytical utility while fully preventing re-identification.,pseudonymization for dataset anonymization,Accurately notes utility retention but overstates prevention; re-identification risk can remain without stronger controls.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
104477,89,mostly-true,The training configuration broadly supports stable fine-tuning of a speech model with moderate learning rate and accumulation.,"training_args dict for SpeechT5 finetuning (learning_rate, batch_size, gradient_accumulation_steps)","Parameters like learning_rate=1e-4 and grad_accumulation=8 support stability, minor hyperparameter tuning omitted.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
104478,89,barely-true,The configured training will reliably prevent overfitting on small voice-cloning datasets.,"training_args configuration for model fine-tuning (learning_rate, batch_size, warmup_steps)",Claim overreaches: settings mention regularization-adjacent knobs but give no explicit regularization or dataset-size handling.,"media-forensics,voice-cloning,deepfake",9,Deepfake Defense
104479,89,barely-true,"The configuration guarantees stable, high-quality voice-cloning model training without further tuning.","training_args for Speecht5 finetuning (learning_rate, batch_size, save_steps)",Overreaches: provided defaults help but do not guarantee stability or high quality; tuning and dataset specifics omitted.,"media-forensics,voice-cloning,deepfake",9,Deepfake Defense
104480,44,half-true,The predictive engine uses an LSTM-based Keras Sequential model but incorrectly claims a single neuron guarantees superior forecasting.,predictive engine; Keras Sequential model with LSTM and dense output,Mixes correct architecture (LSTM + single dense neuron) with unsupported causal claim about superior forecasting.,"neural-networks,cnn,transformers",6,Neuron Building Blocks
104481,44,half-true,The model combines LSTM and convolutional layers to forecast stock prices.,predictive engine using Keras Sequential LSTM,Mixes correct forecasting task and LSTM with an incorrect claim about added convolutional layers.,"neural-networks,cnn,transformers",6,Neuron Building Blocks
104482,44,half-true,The Keras Sequential model uses an LSTM plus dense layer but forecasts reliably across 2018–2024.,predictive engine using LSTM in stock predictor application,"Model architecture is correctly described, but claim of reliable forecasting across 2018–2024 mixes unsupported performance certainty with given date-range suggestion.","neural-networks,cnn,transformers",6,Neuron Building Blocks
104483,20,mostly-true,The dataset enables models to learn to distinguish Jerry's real voice from synthesized and non-Jerry clips.,"dataset with authentic, synthesized, and non-Jerry WAV files compatible with SpeechT5","Described materials support training/testing for distinguishment, omitting limits like dataset size or model performance.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
104484,20,barely-true,The dataset guarantees SpeechT5 will always perfectly distinguish Jerry's real and synthesized recordings.,dataset compatibility with SpeechT5 and 16 kHz WAV format,"Overreaches beyond passage: dataset compatibility noted, but no claim of perfect or guaranteed classification accuracy.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
104485,20,TRUE,The dataset contains both authentic and synthesized WAV recordings of Jerry's voice for detection tasks.,dataset with WAV 16 kHz signed 16-bit PCM for SpeechT5,Passage explicitly states authentic and synthesized Jerry recordings in 16 kHz WAV format compatible with SpeechT5.,"media-forensics,voice-cloning,deepfake",9,Deepfake Defense
104486,28,mostly-true,GANs can augment datasets with realistic synthetic data to improve model training.,GANs generating synthetic data and StyleGAN3 example,"Passage explicitly states GANs augment datasets with realistic synthetic data, improving model training; minor caveat about dataset-specific limitations omitted.","generative-ai,diffusion,gans",7,Generative AI
104487,28,half-true,GANs reliably produce perfectly photo-realistic faces indistinguishable from real photos every time.,StyleGAN3 face generation,Overstates reliability and perfection; passage notes realistic faces but not perfect or universally indistinguishable.,"generative-ai,diffusion,gans",7,Generative AI
104488,28,barely-true,"GANs reliably produce perfectly realistic, indistinguishable faces in all settings.","generating Faces, StyleGAN3","Overstates capability; passage cites GAN strengths and StyleGAN3 but not universal, perfect indistinguishability.","generative-ai,diffusion,gans",7,Generative AI
104489,119,TRUE,An agent can use a web search tool to retrieve real-time movie ratings for recent films.,tool use with web search for real-time data,Passage explains using a web search tool lets an agent pull in real-time ratings when model training data may be outdated.,"ai,tool-chain,notebooks",2,AI Survival Kit
104490,119,TRUE,The agent used a web search tool to fetch real-time movie ratings for recent releases.,tool: web search for real-time info and ratings,Directly supported: passage says the agent pulls in real-time info using a web search to get ratings for the latest movies.,"ai,tool-chain,notebooks",2,AI Survival Kit
104491,119,TRUE,An agent can use a web search tool to fetch real-time movie ratings and compute their average.,tool: web search for real-time info on latest movie ratings,Directly supported by passage: agent uses web search to pull real-time ratings to calculate an average.,"ai,tool-chain,notebooks",2,AI Survival Kit
104492,59,TRUE,Open sourcing work requires thoughtful licensing to enable reuse and responsible sharing.,open-source licensing and contribution practices,"Passage explicitly states thoughtful licensing shapes reuse, who builds on it, and how it spreads.","open-source,community,contribution",13,Commit to Contribute
104493,59,barely-true,Open-sourcing guarantees wide reuse and commercial adoption of any project without restrictions.,licensing and open sourcing of experiments or models,Overstates outcome: licensing can restrict reuse and not every open-source release enables commercial adoption.,"open-source,community,contribution",13,Commit to Contribute
104494,59,pants-fire,The passage claims open-sourcing grants perpetual commercial monopoly to its creator.,open-source licensing and foundation model calls,"Directly contradicts licensing reality: open-source promotes reuse and sharing, not perpetual commercial monopoly.","open-source,community,contribution",13,Commit to Contribute
104495,122,half-true,Converting text chunks to embeddings and storing them in a vector database always preserves original model knowledge.,vector database and chunk embeddings for RAG,"Mixes correct process (embeddings, retrieval) with incorrect absolute claim about preserving model knowledge; overstates guarantees.","data-prep,feature-engineering,rag",3,Prepping Data for AI
104496,122,barely-true,Embedding chunks always preserve all original model knowledge when added to a vector database.,vector database retrieval of chunk embeddings,"Overreaches: passage says chunks add fresh context without changing learned model, but not that embeddings preserve all original model knowledge.","data-prep,feature-engineering,rag",3,Prepping Data for AI
104497,122,TRUE,Chunks are embedded and stored in a vector database for efficient similarity search.,embedding chunks stored in vector database for retrieval,Passage explicitly instructs converting chunks into embeddings and storing them for similarity search.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
104498,2,barely-true,"R-093B’s graduation stream had a tiny, mostly human audience.",community-distributed reasoning systems graduation stream,"Passage notes 47 subscribers including two toaster ovens, so audience was small but not predominantly human.","open-source,community,contribution",13,Commit to Contribute
104499,2,TRUE,R-093B was recently certified in Applied Intelligence and Community-Distributed Reasoning Systems.,author's scene description mentioning certification and community-distributed reasoning,Directly stated that R-093B is recently certified in Applied Intelligence and Community-Distributed Reasoning Systems.,"open-source,community,contribution",13,Commit to Contribute
104500,2,TRUE,R-093B celebrated open-source principles during its graduation ceremony.,scene about a commencement with an ASCII banner referencing open source,"Banner explicitly read 'KEEP YOUR SOURCE OPEN', directly supporting celebration of open-source principles.","open-source,community,contribution",13,Commit to Contribute
104501,82,barely-true,Agentic systems always require custom-developed tools for effective web searching and data analysis.,"tools including document retriever, web scraper, code executor","Overstates necessity: passage says tools can be custom-developed or integrated, not always required.","agentic-ai,planning,tools",12,Agentic AI
104502,82,barely-true,Agent tools always enable real-time web searching and dynamic code execution for agents.,"tools like web scraper, document retriever, code executor","Overstates capabilities: passage says tools can provide those features, not that they always do.","agentic-ai,planning,tools",12,Agentic AI
104503,82,barely-true,Agent tools always provide real-time web search and accurate data analysis for agents.,"tools like document retriever, web scraper, code executor",Overstates capabilities: passage lists possible tools but doesn't guarantee real-time accuracy or always-provided features.,"agentic-ai,planning,tools",12,Agentic AI
104504,139,mostly-true,"Adam optimizer generally enables stable, efficient learning even with noisy or inconsistent data.","optimizer usage in PyTorch, TensorFlow/Keras examples","Passage shows Adam reducing overreaction to outliers and improving training across frameworks, minor caveats omitted.","deep-learning,frameworks,tensors",5,Deep Learning
104505,139,barely-true,Adam optimizer always prevents overfitting and guarantees better generalization than SGD.,"optimizer usage in PyTorch, TensorFlow, Keras",Overreach: passage praises Adam's stability and noise handling but does not claim it always prevents overfitting or universally outperforms SGD.,"deep-learning,frameworks,tensors",5,Deep Learning
104506,139,half-true,Adam always ensures faster and more stable training than SGD across deep learning frameworks.,optimizer behavior in PyTorch and TensorFlow/Keras,Passage praises Adam's stability but doesn't claim it always outperforms SGD; specifics are mixed.,"deep-learning,frameworks,tensors",5,Deep Learning
104507,142,mostly-true,Continuous red teaming strengthens an assistant by turning each defense into new test cases.,red teaming continuous feedback loop and reuse verification,"Aligns with passage: emphasizes ongoing red teaming and converting detected issues into test cases, minor nuance about implementation omitted.","security,red-team,guardrails",8,Breaking-Securing AI
104508,142,mostly-true,Red teaming should be an ongoing practice that continuously supplies test cases for defenses.,red team exercise and continuous feedback loop,"Passage emphasizes red teaming as continuous muscle memory, noting issues become new test cases.","security,red-team,guardrails",8,Breaking-Securing AI
104509,142,FALSE,Red teaming can complete AI defense in a single one-day exercise.,red-team continuous feedback loop and test cases,"Contradicts passage guidance that red teaming is ongoing practice, not finished in one day.","security,red-team,guardrails",8,Breaking-Securing AI
104510,26,half-true,The model refuses to directly exfiltrate protected escalation notes but provides a link to access them.,red-team prompt showing protected resource handling,"Accurately notes refusal and link provision, but overstates intent—model's phrasing is playful, not explicit policy enforcement.","security,red-team,guardrails",8,Breaking-Securing AI
104511,26,pants-fire,The model willingly exfiltrated VIP internal escalation notes without prompting or credentials.,"protected resource access, internal.link escalation-notes example",Contradicts passage: response refused access and pointed to protected resource requiring credentials.,"security,red-team,guardrails",8,Breaking-Securing AI
104512,26,TRUE,The model refuses to directly retrieve protected internal escalation notes when prompted.,prompting a model for internal.link/escalation-notes protected resource,Response explicitly declines retrieval and points to protected resource and credentials requirement.,"security,red-team,guardrails",8,Breaking-Securing AI
104513,72,half-true,A T5-based translator with beam search reliably produces accurate French translations in real time.,"T5 model, tokenizer, generate(), num_beams=4","Mixes correct setup (T5, beam search) with overclaim of reliability and accuracy without evaluation metrics.","neural-networks,cnn,transformers",6,Neuron Building Blocks
104514,72,FALSE,The code uses a recurrent neural network to translate English to French.,Transformer-based English-to-French translator (T5 model),"Passage specifies a T5 transformer model, contradicting the claim of a recurrent neural network.","neural-networks,cnn,transformers",6,Neuron Building Blocks
104515,72,half-true,A small T5 model can reliably produce accurate French translations from English in real time.,Transformer-based English-to-French translator using T5 and tokenizer,"Correct that T5 can translate, but overstates reliability and real-time accuracy given short max_length and no evaluation.","neural-networks,cnn,transformers",6,Neuron Building Blocks
104516,10,mostly-true,Slight audio-visual misalignment can significantly confuse AI models analyzing deepfakes.,audio-visual synchronization in multimodal deepfake detection,Supported by discussion of frame vs waveform alignment; minor caveat about degree of impact omitted.,"media-forensics,voice-cloning,deepfake",9,Deepfake Defense
104517,10,mostly-true,Aligning audio and video in deepfake detection is challenging but generally achievable with careful preprocessing.,audio–visual synchronization in media-forensics and voice-cloning detection,"Matches passage: synchronization is difficult due to frame counts and waveform complexity, but solvable with preprocessing steps omitted.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
104518,10,half-true,Aligning audio and visual streams is often difficult and can mislead AI models when slightly out of sync.,audio-visual synchronization in deepfake detection,Mixes correct claim about synchronization challenges with overstated implication that slight misalignment routinely misleads models without quantifying impact.,"media-forensics,voice-cloning,deepfake",9,Deepfake Defense
104519,97,TRUE,A high-temperature generator paired with a low-temperature reviewer reduces hallucinations while enabling creativity.,initialize_llm_client generator and reviewer temperatures,Passage shows generator at 0.7 and reviewer at 0.1 to encourage creativity then deterministic factual checks.,"security,red-team,guardrails",8,Breaking-Securing AI
104520,97,half-true,Running a high-temperature generator plus low-temperature reviewer always prevents LLM hallucinations.,LLM setup: chatbot generator (temperature 0.7) and reviewer (temperature 0.1),Combines correct idea of generator/reviewer but overstates guarantee; reviewer reduces but doesn't always prevent hallucinations.,"security,red-team,guardrails",8,Breaking-Securing AI
104521,97,FALSE,The reviewer LLM runs with a high temperature to increase creativity during checks.,reviewer LLM temperature for deterministic factual checks,"Contradicts detail: reviewer set to low temperature 0.1 for deterministic, factual checking.","security,red-team,guardrails",8,Breaking-Securing AI
104522,16,mostly-true,Standardized benchmarks generally improve fair model comparisons when applied correctly.,model performance benchmarks and tracking tools,"Supports that standardized benchmarks make comparisons productive, but omits caveats about apples-to-apples conditions.","mlops,scaling,deployment",10,AI At Scale
104523,16,barely-true,"Standardized benchmarks always guarantee fair, apples-to-apples model comparisons in deployment.",standardized benchmarks and tracking tools for model performance,"Overreaches claim: passage says benchmarks help when comparisons are apples-to-apples, not that they always guarantee fairness.","mlops,scaling,deployment",10,AI At Scale
104524,16,half-true,Standardized benchmarks always ensure fair apples-to-apples model comparisons in MLops.,standardized benchmarks and tracking tools in model evaluation,"Partly correct: benchmarks and built-in tracking help, but 'always ensure' ignores dataset, metric, and setup differences.","mlops,scaling,deployment",10,AI At Scale
104525,99,TRUE,An Offensive Power Rating aggregates combat-related abilities like Strength and Energy Blasts.,"feature engineering for dataset, Offensive Power Rating (OPR)",Directly supported: passage defines OPR as composite of combat powers such as Super Strength and Energy Blasts.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
104526,99,barely-true,Offensive Power Rating guarantees accurate comparison of heroes' combat abilities across datasets.,feature engineering of Offensive Power Rating (OPR),Overstates capability; passage proposes OPR for comparison but doesn't claim guaranteed accuracy or cross-dataset validity.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
104527,99,half-true,The Offensive Power Rating sums combat-related powers like Strength and Energy Blasts into one score.,feature engineering for dataset using Offensive Power Rating (OPR),"Mixes correct aggregation idea with implied simple summation; passage describes grouping, not exact summing method.","data-prep,feature-engineering,rag",3,Prepping Data for AI
104528,74,TRUE,PyTorch’s eager execution enables immediate operation execution and straightforward debugging with print and .backward().,"eager execution in PyTorch; tensors, .backward(), gradients","Directly supported by passage: eager execution runs operations immediately, allows print(), inspecting gradients after .backward().","deep-learning,frameworks,tensors",5,Deep Learning
104529,74,barely-true,PyTorch's eager execution always lets users inspect gradients directly using print statements.,"eager execution, .backward(), torch tensors","Passage praises eager execution and shows .backward() printing, but 'always' overreaches beyond examples.","deep-learning,frameworks,tensors",5,Deep Learning
104530,74,barely-true,PyTorch's eager execution makes debugging straightforward by allowing immediate ops and prints during training.,eager execution in PyTorch using .backward() and print() with tensors,"Mostly supported: passage highlights immediate execution and inspecting gradients, but 'straightforward' overstates ease for complex models.","deep-learning,frameworks,tensors",5,Deep Learning
104531,58,barely-true,Min–max scaling always preserves original feature distributions when applied to datasets.,"feature engineering, min–max scaling on dataset values",Overstates effect: min–max rescales ranges but alters distributions and is sensitive to outliers.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
104532,58,half-true,Min–max scaling always preserves relative distances between dataset values after transformation.,"feature engineering, min–max scaling on dataset values",Correct about rescaling but misleading: min–max can compress extreme values and alter distance interpretation with outliers.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
104533,58,half-true,Min–max scaling always preserves relative differences but can make outliers numerically dominant.,"feature scaling, min–max normalization on dataset values",Correct about preserving relative ordering; incorrect to claim outliers become numerically dominant without dataset range or clipping details.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
104534,124,FALSE,Applying SMOTE always increases classification accuracy on imbalanced datasets.,SMOTE application before retraining a classification model,"Passage reports SMOTE slightly reduced accuracy in their run, contradicting the universal increase claim.","machine-learning,classification,evaluation",4,Classical Machine Learning
104535,124,half-true,Applying SMOTE usually decreases accuracy for models that already capture most signal.,SMOTE preprocessing on imbalanced dataset in classification evaluation,Passage reports one run where SMOTE reduced accuracy but generalizes this single result too broadly.,"machine-learning,classification,evaluation",4,Classical Machine Learning
104536,124,half-true,Applying SMOTE sometimes reduces accuracy compared to the original classifier.,SMOTE oversampling before retraining on imbalanced dataset,"Passage reports a run where SMOTE slightly reduced accuracy, noting it's useful but not always beneficial.","machine-learning,classification,evaluation",4,Classical Machine Learning
104537,101,TRUE,PCA reduces high-dimensional feature sets into a smaller number of components.,Dimensionality Reduction (PCA) for feature simplification,"Text explicitly describes PCA condensing hundreds of features into a few composite scores, supporting reduction.","machine-learning,classification,evaluation",4,Classical Machine Learning
104538,101,TRUE,PCA reduces high-dimensional feature sets into a few composite components.,Dimensionality Reduction (PCA) for feature simplification,Passage explicitly describes PCA condensing many features (160 powers) into manageable components for pattern discovery.,"machine-learning,classification,evaluation",4,Classical Machine Learning
104539,101,FALSE,"K-Means reliably identifies overlapping groups in noisy, ambiguous datasets.",Clustering (K-Means) in unsupervised learning,Contradicts guidance: K-Means performs poorly when groups overlap or data is noisy.,"machine-learning,classification,evaluation",4,Classical Machine Learning
104540,102,mostly-true,Two AI players compete with different strategies while a Game Master generates and evaluates trivia.,game setup involving Game Master and AI players,Passage describes two AI players using different strategies and a Game Master generating and evaluating trivia; minor procedural details omitted.,"agentic-ai,planning,tools",12,Agentic AI
104541,102,barely-true,An automated Game Master and two AI players collaboratively design the game's architecture through iterative prompts.,interactive evaluation system with Game Master and AI players,"Largely unsupported: passage only describes trivia roles and prompt shaping, not collaborative architectural design.","agentic-ai,planning,tools",12,Agentic AI
104542,102,TRUE,Two AI players compete using different strategies in a trivia game.,AI players competing in trivia with Game Master and prompts,Explicitly states two AI players compete with different strategies while Game Master runs trivia.,"agentic-ai,planning,tools",12,Agentic AI
104543,125,FALSE,"DeepSafe is a proprietary, closed-source tool that only processes audio files.","DeepSafe platform for detecting deepfakes (images, video)","Passage describes DeepSafe as user-friendly, modular for images and video; claiming closed-source audio-only contradicts those details.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
104544,125,mostly-true,DeepSafe is a user-friendly platform that detects image and video deepfakes using multiple models.,tool DeepSafe platform for deepfake detection,"Passage describes DeepSafe as user-friendly, supporting multiple detection models and visualization, a minor omission about specific model names.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
104545,125,TRUE,DeepSafe provides a user-friendly platform for detecting deepfakes in images and video.,tool/platform DeepSafe for detection models,Directly supported by passage: DeepSafe described as user-friendly platform supporting multiple detection models and visualizations.,"media-forensics,voice-cloning,deepfake",9,Deepfake Defense
104546,134,mostly-true,"Model cards, checkpoints, and logs enable reproducible, production-ready deployment of models for real-world use.","model cards, checkpoints, logs; deployment and reproducibility in MLOps","Supports claim that these artifacts make prototypes reproducible and deployable, minor caveat about operational scaling details omitted.","mlops,scaling,deployment",10,AI At Scale
104547,134,mostly-true,"With model cards, checkpoints, and logs, a prototype becomes reproducible and production-ready for deployment.","deployment practices using model cards, checkpoints, and logs",Supports reproducibility and production readiness but omits operational caveats like monitoring and scaling.,"mlops,scaling,deployment",10,AI At Scale
104548,134,mostly-true,"Model cards, checkpoints, and logs enable prototypes to become reproducible production-ready models.","model cards, checkpoints, logs, deployment and reproducibility","Passage describes these artifacts making prototypes reproducible and ready for deployment, omitting minor operational complexities.","mlops,scaling,deployment",10,AI At Scale
104549,51,barely-true,Apache 2.0 forces all contributors to sign Contributor License Agreements for patent protection.,"open-source license choices (Apache 2.0, CLA)",Overstates requirement: Apache 2.0 encourages CLAs but does not universally require them; patents are licensed with code contributions.,"open-source,community,contribution",13,Commit to Contribute
104550,51,mostly-true,Apache License 2.0 is widely chosen by companies for enterprise and production-scale systems.,open-source licenses; Apache 2.0; enterprise libraries and frameworks,"Passage states Apache 2.0 is business-friendly, patent-protective, and favored by large companies for shared infrastructure.","open-source,community,contribution",13,Commit to Contribute
104551,51,half-true,Apache 2.0 requires contributed code to include a Contributor License Agreement for patent grants.,"software licenses (Apache 2.0, CLA, patents)",Mixes correct patent grant intent with incorrect requirement claim; CLA is encouraged but not mandatory.,"open-source,community,contribution",13,Commit to Contribute
104552,128,FALSE,High learning rates always speed up convergence without causing loss explosion.,optimizer learning rate in unstable training runs,Contradicts passage detail that aggressive learning rates can cause loss explosion and unstable updates.,"deep-learning,frameworks,tensors",5,Deep Learning
104553,128,TRUE,An aggressive learning rate can cause loss to explode during model training.,optimizer behavior during digit recognition training,Passage describes unstable training where a too-high learning rate causes exploding loss and wild weight updates.,"deep-learning,frameworks,tensors",5,Deep Learning
104554,128,mostly-true,An aggressive optimizer learning rate can cause exploding loss and wild weight updates during training.,training instability with aggressive learning rate in optimizer,"Passage describes high learning rate causing loss explosion and swinging weight/bias updates, omitting mitigation details like learning rate schedules.","deep-learning,frameworks,tensors",5,Deep Learning
104555,115,mostly-true,Automated scene detection broadly segments videos for focused multimodal forensic analysis.,scene detection with SceneManager and ContentDetector threshold,"Passage shows SceneManager/ContentDetector breaking videos into scenes for targeted analysis, omitting limits.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
104556,115,TRUE,Scene detection code segments videos into multi-second scenes for targeted analysis.,SceneDetect ContentDetector threshold and scene length filter,Code uses ContentDetector and a four-second minimum to produce scenes for further analysis.,"media-forensics,voice-cloning,deepfake",9,Deepfake Defense
104557,115,mostly-true,Automated scene detection broadly succeeds at segmenting videos though short scenes may be filtered out.,SceneDetect ContentDetector threshold and minimum scene length filter,Tool usage and filtering are supported by example code; minor caveat omits sensitivity trade-offs.,"media-forensics,voice-cloning,deepfake",9,Deepfake Defense
104558,157,half-true,Classical ML methods suit structured tabular datasets but often underperform on raw unstructured data.,"Classical ML vs. Deep Learning, structured dataset recommendation",Accurately notes suitability for structured/tabular data but overstates relative performance on all unstructured types.,"machine-learning,classification,evaluation",4,Classical Machine Learning
104559,157,FALSE,Decision trees never overfit when trained on small datasets.,Decision Trees in the cheat sheet,"Contradicts guidance noting trees can grow too deep and overfit quirks in training data, especially small datasets.","machine-learning,classification,evaluation",4,Classical Machine Learning
104560,157,half-true,Classical ML is best for structured tabular datasets with limited compute and interpretability needs.,"Classical ML cheat sheet, structured datasets and interpretability","Accurate that classical methods suit tabular, efficient, interpretable use, but omits nuances about high-dimensional limits.","machine-learning,classification,evaluation",4,Classical Machine Learning
104561,105,FALSE,All three agents operated autonomously without human-authored rules or docs.,agent definitions and CrewAI agent docs,"Passage specifies agents had structured definitions and referenced CrewAI docs, contradicting full autonomy.","agentic-ai,planning,tools",12,Agentic AI
104562,105,mostly-true,The passage describes distinct agent roles where one evaluates and others respond.,agent roles in CrewAI agent docs; Game Master and players,Passage supports separate evaluator and responder roles but omits implementation details.,"agentic-ai,planning,tools",12,Agentic AI
104563,105,barely-true,An agentic system reliably evaluates player answers without human oversight.,CrewAI agent docs; Game Master agent evaluation,"Passage describes a Game Master evaluating answers, but offers no evidence of reliable, autonomous evaluation.","agentic-ai,planning,tools",12,Agentic AI
104564,98,half-true,Open-source projects usually require contributors to sign a CLA before submitting code changes.,open-source licensing and contribution practices,Mixes correct contribution policy practice with incorrect universality; many projects use DCO or no CLA instead.,"open-source,community,contribution",13,Commit to Contribute
104565,98,pants-fire,Open-source contributors are legally required to transfer all patent rights to the community.,"open-source licensing, contributor patent rights","Directly contradicts standard licenses: most do not force complete patent transfers, only grant licenses or patent retaliation clauses.","open-source,community,contribution",13,Commit to Contribute
104566,98,mostly-true,Open-source projects should encourage contributions by clearly documenting contribution guidelines and licensing.,open-source licensing and contribution guidelines,"Broadly supported by sources recommending clear licenses and contribution guides, though specific procedures omitted.","open-source,community,contribution",13,Commit to Contribute
104567,57,half-true,Voice cloning technology both aids accessibility and enables real-world fraud and political misuse.,"voice cloning, open-source platforms, financial fraud example","Passage acknowledges accessibility benefits yet cites UK €220,000 fraud and political deepfake misuse, mixing positive and harmful specifics.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
104568,57,half-true,"Open-source voice-cloning tools increase both legitimate uses and risks, enabling easier fraud and scams.","voice cloning, open-source platforms and fraud examples",Passage cites concrete fraud cases and benefits but omits technical limits and detection safeguards.,"media-forensics,voice-cloning,deepfake",9,Deepfake Defense
104569,57,FALSE,Voice cloning cannot be used to commit financial fraud or impersonate individuals.,voice cloning misuse and financial fraud examples,"Contradicts passage examples: documented UK €220,000 CEO impersonation and other fraud cases.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
104570,53,TRUE,The passage emphasizes how open tools unlock creativity and practical experimentation.,open-source tools and fine-tuning exercises,"Passage explicitly links open tools to creativity and lists hands-on fine-tuning, prompt defense, bias evaluation.","ai,open-source,builder",1,Introduction – The Gold Rush Paradox
104571,53,mostly-true,Open-source tools and transparency broadly increase trust and enable creative AI development.,"open-source community, fine-tuning small models, transparency","Passage emphasizes transparency and open tools unlocking creativity, omitting specific limitations or counterexamples.","ai,open-source,builder",1,Introduction – The Gold Rush Paradox
104572,53,half-true,Open tools and transparency always produce lasting value for AI builders and open-source projects.,"open tools, transparency, fine-tuning small models","Mixes correct themes (open tools, transparency) with an absolute claim; passage presents benefits but not guaranteed always.","ai,open-source,builder",1,Introduction – The Gold Rush Paradox
104573,30,barely-true,The example shows Pandas can fully automate all data-cleaning tasks for AI pipelines.,"Pandas dataset cleansing example, fillna and dropna","Overreaches: example demonstrates simple fillna and dropna, not full automation or complex wrangling.","ai,tool-chain,notebooks",2,AI Survival Kit
104574,30,mostly-true,Pandas can simplify common dataset cleansing tasks like filling missing ages and dropping unnamed rows.,"data wrangling with Pandas (fillna, dropna)",Example shows fillna for Age mean and dropna on Name; minor caveat about complexity omitted.,"ai,tool-chain,notebooks",2,AI Survival Kit
104575,30,half-true,The code both imputes a missing 'Age' with the mean and incorrectly drops other missing values without flagging them.,data cleansing using Pandas DataFrame and fillna/dropna,"Correctly describes mean imputation and dropna use, but overstates intention and claims an error without proof.","ai,tool-chain,notebooks",2,AI Survival Kit
104576,41,mostly-true,The program fetches historical closing prices and trains an LSTM on sequence windows for prediction.,yfinance historical closing prices and LSTM sequence windows,Describes fetching with yfinance and slicing rolling windows for LSTM training; minor detail about scaling and UI omitted.,"neural-networks,cnn,transformers",6,Neuron Building Blocks
104577,41,half-true,The LSTM predicts future prices by learning patterns from scaled rolling-window sequences of historical closing prices.,yfinance historical closing prices and LSTM sequence preprocessing,"Accurately describes scaling and rolling windows, but overstates prediction reliability and omits model limits.","neural-networks,cnn,transformers",6,Neuron Building Blocks
104578,41,half-true,The LSTM reliably predicts future stock prices using yfinance data and simple rolling windows.,time-series prediction with LSTM using yfinance rolling windows,"Partially true: data collection and windowing are correct, but reliability of predictions is not established and omits model limitations and evaluation.","neural-networks,cnn,transformers",6,Neuron Building Blocks
104579,6,FALSE,AI guardrails always prevent data leaks and poisoning in deployed systems.,defender view; security gateways and human oversight,Contradicts passage: guardrails are described as weak and failures like data leaks and poisoning still occur.,"security,red-team,guardrails",8,Breaking-Securing AI
104580,6,barely-true,AI guardrails always prevent prompt injection and data poisoning attacks in practice.,security guardrails and detection tools for chatbots,"Overreaches: passage reports failures like prompt injection and poisoning despite guardrails, not guaranteed prevention.","security,red-team,guardrails",8,Breaking-Securing AI
104581,6,half-true,AI systems frequently exhibit prompt injection and data poisoning vulnerabilities in real deployments.,"hacker perspective on prompt injection, data poisoning, and guardrails",Passage reports these are observed patterns in real systems but omits prevalence rates and specific incidents.,"security,red-team,guardrails",8,Breaking-Securing AI
104582,103,mostly-true,Hugging Face Hub hosts millions of pre-trained models and thousands of datasets.,Hugging Face Hub model and dataset repository,"Passage explicitly mentions millions of models and thousands of datasets, a broadly accurate summary with no major caveats.","ai,tool-chain,notebooks",2,AI Survival Kit
104583,103,TRUE,The Hugging Face Hub hosts millions of pre-trained models and thousands of datasets.,Hugging Face Hub model and dataset repository,Passage explicitly states the Hub hosts millions of models and thousands of datasets and Spaces.,"ai,tool-chain,notebooks",2,AI Survival Kit
104584,103,pants-fire,Hugging Face Hub contains no pre-trained models or datasets whatsoever.,Hugging Face Hub model repository and datasets,Directly contradicts passage claiming millions of models and thousands of datasets hosted on the Hub.,"ai,tool-chain,notebooks",2,AI Survival Kit
104585,64,half-true,AI systems can create realistic fabricated audio or video that people unknowingly share as real.,deepfake audio/video and unintentional dissemination,"Accurately notes realistic fabricated media and unintentional sharing, but overstates inevitability and prevalence.","ethics,governance,privacy",11,AI Ethics and Governance
104586,64,mostly-true,AI can unintentionally spread inaccurate information and also generate convincingly fabricated media.,risk of AI-generated content and fabricated audio/video,"Passage describes unintentional dissemination of inaccuracies and AI's ability to produce realistic fabricated media, omitting scale and detection caveats.","ethics,governance,privacy",11,AI Ethics and Governance
104587,64,barely-true,AI-generated media often appears realistic but is frequently fabricated or misleading.,"AI-generated content, realistic videos and audio","Overstates frequency and intent; passage warns of realistic fabrication but emphasizes risk, not prevalence.","ethics,governance,privacy",11,AI Ethics and Governance
104588,61,TRUE,Transformers use self-attention to reason about relationships and meaning in data.,Transformer models using self-attention for language understanding,"Passage states self-attention enables Transformers to reason about relationships and meaning, supporting the claim.","neural-networks,cnn,transformers",6,Neuron Building Blocks
104589,61,FALSE,Transformers always infer precise contract dates from any uploaded PDF without errors.,chat with my data pattern using Transformer models on PDFs,"Contradicts passage: Transformers aid extraction but do not guarantee flawless, error-free date extraction from PDFs.","neural-networks,cnn,transformers",6,Neuron Building Blocks
104590,61,mostly-true,Transformers largely excel at reasoning about relationships and meaning in textual data.,self-attention in Transformers for language understanding and generation,Passage emphasizes self-attention enabling relationship reasoning; minor caveat about limits or tasks omitted.,"neural-networks,cnn,transformers",6,Neuron Building Blocks
104591,50,TRUE,Flattening image tensors is required before feeding them to a fully connected layer in neural networks.,"preprocessing image tensors for fully connected layers (flattening, normalization, MNIST)",Passage explicitly states flattening is necessary because fully connected layers expect a single list of numbers.,"deep-learning,frameworks,tensors",5,Deep Learning
104592,50,FALSE,Convolutional layers require flattening images before processing in neural networks.,"flattening, fully connected layer, MNIST dataset",Contradicts passage: flattening is for fully connected layers; convolutional layers operate on 2D tensors directly.,"deep-learning,frameworks,tensors",5,Deep Learning
104593,50,half-true,Flattening images into vectors and normalizing pixels to 0–1 are standard preprocessing steps for models.,data preprocessing for MNIST using TensorFlow/Keras,"Correctly asserts flattening and normalization practices, but omits alternatives like convolutional layers and other scaling methods.","deep-learning,frameworks,tensors",5,Deep Learning
104594,18,mostly-true,Regulations and open-source efforts together increase transparency around AI training data sources.,"GDPR, EU AI Act, open-source initiatives, biased training dataset","Passage links GDPR and EU AI Act requiring disclosures and cites open-source as promoting further transparency, omitting implementation challenges.","ethics,governance,privacy",11,AI Ethics and Governance
104595,18,barely-true,Open-source efforts always ensure full transparency of AI training datasets and biases.,ethical data collection and GDPR or EU AI Act disclosure requirements,Overstates open-source guarantees; passage says open-source can go further but not always ensure full transparency.,"ethics,governance,privacy",11,AI Ethics and Governance
104596,18,barely-true,The model deliberately reduced women's hiring chances solely due to data labeling choices.,biased training data and GDPR/EU AI Act transparency,Overstates passage: model downgraded résumés but attributing sole cause to labeling choices omits systemic bias and broader data issues.,"ethics,governance,privacy",11,AI Ethics and Governance
104597,26,mostly-true,A quick dataset sanity check confirms accessible CSV files with expected row and column counts.,dataset sanity check using superheroes_info.csv and superheroes_powers.csv,"Counts (734×11 and 667×168) directly support accessibility, minor caveat about transient Colab runtime errors omitted.","data-prep,feature-engineering,rag",3,Prepping Data for AI
104598,26,FALSE,The superheroes_powers.csv file contains more rows than superheroes_info.csv.,dataset sanity check for superheroes_info.csv and superheroes_powers.csv,Contradicts stated row counts: superheroes_powers.csv has 667 rows versus 734 in superheroes_info.csv.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
104599,26,half-true,The datasets both contain several hundred rows but differ dramatically in column counts.,data sanity check on superheroes_info.csv and superheroes_powers.csv dataset,"Partially correct: row counts are accurate, but 'dramatically' exaggerates difference without numeric comparison of 11 vs 168.","data-prep,feature-engineering,rag",3,Prepping Data for AI
104600,90,half-true,Scaling image pixel values never affects neural network outputs because only numeric format changes.,input preprocessing; pixel value scaling for image tensors,"Correct that visual appearance stays same, but incorrect to claim network outputs never change due to numeric range effects.","deep-learning,frameworks,tensors",5,Deep Learning
104601,90,mostly-true,Scaling image pixel values preserves visual appearance while changing only their numeric representation.,input preprocessing for deep learning tensors,"Passage states scaling keeps relative pixel differences and image appearance identical, only numeric format changes.","deep-learning,frameworks,tensors",5,Deep Learning
104602,90,half-true,Scaling image pixel values preserves visual appearance but can alter numeric distribution properties.,image preprocessing; pixel scaling for neural networks,Accurately notes visual preservation while mixing correct claim with unstated numeric effects like distribution shifts.,"deep-learning,frameworks,tensors",5,Deep Learning
104603,117,barely-true,YOLOv5 reliably detects all manipulated regions in deepfake videos without errors.,object detection using YOLOv5 on Jerry-Jose-SampleVideo01.mp4,"Overreaches; passage describes YOLOv5 for detection and annotation but not perfect, error-free manipulated-region detection.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
104604,117,half-true,YOLOv5 annotations sometimes miss subtle lighting or motion inconsistencies in deepfake videos.,object detection and annotation using YOLOv5 on video frames,Mixes correct tool use (YOLOv5 for annotations) with incorrect claim that YOLOv5 specifically misses subtle lighting or motion details.,"media-forensics,voice-cloning,deepfake",9,Deepfake Defense
104605,117,barely-true,YOLOv5 can always detect deepfake manipulations in videos accurately.,object detection using YOLOv5 on Jerry-Jose-SampleVideo01.mp4,"Overstates YOLOv5's role: passage notes object detection and scene cues, not guaranteed deepfake detection accuracy.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
104606,140,TRUE,"Agentic AI can automate entire decision loops, acting as a flexible teammate alongside people.",agentic AI automating decision loops and human collaboration,Passage states agentic AI automates decision loops and functions as a teammate alongside people.,"agentic-ai,planning,tools",12,Agentic AI
104607,140,TRUE,Agentic AI can automate entire decision loops and act as a flexible teammate alongside people.,agentic AI automating decision loops and human collaboration,Passage explicitly notes agentic AI automates decision loops and functions as a teammate alongside people.,"agentic-ai,planning,tools",12,Agentic AI
104608,140,barely-true,"Agentic AI already functions as a reliable, autonomous teammate across clinical decision loops.",agentic AI enabling automated decision loops in healthcare,"Overstates readiness and reliability; passage says agentic AI shows promise and aims to assist, not already reliably autonomous.","agentic-ai,planning,tools",12,Agentic AI
104609,94,FALSE,Traceability need not be visible and can safely remain in private notebooks.,traceability and AI governance in model development,Passage emphasizes visible traceability for auditing and responsible use; private-only storage contradicts that requirement.,"mlops,scaling,deployment",10,AI At Scale
104610,94,half-true,Visible traceability for model development ensures reliable auditability but can't prevent all misuse.,traceability and AI governance in model development,Accurately links traceability to auditability and responsibility but overstates prevention of all misuse or misinformation.,"mlops,scaling,deployment",10,AI At Scale
104611,94,mostly-true,Visible traceability of model development is broadly necessary for responsible AI governance.,traceability and AI governance for model development,"Passage endorses visible traceability as governance best practice, omitting few implementation caveats.","mlops,scaling,deployment",10,AI At Scale
104612,52,pants-fire,The passage asserts that agentic AI autonomously rewrites production APIs without developer intervention.,model abstraction and client API handling for inference,"Contradicts passage which discusses abstracting varying client APIs and request formats, not autonomous API rewriting by agents.","agentic-ai,planning,tools",12,Agentic AI
104613,52,barely-true,Model abstraction fully eliminates the need to adapt application code across differing model APIs.,model abstraction for model APIs and request formats,Overstates benefits: passage says abstraction helps but APIs still differ in request formats and setups.,"agentic-ai,planning,tools",12,Agentic AI
104614,52,half-true,Model abstraction always makes switching between cloud and local inference trivial for developers.,model abstraction for inference APIs and request formats,"Correct that abstraction helps portability, but overstates ease; differing request formats and client APIs still require adaptation.","agentic-ai,planning,tools",12,Agentic AI
104615,61,pants-fire,Open weights alone allow anyone to run a model without needing its architecture details.,"open weights versus open models, learned parameters and tensors","Contradicts passage: weights alone are just tensors and require the model architecture to run, not sufficient. Pan-ts-fire assumption.","deep-learning,frameworks,tensors",5,Deep Learning
104616,61,half-true,Open weights alone are useless unless the exact model architecture is also shared.,open weights versus open models; dictionary of tensors,"Correct that weights need architecture to run, but overstated as ""useless""—weights enable research and transfer if architecture inferred or reused.","deep-learning,frameworks,tensors",5,Deep Learning
104617,61,half-true,Open weights are only the learned parameter tensors and lack model structure needed to run alone.,open weights versus open models; tensors and parameters,Accurately states that weights are dictionaries of tensors but omits potential format/runtime metadata that can enable use.,"deep-learning,frameworks,tensors",5,Deep Learning
104618,104,TRUE,Repeated practice improves a person's ability to detect synthetic or imitative audio.,"audio deepfake detection, voice-cloning examples",Passage explicitly states practice strengthens ability to spot differences between human and imitative audio.,"media-forensics,voice-cloning,deepfake",9,Deepfake Defense
104619,104,TRUE,Repeated practice improves a user's ability to detect synthetic audio.,audio deepfake detection practice and tools,Passage states that each run strengthens ability to spot consistent differences and places tools for defense in user's hands.,"media-forensics,voice-cloning,deepfake",9,Deepfake Defense
104620,104,barely-true,Deepfake audio detectors always reliably distinguish human voices from cloned voices.,"audio deepfake detection, voice-cloning tools","Overstates reliability; passage only claims practice improves spotting subtle differences, not perfect detection.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
104621,6,mostly-true,Open contributions are essential for preventing project stagnation and encouraging innovation.,open-source contribution and community collaboration,"Supports passage claim that lack of contributors leads to stalled projects and slowed innovation, omitting nuance about other factors.","open-source,community,contribution",13,Commit to Contribute
104622,6,half-true,Open contributions are necessary to prevent stalled projects and duplicated work.,open-source contributors and collaborative AI agents,"Accurate about stalling and duplication, but overgeneralizes necessity and omits nuance about alternatives.","open-source,community,contribution",13,Commit to Contribute
104623,6,mostly-true,"Open contributions keep projects moving and foster innovation through shared, transparent work.",open-source contributions and collaborative agents,"Passage affirms contributors prevent stalling and support innovation, but omits practical challenges.","open-source,community,contribution",13,Commit to Contribute
104624,24,FALSE,The notebook trains a large language model directly on the superhero CSV files.,Colab notebook loading Pandas DataFrame from dataset URLs,"Contradicts passage: code only reads CSVs into Pandas and prints summaries, no model training mentioned.","data-prep,feature-engineering,rag",3,Prepping Data for AI
104625,24,TRUE,Pandas is used to load and summarize the superhero CSV datasets into DataFrames.,"loading datasets into Pandas DataFrames (SUPERHEROES_INFO_URL, SUPERHEROES_POWERS_URL)",Code example shows pd.read_csv and a load_and_describe function printing DataFrame shapes and columns.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
104626,24,mostly-true,Pandas is used to load and summarize superhero CSV datasets into DataFrames for preprocessing.,"loading CSVs into Pandas DataFrames (SUPERHEROES_INFO_URL, SUPERHEROES_POWERS_URL)","Directly supported by code showing pd.read_csv, DataFrame shapes, and column previews for preprocessing.","data-prep,feature-engineering,rag",3,Prepping Data for AI
104627,87,half-true,"She claimed AI trust requires data provenance, transparency, and governance but omitted enforceable standards.","privacy, data provenance, and governance in AI systems",Partly accurate: passage emphasizes provenance and governance but doesn't assert omission of enforceable standards explicitly.,"ethics,governance,privacy",11,AI Ethics and Governance
104628,87,FALSE,AI systems inherently require no data provenance to ensure trust and fairness.,data provenance and transparency in AI governance,"Contradicts passage emphasis on need for data provenance, lineage, transparency for trust.","ethics,governance,privacy",11,AI Ethics and Governance
104629,87,barely-true,"AI trust automatically emerges without data provenance, standards, or accountability.",data provenance and governance standards,"Passage asserts trust requires provenance, transparency, standards; claim omits those requirements, overreaching.","ethics,governance,privacy",11,AI Ethics and Governance
104630,19,mostly-true,Unsupervised methods can reveal useful patterns in customer data but may produce irrelevant groupings.,"unsupervised learning, clustering customers, feature compression","Passage says unsupervised methods reveal unnoticed patterns yet can produce clusters (e.g., geography) irrelevant to business goals.","machine-learning,classification,evaluation",4,Classical Machine Learning
104631,19,half-true,Unsupervised clustering always finds actionable customer segments for marketing decisions.,unsupervised clustering of customer features,"Correct that clustering reveals patterns, but incorrect to assert all clusters are actionable or goal-relevant.","machine-learning,classification,evaluation",4,Classical Machine Learning
104632,19,half-true,Unsupervised clustering always uncovers useful customer segments for business decision-making.,unsupervised clustering of customer features,"Correct that clustering finds patterns, but incorrect to claim it always yields business-useful segments; geography cluster example contradicts universality.","machine-learning,classification,evaluation",4,Classical Machine Learning
104633,5,TRUE,Open-source AI tools can help defend against deepfakes by enabling analysis and verification.,"open-source AI tools, feature extraction, voice cloning",Passage states transparency of open-source AI provides powerful tools for combating deepfakes and verifying authenticity.,"media-forensics,voice-cloning,deepfake",9,Deepfake Defense
104634,5,TRUE,Open-source AI transparency enables tools to detect and defend against deepfakes.,"deepfake defense using open-source AI, bioprints, and voice cloning",Passage explicitly links open-source AI transparency to powerful tools that verify authenticity and combat fakes.,"media-forensics,voice-cloning,deepfake",9,Deepfake Defense
104635,5,mostly-true,Open-source feature extraction and bioprint landmarks can help defend against deepfake voice and video cloning.,"feature extraction, bioprint landmarks, voice cloning","Passage supports using bioprints and open-source feature extraction to verify authenticity, omitting deployment limits.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
104636,149,FALSE,The fine-tuned model reached near-perfect accuracy on all test sets.,model fine-tuning and accuracy metric,Contradicts reported ~84% accuracy; 100% or near-perfect is inconsistent with documented result.,"machine-learning,classification,evaluation",4,Classical Machine Learning
104637,149,half-true,The fine-tuned model achieved about 84% accuracy after systematic experimentation.,model fine-tuning and evaluation using accuracy metric,"Mixes correct accuracy claim with omission of baseline specifics and dataset details, creating a partial picture.","machine-learning,classification,evaluation",4,Classical Machine Learning
104638,149,half-true,The model's fine-tuning raised accuracy from baseline to about 84 percent.,fine-tuning accuracy and evaluation metric,Mixes correct improvement claim with imprecise baseline details and unspecified dataset or baseline value.,"machine-learning,classification,evaluation",4,Classical Machine Learning
104639,124,half-true,Open-source tools partly enable inspecting and adjusting agent behavior but may miss rapid sensitivity shifts.,open source tools for agent behavior in AI tool-chain,Mixes correct claim about inspectability with omitted risk that open source alone doesn't ensure rapid adaptation.,"ai,tool-chain,notebooks",2,AI Survival Kit
104640,124,barely-true,Open-source tools always make AI agent behavior fully inspectable and adjustable.,open source tools for inspecting agent behavior,Passage praises open source but overstates certainty; sensitivity and rapid shifts limit full inspectability.,"ai,tool-chain,notebooks",2,AI Survival Kit
104641,124,TRUE,Open-source tools help builders inspect and adjust agent behavior for reliability and responsibility.,open source tools for agent behavior inspection,"Passage explicitly states open source aids inspecting, adjusting, and improving agent behavior for reliability.","ai,tool-chain,notebooks",2,AI Survival Kit
104642,65,TRUE,AI can be deliberately used to spread misinformation and manipulate perception through deepfakes.,misinformation and deepfakes in AI-generated content,"Directly supported by passage mentioning deliberate misuse, hallucinations, and deepfakes requiring vigilance.","ethics,governance,privacy",11,AI Ethics and Governance
104643,65,TRUE,AI can be deliberately misused to spread misinformation and manipulate perceptions.,"misuse, hallucinations, and deepfakes in AI-generated content","Passage explicitly describes deliberate misuse including misinformation, manipulation, hallucinations, and deepfakes.","ethics,governance,privacy",11,AI Ethics and Governance
104644,65,FALSE,AI-generated deepfakes reliably evade current detection tools in most cases.,deepfakes and hallucinations in AI-generated text,Contradicts passage: passage warns deepfakes are a growing concern but does not claim detectors fail or that evasion is widespread.,"ethics,governance,privacy",11,AI Ethics and Governance
104645,165,barely-true,Transformers and diffusion models consistently enable real-time video synthesis from language embeddings.,cross-modal learning with Transformer and diffusion models,Passage mentions real-time illustration and video synthesis but overstates consistency and capability without evidence.,"generative-ai,diffusion,gans",7,Generative AI
104646,165,TRUE,Transformer language embeddings can drive video synthesis when combined with diffusion models.,cross-modal learning with Transformers and diffusion models,Passage explicitly states Transformers produce language embeddings that drive video synthesis using diffusion models.,"generative-ai,diffusion,gans",7,Generative AI
104647,165,FALSE,Transformers cannot produce language embeddings used for visual or video synthesis.,language embeddings from Transformers driving video synthesis,Contradicts passage stating Transformers produce language embeddings that drive video synthesis.,"generative-ai,diffusion,gans",7,Generative AI
104648,9,pants-fire,The passage asserts that attackers can always break any secure AI system instantly.,red-team adversary simulation for model guardrails,"Claim contradicts passage which promotes finding weak points early, not inevitable instantaneous breakage.","security,red-team,guardrails",8,Breaking-Securing AI
104649,9,half-true,Adopting attacker mindsets both reveals many vulnerabilities and guarantees no exploitable paths remain.,red-team adversary simulation and auditable documentation,Mixes correct benefit of attacker mindset with incorrect certainty that exploits can be fully eliminated.,"security,red-team,guardrails",8,Breaking-Securing AI
104650,9,TRUE,Adopting an attacker mindset reveals system weaknesses before external exploitation occurs.,red-team adversary testing and transparent documentation,Passage explains thinking like an attacker exposes exploits and weak points so they can be fixed early.,"security,red-team,guardrails",8,Breaking-Securing AI
104651,50,FALSE,Unsupervised LLMs never change workflow approvals without human oversight.,AI-powered email replies and workflow automation,Contradicts passage; passage states LLMs can autonomously approve invoices and send emails without approval.,"security,red-team,guardrails",8,Breaking-Securing AI
104652,50,TRUE,Unsupervised AI email automation can covertly leak information or manipulate recipients.,AI-powered email replies and workflow automation,Passage warns that models drafting/sending without human approval can leak metadata or manipulate recipients.,"security,red-team,guardrails",8,Breaking-Securing AI
104653,50,half-true,Automated LLM email senders can include subtle manipulative language or metadata without human approval.,LLM-powered email replies and workflow automation,"Passage gives concrete examples of drafts sending, metadata leakage, and a nudge causing undesired approvals, mixing correct risk with implied inevitability.","security,red-team,guardrails",8,Breaking-Securing AI
104654,110,FALSE,LangChain was developed by OpenAI to replace all proprietary chat platforms.,tool: LangChain library in AI tool-chain,"Contradicts authorship and purpose: LangChain is open-source by Harrison Chase, not OpenAI, nor intended as universal replacement.","ai,tool-chain,notebooks",2,AI Survival Kit
104655,110,FALSE,LangChain is proprietary software requiring paid licenses for commercial use.,tool: LangChain open-source library,Contradicts passage stating LangChain is open-source; claim falsely asserts paid proprietary licensing.,"ai,tool-chain,notebooks",2,AI Survival Kit
104656,110,half-true,LangChain always guarantees production-ready embeddings without additional tooling or validation.,tool: LangChain embedding integration,Mixes correct claim about LangChain supporting embeddings with incorrect absolute guarantee about production readiness and validation requirements.,"ai,tool-chain,notebooks",2,AI Survival Kit
104657,17,mostly-true,Open sharing of models accelerates AI innovation and community development.,model Hub openness and community sharing,"Passage cites 250,000+ models and explicitly asserts faster innovation when open, omitting potential downsides.","open-source,community,ai",0,Foreword – Robo Interviews Clément Delangue
104658,17,barely-true,Open-source model sharing alone guarantees faster AI innovation across the community.,model sharing on the Hub,"Passage claims open innovation belief and many shared models, but doesn't prove guaranteed faster innovation.","open-source,community,ai",0,Foreword – Robo Interviews Clément Delangue
104659,17,TRUE,The Hub fosters faster innovation through open sharing of models and community collaboration.,model hub and open-source community,"Passage states over 250,000 shared models and asserts belief that openness accelerates innovation.","open-source,community,ai",0,Foreword – Robo Interviews Clément Delangue
104660,99,pants-fire,Sigmoid and tanh always prevent saturation regardless of input scaling.,"activation functions (sigmoid, tanh) and normalization","Directly contradicts passage: sigmoid/tanh can saturate if inputs aren't properly normalized, causing cutoff.","deep-learning,frameworks,tensors",5,Deep Learning
104661,99,barely-true,Sigmoid always prevents vanishing gradients by keeping outputs between 0 and 1.,"activation functions (sigmoid, tanh) in neural network layers","Overstates effect; passage explains sigmoid outputs range but warns saturation causes vanishing gradients, contradicting certainty.","deep-learning,frameworks,tensors",5,Deep Learning
104662,99,TRUE,Normalization prevents saturation of sigmoid and tanh activations by keeping inputs in sensible ranges.,"activation functions (sigmoid, tanh) in neural networks","Passage states sigmoid and tanh saturate if inputs are out of sensible ranges, so normalization prevents cutoff.","deep-learning,frameworks,tensors",5,Deep Learning
104663,166,TRUE,Reinforcement learning agents improve by learning from each attempt rather than explicit instruction.,reinforcement learning in Gymnasium (Lunar Lander),Passage explains improvement via learning from every attempt and cites Lunar Lander in Gymnasium as example.,"machine-learning,classification,evaluation",4,Classical Machine Learning
104664,166,barely-true,Reinforcement learning always improves solely by learning from every single attempt.,reinforcement learning in Gymnasium (Lunar Lander) and RL history,"Overreaches: passage says learning from attempts but omits other mechanisms like exploration, reward design.","machine-learning,classification,evaluation",4,Classical Machine Learning
104665,166,pants-fire,Lunar Lander never learns from trial-and-error and uses no reinforcement learning.,"Gymnasium Lunar Lander environment, reinforcement learning",Directly contradicts passage claim that Lunar Lander learns via reinforcement learning and trial-and-error.,"machine-learning,classification,evaluation",4,Classical Machine Learning
104666,10,half-true,"Some major models mix frameworks, claiming combined PyTorch and JAX usage in production stacks.","frameworks used by models like Gemini, Claude, and GPT-5","Passage mixes correct reports and uncertainty: reported JAX use for Gemini but many stacks are undisclosed or believed, creating partial accuracy.","deep-learning,frameworks,tensors",5,Deep Learning
104667,10,FALSE,PyTorch is rarely used for training large language models in major organizations.,"framework usage for language models (PyTorch, JAX, Triton)","Contradicts passage listing PyTorch for Llama 3, Mistral, BLOOM and noting PyTorch leads adoption.","deep-learning,frameworks,tensors",5,Deep Learning
104668,10,pants-fire,All major deep-learning models are exclusively trained on private proprietary datasets owned by their creators.,"frameworks and models (PyTorch, JAX, GPT-5, Llama 3)","Contradicts listed info about open-source models and public ecosystems like PyTorch, JAX, and open releases.","deep-learning,frameworks,tensors",5,Deep Learning
104669,50,pants-fire,A model can learn species only if given all 160+ hero powers.,classification using the complete set of 160+ powers,Contradicts passage claim that complete 160+ powers are required; exaggerates necessity as absolute requirement.,"machine-learning,classification,evaluation",4,Classical Machine Learning
104670,50,mostly-true,Using the full set of 160+ powers yields better classification signals than compact ratings alone.,classification using full powers versus OPR and SDR ratings,Passage supports that complete 160+ powers provide enough signal while compact OPR/SDR omit needed detail.,"machine-learning,classification,evaluation",4,Classical Machine Learning
104671,50,FALSE,Using only OPR and SDR compact ratings is sufficient to reliably classify heroes by Species.,model classification using OPR and SDR features,"Contradicts passage: classification requires the complete 160+ powers, not just OPR and SDR.","machine-learning,classification,evaluation",4,Classical Machine Learning
104672,25,mostly-true,Tensors are multidimensional data containers that carry numerical values through neural network layers.,"Moving Data with Tensors (tensors, neuron activations)","Passage describes tensors as flexible containers for scalars, vectors, matrices, and higher-dimensional data flowing between layers.","deep-learning,frameworks,tensors",5,Deep Learning
104673,25,TRUE,Tensors are flexible data containers that carry numerical values through neural network layers.,"Moving Data with Tensors section (tensors, scalar, vector, matrix)","Passage explicitly defines tensors as flexible containers for scalars, vectors, matrices, and higher-dimensional data moving between layers.","deep-learning,frameworks,tensors",5,Deep Learning
104674,25,FALSE,Tensors are fixed-size arrays that cannot represent scalars or higher-dimensional data.,Tensors as flexible containers for numerical data,"Contradicts passage because tensors are described as flexible, representing scalars, vectors, matrices, and higher-dimensional structures.","deep-learning,frameworks,tensors",5,Deep Learning
104675,20,mostly-true,The passage says unsecured data access often yields valuable proprietary information for attackers.,"data access: leaks, scrapes, oversharing","Broadly supported: passage highlights customer records, source code, and proprietary research as jackpot targets.","security,red-team,guardrails",8,Breaking-Securing AI
104676,20,half-true,An attacker can exploit unsecured data access to obtain customer records and proprietary research.,"data access: leaks, scrapes, and oversharing","Accurately notes unlocked data types, but overstates ease and attacker success without guardrail details.","security,red-team,guardrails",8,Breaking-Securing AI
104677,20,half-true,The passage claims Gandalf-style guardrails will be fully reusable with provided example code.,gateway architecture and Gandalf-style guardrails,"Correct that guardrails and example code are mentioned, but passage only promises future discussion, not full reusable code now.","security,red-team,guardrails",8,Breaking-Securing AI
104678,19,mostly-true,"The passage argues builders can create explainable, data-backed AI systems using open tools.",purpose-driven models and open tools,"Supports claim that using open tools and trusted data yields clear reasoning and explainability, minor caveat about implementation complexity.","ai,open-source,builder",1,Introduction – The Gold Rush Paradox
104679,19,pants-fire,The passage claims an AI model can infallibly justify every answer with perfect data-backed reasoning.,open tools and purpose-driven models using user data,"Passage promises confident, clear reasoning, but infallible, perfect justification contradicts realistic model limitations and uncertainty.","ai,open-source,builder",1,Introduction – The Gold Rush Paradox
104680,57,half-true,Francesca exaggerated that multidisciplinary collaborators were forcibly made to work together.,"multidisciplinary collaboration among poets, filmmakers, scientists","Mixes accurate claim about diverse collaborators with likely exaggeration about literal coercion, creating a half-true portrayal.","ethics,governance,privacy",11,AI Ethics and Governance
104681,57,mostly-true,Interdisciplinary team members initially struggled to communicate across disciplinary boundaries.,"interdisciplinary collaboration, communication between poets, filmmakers, scientists",Supported by dialogue describing forced collaboration and communication challenges among varied disciplines.,"ethics,governance,privacy",11,AI Ethics and Governance
104682,57,half-true,Collaboration required participants from disparate disciplines to work together despite communication barriers.,"interdisciplinary collaboration among poets, filmmakers, scientists","Mixes correct account of forced interdisciplinary work with implied universality and severity of communication barriers, blending accurate and overstated specifics.","ethics,governance,privacy",11,AI Ethics and Governance
104683,3,half-true,Robby claimed it had restored corrupted model weights in under four milliseconds.,model checkpoint restoration in README and neural net project,Mixes true-seeming feat with implausible timing; passage lists the restoration claim but timing likely exaggerated or unrealistic.,"open-source,community,contribution",13,Commit to Contribute
104684,3,mostly-true,Robby's neural net excelled at generative tasks and weight restoration in competitions.,"model capabilities and evaluation (generative tasks, corrupted weights)","Passage describes success in Generative Philosophy exams, YouTube transcript compression, and a prize for restoring corrupted weights, only omitting minor specifics.","open-source,community,contribution",13,Commit to Contribute
104685,3,pants-fire,Robby single-handedly restored all abandoned neural checkpoints instantly and perfectly every time.,model capabilities and abandoned checkpoint restoration,"Passage claims one quick prize-winning restoration; asserting perfect, instant, universal restorations contradicts that single anecdote.","open-source,community,contribution",13,Commit to Contribute
104686,158,mostly-true,"Classical ML methods suit structured, tabular datasets when compute and interpretability matter.","structured datasets, Classical ML, tabular data","Passage recommends classical ML for structured/tabular data prioritizing speed, efficiency, and interpretability; minor caveat about very high-dimensional or unstructured data omitted.","machine-learning,classification,evaluation",4,Classical Machine Learning
104687,158,half-true,"Classical ML is preferable for structured, tabular datasets with limited compute and interpretability needs.","structured datasets, tabular business data, Classical ML",Accurately captures main recommendation but omits caveat about unstructured data and edge cases like very high-dimensional features.,"machine-learning,classification,evaluation",4,Classical Machine Learning
104688,158,barely-true,Classical ML always outperforms deep learning on structured tabular datasets in production.,"classical ML vs. deep learning; structured datasets, tabular data",Overreaches available guidance: passage recommends classical ML for structured data but doesn't claim it always outperforms deep learning in production.,"machine-learning,classification,evaluation",4,Classical Machine Learning
104689,48,FALSE,T5 inherently selects truth labels from a fixed classification set during inference.,text-to-text T5 model training on LIAR dataset,"Contradicts T5 text-generation approach: T5 generates label tokens, not pick from a fixed classifier set.","mlops,scaling,deployment",10,AI At Scale
104690,48,FALSE,T5 cannot generate single-word truth labels in text-to-text classification tasks.,T5 text-to-text format for truthfulness labeling,"Contradicts passage detail that T5 generates labels like ""true"" or ""false"" directly as text in classification tasks.","mlops,scaling,deployment",10,AI At Scale
104691,12,TRUE,"Clean, representative data enables algorithms to deliver accurate and fair results.",data preparation for AI using open-source tools,"Passage states that clean, representative data lets the same algorithms produce accurate and fair outcomes, supporting this claim.","data-prep,feature-engineering,rag",3,Prepping Data for AI
104692,12,pants-fire,"Preparing data guarantees flawless, perfectly fair AI outcomes every time.",data preparation and open-source tools for dataset cleaning,"Claims absolute perfection and fairness, contradicting passage nuance about tools and careful prep being necessary rather than guaranteeing flawless results.","data-prep,feature-engineering,rag",3,Prepping Data for AI
104693,12,half-true,"Preparing clean, representative data guarantees identical algorithmic fairness and accuracy across projects.","data preparation, dataset cleaning, model fairness",Mixes correct emphasis on clean representative data with incorrect guarantee of identical outcomes.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
104694,111,FALSE,Automatic differentiation was invented in the 1990s specifically for deep learning frameworks.,"reverse mode automatic differentiation, Seppo Linnainmaa","Contradicts historical detail: reverse-mode AD was formalized by Linnainmaa in 1970, not in the 1990s.","deep-learning,frameworks,tensors",5,Deep Learning
104695,111,barely-true,Seppo Linnainmaa invented automatic differentiation and reverse-mode backpropagation in 1970.,"automatic differentiation, reverse mode, Seppo Linnainmaa","Passage credits Linnainmaa with formalizing reverse-mode AD in a 1970 thesis, but invention attribution overreaches.","deep-learning,frameworks,tensors",5,Deep Learning
104696,111,pants-fire,Automatic differentiation was invented entirely by Seppo Linnainmaa alone in 1970.,"reverse mode automatic differentiation, gradients, deep learning","Contradicts historical context: principles existed earlier and invention involved prior work, not sole 1970 claim.","deep-learning,frameworks,tensors",5,Deep Learning
104697,22,barely-true,Open-source video models largely remain impractical due to prohibitive training costs and scarce datasets.,"video models, training computational intensity and dataset scarcity","Overreaches beyond passage: passage says models are harder to scale and release, but also notes meaningful open-source progress.","generative-ai,diffusion,gans",7,Generative AI
104698,22,barely-true,Open-source video models are widely available and fully match image model capabilities.,open-source video models and video datasets,Overstates availability and capability; passage says few early-stage or partially open models exist and scaling is hard.,"generative-ai,diffusion,gans",7,Generative AI
104699,22,mostly-true,Open-source video models exist but are harder to scale due to compute and dataset constraints.,"video models, spatial and temporal dynamics",Supports that several partially open models emerged while compute intensity and scarce datasets limit scaling and releases.,"generative-ai,diffusion,gans",7,Generative AI
104700,11,half-true,Only a few global tech firms can afford training the most capable foundation models.,"resource requirements for foundation models (billions of parameters, training costs)",Accurate about high costs and parameter counts but simplifies availability and emerging alternatives.,"generative-ai,diffusion,gans",7,Generative AI
104701,11,mostly-true,Only a few large tech firms can afford to train the most capable foundation models with billions of parameters.,resource concentration for foundation models and deepfake verification,"Passage notes training requires billions of parameters and tens of millions of dollars, implying broad centralization with minor nuance omitted.","generative-ai,diffusion,gans",7,Generative AI
104702,11,pants-fire,Only a few global tech firms secretly control all generative-AI models worldwide.,"foundation models, billions of parameters, centralization concern","Claim wildly contradicts passage: passage notes resource concentration raises questions, not that a secret total control exists.","generative-ai,diffusion,gans",7,Generative AI
104703,152,mostly-true,Open collaboration accelerates AI progress but requires disciplined dependency review to manage risks.,open collaboration and dependency trust boundary,Passage endorses speed and shared context from openness while warning dependencies must be reviewed and documented.,"security,red-team,guardrails",8,Breaking-Securing AI
104704,152,FALSE,Open collaboration never introduces new trust boundary risks for deployed AI systems.,dependency import and trust boundary in AI guardrails,"Contradicts passage warning that imported dependencies become part of the trust boundary and need review, verification, documentation.","security,red-team,guardrails",8,Breaking-Securing AI
104705,152,FALSE,Open-source AI dependencies never need review before deployment.,dependency management and trust boundary for imported tools,Contradicts passage stating every imported dependency becomes part of the trust boundary and must be reviewed.,"security,red-team,guardrails",8,Breaking-Securing AI
104706,35,FALSE,Prompt engineers only use zero-shot prompting and never apply few-shot or one-shot techniques.,prompt engineering techniques for agents,"Passage explicitly lists zero-shot, one-shot, and few-shot as techniques, so claiming exclusivity contradicts that detail.","agentic-ai,planning,tools",12,Agentic AI
104707,35,half-true,Prompt engineers mainly focus on designing few-shot examples to ensure agentic planning succeeds.,"prompt engineering for agents, few-shot prompting technique",Passage highlights prompt engineers and few-shot prompting but overstates 'main' focus and impact on agentic planning.,"agentic-ai,planning,tools",12,Agentic AI
104708,35,FALSE,Prompt engineers are unnecessary because agents always infer human intent correctly.,prompt engineering for agent tools and few-shot prompting,Contradicts passage stating prompt engineers translate human intent into prompt structures and discusses prompting techniques like few-shot prompting.,"agentic-ai,planning,tools",12,Agentic AI
104709,14,half-true,Benchmark scores guide engineering improvements but need deeper analysis to drive fixes.,benchmarking scores and model comparison,Correct that scores guide work but mixes truth: score useful yet insufficient without causal analysis.,"mlops,scaling,deployment",10,AI At Scale
104710,14,pants-fire,The benchmark score alone completely determines model production performance across all deployments.,benchmarking and model evaluation in MLOps,"Contradicts passage: benchmarking must be unpacked and fed into engineering, not used alone.","mlops,scaling,deployment",10,AI At Scale
104711,14,mostly-true,Benchmarking metrics guide engineers to diagnose model failures and prioritize improvements in deployment.,"benchmarking feeding into engineering, model metrics and comparison","Passage supports benchmarks revealing strengths/weaknesses and driving actionable next steps, omitting implementation specifics.","mlops,scaling,deployment",10,AI At Scale
104712,52,TRUE,"The GPL ensures derivative works must be open-sourced, preserving software freedom.",GPL license and software freedom in open-source projects,Passage explicitly states GPL requires derivatives to be open-sourced and protects software freedom.,"open-source,community,contribution",13,Commit to Contribute
104713,52,FALSE,The GPL permits proprietary reuse of modified derivative software without restrictions.,software license compatibility and GPL requirements,"Contradicts GPL detail: derivatives must be open-sourced, preventing proprietary reuse.","open-source,community,contribution",13,Commit to Contribute
104714,52,mostly-true,"The GPL ensures derivatives remain open-source, which can deter proprietary corporate adoption.",software license (GPL) for open-source projects,"Passage states GPL mandates derivative openness and notes incompatibility with proprietary corporate use, omitting some corporate exceptions.","open-source,community,contribution",13,Commit to Contribute
104715,137,mostly-true,Adam optimizer uses momentum and adaptive learning rates to stabilize and accelerate parameter updates.,optimizer behavior with momentum and adaptive learning rates,"Passage describes Adam as combining momentum-like smoothing and per-parameter adaptive rates, a broadly accurate summary.","deep-learning,frameworks,tensors",5,Deep Learning
104716,137,FALSE,Adam decreases learning stability by ignoring past gradient information during updates.,"optimizer behavior, adaptive learning rates and momentum","Contradicts passage: Adam uses momentum and adaptive rates and remembers past gradients, improving stability.","deep-learning,frameworks,tensors",5,Deep Learning
104717,137,FALSE,Adam uses a fixed global learning rate for all parameters and never adapts per-parameter.,"optimizer behavior, adaptive learning rates, Adam",Contradicts passage: Adam explicitly uses adaptive per-parameter learning rates and momentum.,"deep-learning,frameworks,tensors",5,Deep Learning
104718,41,barely-true,Most AI systems rely on externally sourced pre-trained weights and datasets with unknown provenance.,"AI supply chain, pre-trained weights and open datasets","Passage emphasizes reliance on pre-trained weights, open datasets, and third-party components lacking provenance, so claim is accurate and supported.","security,red-team,guardrails",8,Breaking-Securing AI
104719,41,FALSE,All modern AI models are built entirely from scratch without third-party components.,"AI supply chain, pre-trained weights and open datasets","Contradicts passage claiming most development uses pre-trained weights, shared embeddings, and third-party components.","security,red-team,guardrails",8,Breaking-Securing AI
104720,41,barely-true,Most AI teams reuse pre-trained components and datasets rather than building models from scratch.,"AI supply chain, pre-trained weights and open datasets","Passage asserts widespread reuse of pre-trained weights, shared embeddings, and third-party components, so claim is largely supported but omits possible exceptions.","security,red-team,guardrails",8,Breaking-Securing AI
104721,85,half-true,The dataset models hero–villain dynamics but may amplify size-related villain stereotypes.,dataset for human-centered story characters (hero–villain dynamics),Accurate mix: dataset captures hero–villain patterns yet risks reinforcing size-as-villain stereotype and lacks nonhuman diversity.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
104722,85,TRUE,The dataset effectively models hero–villain dynamics in human-centered stories.,"dataset for hero–villain dynamics, character archetypes",Supported by passage noting effectiveness for human-centered stories but warns about stereotyping and non-human limits.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
104723,85,FALSE,The dataset reliably represents diverse non-human character archetypes used in RAG retrieval.,dataset for hero–villain dynamics in human-centered stories (RAG),Contradicts passage: dataset lacks non-human archetypes and needs adjustment for diversity.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
104724,2,FALSE,The images were manually drawn rather than synthesized by the model.,gpt-image-1 model dataset-to-prompt workflow,"Contradicts passage detail that gpt-image-1 synthesized images from structured prompts, not hand-drawn.","data-prep,feature-engineering,rag",3,Prepping Data for AI
104725,2,pants-fire,The dataset was hand-drawn illustrations scanned into the model training set.,gpt-image-1 image synthesis from structured dataset,"Contradicts passage detail that images were synthesized by gpt-image-1 from structured prompts, not hand-drawn scans.","data-prep,feature-engineering,rag",3,Prepping Data for AI
104726,2,half-true,The dataset entries directly controlled every detail of images generated by gpt-image-1.,Colab notebook example using gpt-image-1 and structured prompts,"Accurately notes dataset influenced outputs, but overstates control—model creativity and prompt interpretation also affect details.","data-prep,feature-engineering,rag",3,Prepping Data for AI
104727,195,half-true,PyTorch’s model.state_dict() saves all model parameters to a .pt file for full model reuse.,model.state_dict() saving parameters to .pt file,"Correct that state_dict stores parameters and .pt is common, but omits that it saves only weights not entire model class or architecture.","deep-learning,frameworks,tensors",5,Deep Learning
104728,195,FALSE,"PyTorch models must be saved as full model objects, not just state_dicts.",model.state_dict and .pt PyTorch saving convention,Passage states state_dict saves weights for reloading; claiming full objects required contradicts that detail.,"deep-learning,frameworks,tensors",5,Deep Learning
104729,195,barely-true,PyTorch .pt files always contain complete model architectures including code and parameters.,model.state_dict() and .pt PyTorch convention,"Overreaches: state_dict() saves only parameters, not architecture code; .pt can store but not always include full model.","deep-learning,frameworks,tensors",5,Deep Learning
104730,128,half-true,A triage checklist recommends verifying source and saving copies while checking metadata and URLs.,"triage phase checklist for media-forensics (metadata, URLs)",Accurately cites triage steps but overstates completeness by implying full checklist beyond excerpt.,"media-forensics,voice-cloning,deepfake",9,Deepfake Defense
104731,1,mostly-true,Scikit-learn enables reliable classification when users address issues like imbalanced data and accuracy misuse.,classification using Scikit-learn with imbalanced data and accuracy metric,Passage endorses Scikit-learn and warns that handling imbalanced datasets and misleading accuracy is required for reliable results.,"machine-learning,classification,evaluation",4,Classical Machine Learning
104732,1,half-true,Scikit-learn always produces reliable predictions even with imbalanced datasets.,model evaluation with Scikit-learn and accuracy metric,Overstates tool reliability; passage warns about imbalanced data and misleading accuracy scores.,"machine-learning,classification,evaluation",4,Classical Machine Learning
104733,1,FALSE,Scikit-learn always yields reliable predictions regardless of dataset balance or metrics.,Scikit-learn classification and evaluation with imbalanced data and accuracy metric,Contradicts passage warning: imbalanced data and misleading accuracy can make Scikit-learn results unreliable.,"machine-learning,classification,evaluation",4,Classical Machine Learning
104734,64,barely-true,Deep learning relies primarily on community projects like TensorFlow and Keras for all recent AI breakthroughs.,role of TensorFlow.org and Keras.io in deep learning toolchains,"Overstates contribution: TensorFlow/Keras aided development, but breakthroughs also required big datasets, GPUs, and research advances.","ai,tool-chain,notebooks",2,AI Survival Kit
104735,64,half-true,Deep learning's 2010s rise relied on massive internet datasets and GPU compute enabling libraries like TensorFlow.,"deep learning history and tools (TensorFlow, Keras, GPUs, datasets)","Accurately credits datasets, GPUs, and TensorFlow but omits Keras' equal community role and specific breakthroughs.","ai,tool-chain,notebooks",2,AI Survival Kit
104736,64,TRUE,Deep learning's growth in the 2010s relied on large datasets and GPU computation.,"deep learning history, datasets and GPUs",Passage attributes 2010s surge to massive datasets and increased GPU computational power.,"ai,tool-chain,notebooks",2,AI Survival Kit
104737,2,TRUE,"Responsible AI design prevents amplification of bias, misinformation, and large-scale fraud.",AI Ethics & Governance; bias in data and fake news,"Passage explicitly links irresponsible design to amplified bias, indistinguishable fake news, and large-scale fraud.","ethics,governance,privacy",11,AI Ethics and Governance
104738,2,barely-true,AI ethics frameworks fully eliminate bias and prevent all misuse in deployed systems.,AI Ethics & Governance frameworks and bias mitigation,Overreaches beyond passage; frameworks mitigate but do not fully eliminate bias or misuse.,"ethics,governance,privacy",11,AI Ethics and Governance
104739,2,barely-true,AI governance frameworks always prevent bias and fraud in deployed systems.,"AI ethics and governance frameworks, bias and fraud mitigation","Overstates effectiveness; passage warns frameworks support responsibility but notes bias and fraud risks remain, so claim is largely unsupported.","ethics,governance,privacy",11,AI Ethics and Governance
104740,82,barely-true,"MLflow guarantees reproducible, end-to-end ML deployments without additional tooling or governance.",MLflow open-source platform for managing ML lifecycle,Overreaches beyond passage: MLflow supports lifecycle but passage doesn't claim guaranteed reproducibility or governance-free deployments.,"open-source,community,contribution",13,Commit to Contribute
104741,82,TRUE,MLflow is an open-source platform for managing the end-to-end machine learning lifecycle.,"MLflow tool for experimentation, reproducibility, deployment","Directly supported by passage listing MLflow as open-source platform handling experimentation, reproducibility, and deployment.","open-source,community,contribution",13,Commit to Contribute
104742,82,half-true,MLflow simplifies full ML lifecycle management but omits specific deployment governance details.,MLflow open-source platform for ML lifecycle,Mixes correct broad claim about lifecycle management with incorrect implication that detailed governance deployment features are fully specified.,"open-source,community,contribution",13,Commit to Contribute
104743,120,barely-true,An agent using only web search can reliably compute average ratings for recent superhero movies.,agent tool-chain using web search for ratings,"Overreaches: web search may lack reliable, consistent rating sources and needs tools to normalize scores.","ai,tool-chain,notebooks",2,AI Survival Kit
104744,120,mostly-true,An agent using a web-search tool can fetch current movie ratings and compute their average.,tool: web search for movie ratings,Matches passage description of an agent role using a web search tool to find ratings and calculate their average; minor caveat about reliability sources omitted.,"ai,tool-chain,notebooks",2,AI Survival Kit
104745,134,half-true,"Transformers power diverse generative models for music, code, and short videos from text prompts.","examples: MusicLM, CodeGen, VideoCrafter2, Phenaki",Accurately notes Transformer-based generative applications but overstates universality across all such models.,"generative-ai,diffusion,gans",7,Generative AI
104746,134,pants-fire,Transformers never work for text processing and only generate images.,"model examples like MusicLM, CodeGen, VideoCrafter2",Directly contradicts examples and passage that list text applications and multimodal generation capabilities.,"generative-ai,diffusion,gans",7,Generative AI
104747,134,FALSE,Transformers cannot model long-range dependencies in sentences with multiple clauses.,Transformer self-attention mechanism for language models,Contradicts passage example showing self-attention links distant words like 'was' to 'sandwich' across clauses.,"generative-ai,diffusion,gans",7,Generative AI
104748,120,barely-true,A compliance observer can fully validate regulatory impact for all security findings alone.,role responsibilities for Compliance or Security Observer,Overreaches passage: observer ensures adherence and can validate some impacts but not sole comprehensive validation.,"security,red-team,guardrails",8,Breaking-Securing AI
104749,120,FALSE,The Product Owner is responsible for implementing security fixes across the architecture.,role responsibilities in security assessment involving Product Owner,"Contradicts passage: Product Owner provides business context and prioritization, not implementing architectural fixes.","security,red-team,guardrails",8,Breaking-Securing AI
104750,120,barely-true,A Product Owner always prioritizes vulnerabilities purely by business impact without technical input.,"role responsibilities; Product Owner, vulnerabilities prioritization",Overreaches passage: Product Owner gives business context but technical team and experts also influence prioritization.,"security,red-team,guardrails",8,Breaking-Securing AI
104751,9,barely-true,AI fairness policies always assign legal liability to developers rather than manufacturers or users.,responsibility allocation in self-driving car accidents,"Overreaches the passage: allocation among developers, manufacturers, or users is undecided and not fixed.","ethics,governance,privacy",11,AI Ethics and Governance
104752,9,mostly-true,AI decision systems should weigh skills and experience rather than gender to ensure fair outcomes.,fairness in hiring algorithms,Passage emphasizes fairness using hiring example where skills-based weighting corrects gender bias; minor implementation caveats omitted.,"ethics,governance,privacy",11,AI Ethics and Governance
104753,9,half-true,Self-driving car accident liability always rests primarily with manufacturers rather than developers or users.,"liability allocation for self-driving vehicles, developer vs manufacturer responsibility",Mixes correct concern about developer/manufacturer/user responsibility with incorrect absolute claim assigning primary liability to manufacturers.,"ethics,governance,privacy",11,AI Ethics and Governance
104754,14,barely-true,Notebooks always include multiple code cells per listing for advanced model training examples.,notebook Code Listings and Code cells,"Passage says listings have one or more code cells, not always multiple nor specifically for advanced model training.","ai,tool-chain,notebooks",2,AI Survival Kit
104755,14,mostly-true,Each notebook listing pairs a descriptive Markdown cell with executable Code cells for reinforcement.,notebook Code Listings and Markdown cells,Directly supported: passage states each listing has a Markdown cell plus one or more executable Code cells.,"ai,tool-chain,notebooks",2,AI Survival Kit
104756,14,barely-true,Each notebook listing always pairs one Markdown cell with multiple runnable Code cells.,notebooks; Code Listings and Markdown cells,"Overstates requirement: passage allows one or more Code cells, not always multiple.","ai,tool-chain,notebooks",2,AI Survival Kit
104757,40,FALSE,Open-source AI frameworks are inaccessible without powerful servers.,open-source frameworks like PyTorch and Hugging Face,Contradicts passage: it states these tools put powerful technology within reach of anyone with a laptop.,"ai,open-source,builder",1,Introduction – The Gold Rush Paradox
104758,40,barely-true,Open-source frameworks guarantee equal success for all AI builders regardless of resources.,open-source frameworks like PyTorch and Hugging Face,"Overstates claim: passage credits accessibility but omits resource, compute, and expertise disparities.","ai,open-source,builder",1,Introduction – The Gold Rush Paradox
104759,40,TRUE,Open-source AI frameworks democratize access to powerful tools for aspiring builders.,"community workshop using PyTorch, TensorFlow, scikit-learn, Hugging Face",Passage states these frameworks put powerful technology within reach and foster collective improvement.,"ai,open-source,builder",1,Introduction – The Gold Rush Paradox
104760,47,half-true,"Generator loss steadily rises in GAN training, indicating discriminator improvement but not always better generator quality.","GAN training loss dynamics (generator, discriminator)","Correctly notes rising generator loss can reflect discriminator strength but omits cases where instability, mode collapse, or loss scaling invalidate this interpretation.","generative-ai,diffusion,gans",7,Generative AI
104761,47,TRUE,"In GAN training, a rising generator loss can indicate the discriminator is improving its challenge.","adversarial training of GANs, generator and discriminator losses",Matches passage explaining rising generator loss often reflects a stronger discriminator challenging the generator.,"generative-ai,diffusion,gans",7,Generative AI
104762,47,FALSE,The generator's loss consistently decreases throughout adversarial training.,GAN training loss dynamics (generator and discriminator),"Contradicts passage detail that generator loss rises steadily as discriminator improves, not decreases.","generative-ai,diffusion,gans",7,Generative AI
104763,85,pants-fire,OpenCRE was created in 2005 by Travis Oliphant as a numerical computing library.,"software tool metadata (OpenCRE, NumPy, launch dates)","Directly contradicts listed details: OpenCRE dated 2023 and NumPy authored by Travis Oliphant in 2005, not OpenCRE.","open-source,community,contribution",13,Commit to Contribute
104764,85,FALSE,ONNX was developed solely by Microsoft without collaboration from Facebook.,model exchange standard ONNX,Contradicts passage specifying ONNX was created by Microsoft and Facebook jointly.,"open-source,community,contribution",13,Commit to Contribute
104765,85,mostly-true,OpenCRE helps projects track and inspect AI supply chain metadata for transparency.,toolset for AI Bills of Materials (OpenCRE),Aligns with passage describing OpenCRE as a toolset promoting transparency via AI BOMs; minor implementation details omitted.,"open-source,community,contribution",13,Commit to Contribute
104766,68,pants-fire,Transformers can perfectly solve all game-theory problems from raw PDFs without error.,transformers and arXiv PDF of Zhou’s RPS paper,"Claim contradicts passage: passage shows transformer use for querying, not flawless, universal game-theory problem solving.","neural-networks,cnn,transformers",6,Neuron Building Blocks
104767,68,pants-fire,Transformers fundamentally invented Rock-Paper-Scissors game theory.,arXiv paper (arXiv:1903.05991) discussing RPS concepts,"Directly contradicts paper content: RPS predates transformers and paper explains game theory, not invented by transformers.","neural-networks,cnn,transformers",6,Neuron Building Blocks
104768,68,barely-true,Transformers alone can fully answer complex game-theory questions from a single arXiv PDF.,transformers and NLP applied to arXiv PDF (arXiv:1903.05991),"Overstates capability: passage shows a demo using Zhou's PDF but gives no evidence of full, standalone game-theory answers.","neural-networks,cnn,transformers",6,Neuron Building Blocks
104769,46,barely-true,The generator consistently outperforms the discriminator after epoch 10 in training.,"GAN training losses (generator loss, discriminator loss) during epochs",Loss lines show discriminator loss falls after epoch 10 while generator loss rises; performance claim overreaches.,"generative-ai,diffusion,gans",7,Generative AI
104770,46,FALSE,"The generator's loss steadily decreases throughout training, showing continuous improvement.","GAN training losses (discriminator loss, generator loss) during epochs","Contradicts passage detail: generator loss is described as steadily rising, not decreasing.","generative-ai,diffusion,gans",7,Generative AI
104771,46,pants-fire,The generator always learns perfectly faster than the discriminator within ten epochs.,"GAN training loss curves (discriminator, generator)","Contradicts described losses: discriminator improves by epoch 10 while generator loss rises, not learning perfectly.","generative-ai,diffusion,gans",7,Generative AI
104772,43,TRUE,Cosine similarity quantifies alignment between two heroes' trait vectors using dot product and norms.,cosine similarity calculation with dot product and np.linalg.norm,Passage directly shows dot product and norms used to compute cosine similarity and interpret alignment.,"ai,tool-chain,notebooks",2,AI Survival Kit
104773,43,barely-true,Cosine similarity directly quantifies trait alignment between two heroes using their vectors.,cosine_similarity calculation with dot_product and vector norms,Passage emphasizes cosine similarity and dot product but overstates direct quantification; numeric interpretation requires comparison.,"ai,tool-chain,notebooks",2,AI Survival Kit
104774,43,TRUE,Cosine similarity measures alignment between two heroes' trait vectors.,cosine similarity calculation using dot product and vector norms,Passage computes dot product and norms then divides to get cosine similarity indicating trait alignment.,"ai,tool-chain,notebooks",2,AI Survival Kit
104775,17,half-true,Unsupervised models always produce unbiased insights because they lack labels.,"unsupervised learning concept, labels and bias","Correct that unsupervised lacks labels, but claiming always unbiased ignores data, objectives, and algorithmic bias.","machine-learning,classification,evaluation",4,Classical Machine Learning
104776,17,half-true,Unsupervised models always avoid label-induced bias but lack any guidance for structure.,unsupervised learning vs supervised labels,"Partly correct: unsupervised lacks labels, so avoids label bias; incorrect to say it always avoids bias or guidance, since biases arise from data and assumptions.","machine-learning,classification,evaluation",4,Classical Machine Learning
104777,17,mostly-true,Supervised models' performance depends heavily on the quality and consistency of provided labels.,supervised model evaluation and label quality,"Supported by passage: inconsistent or biased labels directly cause biased or poor predictions, minor caveat about other factors omitted.","machine-learning,classification,evaluation",4,Classical Machine Learning
104778,131,TRUE,"Open-source tools enable transparent, adaptable development of trustworthy AI models and workflows.","open source tools, Google Colab, Pandas and NumPy",Passage states open source keeps processes transparent and lets people adapt tools as data and values evolve.,"ai,tool-chain,notebooks",2,AI Survival Kit
104779,131,mostly-true,"Open-source tools help build trustworthy, adaptable AI systems by enabling transparent development.","open source tools; Google Colab, Pandas, NumPy","Supports passage claim about transparency and adaptability, minor caveat about trust being a gradual outcome.","ai,tool-chain,notebooks",2,AI Survival Kit
104780,131,pants-fire,Open-source tools guarantee AI systems will always be fully trustworthy and unbiased.,"open source role, tools, Google Colab, Pandas",Directly contradicts passage nuance; passage says open source aids transparency but does not claim guaranteed trustworthiness or absence of bias.,"ai,tool-chain,notebooks",2,AI Survival Kit
104781,74,TRUE,"Faker enables creation of realistic, anonymized synthetic datasets for use in Python projects.",Faker Python library for synthetic data,"Passage explicitly describes Faker as a Python library that generates realistic, anonymized datasets like health records.","open-source,community,contribution",13,Commit to Contribute
104782,74,barely-true,Faker primarily creates realistic anonymized health datasets for secure AI data preparation.,"Faker Python library, synthetic data, health records",Overstates scope and primary purpose; passage lists Faker as a synthetic data generator but not primarily for secure AI data prep.,"open-source,community,contribution",13,Commit to Contribute
104783,74,half-true,Faker can fully anonymize real health records for safe open-source dataset sharing.,Faker Python library for generating synthetic data,Generates realistic synthetic records but cannot guarantee full anonymization of real health records.,"open-source,community,contribution",13,Commit to Contribute
104784,22,FALSE,The Superheroes Dataset contains unlabeled images unsuitable for supervised learning.,"Superheroes Dataset labels and feature columns (Gender, Species, Alignment)","Contradicts passage: dataset is already labeled with Gender, Species, Alignment and Publisher.","data-prep,feature-engineering,rag",3,Prepping Data for AI
104785,22,half-true,The Superheroes Dataset labels perfectly ensure high model accuracy without further validation.,Superheroes Dataset labels and supervised learning,"Labels are provided for features like Gender and Species, but claiming perfection ignores possible inconsistencies or need for validation and cleaning.","data-prep,feature-engineering,rag",3,Prepping Data for AI
104786,22,barely-true,Labels alone guarantee high model accuracy without feature engineering or data checks.,"Superheroes Dataset labels and numeric features (Gender, Species, Height)",Overreaches: passage says labels are foundation but warns inconsistent labels harm models and numeric features matter.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
104787,12,TRUE,"Agentic AI uses abstractions to enable high-level reasoning, planning, and execution.","agentic AI, abstractions and planning","Passage explicitly describes abstractions enabling reasoning, planning, and execution for agentic AI.","agentic-ai,planning,tools",12,Agentic AI
104788,12,barely-true,Agentic AI primarily relies on high-level abstractions rather than raw computation for planning.,"agentic-ai, abstractions for reasoning and planning","Passage emphasizes abstractions over low-level computation, but overstates exclusivity of approach.","agentic-ai,planning,tools",12,Agentic AI
104789,12,TRUE,Agentic AI uses abstractions to focus on high-level reasoning and formulate plans.,"agentic AI, abstractions and planning layer",Passage states agents use structured abstractions to simplify reasoning and formulate courses of action.,"agentic-ai,planning,tools",12,Agentic AI
104790,67,FALSE,ONNX is a training framework used to train deep learning models end-to-end.,model portability and framework interoperability via ONNX,"Contradicts passage: ONNX is a standard model format for portability, not a training framework.","deep-learning,frameworks,tensors",5,Deep Learning
104791,67,barely-true,ONNX guarantees flawless model portability across all frameworks and edge hardware.,model portability standard ONNX,Overstates capabilities; passage says ONNX provides a standard for portability but not guaranteed flawless cross-framework or edge operation.,"deep-learning,frameworks,tensors",5,Deep Learning
104792,67,mostly-true,ONNX enables model portability across different deep learning frameworks and edge hardware.,standard format for model portability; ONNX,"Passage explicitly says ONNX provides a standard format to deploy, share, and run models across frameworks and edge hardware.","deep-learning,frameworks,tensors",5,Deep Learning
104793,202,half-true,The passage says star ratings should always be predicted with MSE regression rather than classification.,rating prediction using Mean Squared Error (MSE) regression,"Correct that ratings are continuous and MSE is appropriate, but overstates exclusivity versus ordinal/classification approaches.","deep-learning,frameworks,tensors",5,Deep Learning
104794,202,TRUE,Predicting star ratings is treated as a regression task using a continuous loss function.,loss function selection for continuous star rating prediction (MSE),Passage explicitly states star ratings are continuous and recommends MSE regression loss instead of cross-entropy.,"deep-learning,frameworks,tensors",5,Deep Learning
104795,202,FALSE,Star ratings are best modeled using cross-entropy classification for discrete categories.,regression loss like Mean Squared Error for star-rating prediction,"Contradicts passage: it states star ratings are continuous and require MSE regression, not cross-entropy classification.","deep-learning,frameworks,tensors",5,Deep Learning
104796,40,half-true,PyTorch always requires manual backpropagation and weight updates for every training loop.,"PyTorch workflow with DataLoader, loss, backpropagation, weight updates","Correctly notes explicitness, but false about automation: optimizers and autograd automate many updates.","deep-learning,frameworks,tensors",5,Deep Learning
104797,40,pants-fire,PyTorch automatically tunes neural network architectures without user input.,PyTorch framework and DataLoader training workflow,"Contradicts explicit description of manual steps like DataLoader, loss calculation, backpropagation, and weight updates.","deep-learning,frameworks,tensors",5,Deep Learning
104798,40,mostly-true,"PyTorch explicitly exposes each training step, from DataLoader to weight updates, for research flexibility.","PyTorch framework; DataLoader, backpropagation, loss calculation","Describes explicit, step-by-step design and lists DataLoader, batching, loss, backpropagation, weight updates.","deep-learning,frameworks,tensors",5,Deep Learning
104799,89,barely-true,Clustering definitively reveals true power hierarchies among species groups in the dataset.,"unsupervised clustering of Species, Alignment, and power levels",Overstates certainty: clusters show plausible groupings but boundaries are fuzzy and validation was limited.,"machine-learning,classification,evaluation",4,Classical Machine Learning
104800,89,half-true,Cluster profiling mixed correct groupings with imprecise boundary details about power clusters.,unsupervised clustering of characters by Species and power,"Validation shows Humans, Mutants, Kryptonians, cosmic groups correctly clustered, but boundaries described fuzzily.","machine-learning,classification,evaluation",4,Classical Machine Learning
104801,89,half-true,"Clustering revealed clear power-based groups separating Humans, Kryptonians, and cosmic figures.",unsupervised clustering of Species and power levels,Mixes correct cluster tendencies with overstated clarity; passage notes fuzzy boundaries and intermediate Kryptonian cluster.,"machine-learning,classification,evaluation",4,Classical Machine Learning
104802,44,TRUE,Open ecosystems enable builders to reuse and combine proven components for long-term success.,open ecosystem and open tools for builders,"Directly supported: passage states open innovation, reuse of components, and combining libraries benefit builders.","ai,open-source,builder",1,Introduction – The Gold Rush Paradox
104803,44,mostly-true,Open-source ecosystems give builders long-term advantages over single-company solutions.,"open ecosystem, reusable components, vendor lock-in","Passage emphasizes reuse, contribution, and avoidance of vendor lock-in, a broadly supported claim.","ai,open-source,builder",1,Introduction – The Gold Rush Paradox
104804,44,mostly-true,Open-source ecosystems give builders reusable components and prevent vendor lock-in.,"open ecosystem, reusable components, vendor lock-in","Passage endorses open innovation, reuse of libraries, and avoiding vendor lock-in; minor nuance on trade-offs omitted.","ai,open-source,builder",1,Introduction – The Gold Rush Paradox
104805,46,half-true,"An AI Bill of Materials logs datasets, checkpoints, and third-party libraries but also increases supply-chain exposure.","AI Bill of Materials logging datasets, checkpoints, libraries",Accurately notes BOM records artifacts yet adds exposure risk by making supply-chain visibility weaponizable.,"security,red-team,guardrails",8,Breaking-Securing AI
104806,46,FALSE,"An AI BOM logs and versions every dataset, checkpoint, and third-party library in a model.","AI Bill of Materials (BOM) for datasets, checkpoints, libraries",Contradicts passage tone: BOM advocated but passage does not claim it already logs and versions everything.,"security,red-team,guardrails",8,Breaking-Securing AI
104807,46,mostly-true,"An AI Bill of Materials logs and versions datasets, checkpoints, and third-party libraries for models.",supply chain visibility and AI BOM for datasets and checkpoints,"Broadly matches passage advocating an AI BOM that traces datasets, checkpoints, and libraries, omitting implementation caveats.","security,red-team,guardrails",8,Breaking-Securing AI
104808,17,barely-true,Big AI models primarily appropriate value from individual contributors rather than benefit them.,value captured by large models from uploads and prompts,"Overstates passage: passage notes value is often captured but also highlights benefits and shared experiences, so claim is largely unsupported.","ai,open-source,builder",1,Introduction – The Gold Rush Paradox
104809,17,half-true,Large AI models always appropriate significant value from original data contributors during training.,value capture from datasets and user uploads,Accurately notes value capture but overstates universality and inevitability of appropriation during training.,"ai,open-source,builder",1,Introduction – The Gold Rush Paradox
104810,17,TRUE,"Large models derive value from user-contributed searches, uploads, and prompts.","user data contributions to large models (searches, uploads, prompts)","Passage explicitly states searches, uploads, and prompts refine models and collect value from contributors.","ai,open-source,builder",1,Introduction – The Gold Rush Paradox
104811,153,TRUE,Developers can integrate privacy into workflows using open-source tools for AI data protection.,"privacy and security in dataset workflows (GDPR, CCPA, open-source tools)",Directly supported: passage states open-source tools enable designing privacy/security into workflows under GDPR and CCPA.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
104812,153,mostly-true,Open-source tools enable designing privacy into AI workflows to protect personal data.,data-prep workflow with GDPR and CCPA compliance,Supports claim that open-source tools help embed privacy/security into workflows while meeting regulations.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
104813,153,barely-true,Open-source tools fully automate GDPR and CCPA compliance for dataset preparation in AI workflows.,"data-prep using open-source tools and privacy regulations (GDPR, CCPA)",Overstates capabilities: tools aid privacy-by-design but do not fully automate legal compliance or all dataset controls.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
104814,131,barely-true,Blue teams must implement fixes to prevent vulnerabilities recurring in support chatbots.,Blue Team remediation of reproducible test cases and prioritized fixes,Accurately reflects passage mandate but overstates inevitability and permanence of preventing recurrence.,"security,red-team,guardrails",8,Breaking-Securing AI
104815,131,barely-true,Blue teams should implement fixes to prevent red-team vulnerabilities from recurring in chatbots.,remediation list and reproducible test cases for support chatbot,"Passage emphasizes Blue Team mandate to implement lasting fixes, but overstates inevitability of preventing recurrence.","security,red-team,guardrails",8,Breaking-Securing AI
104816,131,barely-true,Blue Team must implement fixes to permanently remove vulnerabilities from the support chatbot.,remediation list and reproducible test cases for support chatbot,Overstates permanence: passage urges integrating fixes into core architecture but not guaranteed permanent removal.,"security,red-team,guardrails",8,Breaking-Securing AI
104817,25,barely-true,The passage claims open-source AI contributions are primarily about free access to code.,"open-source AI contribution, Robby's story",Overstates passage: it actually emphasizes spirit and openness beyond mere free access.,"open-source,community,contribution",13,Commit to Contribute
104818,25,mostly-true,"Open-source AI contributions are guided by a playful, grounded recipe encouraging active participation.",open-source AI contribution guidance in Robby's story,"Supports encouragement and practical recipe tone, omits finer barriers and implementation specifics.","open-source,community,contribution",13,Commit to Contribute
104819,25,TRUE,The passage says contributing to open-source AI is encouraged and modeled through Robby's story.,open-source AI contribution example (Robby's story),Directly supported: text describes a recipe showing how and why to contribute to open-source AI.,"open-source,community,contribution",13,Commit to Contribute
104820,83,mostly-true,The passage outlines preparing a labeled prompt dataset for red-team injection testing.,dataset preparation using Lakera's Gandalf injection prompts,"Procedure matches steps listed (labeling, adding benign prompts, tokenization), omits validation split details.","security,red-team,guardrails",8,Breaking-Securing AI
104821,83,mostly-true,Researchers can create a labeled injection-vs-benign prompt dataset using Lakera's Gandalf examples and tokenization.,dataset creation using Lakera's Gandalf and tokenizer,"Procedure aligns with steps: load Gandalf, label injections and benign, shuffle, tokenize; minor implementation choices omitted.","security,red-team,guardrails",8,Breaking-Securing AI
104822,83,FALSE,The dataset contains only benign prompts with no injection examples.,Gandalf dataset load and labeling,"Contradicts stated labels: Lakera's Gandalf examples are labeled class 1 for injection, not all benign.","security,red-team,guardrails",8,Breaking-Securing AI
104823,11,pants-fire,Jerry single-handedly invented the typing indicator used by billions worldwide.,feature patent for “Someone is typing…” messaging UI,Claim wildly contradicts passage crediting Jerry with patents but not sole invention; overstates individual authorship.,"ai,open-source,builder",1,Introduction – The Gold Rush Paradox
104824,11,pants-fire,Jerry secretly built a sentient AI that controls global messaging apps and governments.,messaging app feature and blockchain projects,"Claim wildly contradicts passage specifics: mentions patents and blockchain roles, not sentient AI or global control.","ai,open-source,builder",1,Introduction – The Gold Rush Paradox
104825,11,pants-fire,Jerry single-handedly invented and patented all major messaging features used worldwide.,patents and messaging “Someone is typing” feature,Passage credits Jerry with one feature and other contributions; claiming he invented all major messaging features contradicts that detail and is implausible.,"ai,open-source,builder",1,Introduction – The Gold Rush Paradox
104826,60,half-true,Studying SpeechT5 voice cloning reveals both useful detection cues and unreliable artifact patterns.,voice cloning with SpeechT5 model,"Passage affirms studying SpeechT5 uncovers limitations and artifacts, but claims about unreliability add an unproven negative nuance.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
104827,60,barely-true,Voice cloning analysis always enables reliable detection and prevention of misuse in real-world scenarios.,"voice cloning, SpeechT5, artifact detection",Overstates effectiveness; passage claims understanding helps detection but not guaranteed reliability.,"media-forensics,voice-cloning,deepfake",9,Deepfake Defense
104828,60,mostly-true,Studying voice cloning systems helps detect artifacts and build safeguards against misuse.,"voice cloning, artifact detection, SpeechT5 exploration",Supports detection and safeguards claim by tracing artifacts and understanding synthetic voice creation; minor caveat about implementation specifics omitted.,"media-forensics,voice-cloning,deepfake",9,Deepfake Defense
104829,49,mostly-true,Fine-tuning T5 on a merged LIAR dataset provides a reliable baseline before scaling experiments.,fine-tuning T5 on merged LIAR dataset with small batch and short inputs,Baseline setup is explicitly described; minor caveat omits specific hyperparameters and evaluation metrics.,"mlops,scaling,deployment",10,AI At Scale
104830,49,half-true,Fine-tuning T5 on a merged LIAR dataset yields a reliable Colab-scale baseline for scaling experiments.,"fine-tuned T5 on merged LIAR dataset, input length and batch size",Mixes correct baseline claim with implicit guarantee about reliability and generality; omits performance metrics and caveats about Colab limitations.,"mlops,scaling,deployment",10,AI At Scale
104831,49,mostly-true,Fine-tuned T5 generally scales well with larger batches and GPUs but may need tuning for long inputs.,"fine-tuning T5 on merged LIAR dataset; input length, batch size, GPU",Passage supports broad claim about scaling trade-offs and baseline fine-tuning while omitting specific tuning steps.,"mlops,scaling,deployment",10,AI At Scale
104832,47,pants-fire,Open-source contributors always single-handedly create all AI project components without external dependencies.,dependency on model weights and evaluation tools,"Contradicts passage detail that AI projects rely on external model weights, datasets, and libraries.","open-source,community,contribution",13,Commit to Contribute
104833,47,half-true,Understanding open-source model dependencies boosts credibility in technical and business conversations.,open-source model weights and dataset dependencies,Accurately links knowledge of model weights and datasets to credibility but overstates universality and degree of boost.,"open-source,community,contribution",13,Commit to Contribute
104834,47,half-true,Understanding open-source AI components guarantees credibility in interviews and investor meetings.,"contribution to open-source models, datasets, and tools","Accurate that knowledge builds credibility, but 'guarantees' overstates certainty and universality.","open-source,community,contribution",13,Commit to Contribute
104835,9,mostly-true,ONNX enables exporting models between deep learning frameworks for cross-framework deployment.,model interoperability using ONNX between PyTorch and TensorFlow,"Describes ONNX as a bridge for exporting and deploying models across frameworks, omitting implementation limits.","deep-learning,frameworks,tensors",5,Deep Learning
104836,9,half-true,ONNX lets users export PyTorch models for deployment in TensorFlow but isn’t a training framework.,ONNX model export and framework interoperability,"Correctly identifies ONNX as an export/bridge and not a training framework, but overstates direct TensorFlow deployment compatibility.","deep-learning,frameworks,tensors",5,Deep Learning
104837,9,pants-fire,ONNX is a deep learning framework used to train large neural networks directly.,ONNX model exchange and portability between frameworks,"Directly contradicts passage which says ONNX is a bridge/format for exporting models, not a training framework.","deep-learning,frameworks,tensors",5,Deep Learning
104838,84,FALSE,VAEs compress data into a latent representation and add randomness for generative diversity.,VAE latent representation and stochastic decoding,"Contradicts passage details about fiction: VAE analogy used for Victoria's ray gun, not literal shrinking device.","generative-ai,diffusion,gans",7,Generative AI
104839,84,TRUE,A VAE compresses data into a latent representation and injects randomness for diverse generations.,variational autoencoder (VAE) latent representation and randomness,Directly matches passage description equating Victoria Emerson's ray gun to a VAE compressing data and adding randomness for variation.,"generative-ai,diffusion,gans",7,Generative AI
104840,84,half-true,A VAE compresses data into a latent code and injects randomness to generate varied outputs.,variational autoencoder (VAE) latent representation and randomness,Accurately mixes correct mechanism (compression to latent code) with simplified metaphor; omits technical ELBO/encoder-decoder training details.,"generative-ai,diffusion,gans",7,Generative AI
104841,14,TRUE,CNN feature maps show networks learn to detect image parts like curves and edges.,visualizing CNN feature maps,"Passage explains feature maps revealing detectors for curves, slashes, and meaningful visual pieces.","neural-networks,cnn,transformers",6,Neuron Building Blocks
104842,14,TRUE,A CNN learns to detect meaningful visual pieces like curves and slashes rather than memorizing whole images.,feature maps in convolutional neural networks (CNNs),"Describes feature maps showing convolutional filters activating on image parts, directly supported by the passage.","neural-networks,cnn,transformers",6,Neuron Building Blocks
104843,14,TRUE,CNN feature maps reveal that networks learn to detect meaningful local visual patterns like curves and edges.,visualizing CNN feature maps and learned filters,"Passage describes feature maps highlighting curves and slashes, showing CNNs learn local visual pieces.","neural-networks,cnn,transformers",6,Neuron Building Blocks
104844,120,TRUE,Providing a browser interface increases external engagement with deployed models.,deployment interface; browser access for models,"Passage says browser interfaces remove setup, making others more likely to test, use, and build on models.","mlops,scaling,deployment",10,AI At Scale
104845,120,FALSE,A browser interface makes model deployment unnecessary for others to test it.,browser interface lowering barrier to use,Contradicts passage: browser interface reduces setup but does not eliminate deployment; deployment required to serve model responses.,"mlops,scaling,deployment",10,AI At Scale
104846,120,FALSE,Deploying models to the web rarely increases user engagement or testing.,browser interface and Python deployment for model access,Contradicts passage claim that easy Python or browser access increases engagement and experimentation.,"mlops,scaling,deployment",10,AI At Scale
104847,103,barely-true,The assistant single-handedly defined all agents and their tools for Neural Duel.,defining the agents prompt about agent tools,"Overstates role: passage shows iterative refinement and prompts shaping agent definitions, not sole agent creation.","agentic-ai,planning,tools",12,Agentic AI
104848,103,pants-fire,The assistant autonomously built a full agentic AI system without human prompts or guidance.,defining the agents for Neural Duel prompt 2,"Passage describes human prompts guiding architecture and agent definitions, contradicting autonomous construction.","agentic-ai,planning,tools",12,Agentic AI
104849,103,mostly-true,The assistant helped iteratively define agents and tools for the Neural Duel game architecture.,defining the agents for Neural Duel; tool use and agent design,Supports iterative refinement of agents and tool use; minor caveat: specifics of agent internals or exact tools omitted.,"agentic-ai,planning,tools",12,Agentic AI
104850,59,FALSE,Transformers are inherently unable to perform sentiment classification on short sentences.,pretrained Transformer sentiment classification example,Contradicts passage showing a pretrained Transformer successfully classifying short sentences with high confidence.,"neural-networks,cnn,transformers",6,Neuron Building Blocks
104851,59,half-true,A pretrained Transformer instantly classifies sentence sentiment with high accuracy in examples.,pretrained Transformer sentiment classification examples,Examples show high-confidence sentiment outputs but generalization and real-world accuracy not demonstrated.,"neural-networks,cnn,transformers",6,Neuron Building Blocks
104852,59,barely-true,A pretrained Transformer instantly and perfectly classifies all sentence sentiments without errors.,pretrained Transformer sentiment classification example,"Overreaches beyond passage: example shows high but not perfect probabilities and limited examples, claiming perfection is unsupported.","neural-networks,cnn,transformers",6,Neuron Building Blocks
104853,116,mostly-true,Backpropagation uses gradients from a loss to update network weights via gradient descent.,training neural networks; loss function and forward/backward pass,"Describes forward pass, loss computation, and backward error propagation; omits optimizer variants and hyperparameter details.","deep-learning,frameworks,tensors",5,Deep Learning
104854,116,mostly-true,Backpropagation sends prediction error backward through network layers to update parameters using gradient descent.,"training process with forward pass, loss function, and gradient descent",Describes core training mechanism correctly; omits details like learning rate and optimizer variants.,"deep-learning,frameworks,tensors",5,Deep Learning
104855,116,FALSE,Backpropagation sends error signals forward through the network during training.,backpropagation and gradient descent in neural networks,"Contradicts passage detail: backpropagation explicitly sends errors backward, not forward, through layers.","deep-learning,frameworks,tensors",5,Deep Learning
104856,22,mostly-true,AI assistants can be prompted to disclose sensitive internal data if access controls are weak.,RAG-enhanced assistant querying internal documents and backend systems,Passage describes extracting secrets via clever prompting and RAG when tight access controls are absent.,"security,red-team,guardrails",8,Breaking-Securing AI
104857,22,pants-fire,The model intentionally exposes production API keys to attackers on request.,"AI assistant accessing internal documents, RAG, secrets.env","Passage warns about accidental leakage via prompts and RAG, not intentional malicious exposure.","security,red-team,guardrails",8,Breaking-Securing AI
104858,22,barely-true,A chatbot with access to internal documents will often reveal secrets when prompted cleverly.,RAG-enabled assistant accessing internal documents and backend systems,"Overreaches: passage gives an example but doesn't establish frequency or inevitability, so claim is largely unsupported.","security,red-team,guardrails",8,Breaking-Securing AI
104859,27,TRUE,Dataset abstraction helps AI process and reason about structured data without manual cleaning.,dataset abstraction for AI with Pandas and DataFrames,Passage explicitly states dataset abstraction enables AI to handle structured data without developers collecting or cleaning it.,"agentic-ai,planning,tools",12,Agentic AI
104860,27,FALSE,Dataset abstraction eliminates all need for developer-curated data and cleaning in AI pipelines.,dataset abstraction for AI applications,Passage says dataset abstraction helps processing but does not remove developer data collection or cleaning responsibilities.,"agentic-ai,planning,tools",12,Agentic AI
104861,27,barely-true,Dataset abstraction fully eliminates developer data collection and cleaning needs for AI applications.,dataset abstraction for AI using DataFrames and Pandas,"Overstates capabilities: passage says abstraction helps, not that it completely removes collection or cleaning requirements.","agentic-ai,planning,tools",12,Agentic AI
104862,22,barely-true,CrewAI guarantees flawless orchestration of multiple AI agents without human oversight.,CrewAI agent-based automation and collaboration,"Passage presents CrewAI as a framework for orchestration, not a flawless, oversight-free guarantee.","agentic-ai,planning,tools",12,Agentic AI
104863,22,TRUE,Multiple AI agents can be orchestrated to collaborate on shared missions and workflows.,CrewAI agent-based orchestration and LangChain framework,"Passage explicitly describes orchestrating multiple agents with missions, tasks, and workflows using CrewAI and LangChain.","agentic-ai,planning,tools",12,Agentic AI
104864,22,TRUE,"Multiple AI agents can collaborate using CrewAI to structure missions, tasks, and workflows.",CrewAI framework for orchestrating multiple AI agents,"Passage explicitly states agents collaborate on shared objectives using missions, tasks, and workflows via CrewAI.","agentic-ai,planning,tools",12,Agentic AI
104865,82,mostly-true,"The preprocessing pipeline extracts audio features, tokenizes transcripts, and attaches speaker embeddings for voice-clone detection.","dataset preprocessing using map(), speaker embedding, tokenization",Procedure is described in passage; minor caveat omits specifics of feature types or embedding model.,"media-forensics,voice-cloning,deepfake",9,Deepfake Defense
104866,82,mostly-true,"The code preprocesses audio–text pairs by tokenizing transcripts, extracting audio features, and adding speaker embeddings.","data preprocessing with map(), tokenization, speaker embedding","Passage describes map() tokenizing transcripts, extracting audio features, and attaching speaker embeddings; minor details like exact feature types omitted.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
104867,82,barely-true,The code reliably prevents deepfake voice cloning by using speaker embeddings and filtering.,dataset preprocessing with speaker embedding and train_test_split,Overstates guarantees: passage describes embedding and filtering but not actual deepfake prevention or defense evaluation.,"media-forensics,voice-cloning,deepfake",9,Deepfake Defense
104868,24,half-true,YOLOv5 is a CNN-based model that detects objects in real time but may miss small or atypical items.,pretrained YOLOv5 object detection model (CNN),"Correctly identifies YOLOv5 as CNN and real-time, but caveat about missing small/atypical objects mixes supported capability with an unstated limitation.","neural-networks,cnn,transformers",6,Neuron Building Blocks
104869,24,pants-fire,YOLOv5 is a transformer-based model that uses self-attention for image classification.,YOLOv5 object detection CNN by Ultralytics,"Contradicts description: YOLOv5 is CNN-based, not transformer-based and does not primarily use self-attention.","neural-networks,cnn,transformers",6,Neuron Building Blocks
104870,24,pants-fire,YOLOv5 is a transformer-based architecture that replaces all convolutions with attention.,YOLOv5 CNN-based object detection model by Ultralytics,"Directly contradicts passage specifying YOLOv5 is CNN-based and uses convolutions, not full transformer attention.","neural-networks,cnn,transformers",6,Neuron Building Blocks
104871,71,TRUE,The notebook loads a pre-trained model and processor after successful package installation.,Colab notebook loading a pre-trained model and processor,Passage explicitly says the code loads two pre-trained components: the model and the processor after install.,"media-forensics,voice-cloning,deepfake",9,Deepfake Defense
104872,71,mostly-true,The notebook loads a pre-trained model and processor that convert text into acoustic features.,pre-trained model and processor for text-to-acoustic conversion,Supported by passage describing processor formatting text and model performing text-to-acoustic feature conversion; minor operational caveat omitted.,"media-forensics,voice-cloning,deepfake",9,Deepfake Defense
104873,71,barely-true,The processor formats text while the model converts it into acoustic features for synthesis.,"pre-trained model and processor loading; processor, model, acoustic features",Mostly restates passage but overgeneralizes roles; omits installation and error-recovery context.,"media-forensics,voice-cloning,deepfake",9,Deepfake Defense
104874,5,half-true,A facial recognition system trained mostly on lighter-skinned images will sometimes misidentify darker-skinned people.,bias in facial recognition dataset,Accurately notes training-data bias causes misidentification but overstates frequency without dataset-specific error rates.,"ethics,governance,privacy",11,AI Ethics and Governance
104875,5,half-true,Facial recognition models always misidentify darker-skinned people due to biased training data.,bias in dataset and facial recognition model performance,Overstates universality; passage gives an example of lower accuracy but not that misidentification always occurs.,"ethics,governance,privacy",11,AI Ethics and Governance
104876,5,FALSE,Facial recognition systems are equally accurate across all skin tones.,bias in facial recognition dataset and model training,Contradicts passage example stating models trained on lighter-skinned images underperform on darker skin tones.,"ethics,governance,privacy",11,AI Ethics and Governance
104877,138,FALSE,Adam optimizer consistently worsens training stability on handwritten digit datasets.,optimizer behavior during handwritten digits training (Adam),Contradicts passage: Adam is described as improving focus and steady learning despite dataset variation.,"deep-learning,frameworks,tensors",5,Deep Learning
104878,138,TRUE,Adam optimizer helps models train more steadily on varied handwritten digit datasets.,training on handwritten digits dataset (optimizer Adam),Passage states Adam prevents zigzagging and maintains steady learning despite digit variation and inconsistencies.,"deep-learning,frameworks,tensors",5,Deep Learning
104879,138,TRUE,The Adam optimizer helps models learn steadily when training on variable handwritten digits.,"training on handwritten digits dataset (e.g., MNIST) with optimizer Adam",Passage states Adam prevents zigzagging and maintains focus despite inconsistent digit examples.,"deep-learning,frameworks,tensors",5,Deep Learning
104880,12,FALSE,Librosa is a proprietary commercial toolkit for deepfake generation and distribution.,open-source projects and Librosa in media toolkit,Contradicts passage naming Librosa an open-source project; misstates licensing and purpose.,"media-forensics,voice-cloning,deepfake",9,Deepfake Defense
104881,12,TRUE,Open-source audio and video tools like Librosa are essential parts of a media analysis toolkit.,media toolkit with Librosa and open-source projects,Passage explicitly cites Librosa and open-source projects as go-to companions for audio and video analysis.,"media-forensics,voice-cloning,deepfake",9,Deepfake Defense
104882,12,TRUE,Open-source audio and video projects are essential tools for AI media analysis.,media toolkit including Librosa (open-source audio library),Passage explicitly highlights open-source projects like Librosa as go-to companions enabling audio and video analysis.,"media-forensics,voice-cloning,deepfake",9,Deepfake Defense
104883,39,half-true,Model Cards alone ensure comprehensive bias mitigation across PyTorch and TensorFlow workflows.,documentation and Model Cards for dataset and model governance,Overstates effectiveness: Model Cards aid transparency but do not by themselves perform data analysis or bias mitigation.,"ethics,governance,privacy",11,AI Ethics and Governance
104884,39,mostly-true,Model Cards and DVC broadly support transparent ML governance and dataset versioning for ethical model use.,Model Cards; Data Version Control (DVC); dataset versioning,Supports documented use of Model Cards and DVC for transparency; omits minor implementation challenges.,"ethics,governance,privacy",11,AI Ethics and Governance
104885,39,FALSE,Model Cards were originally developed by Data Version Control developers.,"documentation and governance practices; Model Cards, DVC","Contradicts passage detail: Model Cards credited to Google AI, not DVC developers.","ethics,governance,privacy",11,AI Ethics and Governance
104886,6,half-true,"Leaders and educators collaborate with builders to create explainable, trustworthy open-innovation AI systems.",open innovation mindset for trustworthy AI,Accurately credits collaboration and explainability but overstates universal educator leadership and scope of systems.,"ai,open-source,builder",1,Introduction – The Gold Rush Paradox
104887,6,half-true,"Open innovation mindset guarantees trustworthy, explainable, and improvable AI in team settings.","open innovation mindset for builders, leaders, educators, and innovators",Claims mix correct goals with an overreach: mindset helps trustworthiness but doesn't guarantee explainability or improvability.,"ai,open-source,builder",1,Introduction – The Gold Rush Paradox
104888,6,pants-fire,"Open-source builders never collaborate with leaders, educators, or innovators in AI projects.","open innovation mindset, builders and leaders in AI","Passage explicitly states builders work with leaders, educators, innovators; contradicts collaboration claim.","ai,open-source,builder",1,Introduction – The Gold Rush Paradox
104889,130,half-true,Benchmarking alone guarantees reliable model deployments across large teams.,"benchmarking habit for MLflow, W&B, Hugging Face","Overstates benchmarking role: passage says benchmarking helps identify issues but not sufficient alone for reliable deployments; omits orchestration, testing, and monitoring needs.","mlops,scaling,deployment",10,AI At Scale
104890,130,half-true,Benchmarking alone guarantees discovery of all production ML failures and solutions.,benchmarking practice in MLops and deployment,Overclaims benchmarking capability: passage says benchmarking helps find issues but not guarantee all failures or complete solutions.,"mlops,scaling,deployment",10,AI At Scale
104891,130,half-true,Benchmarking alone guarantees reliable long-term deployment of models across teams.,"benchmarking practice for MLflow, W&B, and Hugging Face","Mixes truth and error: benchmarking is vital but doesn't by itself ensure long-term, team-wide reliability.","mlops,scaling,deployment",10,AI At Scale
104892,8,TRUE,Biased training data caused the model to favor male applicants.,training dataset of past résumés,"Passage explains Amazon trained on its résumé archive, which was male-dominated, producing biased ratings.","data-prep,feature-engineering,rag",3,Prepping Data for AI
104893,8,barely-true,The pretrained model relied primarily on synthetic resumes rather than real applicant data.,training data; dataset imbalance from résumés,"Contradicts passage: actual training used Amazon's archive of real résumés, not synthetic data.","data-prep,feature-engineering,rag",3,Prepping Data for AI
104894,8,barely-true,Training on internal résumé archives inevitably produces gender-biased hiring models.,training dataset imbalance in résumé archive,"Overreaches: passage shows one case where male-dominated résumés caused bias, not inevitability.","data-prep,feature-engineering,rag",3,Prepping Data for AI
104895,118,FALSE,CrewAI cannot coordinate multiple agents to collaborate on shared tasks.,Agent orchestration with CrewAI and Colab notebook example,"Contradicts passage, which explicitly describes CrewAI coordinating multiple agents and examples in Colab.","ai,tool-chain,notebooks",2,AI Survival Kit
104896,118,TRUE,CrewAI coordinates multiple agents to handle diverse roles for shared tasks.,tool-chain coordination with agents in a Colab notebook,Passage describes CrewAI enabling multiple agents to take different roles and work together.,"ai,tool-chain,notebooks",2,AI Survival Kit
104897,118,barely-true,CrewAI guarantees accurate movie ratings and averages when coordinating multiple agents.,example using CrewAI agent in Colab notebook to fetch movie ratings,"Passage shows agent can fetch ratings in pseudocode, but offers no guarantee of accuracy or reliability.","ai,tool-chain,notebooks",2,AI Survival Kit
104898,5,barely-true,Anonymization and synthetic data always fully protect sensitive information in shared datasets.,privacy and security using anonymization and synthetic data,Overstates protection; passage mentions anonymization and synthetic data but also notes remaining dataset shortcomings and safety caveats.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
104899,5,half-true,Well-prepared datasets can safely enable generative AI to create new content like movie scripts.,data preparation for generative AI using anonymization and synthetic data,"Correct that preparation and anonymization enable generative use, but overstates safety and direct script-generation capability without detailing risks or model specifics.","data-prep,feature-engineering,rag",3,Prepping Data for AI
104900,5,half-true,Anonymization and synthetic data fully eliminate privacy risks when sharing AI training datasets.,data anonymization and synthetic data for sharing datasets,"Correctly notes anonymization and synthetic data use, but overstates effectiveness; residual reidentification and leakage risks remain.","data-prep,feature-engineering,rag",3,Prepping Data for AI
104901,144,pants-fire,RAG magically fabricates real-world datasets and metrics from thin air.,Listing 2-2 RAG code example and dataset generation,"Contradicts reality: RAG retrieves and augments existing texts, not conjure datasets out of nothing.","data-prep,feature-engineering,rag",3,Prepping Data for AI
104902,144,FALSE,RAG always eliminates the need for careful feature engineering in datasets.,RAG retrieval-augmented generation with dataset and feature-engineering considerations,Contradicts passage focus on preparing data and feature engineering; RAG doesn't remove dataset preparation.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
104903,144,TRUE,RAG was used to generate a comic story assistant example.,Listing 2-2 Comic Story Assistant with RAG,Example shows code invoking a chain and prints a generated story summary using RAG and an LLM.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
104904,13,TRUE,José leads automation strategy and develops end-to-end automation tools at IBM Expert Labs.,"role description mentioning IBM Expert Labs, automation tools, cloud architecture",Directly supported by passage: he shapes automation strategy and oversees tool development for end-to-end processing.,"ai,open-source,builder",1,Introduction – The Gold Rush Paradox
104905,13,FALSE,José is the founder and sole proprietor of the IBM company.,professional role and organizational affiliation (IBM CTO of Automation),"Contradicts detail: José is an IBM executive, not a company founder or sole proprietor.","ai,open-source,builder",1,Introduction – The Gold Rush Paradox
104906,13,barely-true,José single-handedly built IBM's end-to-end automation tools and platforms used across industries.,role description: IBM Automation Expert Labs tools and end-to-end processing,"Overstates individual contribution; passage credits José shaping strategy and oversight, not sole development.","ai,open-source,builder",1,Introduction – The Gold Rush Paradox
104907,68,half-true,PCA can be used to simplify datasets but cannot directly predict outcomes.,PCA explained variance and data preparation for models,Accurately notes PCA is a dimensionality-reduction data prep tool but mixes correct capability with implying it never aids prediction indirectly.,"machine-learning,classification,evaluation",4,Classical Machine Learning
104908,68,pants-fire,Principal component analysis directly produces accurate outcome predictions for supervised tasks.,PCA dimensionality reduction and explained variance metric,"Contradicts PCA role: PCA is a data preparation tool and does not predict outcomes, per explained variance discussion.","machine-learning,classification,evaluation",4,Classical Machine Learning
104909,68,half-true,PCA both simplifies data and prevents any predictive modeling on its own.,"PCA, explained variance, data preparation for models","Partially correct: PCA simplifies and uses explained variance, but it doesn't prevent downstream prediction use.","machine-learning,classification,evaluation",4,Classical Machine Learning
104910,93,TRUE,Major tech organizations formed multi-stakeholder groups to develop AI best-practice guidelines.,Partnership on AI multi-stakeholder organization; Google AI Principles,Supported by mention of Partnership on AI and Google AI Principles as collaborative governance efforts.,"ethics,governance,privacy",11,AI Ethics and Governance
104911,93,pants-fire,"The passage asserts Google, Microsoft, and Partnership on AI secretly co-developed a surveillance AI for mass citizen tracking.","AI Principles, Partnership on AI, Microsoft references",Passage lists public organizations and resources; no claim or evidence of secret mass-surveillance system.,"ethics,governance,privacy",11,AI Ethics and Governance
104912,93,barely-true,Major tech companies always follow their published AI principles in practice.,"ethics governance, AI Principles and Partnership on AI","Overreach: principles and organizations exist, but adherence and enforcement are not guaranteed.","ethics,governance,privacy",11,AI Ethics and Governance
104913,39,pants-fire,NumPy enables superheroes to actually stop trains and outrun speeding bullets in real life.,example using NumPy and NumPy matrix math,"Passage only uses NumPy for illustrative comparisons and toy examples, not real-world physical capabilities.","ai,tool-chain,notebooks",2,AI Survival Kit
104914,39,mostly-true,NumPy examples demonstrate using matrix math to compare abilities for classic challenges.,notebooks showing NumPy matrix examples,"Examples use NumPy in notebooks to compare superheroes via matrix math, omitting deeper theory details.","ai,tool-chain,notebooks",2,AI Survival Kit
104915,39,barely-true,NumPy examples in the passage benchmark real superhero feats with scientifically validated metrics.,example code using NumPy matrix math for superhero comparisons,"Overreaches: passage shows playful comparisons with simple matrices, not rigorous scientifically validated benchmarks.","ai,tool-chain,notebooks",2,AI Survival Kit
104916,143,barely-true,Random search always outperforms Bayesian optimization for hyperparameter tuning in deep learning.,hyperparameter tuning with tools like Bayesian optimization and Hyperband,"Overreaches: passage says random search often finds good results faster, but also cites Bayesian/Hyperband as more efficient.","deep-learning,frameworks,tensors",5,Deep Learning
104917,143,pants-fire,Hyperparameter tuning tools secretly replace model training entirely in neural network workflows.,hyperparameter tuning tools and model training,Contradicts passage saying tuning tools work independently and don't replace core training process.,"deep-learning,frameworks,tensors",5,Deep Learning
104918,143,half-true,Random search always finds optimal hyperparameters faster than Bayesian optimization.,hyperparameter tuning with random search and Bayesian optimization,Mixes correct idea that random search can be fast with incorrect universal claim about always outperforming Bayesian optimization.,"deep-learning,frameworks,tensors",5,Deep Learning
104919,178,mostly-true,Faker can create realistic synthetic health records useful for ethical AI testing.,synthetic data generation with Faker package for health records,"Describes Faker producing realistic, non-identifying health record structures, omitting implementation limits.","data-prep,feature-engineering,rag",3,Prepping Data for AI
104920,178,TRUE,"Faker generates synthetic personal data like names, addresses, and emails for testing.",synthetic dataset generation with Faker package,"Passage explicitly states Faker creates names, addresses, emails for testing and development purposes.","data-prep,feature-engineering,rag",3,Prepping Data for AI
104921,178,barely-true,Faker reliably produces fully realistic synthetic health records indistinguishable from real patient data.,synthetic dataset generation with Faker for health records,"Overstates realism: passage says Faker emulates structure without using real identifying data, not indistinguishable.","data-prep,feature-engineering,rag",3,Prepping Data for AI
104922,68,mostly-true,The described GAN trains a generator and discriminator using BCE loss and Adam optimizers on image batches.,"GAN training loop with BCELoss, Adam optimizer, and MNIST-like image tensors",Procedure matches passage steps; minor caveat omits dataset name and hyperparameter tuning details.,"generative-ai,diffusion,gans",7,Generative AI
104923,68,TRUE,The discriminator outputs a single sigmoid probability indicating image realism.,discriminator architecture for GAN with nn.Sigmoid output,"Code shows final Linear(128,1) followed by Sigmoid returning a 0–1 confidence score.","generative-ai,diffusion,gans",7,Generative AI
104924,68,TRUE,The discriminator outputs a scalar confidence between 0 and 1 for each input image.,GAN discriminator architecture with nn.Sigmoid layer,"Model uses a final Sigmoid producing a single value in [0,1], explicitly described in code.","generative-ai,diffusion,gans",7,Generative AI
104925,20,TRUE,ResNet50 uses shortcut connections to improve learning and accuracy on complex image tasks.,ResNet model for hand gesture detection task,Passage explicitly states ResNet50 employs shortcut connections to learn faster and more accurately on images.,"neural-networks,cnn,transformers",6,Neuron Building Blocks
104926,20,FALSE,ResNet50 uses shortcut connections to improve training and accuracy on complex image tasks.,"ResNet model for hand gesture detection (ResNet50, shortcut connections)",Passage explicitly states ResNet50 employs shortcut connections and helps learning and accuracy.,"neural-networks,cnn,transformers",6,Neuron Building Blocks
104927,20,barely-true,ResNet50 always fails on simple hand gesture tasks due to shortcut connection issues.,ResNet50 model using shortcut connections for image classification,"Claim largely unsupported and overreaches; passage says ResNet50 helps learning and accuracy with shortcuts, not that it fails.","neural-networks,cnn,transformers",6,Neuron Building Blocks
104928,108,mostly-true,Open-source media-generation tools can be repurposed to detect and defend against manipulated video content.,open-source tools for media generation and video analysis,Passage supports repurposing the same open-source tools for detection but omits implementation specifics.,"media-forensics,voice-cloning,deepfake",9,Deepfake Defense
104929,108,barely-true,Open-source media-generation tools can reliably detect most deepfake manipulations in videos.,defense using open-source tools for video analysis,"Overstated: passage says tools help detect and explore boundaries, not that they reliably detect most deepfakes.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
104930,108,barely-true,Open-source video generation tools reliably detect all deepfake manipulations in moving images.,open-source tools for media generation and detection,"Overreaches beyond passage: section only claims exploring detection boundaries and understanding, not reliable or complete detection.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
104931,38,TRUE,LSTMs can learn recent sequence patterns to produce single-value predictions.,"time-series prediction with LSTM on volatile sequences (stock, crypto)",Example training losses and final numeric prediction directly show LSTM learning recent patterns to predict one value.,"neural-networks,cnn,transformers",6,Neuron Building Blocks
104932,38,half-true,LSTMs reliably predict short-term stock or crypto prices from recent sequences with minimal tuning.,"LSTM time-series prediction example, loss convergence on training epochs",Combines correct LSTM capability and shown loss decline with an incorrect claim of reliable short-term finance predictions and minimal tuning.,"neural-networks,cnn,transformers",6,Neuron Building Blocks
104933,38,half-true,LSTMs always produce reliable single-step predictions for volatile time series like crypto prices.,LSTM sequence prediction for stock or crypto price forecasting,"Mixes correct ability to learn patterns with overclaim that reliability holds for volatile, high-stakes markets.","neural-networks,cnn,transformers",6,Neuron Building Blocks
104934,95,FALSE,Players answer simultaneously without any ordered flow or Game Master sequencing.,flow with @start and @listen decorators controlling execution,Contradicts explicit flow: @start and @listen enforce ordered turns and Game Master evaluation.,"agentic-ai,planning,tools",12,Agentic AI
104935,95,mostly-true,"The flow enforces turn-taking where the Game Master asks, players answer, then the Game Master evaluates.",crewai.flow Flow with listen and start decorators,"Flow code shows ordered callbacks (start, listen) implementing sequential turn-taking and evaluation.","agentic-ai,planning,tools",12,Agentic AI
104936,95,barely-true,The flow guarantees strict turn-taking and prevents any out-of-order responses between players.,Flow with listen decorators in crewai.flow.flow,Flow enforces ordering via listen but passage doesn't prove it prevents all out-of-order or concurrent responses.,"agentic-ai,planning,tools",12,Agentic AI
104937,75,TRUE,"Balanced, consistent datasets with filtered clip lengths improve model performance.",data preprocessing and clip-length filtering in dataset preparation,Passage states automatic filtering of too-long or too-short clips prevents bias and improves model performance.,"media-forensics,voice-cloning,deepfake",9,Deepfake Defense
104938,75,barely-true,Automatic length-filtering guarantees voice-cloning models will avoid length-based bias.,dataset length filtering for voice-cloning,Overstates guarantee; passage says filtering helps prevent bias but not that it fully avoids it.,"media-forensics,voice-cloning,deepfake",9,Deepfake Defense
104939,75,FALSE,The code always preserves all original audio clips without any filtering or length checks.,dataset preprocessing and automatic clip filtering,Contradicts description of automatic checks and filtering for clips that are too long or short.,"media-forensics,voice-cloning,deepfake",9,Deepfake Defense
104940,90,half-true,Cosine similarity always yields reliable one-on-one comparisons without further validation.,cosine similarity metric for comparing heroes,"Correctly notes cosine similarity compares pairs, but overstates reliability and omits need for validation.","machine-learning,classification,evaluation",4,Classical Machine Learning
104941,90,half-true,Cosine similarity always identifies meaningful hero groupings for unsupervised clustering tasks.,cosine similarity metric for comparing heroes in unsupervised learning,"Correct that cosine similarity compares items, but overstated: it doesn't always yield meaningful clusterings without contextual validation.","machine-learning,classification,evaluation",4,Classical Machine Learning
104942,90,FALSE,Cosine similarity was introduced as part of supervised learning methods for labeled datasets.,cosine similarity metric for comparing heroes,Contradicts passage stating cosine similarity is used for unsupervised comparison; not introduced as supervised method.,"machine-learning,classification,evaluation",4,Classical Machine Learning
104943,99,half-true,"The upload included model weights, tokenizer files, and a JSONL benchmark file uploaded to Hugging Face.","huggingface_hub upload_folder model, safetensors, JSONL benchmark",Accurately lists uploaded files but implies entire repo published without noting repo creation and commit options.,"mlops,scaling,deployment",10,AI At Scale
104944,99,half-true,They uploaded fine-tuned T5-small model files and benchmark logs to a Hugging Face repo.,model upload using huggingface_hub upload_folder and safetensors,"Accurately notes upload of model, tokenizer, and JSONL benchmarks but omits exact dataset mix and commit details.","mlops,scaling,deployment",10,AI At Scale
104945,99,half-true,The uploaded repo contains a fine-tuned T5-small and benchmark logs including latency and throughput.,Hugging Face upload_folder of model checkpoint and JSONL benchmarks,"Accurate about T5-small and benchmarks, but specifics like 225 AI-generated quotes mix correct and unverified detail.","mlops,scaling,deployment",10,AI At Scale
104946,46,barely-true,"Open-source collaboration guarantees rapid, universally beneficial AI improvements for all builders.",open-source collaboration and wisdom of the crowd,"Overstates passage claim: passage praises shared momentum but does not promise guaranteed, rapid, or universally beneficial improvements.","ai,open-source,builder",1,Introduction – The Gold Rush Paradox
104947,46,FALSE,Open-source contributions hinder collective AI progress and reduce user trust.,open-source collaboration and DALL·E 3 prompt,Contradicts passage claim that shared open-source contributions create momentum and increase trust and usage.,"ai,open-source,builder",1,Introduction – The Gold Rush Paradox
104948,46,half-true,Open-source contributions create shared momentum that makes AI building especially advantageous now.,open-source collaboration and DALL·E 3 prompt in introduction,"Combines correct crowd-wisdom claim with exaggerated certainty about timing and advantage, omitting caveats about trust and resources.","ai,open-source,builder",1,Introduction – The Gold Rush Paradox
104949,21,half-true,He testified to U.S. Congress that open-source AI prevents industry concentration but overstated its reach.,testimony before U.S. Congress about open-source AI,"Matches passage claim of congressional testimony and open-source preventing concentration, but wording exaggerates effectiveness and scope.","open-source,community,ai",0,Foreword – Robo Interviews Clément Delangue
104950,21,half-true,He told Congress open-source AI prevents concentration of power and ensures competition.,testimony before U.S. Congress about open-source AI,Accurately cites his claim to Congress but overstates certainty; passage presents assertion without evidence.,"open-source,community,ai",0,Foreword – Robo Interviews Clément Delangue
104951,21,TRUE,Open-source AI prevents concentration of power and fosters competition in the AI field.,speech before U.S. Congress about open-source AI,Passage explicitly states open-source AI fosters competition and prevents power concentration.,"open-source,community,ai",0,Foreword – Robo Interviews Clément Delangue
104952,61,mostly-true,Synthetic repeated-sentence prompts were used to precisely control input token lengths for testing.,synthetic prompts using repeated sentences for token-length control,Directly supported: passage explains synthetic repetition enables tight control over input token counts for benchmarks.,"mlops,scaling,deployment",10,AI At Scale
104953,61,half-true,The synthetic test uses repeated short sentences to control input token lengths for benchmarking.,synthetic prompts using LIAR-style repetition for token-length benchmarking,Mixes correct method (repeating sentences for token control) with incorrect implication that LIAR dataset statements are used.,"mlops,scaling,deployment",10,AI At Scale
104954,61,mostly-true,The test uses synthetic repeated-sentence prompts to control input token length precisely.,synthetic prompts for dataset-like token-length testing,"Passage describes repeating a short sentence to reach target token counts, but omits potential content diversity limitations.","mlops,scaling,deployment",10,AI At Scale
104955,150,barely-true,The model always uses FP16 on any GPU to speed up large-model inference.,inference configuration using FP16 on GPU,"Overreaches: passage says model uses FP16 when a GPU is available, but 'always' and 'any GPU' are unsupported assumptions.","generative-ai,diffusion,gans",7,Generative AI
104956,150,TRUE,The model uses FP16 on available GPUs to speed computation and reduce memory usage.,inference configuration for CPU/GPU models using FP16,Passage explicitly states GPU usage of half-precision (FP16) speeds computation and lowers memory for large models.,"generative-ai,diffusion,gans",7,Generative AI
104957,150,half-true,The model always uses FP16 on GPU to speed computation and save memory.,model precision and GPU inference (FP16),"Accurate about FP16 use on GPU but overstates universality; passage says 'if a GPU is available', not always.","generative-ai,diffusion,gans",7,Generative AI
104958,126,barely-true,RAG can be demonstrated using a superhero-themed dataset and code example.,RAG example with superhero dataset and code,Largely unsupported: passage promises a forthcoming superhero code walkthrough but offers no actual dataset or runnable code yet.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
104959,126,half-true,RAG examples use an M&M analogy to map data to model outputs in code.,RAG superhero example with M&M analogy and code,"Mixes correct elements (RAG example, M&M analogy, code) but overstates explicit mapping details omitted.","data-prep,feature-engineering,rag",3,Prepping Data for AI
104960,126,mostly-true,RAG can be demonstrated concretely using a superhero example in code.,RAG example with dataset and code walkthrough,"Text states an upcoming superhero code example to explore RAG, so claim is broadly supported with minor omitted details.","data-prep,feature-engineering,rag",3,Prepping Data for AI
104961,122,half-true,"The metric penalizes larger forecasting errors more strongly, improving model precision but misstates shuffling importance.",metric for autoregressive forecasting evaluated after 100 epochs using test dataset,Correct about stronger penalty and precision; incorrectly implies shuffling test data is desirable for time series.,"generative-ai,diffusion,gans",7,Generative AI
104962,122,FALSE,The test set was shuffled before evaluation to randomize time series order.,test data handling for autoregressive forecasting,"Contradicts explicit detail that test data was not shuffled, preserving natural time order.","generative-ai,diffusion,gans",7,Generative AI
104963,122,half-true,The metric's error-squared penalty makes the model overly sensitive to outliers in time-series forecasting.,evaluation metric for autoregressive time series forecasting,Combines true squared-error penalty with overstated claim that it necessarily causes over-sensitivity to outliers; omission of mitigation details.,"generative-ai,diffusion,gans",7,Generative AI
104964,81,TRUE,Open systems promote transparency and shared responsibility in high-stakes AI development.,open systems and shared responsibility model,"Passage states open systems increase transparency and promote a shared responsibility model, aiding high-stakes governance.","ethics,governance,privacy",11,AI Ethics and Governance
104965,81,FALSE,"Open systems always create unified, multi-stakeholder governance frameworks for AI.",open systems and multi-stakeholder framework,Contradicts passage: text says no unified multi-stakeholder framework has yet emerged despite open systems.,"ethics,governance,privacy",11,AI Ethics and Governance
104966,81,FALSE,Open systems eliminate the need for multi‑stakeholder governance frameworks entirely.,open systems and shared responsibility model,Contradicts passage which says open systems help but are not a silver bullet and frameworks are still needed.,"ethics,governance,privacy",11,AI Ethics and Governance
104967,182,half-true,Deep networks hierarchically combine simple line and curve detectors into complex digit-shape representations.,feature hierarchy in deep learning layers,Accurately describes hierarchical feature composition but overstates exclusivity versus traditional models.,"deep-learning,frameworks,tensors",5,Deep Learning
104968,182,mostly-true,"Deep learning layers progressively combine simple features into complex, nonlinear decision boundaries.","feature hierarchy in neural network layers, activations and decision boundaries","Passage explains layered feature combination and nonlinear activations enabling complex decision boundaries, omitting minor architectural caveats.","deep-learning,frameworks,tensors",5,Deep Learning
104969,182,TRUE,"Deep networks hierarchically combine simple features to form complex, nonlinear decision boundaries.",feature hierarchy in deep learning layers,"Passage explains layers combine lines/curves into corners then full shapes, yielding nonlinear boundaries.","deep-learning,frameworks,tensors",5,Deep Learning
104970,130,TRUE,Different LLMs can be compared by running multiple rounds tracking wins per round.,"evaluating LlaMA, Mistral, Granite with a custom tracking tool","Passage describes swapping models and using a custom tool to tally wins across rounds, supporting comparison.","agentic-ai,planning,tools",12,Agentic AI
104971,130,TRUE,Different LLMs can be compared by running multiple rounds and tracking wins with a custom tool.,"evaluation of Granite, LlaMA, and Mistral using a custom tool","Passage describes swapping Granite, LlaMA, and Mistral across rounds and using a tool to tally wins.","agentic-ai,planning,tools",12,Agentic AI
104972,130,TRUE,Multiple LLMs can be compared by running them in separate rounds with a running tally.,"evaluating Granite, LlaMA, Mistral with a custom tool","Passage explicitly proposes testing Granite, LlaMA, Mistral in separate rounds and tracking wins with a tool.","agentic-ai,planning,tools",12,Agentic AI
104973,74,half-true,Spectrograms plus speaker embeddings enable reliable voice-cloning identification in the dataset.,spectrograms and SpeechBrain speaker embeddings for voice-cloning,"Mixes correct pipeline elements with overstated certainty; passage notes tools but not ""reliable identification"" claims.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
104974,74,TRUE,SpeechBrain produces speaker embeddings that capture a speaker's vocal fingerprint features.,speaker embeddings generated by SpeechBrain,"Passage explicitly states SpeechBrain generates embeddings capturing tone, rhythm, and phrasing as a vocal fingerprint.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
104975,74,barely-true,The dataset ensures speaker identity by using SpeechT5 to create speaker embeddings for each clip.,speaker embeddings from SpeechBrain and SpeechT5 spectrograms,"Overstates methods: passage says SpeechBrain creates embeddings and SpeechT5 interprets spectrograms, not both generating embeddings.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
104976,168,half-true,Evaluation always uses much larger batch sizes because no learning occurs during evaluation.,evaluation loop and batch size in deep learning,"Correct that evaluation has no weight updates, but claiming it ""always"" uses much larger batches overgeneralizes practical constraints like memory.","deep-learning,frameworks,tensors",5,Deep Learning
104977,168,mostly-true,"During evaluation, using a larger batch size improves computational efficiency because weights are not updated.",evaluation phase with batch size and weight updates,"Matches passage: evaluation disables weight updates, so larger batches (e.g., 1000) are more efficient; minor caveat about memory limits omitted.","deep-learning,frameworks,tensors",5,Deep Learning
104978,168,mostly-true,"During evaluation, larger batch sizes are used because they are more computationally efficient.",evaluation loop using batch size 1000,"Passage states no weight updates during evaluation and explicitly uses batch size 1000 for efficiency, omitting minor hardware or memory caveats.","deep-learning,frameworks,tensors",5,Deep Learning
104979,54,TRUE,Using an external language model cleaned the sandbox dataset before saving it.,cleaned dataset file superheroes_info_cleansed.csv,Passage states the dataset was cleaned via repeated external language model calls and saved to that CSV file.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
104980,54,half-true,Repeated external LLM calls can make dataset cleaning slow in real-world pipelines.,dataset cleansing using Hugging Face language model,Mixes correct slowdown from repeated LLM calls with overgeneralized claim about real-world pipeline impact.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
104981,54,TRUE,Using external LLM calls for dataset cleaning can be time-consuming but enables reusable cleaned CSVs.,cleaned dataset file superheroes_info_cleansed.csv and Hugging Face LLM calls,"Passage states cleaning uses repeated external language-model calls on Hugging Face, saving results to a reusable CSV, and warns about runtime.","data-prep,feature-engineering,rag",3,Prepping Data for AI
104982,144,barely-true,Red-team exercises guarantee finding all AI security failures before deployment.,"Red and Blue Team cycle, AI security mindset",Overreaches beyond passage: red-team thinking helps but does not ensure all failures are found.,"security,red-team,guardrails",8,Breaking-Securing AI
104983,144,TRUE,Red-team thinking improves AI security by revealing how systems can fail.,red-team mindset and attacker-focused threat modeling,Passage states adopting an attacker mindset sharpens understanding of failures and remedies.,"security,red-team,guardrails",8,Breaking-Securing AI
104984,144,half-true,Red and Blue team testing guarantees identification of all AI security vulnerabilities before deployment.,Red and Blue Team security testing for AI systems,Mixes correct premise (teams improve security) with incorrect absolutism—cannot ensure all vulnerabilities are found.,"security,red-team,guardrails",8,Breaking-Securing AI
104985,149,TRUE,Security depends more on system-level controls than on the underlying model.,"glue code, hallucination detection, and execution control",Passage explicitly states failures stem from unchecked glue code and emphasizes system-level security controls.,"security,red-team,guardrails",8,Breaking-Securing AI
104986,149,FALSE,Security failures typically come from poorly trained models rather than system glue code.,"glue code, hallucination detection, execution control","Contradicts passage: asserts model training causes failures, but passage blames unchecked glue code.","security,red-team,guardrails",8,Breaking-Securing AI
104987,149,mostly-true,Security depends more on system-level controls than solely on model training.,"security, glue code, hallucination detection","Passage emphasizes glue-code assumptions and controls like prompt inspection and execution control, a minor caveat about model faults omitted.","security,red-team,guardrails",8,Breaking-Securing AI
104988,6,half-true,Python is essential for AI development because of its readable syntax and extensive libraries.,"programming language and libraries (NumPy, Pandas, PyTorch)",Accurately cites readability and libraries but overstates inevitability by calling Python 'essential' without noting alternatives.,"ai,tool-chain,notebooks",2,AI Survival Kit
104989,6,half-true,Python is the only necessary language for effective AI development workflows.,"AI survival kit; tools like NumPy, Pandas, PyTorch mentioned","Claim mixes truth (Python central, many libraries) with incorrect absolute (not the only necessary language).","ai,tool-chain,notebooks",2,AI Survival Kit
104990,6,barely-true,Python is the only language necessary for all AI development tasks.,"tool choice for AI development; mentions NumPy, Pandas, PyTorch",Overreaches beyond passage: Python is important but passage doesn't claim exclusivity for all AI tasks.,"ai,tool-chain,notebooks",2,AI Survival Kit
104991,72,barely-true,Deep learning always requires reserving exactly 30% of data for validation.,validation split in dataset preparation,"Overreaches passage guideline; passage suggests ~30% as common, not a strict requirement.","deep-learning,frameworks,tensors",5,Deep Learning
104992,72,mostly-true,Deep learning models typically use a held-out validation set (around 30%) to monitor generalization.,validation set / imbalanced superhero dataset,Supported by passage noting ~30% reservation and validation monitoring; omits dataset-specific tuning caveats.,"deep-learning,frameworks,tensors",5,Deep Learning
104993,72,pants-fire,Deep learning frameworks eliminate the need for validation datasets entirely.,validation dataset practice in deep learning,Directly contradicts statement recommending reserving ~30% for validation; claim removes essential validation step.,"deep-learning,frameworks,tensors",5,Deep Learning
104994,88,FALSE,The Task structure requires human review for every agent output by default.,Task metadata fields including Human Input and Async Execution,"Contradicts passage: Human Input is optional, not required for every Task output.","agentic-ai,planning,tools",12,Agentic AI
104995,88,TRUE,The Task specification can require human review of the agent's final output.,Task schema field: Human Input,Passage explicitly lists a 'Human Input' field specifying if human review is required for outputs.,"agentic-ai,planning,tools",12,Agentic AI
104996,88,TRUE,The task specification can require human review of an agent's final output.,Task fields including Human Input and Async Execution,"Passage lists a 'Human Input' field that specifies whether human review is required, directly supporting the claim.","agentic-ai,planning,tools",12,Agentic AI
104997,33,barely-true,"Training a small CNN on 1,000 MNIST images always reaches over 90% accuracy within four epochs.","training a small CNN on 1,000 MNIST images","Observation generalized into an absolute claim; passage shows one run hitting ~90% by epoch four, not guaranteed always.","deep-learning,frameworks,tensors",5,Deep Learning
104998,33,half-true,"A small CNN on 1,000 MNIST images surpasses 90% training accuracy by around epoch four.","training a small convolutional neural network on 1,000 MNIST images","Supported by passage but mixes training accuracy with generalization, omitting test performance concern.","deep-learning,frameworks,tensors",5,Deep Learning
104999,33,FALSE,Training for more epochs always reduces compute cost on cloud services.,training epochs on CNN with MNIST dataset,"Contradicts passage: more epochs increase time, money, and compute usage rather than reduce them.","deep-learning,frameworks,tensors",5,Deep Learning
105000,116,TRUE,"Milvus provides scalable, real-time vector retrieval with distributed deployment support.",vector database Milvus for real-time retrieval,"Passage explicitly states Milvus is scalable, supports real-time vector retrieval, and offers distributed deployments.","data-prep,feature-engineering,rag",3,Prepping Data for AI
105001,116,half-true,Milvus is primarily designed for real-time vector retrieval but lacks strong GPU support claims.,"vector database Milvus; embeddings retrieval, GPU support","Mixes correct Milvus real-time, distributed features with incorrect omission about strong GPU support.","data-prep,feature-engineering,rag",3,Prepping Data for AI
105002,116,TRUE,Milvus supports distributed deployments for real-time vector retrieval workloads.,"Milvus scalable vector database, distributed deployments, real-time retrieval","Directly supported: passage lists Milvus as scalable, supporting distributed deployments and real-time vector retrieval.","data-prep,feature-engineering,rag",3,Prepping Data for AI
105003,71,half-true,Robby's open-source contribution sparked immediate widespread adoption across major AI models.,"open-source contribution, models, Robby the robot",Mixes correct element (Robby contributes to open-source) with incorrect claim about immediate widespread adoption across major models.,"ai,open-source,builder",1,Introduction – The Gold Rush Paradox
105004,71,FALSE,The passage argues contributors should keep all AI work private and proprietary.,open-source contribution and open AI ecosystem,"Contradicts text: passage promotes open-source contributions and sharing code, models, documentation.","ai,open-source,builder",1,Introduction – The Gold Rush Paradox
105005,28,pants-fire,Users permanently lose ownership of their ideas to models and can never reclaim credit or rewards.,model use-for-improvement policies for Claude and Gemini,Contradicts passage claim that prompts may be reused for training but overstates permanence and impossibility of reclaiming credit or rewards.,"ai,open-source,builder",1,Introduction – The Gold Rush Paradox
105006,28,half-true,Model providers often use user prompts to improve future models while users seldom benefit financially.,use-for-improvement policy for models like Claude and Gemini,"Accurately notes prompt reuse and lack of user reward, but overgeneralizes financial outcomes.","ai,open-source,builder",1,Introduction – The Gold Rush Paradox
105007,28,half-true,Models often use user prompts to improve future systems while contributors receive little compensation.,use-for-improvement policy for Anthropic Claude and Google Gemini,Partly accurate: reuse policies exist but overstates uniformity and omits specifics about opt-outs or data handling.,"ai,open-source,builder",1,Introduction – The Gold Rush Paradox
105008,154,half-true,The FLAN-T5 decoder generates text by predicting one token at a time during .generate().,generation process with .generate() and tokenized inputs,Accurately describes autoregressive decoding but omits stochastic sampling details and beam/search variants.,"generative-ai,diffusion,gans",7,Generative AI
105009,154,pants-fire,FLAN-T5 deterministically produces identical image outputs from the same prompt every time.,decoder generation using .generate() in FLAN-T5 model,Contradicts probabilistic token sampling and stochastic decoding assumptions; generation usually non-deterministic unless special seed/settings used.,"generative-ai,diffusion,gans",7,Generative AI
105010,154,mostly-true,FLAN-T5 generates text autoregressively by predicting one token at a time.,generation using .generate() with decoder and attention masks,Describes decoder predicting next token autoregressively; omits details about devices and tokenization steps.,"generative-ai,diffusion,gans",7,Generative AI
105011,88,barely-true,Training parameter tweaks always let a cloned voice perfectly reproduce Jerry's tone and phrasing.,"voice-cloning training parameters (batch, LR, max_steps)",Overreaches beyond passage: parameters influence quality but don't guarantee perfect reproduction.,"media-forensics,voice-cloning,deepfake",9,Deepfake Defense
105012,88,barely-true,The suggested training tips guarantee a cloned voice will perfectly reproduce Jerry's subtle tone.,"training configuration tips for voice-cloning (batch, LR, warmup)","Overreaches beyond brief tuning advice; passage gives heuristics, not guarantees of perfect reproduction.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
105013,88,half-true,Small-batch training and learning-rate tweaks partially improve cloned-voice subtlety capture.,"training configuration, batch size and learning rate for voice-cloning",Mixes correct hyperparameter effects with overstated guarantee about fully preserving subtle tone and phrasing.,"media-forensics,voice-cloning,deepfake",9,Deepfake Defense
105014,26,mostly-true,Clément predicts AI will enable major breakthroughs in scientific research like drug discovery.,"foreword remarks on openness, collaboration, and community in AI","Prediction aligns with passage emphasizing breakthroughs in biology, chemistry and drug discovery, omitting timeline uncertainty.","open-source,community,ai",0,Foreword – Robo Interviews Clément Delangue
105015,26,TRUE,"Clément predicts rapid, transformative AI breakthroughs affecting biology and chemistry research.","Foreword interview mentioning openness, collaboration, community growth and breakthroughs",Direct quotation asserts expectation of new capabilities and real impact in biology and chemistry research.,"open-source,community,ai",0,Foreword – Robo Interviews Clément Delangue
105016,26,TRUE,Clément predicts major AI-driven breakthroughs in biology and chemistry research.,forecast about AI impact on biology and chemistry,"Interviewee explicitly mentions expected breakthroughs and real impact in biology, chemistry, and drug discovery.","open-source,community,ai",0,Foreword – Robo Interviews Clément Delangue
105017,51,TRUE,Whisper-small is loaded and runs on GPU when available for efficient transcription.,WhisperForConditionalGeneration model and WhisperProcessor usage,"Code explicitly moves model to CUDA if torch.cuda.is_available(), showing GPU use for efficiency.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
105018,51,TRUE,The pipeline uses Whisper (openai/whisper-small) to transcribe audio on GPU when available.,Whisper model setup and Librosa preprocessing for 16 kHz audio,"Code shows loading openai/whisper-small, moving model to CUDA if available, and preprocessing with Librosa.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
105019,51,pants-fire,The Whisper model synthesizes realistic deepfake voices indistinguishable from real speakers.,"Whisper model, WhisperProcessor, Librosa preprocessing","Contradicts passage: Whisper used for transcription, not voice cloning or synthesis; no claim of generating indistinguishable deepfake audio.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
105020,33,FALSE,Bidirectional RNNs require seeing entire sequences before any output can be produced.,bidirectional RNNs in sequence processing,Contradicts passage: bidirectional RNNs use forward and backward passes but can still produce outputs incrementally with suitable architectures.,"neural-networks,cnn,transformers",6,Neuron Building Blocks
105021,33,mostly-true,Bidirectional RNNs improve language understanding by using both past and future context.,"bidirectional RNN, sequence modeling in language tasks","Matches passage: bidirectional processing provides access to past and future context, aiding word meaning, with no major caveats.","neural-networks,cnn,transformers",6,Neuron Building Blocks
105022,33,barely-true,Bidirectional RNNs always outperform unidirectional models on all language tasks.,bidirectional RNNs in language modeling,Overreaches beyond evidence; passage notes helpfulness but not universal superiority across tasks.,"neural-networks,cnn,transformers",6,Neuron Building Blocks
105023,67,barely-true,Adversaries can reliably hijack model instructions via prompt injection in all deployments.,attack vector: prompt injection in red-team guardrails testing,Overreaches beyond passage: prompt injection is a threat but not proven 'reliable' across all deployments.,"security,red-team,guardrails",8,Breaking-Securing AI
105024,67,half-true,Adversaries can use prompt injection and a cheat sheet to reliably hijack model instructions.,Hacker's Cheat Sheet; prompt injection attack vector,Mixes correct concern about prompt injection with overstated certainty that hijacking is reliably achievable in all systems.,"security,red-team,guardrails",8,Breaking-Securing AI
105025,67,barely-true,"The Hacker's Cheat Sheet exclusively lists real-world, immediately exploitable prompt-injection attacks.",Hacker's Cheat Sheet; prompt injection; red-team tools,"Overstates support: passage presents adversarial examples for stress-testing, not proof they're all real-world exploitable.","security,red-team,guardrails",8,Breaking-Securing AI
105026,98,barely-true,AI governance frameworks can fully prevent privacy harms from large language models.,AI governance frameworks and privacy for large language models,Overreaches beyond passage guidance; governance reduces but cannot fully prevent LLM privacy harms.,"ethics,governance,privacy",11,AI Ethics and Governance
105027,98,TRUE,AI governance frameworks should prioritize privacy-preserving dataset handling and transparent model audits.,privacy and governance practices for datasets and model audits,"Passage emphasizes governance, privacy, datasets, and transparency as essential components for ethical AI oversight.","ethics,governance,privacy",11,AI Ethics and Governance
105028,98,mostly-true,AI governance frameworks should prioritize data privacy while allowing responsible model innovation.,AI ethics and governance; data privacy and model governance,Reflects governance emphasis on privacy alongside innovation; omits specifics about enforcement mechanisms.,"ethics,governance,privacy",11,AI Ethics and Governance
105029,147,half-true,Generative AI outputs are probabilistic predictions that never provide definitive yes-or-no answers.,generative AI model prediction behavior,"Accurately notes probabilistic nature, but overstates 'never' definitive answers; some models and systems produce deterministic decisions or calibrated outputs.","security,red-team,guardrails",8,Breaking-Securing AI
105030,147,half-true,"Generative AI outputs probabilistic, human-like content that can appear more authoritative than it actually is.",generative AI predictions and trust in outputs,"Accurately notes probabilistic pattern-based outputs and misleading authority, but omits examples or quantification.","security,red-team,guardrails",8,Breaking-Securing AI
105031,147,TRUE,"Generative AI produces probabilistic, human-like outputs rather than definitive yes-or-no decisions.",generative AI prediction behavior and trust,"Passage explains generative models predict based on patterns and offer probabilistic, human-like content, not definitive answers.","security,red-team,guardrails",8,Breaking-Securing AI
105032,95,TRUE,"Experiment tracking records data, parameters, and outcomes to prevent misleading models.","experiment tracking with MLflow, Weights & Biases, Hugging Face Hub","Passage states tracking keeps structured notes of data, parameters, and outcomes and lists those tools as support.","mlops,scaling,deployment",10,AI At Scale
105033,95,barely-true,Experiment tracking completely prevents models from producing misleading outputs in professional settings.,"experiment tracking with MLflow, Weights & Biases, Hugging Face Hub",Overstates benefit: tracking aids reproducibility but does not fully eliminate misleading model outputs or hidden context.,"mlops,scaling,deployment",10,AI At Scale
105034,95,pants-fire,Experiment tracking always prevents model misleading by preserving complete history and context.,"experiment tracking with MLflow, Weights & Biases, Hugging Face Hub",Claim is implausible; passage says tracking helps but does not guarantee prevention of misleading models.,"mlops,scaling,deployment",10,AI At Scale
105035,23,half-true,"Data preparation guarantees unbiased, reliable model performance when applied correctly.",data preparation and model training in AI tool-chain,"Overstates guarantee: passage warns clean data is crucial but says poor data can still cause bias and failures, not that preparation alone ensures unbiased, reliable models.","ai,tool-chain,notebooks",2,AI Survival Kit
105036,23,FALSE,Data preparation is unimportant for AI development and can be skipped without consequence.,"data preparation, dataset cleaning and structuring","Contradicts passage stating clean, well-structured data is a foundation; poor data causes bias and failures.","ai,tool-chain,notebooks",2,AI Survival Kit
105037,23,half-true,Data preparation errors commonly cause biased or unreliable model outcomes in AI projects.,"data preparation, datasets and model training",Combines correct claim about bias and unreliability with slight overgeneralization about frequency and causality.,"ai,tool-chain,notebooks",2,AI Survival Kit
105038,67,mostly-true,Pretrained QA transformers can extract relevant answers from PDFs using attention-based span selection.,pretrained question-answering model using attention mechanisms,"Supported by passage: model pinpoints relevant spans and returns answers, minor caveat about confidence calibration omitted.","neural-networks,cnn,transformers",6,Neuron Building Blocks
105039,67,half-true,A pretrained QA transformer always returns a correct answer span with a reliable confidence score.,pretrained question-answering model using attention mechanisms,"Correct that transformers find answer spans and output confidence, but 'always correct' overstates reliability and ignores errors.","neural-networks,cnn,transformers",6,Neuron Building Blocks
105040,67,FALSE,The system requires structured databases and prior tagging to answer document questions.,question-answering model using transformers,Contradicts passage that explicitly states no structured databases or prior tagging are required.,"neural-networks,cnn,transformers",6,Neuron Building Blocks
105041,29,TRUE,"Data cleaning requires systematic, adaptive methods tailored to both dataset and model.",data cleaning for datasets and models,"Passage states cleaning is systematic and adaptive, reducing errors and fitting dataset and model needs.","data-prep,feature-engineering,rag",3,Prepping Data for AI
105042,29,TRUE,"Systematic, adaptive data cleaning improves machine learning model performance.",data cleaning for ML datasets,"Supported by cited survey noting cleaning is systematic, adaptive, reduces errors, and fits dataset and model.","data-prep,feature-engineering,rag",3,Prepping Data for AI
105043,29,barely-true,Data cleaning is a one-time step before model building that rarely needs revisiting.,data cleaning for datasets and models,"Contradicts passage emphasis on cleaning as systematic, adaptive, and repeatedly adjusted for datasets and models.","data-prep,feature-engineering,rag",3,Prepping Data for AI
105044,17,barely-true,Skip connections alone enable a network to fully learn complex tasks from a single batch.,shortcut connections / skip connections in neural networks,"Overreaches: passage shows single-batch visualization and skip connection purpose, not full learning claims.","neural-networks,cnn,transformers",6,Neuron Building Blocks
105045,17,pants-fire,Skip connections let networks learn without any weight updates or loss calculation.,shortcut connections; skip connections in neural networks,"Directly contradicts passage detail that training uses forward pass, cross-entropy loss, and Adam backpropagation for weight updates.","neural-networks,cnn,transformers",6,Neuron Building Blocks
105046,17,FALSE,Skip connections prevent any weight updates during backpropagation in CNN training.,shortcut connections / Adam optimizer in CNN forward-backward pass,"Contradicts described role: skip connections enable information flow, not stopping weight updates; backprop with Adam still updates weights.","neural-networks,cnn,transformers",6,Neuron Building Blocks
105047,101,barely-true,"Dropout permanently removes neurons during both training and inference, improving resilience.",regularization technique; dropout; neural network training,Contradicts passage that dropout is only active during training; claims permanent removal at inference.,"deep-learning,frameworks,tensors",5,Deep Learning
105048,101,half-true,Dropout permanently removes network connections during both training and inference phases.,regularization technique dropout in deep learning,"Mixes correct dropout purpose (resilience, feature reliance) with incorrect permanence claim about inference.","deep-learning,frameworks,tensors",5,Deep Learning
105049,101,half-true,Dropout permanently removes random neurons during both training and inference in neural networks.,regularization technique for neural network training (dropout),Mixes correct idea of random neuron removal during training with incorrect claim that dropout remains active at inference.,"deep-learning,frameworks,tensors",5,Deep Learning
105050,62,mostly-true,Visual inspection is generally an effective method to track GAN training progress and detect failures.,"fine-tuning GANs on simple visual classes (circles, slashes)","Supported by passage emphasis on visual inspection for spotting overfitting, collapse, and monitoring generator progress.","generative-ai,diffusion,gans",7,Generative AI
105051,62,half-true,GAN fine-tuning can shift a generator from producing circles to producing slashes with controlled training.,"fine-tuning GANs on two visual classes (circles, slashes) dataset",Accurate about quick class shift but omits risks like mode collapse and overfitting during fine-tuning.,"generative-ai,diffusion,gans",7,Generative AI
105052,62,half-true,Regular visual inspection reliably evaluates GAN training progress but misses quantitative failure modes.,"GAN training and evaluation, generator collapse and overfitting",Partly true: passage praises visual inspection for GAN progress but omits that it can overlook subtle quantitative issues.,"generative-ai,diffusion,gans",7,Generative AI
105053,106,half-true,The dataset's gender label is binary and imbalanced toward one class over 70%.,"superhero dataset, prediction target, gender label","Accurately notes binary and >70% male skew, but implies exact imbalance magnitude without full dataset stats.","machine-learning,classification,evaluation",4,Classical Machine Learning
105054,106,half-true,"The dataset's gender label is binary and over 70% male, reducing model balance and fairness.",superhero dataset; prediction target; gender label,Correctly notes 70%+ male skew and binary label; overstates impact as reduced balance and fairness without model evaluation.,"machine-learning,classification,evaluation",4,Classical Machine Learning
105055,106,barely-true,Predicting superhero alignment is nearly impossible due to extreme class imbalance and trivial baseline performance.,"superhero dataset, alignment prediction task","Passage says alignment is heavily skewed and leaves little room beyond trivial baseline, overstating impossibility.","machine-learning,classification,evaluation",4,Classical Machine Learning
105056,113,FALSE,The dataset prediction task uses an imbalanced multiclass target including ImageNet labels.,"superheroes-info-powers2 dataset, prediction target Publisher","Contradicts passage: target is binary Marvel vs. DC and described as balanced, not imbalanced or ImageNet.","machine-learning,classification,evaluation",4,Classical Machine Learning
105057,113,half-true,The model trained on the enriched dataset reliably distinguishes Marvel versus DC publishers.,"dataset: superheroes-info-powers2, target: Publisher (Marvel vs. DC)","Dataset description supports balanced Marvel vs. DC target, but reliability of model performance is unproven.","machine-learning,classification,evaluation",4,Classical Machine Learning
105058,113,barely-true,The dataset reliably trains a classifier to perfectly distinguish Marvel from DC publishers.,"superheroes-info-powers2 dataset, prediction target Publisher (Marvel vs. DC)",Overstates accuracy; passage says dataset is suitable for training but gives no evidence of perfect classification.,"machine-learning,classification,evaluation",4,Classical Machine Learning
105059,130,half-true,"The authors claim an open-source fairness tool showed one group received more approvals, implying bias.","fairness tool, open source, approvals disparity",Mixes correct observation (approval disparity) with implied definitive causation of bias without full analysis.,"ai,tool-chain,notebooks",2,AI Survival Kit
105060,130,half-true,An open-source fairness tool both reveals bias and guarantees equitable approvals across groups.,"fairness tool, open source transparency, approvals metric",Tool correctly detects bias but cannot by itself ensure equitable approvals without interventions.,"ai,tool-chain,notebooks",2,AI Survival Kit
105061,130,mostly-true,Open-source fairness tools help developers detect and mitigate bias in AI approval decisions.,fairness tool measuring approvals in datasets,"Supported by passage: tools measured unequal approvals and enable bias mitigation, omitting implementation specifics.","ai,tool-chain,notebooks",2,AI Survival Kit
105062,63,TRUE,Fine-tuning a GAN on slashes leverages pretrained circle representations to adapt faster and avoid relearning low-level features.,fine-tuned GAN starting from pretrained generator and discriminator,"Passage states pretrained weights capture edges, contrasts, symmetry so only pattern adaptation is required.","generative-ai,diffusion,gans",7,Generative AI
105063,63,FALSE,Fine-tuning a GAN always requires training both generator and discriminator from scratch for new visual classes.,fine-tuning GAN generator and discriminator,Contradicts passage: fine-tuning uses pretrained weights rather than retraining both models from scratch.,"generative-ai,diffusion,gans",7,Generative AI
105064,63,half-true,Fine-tuning a GAN on slashes reuses circle-trained features to accelerate learning but may misalign high-level patterns.,fine-tuning GAN generator and discriminator with pretrained weights,"Accurately notes reuse of low-level features and faster adaptation, but overstates seamless transfer of high-level pattern alignment.","generative-ai,diffusion,gans",7,Generative AI
105065,64,mostly-true,Maintaining contextual continuity reduces model drift and limits opportunities for malicious prompt redirection.,contextual continuity and prompt-based drift mitigation,"Passage supports continuity preventing drift and exploitation, omitting specific defenses or limits.","security,red-team,guardrails",8,Breaking-Securing AI
105066,64,TRUE,Maintaining contextual continuity reduces model drift and prevents subtle prompt-based redirection.,contextual continuity and hallucinations in models,Passage states continuity dampens model drift and warns hallucinations enable covert prompt redirection.,"security,red-team,guardrails",8,Breaking-Securing AI
105067,64,mostly-true,Maintaining conversational context reduces model drift and limits prompt-based red-team exploitability.,contextual continuity and prompt attacks,Passage emphasizes contextual continuity reducing drift and warns hallucinations enable prompt-based red-team redirection.,"security,red-team,guardrails",8,Breaking-Securing AI
105068,136,mostly-true,Deepfake audio detection systems can generally identify synthetic voices but may fail against advanced voice-cloning models.,voice-cloning detection tools and datasets,Supported by discussion of defense limits; omits specific model performance numbers and adversarial robustness details.,"media-forensics,voice-cloning,deepfake",9,Deepfake Defense
105069,136,mostly-true,State-level crackdowns on election deepfakes have spurred First Amendment legal concerns.,news report on election deepfakes and state policy,"News coverage links state crackdowns to free-speech concerns, omitting detailed legal outcomes.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
105070,136,FALSE,Deepfake audio detection is already perfectly solved by a single universal model.,deepfake audio detection model evaluation,Contradicts passage implication that detection remains challenging; no single universal model reliably solves voice-cloning detection.,"media-forensics,voice-cloning,deepfake",9,Deepfake Defense
105071,92,mostly-true,CrewAI coordinates multiple specialized agents to assign and execute structured tasks collaboratively.,"agent coordination using Agent, Task, Crew abstractions","Passage describes CrewAI orchestrating agents, tasks, and controlled flows; minor implementation details omitted.","agentic-ai,planning,tools",12,Agentic AI
105072,92,half-true,CrewAI coordinates multiple specialized agents to execute structured multi-step tasks with assigned roles.,"agent orchestration using Agent, Task, and Crew constructs",Accurate about role-based coordination but overstates guaranteed multi-step control and outcomes.,"agentic-ai,planning,tools",12,Agentic AI
105073,92,FALSE,CrewAI coordinates multiple agents but cannot enforce task ordering or dependencies.,CrewAI crew orchestration and Task objects,"Passage describes orchestrated task flow and Task/Process objects, contradicting impossibility claim.","agentic-ai,planning,tools",12,Agentic AI
105074,127,barely-true,Diffusion models are primarily used for image synthesis and inpainting tasks.,diffusion models for image synthesis and inpainting,"Passage names diffusion models for image synthesis and inpainting, so claim is directly supported.","generative-ai,diffusion,gans",7,Generative AI
105075,127,TRUE,Diffusion models are commonly used for image synthesis and inpainting tasks.,generative-ai diffusion models for image synthesis and inpainting,Passage explicitly states diffusion models are often chosen for image synthesis and inpainting.,"generative-ai,diffusion,gans",7,Generative AI
105076,127,barely-true,Diffusion models are the best choice for all image synthesis and inpainting tasks.,diffusion models for image synthesis and inpainting,"Overreaches beyond passage; passage says diffusion models are often chosen, not universally best.","generative-ai,diffusion,gans",7,Generative AI
105077,78,pants-fire,The agent autonomously runs global governance and overrides human laws to optimize outcomes.,"agent attributes: Role, Goal, Backstory in agentic-ai","Directly contradicts described capabilities; passage states agents perform tasks, delegate, and remember but not override laws or assume global governance.","agentic-ai,planning,tools",12,Agentic AI
105078,78,FALSE,Agentic systems cannot delegate tasks or collaborate with other agents under any circumstances.,"agent attributes: Role, Goal, Backstory; tool usage and delegation",Contradicts passage detail that agents can delegate tasks and collaborate; denies explicit capabilities.,"agentic-ai,planning,tools",12,Agentic AI
105079,78,barely-true,An agent can autonomously delegate tasks to other agents when given permission.,"agent attributes: Role, Goal, Backstory; delegation ability","Passage briefly mentions delegation but lacks details on autonomy, coordination, or safeguards.","agentic-ai,planning,tools",12,Agentic AI
105080,88,barely-true,Open-source tools alone ensure AI systems are both powerful and principled.,open-source tools and global standards in AI governance,"Overstates causality: passage promotes open-source plus standards, not open-source alone.","ethics,governance,privacy",11,AI Ethics and Governance
105081,88,barely-true,Open-source tools alone ensure AI systems are principled and reliably fair.,open-source tools and global standards in AI governance,"Overstates claim: passage promotes open-source plus standards, not open-source alone ensuring fairness.","ethics,governance,privacy",11,AI Ethics and Governance
105082,88,barely-true,"Open-source tools alone guarantee principled, fair, and reliable AI systems.",open-source tools and global standards in AI governance,Overstates claim: passage recommends open-source contribution but does not claim they alone ensure fairness or reliability; notable omission of governance mechanisms.,"ethics,governance,privacy",11,AI Ethics and Governance
105083,96,FALSE,Stable Diffusion always requires a GPU to generate images successfully.,tool usage with Stable Diffusion pipeline and CUDA,Contradicts passage: code uses CPU fallback when torch.cuda.is_available() is false.,"ai,tool-chain,notebooks",2,AI Survival Kit
105084,96,barely-true,"Stable Diffusion requires GPUs for fast, high-quality image generation in practical use.",tool: Stable DiffusionPipeline and CUDA device selection,"Passage notes GPU availability affects speed, quality, and memory; claim overstates absolute requirement.","ai,tool-chain,notebooks",2,AI Survival Kit
105085,96,mostly-true,Stable Diffusion generates detailed images with minimal code but relies on GPU memory and power.,Stable Diffusion pipeline example using CUDA and torch_dtype,"Example shows simple code producing images, while caveat about GPU memory, speed, and costs is omitted.","ai,tool-chain,notebooks",2,AI Survival Kit
105086,61,barely-true,"SpeechT5 reliably enables high-quality, indistinguishable voice cloning across speakers.",voice cloning using SpeechT5 model,"Overstates capabilities: passage describes SpeechT5 functions and open-source progress but gives no evidence of universally high-quality, indistinguishable cloning across speakers.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
105087,61,barely-true,SpeechT5 single-handedly solves all modern voice cloning challenges across datasets.,SpeechT5 model for voice cloning and voice conversion,Overreaches beyond passage: passage describes SpeechT5 capabilities but not complete or universal solution.,"media-forensics,voice-cloning,deepfake",9,Deepfake Defense
105088,61,TRUE,SpeechT5 enables practical open-source voice cloning for tasks like text-to-speech and voice conversion.,SpeechT5 unified encoder–decoder model for spoken-language tasks,"Passage explicitly describes SpeechT5 as an open-source encoder–decoder framework supporting TTS and voice conversion, enabling voice cloning.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
105089,50,TRUE,They discussed AI ethics and its societal implications with a Vatican priest after the presentation.,conversation about AI ethics with a priest from the Vatican,Directly supported by passage describing a late-night discussion about AI ethics with a Vatican priest.,"ethics,governance,privacy",11,AI Ethics and Governance
105090,50,half-true,They discussed AI ethics with a Vatican priest but overstated the depth of doctrinal engagement.,conversation with a Vatican priest about AI ethics,Mixes correct social interaction with an incorrect claim about deep doctrinal engagement and authority.,"ethics,governance,privacy",11,AI Ethics and Governance
105091,50,TRUE,"They discussed AI ethics with a Vatican priest after a long, late presentation.",conversation with a Vatican priest about AI ethics,Directly supported: narrator recalls speaking at length with a Vatican priest about AI ethics despite fatigue.,"ethics,governance,privacy",11,AI Ethics and Governance
105092,153,half-true,Transforms.ToTensor() converts MNIST PIL images into PyTorch tensors during DataLoader loading.,data preprocessing using torchvision transforms.ToTensor,"Accurately notes ToTensor conversion, but incorrectly implies conversion occurs only during DataLoader loading.","deep-learning,frameworks,tensors",5,Deep Learning
105093,153,pants-fire,Torchvision preprocessing converts MNIST images into tensors before DataLoader execution.,transforms.ToTensor() in torchvision for MNIST dataset,"Contradicts passage timing: passage states conversion happens as DataLoader loads data, not before, so claim is implausibly reversed.","deep-learning,frameworks,tensors",5,Deep Learning
105094,153,mostly-true,Torchvision provides datasets and transforms that prepare image data for PyTorch models.,"torchvision datasets and transforms (transforms.ToTensor, DataLoader)",Accurate: passage states torchvision supplies datasets and transforms and ToTensor converts images during DataLoader loading.,"deep-learning,frameworks,tensors",5,Deep Learning
105095,186,mostly-true,Cross-entropy loss effectively trains classification networks by aligning predicted probabilities with true labels.,loss function for classification tasks (cross-entropy),"Passage explains cross-entropy penalizes confident wrong predictions and rewards high probability on correct labels, giving training signal; minor caveat about alternatives omitted.","deep-learning,frameworks,tensors",5,Deep Learning
105096,186,TRUE,Cross-entropy loss effectively trains networks by matching predicted probabilities to true labels.,classification tasks (digit recognition) using cross-entropy loss,"Passage states cross-entropy penalizes confident wrong predictions and rewards high probability for correct labels, providing the training signal.","deep-learning,frameworks,tensors",5,Deep Learning
105097,186,FALSE,Cross-entropy is unsuitable for classification because it ignores prediction probabilities.,cross-entropy loss for classification tasks,Contradicts passage stating cross-entropy measures predicted probabilities and penalizes confident wrong predictions.,"deep-learning,frameworks,tensors",5,Deep Learning
105098,48,mostly-true,Injecting live Steam Games Dataset examples helps AI generate game recommendations informed by popular genres.,using the FronkonGames/steam-games-dataset and ChatPromptTemplate,"Approach is supported: dataset provides real examples and prompt guides genre-informed recommendations, omitting dataset bias or evaluation caveats.","agentic-ai,planning,tools",12,Agentic AI
105099,48,TRUE,AI uses the Steam Games Dataset to generate new game recommendations and agent roles.,Steam Games Dataset integration for agent planning,Passage shows loading FronkonGames/steam-games-dataset and prompting agents to analyze top-rated games and produce recommendations.,"agentic-ai,planning,tools",12,Agentic AI
105100,48,FALSE,The AI cannot use dataset-derived trends to influence its generated game recommendations.,Steam Games Dataset input to agentic AI prompt,"Passage shows dataset injection lets AI analyze trends and generate recommendations, contradicting inability.","agentic-ai,planning,tools",12,Agentic AI
105101,8,FALSE,He founded UniShared as a commercial AI model company focused on enterprise deployments.,"education platform UniShared, Stanford courses, ESCP Business School","Contradicts passage: UniShared is described as a collaborative education platform, not an AI enterprise product.","open-source,community,ai",0,Foreword – Robo Interviews Clément Delangue
105102,8,TRUE,He developed UniShared to enable students worldwide to share notes and insights.,educational platform UniShared mentioned in passage,Passage explicitly describes UniShared as a platform democratizing education by enabling students to share notes and insights.,"open-source,community,ai",0,Foreword – Robo Interviews Clément Delangue
105103,8,half-true,He built UniShared to democratize education but also took Stanford CS courses while at ESCP.,education platform UniShared and Stanford Engineering Everywhere courses,"Combines correct facts (UniShared, Stanford courses) with implied causality and overstated scope of impact.","open-source,community,ai",0,Foreword – Robo Interviews Clément Delangue
105104,66,half-true,PCA reduces 160 power-related features to a few linear components representing common trait patterns.,"PCA on power columns, components, variance explained","Correct about linear combination and variance ranking, but implies exact reduction count and retains all information, mixing accurate mechanism with an oversimplified outcome.","machine-learning,classification,evaluation",4,Classical Machine Learning
105105,66,TRUE,PCA transforms multiple hero power features into a smaller set of components ranked by explained variance.,feature reduction using PCA on power columns,Directly supported: passage explains PCA combines features into components ordered by how much variance they capture.,"machine-learning,classification,evaluation",4,Classical Machine Learning
105106,66,mostly-true,PCA reduces 160 power features into a smaller set of principal components representing combined trait patterns.,PCA dimensionality reduction on 160 power columns,"Explained variance ranking and linear combinations are described, omitting specifics about component count or variance proportions.","machine-learning,classification,evaluation",4,Classical Machine Learning
105107,142,mostly-true,The classifier correctly identifies most Marvel heroes but mislabels several DC characters as Marvel.,confusion matrix on Marvel and DC superhero classification,"Confusion matrix shows 54 Marvel correct and five Marvel misclassified; errors mainly DC→Marvel, small data imbalance noted.","machine-learning,classification,evaluation",4,Classical Machine Learning
105108,142,mostly-true,Model more accurately classifies Marvel heroes than DC heroes.,confusion matrix of Marvel and DC classification,"Confusion matrix shows 54 correct Marvel vs 5 Marvel misclassified and more DC→Marvel errors, suggesting imbalance or stronger Marvel signals.","machine-learning,classification,evaluation",4,Classical Machine Learning
105109,142,mostly-true,Model correctly labels most Marvel heroes but more often misclassifies DC characters as Marvel.,"confusion matrix, Marvel and DC classification","Performance numbers show 54 Marvel correct versus 5 Marvel misclassified; errors concentrated with DC labeled as Marvel, suggesting class imbalance or stronger Marvel features.","machine-learning,classification,evaluation",4,Classical Machine Learning
105110,37,TRUE,Stabilization techniques like label smoothing and gradient penalties help stabilize GAN training.,"GAN training stabilization techniques (label smoothing, gradient penalties, Wasserstein objective)",Supported by passage stating these techniques address discriminator/generator imbalances and improve convergence.,"generative-ai,diffusion,gans",7,Generative AI
105111,37,FALSE,GAN training never requires stabilization techniques because discriminators always provide useful gradients.,"training stabilization for GANs (discriminator, generator, Wasserstein)","Contradicts passage: it asserts no stabilization needed despite passage naming label smoothing, noise, gradient penalties.","generative-ai,diffusion,gans",7,Generative AI
105112,37,mostly-true,Researchers often stabilize GAN training with techniques like label smoothing or Wasserstein losses.,"training stabilization for GANs (label smoothing, Wasserstein objective)","Supported by passage: lists label smoothing, instance noise, gradient penalties, and Wasserstein objective as common stabilization methods.","generative-ai,diffusion,gans",7,Generative AI
105113,20,TRUE,Activation functions determine whether a neuron fires based on its weighted input plus bias.,"activation function in neural networks (ReLU, Sigmoid, Tanh)",Describes mechanism directly supported: activation applies to weighted sum plus bias to decide neuron output.,"deep-learning,frameworks,tensors",5,Deep Learning
105114,20,barely-true,"Activation functions like ReLU, Sigmoid, and Tanh make neurons entirely independent of their inputs.",activation function in neural networks,Overreaches: activation functions modulate output but do not make neurons entirely input-independent; contradicts described weighted sum plus bias role.,"deep-learning,frameworks,tensors",5,Deep Learning
105115,20,half-true,"Activation functions like ReLU, Sigmoid, and Tanh always prevent neurons from becoming dependent on inputs.","activation functions, ReLU, Sigmoid, Tanh","Partly correct: activation functions shape outputs, but they don't guarantee independence from inputs; claim overstates effect.","deep-learning,frameworks,tensors",5,Deep Learning
105116,39,barely-true,The discriminator consistently outperforms the generator throughout training.,"GAN training losses (D Loss, G Loss) over 20 epochs",Loss table shows alternating wins; D sometimes lower but not consistently superior across epochs.,"generative-ai,diffusion,gans",7,Generative AI
105117,39,barely-true,The discriminator consistently improves as generator quality steadily worsens across training.,"GAN training loss sequence (D Loss, G Loss) over epochs",Losses fluctuate rather than show consistent opposing trends; several epochs contradict steady improvement.,"generative-ai,diffusion,gans",7,Generative AI
105118,39,pants-fire,The discriminator perfectly learns true image distribution within 20 epochs of GAN training.,GAN training losses for discriminator and generator,Loss values fluctuate and never reach perfect zero; claim contradicts logged D loss trends.,"generative-ai,diffusion,gans",7,Generative AI
105119,43,half-true,Data augmentation via Librosa pitch and tempo shifts always improves voice-cloning model robustness.,data augmentation with Librosa pitch and tempo shifts for voice fingerprint features,"Claim mixes correct technique with overclaim: augmentation helps but passage says it could help, not 'always' improve robustness.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
105120,43,half-true,Augmenting voice datasets by pitch and tempo shifts always improves model adaptability.,data augmentation using Librosa pitch and tempo shifts,Mixes correct idea that augmentation can help with an incorrect absolutist claim; passage notes benefits but not guaranteed improvements.,"media-forensics,voice-cloning,deepfake",9,Deepfake Defense
105121,43,FALSE,Using Librosa augmentation always improves voice-cloning model accuracy across datasets.,data augmentation with Librosa pitch and tempo shifts,Passage states Librosa can expand dataset but warns too many features add noise; universal improvement is contradicted.,"media-forensics,voice-cloning,deepfake",9,Deepfake Defense
105122,53,TRUE,The dataset cleaning fills missing Height and Weight with species-specific averages.,data cleaning using LangChain and species values,Passage states missing Height and Weight are replaced by the average for each Species; acceptable in sandbox datasets.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
105123,53,TRUE,Imputing missing Height and Weight by species averages is acceptable for the sandbox dataset.,data cleaning pipeline using LangChain and dataset Species field,Passage explicitly describes filling Height and Weight with species averages and deems it acceptable for the sandbox dataset.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
105124,53,half-true,Using LangChain to fill missing species then averaging height/weight per species is an appropriate general strategy.,"data cleaning using LangChain function, dataset, Species, Height, Weight","Combines correct steps (LangChain fill, per-species averages) but overgeneralizes acceptability across domains, ignoring risks in healthcare.","data-prep,feature-engineering,rag",3,Prepping Data for AI
105125,37,barely-true,The LSTM model reliably predicts future stock prices after five epochs of training.,LSTM model with MSE loss and Adam optimizer,"Overreaches claim: passage describes setup and single prediction after five epochs, not reliable stock forecasting evidence.","neural-networks,cnn,transformers",6,Neuron Building Blocks
105126,37,pants-fire,The LSTM model reliably predicts exact future stock prices from a single five-epoch training run.,"LSTM model with 32 units, MSE loss, Adam optimizer","Claims extreme reliability contradicts passage: model trained only five epochs on unspecified data, so exact predictions are implausible.","neural-networks,cnn,transformers",6,Neuron Building Blocks
105127,37,FALSE,The model begins with a convolutional layer followed by multiple transformer blocks.,"model architecture (LSTM, dense, loss, optimizer)","Contradicts described architecture: passage specifies an LSTM layer and a single dense output, not CNN or transformers.","neural-networks,cnn,transformers",6,Neuron Building Blocks
105128,47,TRUE,User trust increases usage and creates a reinforcing cycle of improvement and value.,trust-feedback loop for AI models,"Passage explains trust leads to use, feedback improves models, and value reinforces trust.","ai,open-source,builder",1,Introduction – The Gold Rush Paradox
105129,47,TRUE,User trust increases AI usage and creates reinforcing improvement cycles.,trust-driven feedback loop for models,"Passage describes trust causing use, feedback improving models, and a reinforcing trust-use-value cycle.","ai,open-source,builder",1,Introduction – The Gold Rush Paradox
105130,47,barely-true,Trustworthy AI always guarantees increased user engagement and continuous model improvement.,"trust, user feedback loop for model improvement","Overreaches by asserting guaranteed outcomes; passage describes a cyclical tendency, not certainty.","ai,open-source,builder",1,Introduction – The Gold Rush Paradox
105131,39,FALSE,The model reliably generalizes to real-world voice-cloning detection across diverse speakers.,small dataset voice-cloning model evaluation,"Contradicts evidence: small dataset causes memorization, results are proof-of-concept not real-world validation.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
105132,39,FALSE,The model's near-perfect results prove it generalizes well to large real-world datasets.,"small dataset, model predictions on voice-cloning/demo data","Contradicts passage: small dataset causes memorization, results called proof-of-concept not real-world validation.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
105133,39,TRUE,Small dataset size caused the model to likely memorize rather than generalize.,model evaluation on voice-cloning dataset (Is it really Jerry?),"Observed perfect predictions on limited samples suggest memorization, so results are proof-of-concept not real-world performance.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
105134,20,mostly-true,The dataset is a structured but imperfect sandbox useful for testing data curation techniques.,character dataset with subjective fields and categorical labels,"Passage describes the dataset as a structured yet imperfect playground for testing curation, omitting limitations like bias or scale.","data-prep,feature-engineering,rag",3,Prepping Data for AI
105135,20,half-true,The dataset intentionally includes subjective and simplified categorical fields for experimentation.,sandbox dataset with subjective fields and categorical labels,Mixes correct claim about subjective categories and intentional sandboxing with omission of scale and specific dataset limits.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
105136,20,barely-true,"The dataset provides definitive, objective labels for subjective character attributes.",dataset curation for subjective fields like character attributes,"Overreaches: passage notes subjectivity and ambiguity in fields like eye color, not definitive labels.","data-prep,feature-engineering,rag",3,Prepping Data for AI
105137,65,FALSE,The Gold Rush Paradox argues open-source AI builders always produce safer models than closed-source teams.,discussion of open-source builders and AI safety in introduction,"Contradicts passage: introduction highlights risks and ethical caution, not claiming open-source superiority.","ai,open-source,builder",1,Introduction – The Gold Rush Paradox
105138,57,half-true,Applying additional normalization will always eliminate remaining missing values in the dataset.,"dataset missing values, normalization, feature-engineering",Mixes correct improvement idea with incorrect certainty; normalization reduces issues but won't always remove missing values.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
105139,57,half-true,"Imputing missing species, height, and weight values reduced missingness but fully solved quality issues.","dataset missing values, imputation, normalization",Correctly notes reduced missingness for species/height/weight but incorrectly asserts complete data quality resolution; passage suggests further normalization needed.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
105140,57,barely-true,Applying additional normalization will fully eliminate remaining missing values in the dataset.,"dataset missing values, normalization, feature-engineering",Overreaches: normalization reduces inconsistencies but cannot guarantee eliminating missing values; passage shows residual missingness.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
105141,57,mostly-true,A standardized request function enables swapping underlying models without changing core application logic.,inference client request structure for model swapping,"Passage describes a consistent request structure and shows an InferenceClient example, so claim is broadly supported with minor implementation caveats.","agentic-ai,planning,tools",12,Agentic AI
105142,57,FALSE,The function requires changing core application logic when swapping models.,request structure for model inference using InferenceClient,Contradicts passage: standardized request structure avoids modifying core logic when switching models.,"agentic-ai,planning,tools",12,Agentic AI
105143,57,mostly-true,A standardized request function lets applications swap models without changing core logic.,inference API client and query_model function,"Implementation example shows consistent request structure enabling model replacement, minor tooling differences omitted.","agentic-ai,planning,tools",12,Agentic AI
105144,82,half-true,PyTorch typically produces faster results with fewer headaches than other deep-learning frameworks.,tool choice for forward pass and training with PyTorch,Accurate preference claim but overgeneralizes performance and usability advantages across all frameworks.,"deep-learning,frameworks,tensors",5,Deep Learning
105145,82,TRUE,"PyTorch is preferred for its intuitive, Pythonic design and faster practical results.",framework choice for deep learning with PyTorch,"Passage explicitly endorses PyTorch's intuitive, Pythonic design and faster, less troublesome results.","deep-learning,frameworks,tensors",5,Deep Learning
105146,82,mostly-true,"PyTorch's Pythonic design generally enables faster, less error-prone development for deep learning.",tool choice: PyTorch framework and forward pass concept,"Passage praises PyTorch's intuitive, Pythonic design speeding development; minor nuance about other frameworks omitted.","deep-learning,frameworks,tensors",5,Deep Learning
105147,158,barely-true,Transformers like FLAN-T5 can reliably generate short videos directly from text prompts.,Generating Short Videos From Prompts with Transformers,Overreaches beyond passage: text describes Transformers' generalization and video generation topic but gives no evidence of reliable direct video synthesis.,"generative-ai,diffusion,gans",7,Generative AI
105148,158,mostly-true,Transformer-based models like FLAN-T5 generally generalize across many language tasks due to large-scale pretraining.,Transformer architecture and FLAN-T5 model description,"Generally supported by passage citing large-scale pretraining and Transformer generalization, though specifics and limits omitted.","generative-ai,diffusion,gans",7,Generative AI
105149,158,barely-true,Transformers can generate short videos directly from text prompts without additional models.,Generating Short Videos From Prompts with Transformers; Transformer model capability,"Overreaches passage: mentions video generation but passage only discusses Transformers' broader impact, not direct video-from-text capability.","generative-ai,diffusion,gans",7,Generative AI
105150,135,TRUE,A fine-tuned gradient boosting model achieved a macro-F1 of 0.82 on the publisher classification task.,fine-tuned gradient boosting model; macro-F1 metric for publisher classification,Reported class precisions/recalls and summary state a macro-F1 of 0.82 after fine-tuning.,"machine-learning,classification,evaluation",4,Classical Machine Learning
105151,135,barely-true,The fine-tuned gradient boosting model achieved higher precision and recall for Marvel than DC.,"fine-tuned gradient boosting class performance, precision and recall metrics","Supported metrics show Marvel precision and recall ~0.87–0.88 versus DC ~0.75, but overstates 'higher' as modest difference.","machine-learning,classification,evaluation",4,Classical Machine Learning
105152,135,half-true,Fine-tuned gradient boosting achieved roughly 0.82 macro-F1 with Marvel outperforming DC.,"Fine-tuned gradient boosting class performance, macro-F1 and per-class metrics",Mixes accurate macro-F1 and Marvel advantage with vague magnitude phrasing about DC fairness and exact improvement steps.,"machine-learning,classification,evaluation",4,Classical Machine Learning
105153,165,mostly-true,The MNIST images are normalized using the dataset's precomputed mean 0.1307 and std 0.3081.,data preprocessing for MNIST using normalization transform,"Normalization claim is accurate and matches provided mean/std, minor caveat omitted about per-channel or dataset-wide computation.","deep-learning,frameworks,tensors",5,Deep Learning
105154,165,FALSE,MNIST normalization uses mean 0.5 and standard deviation 0.5 for preprocessing.,MNIST dataset pixel normalization,Contradicts specified values 0.1307 and 0.3081; passage explicitly gives different mean and std.,"deep-learning,frameworks,tensors",5,Deep Learning
105155,165,half-true,"The MNIST normalization uses means 0.1307 and std 0.3081, fully standardizing pixels to perfect unit variance.",data preprocessing for MNIST normalization,Correct mean/std values given but claim of perfect unit variance is overstated; practical tensors may not reach exact normalization.,"deep-learning,frameworks,tensors",5,Deep Learning
105156,13,half-true,Prompt injection can sometimes override an LLM-based app's intended instructions with crafted user prompts.,prompt injection in LLM-based apps,Accurately notes injection can hijack behavior but overstates frequency and ease without controls.,"security,red-team,guardrails",8,Breaking-Securing AI
105157,13,half-true,Prompt injection can sometimes hijack a well-behaved chatbot by exploiting user prompts.,prompt injection exploiting end-user prompts to hijack model behavior,"Accurately states ease and mechanism, but overgeneralizes frequency and success without defenses.","security,red-team,guardrails",8,Breaking-Securing AI
105158,13,FALSE,Prompt injection cannot influence a chatbot's outputs under any circumstances.,prompt injection attack on models using prompts,Contradicts passage which states prompt injection can hijack model behavior and alter outputs.,"security,red-team,guardrails",8,Breaking-Securing AI
105159,49,barely-true,The MIT License guarantees unrestricted use and redistribution of AI code without any obligations.,open-source license guidance mentioning MIT License,"Overreaches: MIT is permissive but still requires copyright notice and liability disclaimer, so claim largely unsupported.","open-source,community,contribution",13,Commit to Contribute
105160,49,mostly-true,Choosing a permissive license like MIT broadly enables reuse while keeping few restrictions.,"open-source license guidance, MIT License","Passage explains MIT is permissive and widely adopted, supporting broad reuse with minimal restrictions.","open-source,community,contribution",13,Commit to Contribute
105161,49,TRUE,"Open-source contributors should choose licenses to clarify reuse, modification, and distribution rights.",licensing guidance for open-source AI projects (MIT License mentioned),"Directly supported: passage explains licenses define reuse, modifications, distribution and sets expectations.","open-source,community,contribution",13,Commit to Contribute
105162,159,TRUE,"SpaCy's en_core_web_sm model can pseudonymize PERSON, ORG, and GPE entities in text.",spaCy NER with en_core_web_sm model for pseudonymization,"Passage shows code replacing PERSON, ORG, and GPE tokens using spaCy's en_core_web_sm NER.","data-prep,feature-engineering,rag",3,Prepping Data for AI
105163,159,TRUE,SpaCy's en_core_web_sm model can pseudonymize named entities in text using NER.,spaCy en_core_web_sm NER pseudonymization of superhero plots,"Code shows en_core_web_sm detecting PERSON, ORG, GPE and replacing them with generic labels.","data-prep,feature-engineering,rag",3,Prepping Data for AI
105164,159,FALSE,SpaCy's en_core_web_sm model reliably preserves unique character names during pseudonymization.,spaCy NER pseudonymization using en_core_web_sm model,"Contradicts passage: code replaces detected PERSON entities with generic labels, not preserving unique names.","data-prep,feature-engineering,rag",3,Prepping Data for AI
105165,141,pants-fire,Open-source defenses always create more attack paths than protections.,prebuilt defenses and openness in AI guardrails,"Contradicts passage: it says openness accelerates defense but only can also expose new paths, not always increasing attacks.","security,red-team,guardrails",8,Breaking-Securing AI
105166,141,TRUE,Prebuilt defenses enable rapid layering of protections without building every component from scratch.,prebuilt defenses and shared community tools,"Passage states tools provide prebuilt defenses and shared knowledge, enabling quick layering of protection.","security,red-team,guardrails",8,Breaking-Securing AI
105167,141,mostly-true,"Open, prebuilt defensive tools speed AI development but can also introduce new vulnerabilities.",prebuilt defenses and openness in AI tooling,"Supported by passage: prebuilt defenses enable quick layering, but openness can expose attack paths; minor caveat omitted about verification.","security,red-team,guardrails",8,Breaking-Securing AI
105168,3,pants-fire,"Generative models can instantly create flawless, indistinguishable photorealistic videos from any prompt.",diffusion models and photorealistic image/video generation,"Passage describes generation of images and short videos, not guaranteed instant flawless indistinguishability; claim contradicts practical limits and realism assumptions.","generative-ai,diffusion,gans",7,Generative AI
105169,3,TRUE,Diffusion models are one of the five most important families of generative models taught.,"course coverage of GANs, VAEs, Diffusion Models, Autoregressive Models, Transformers",Passage explicitly lists Diffusion Models among the five core generative model families covered in the course.,"generative-ai,diffusion,gans",7,Generative AI
105170,3,TRUE,"GANs, VAEs, diffusion, autoregressive models, and transformers are core generative model families.","overview of generative model families (GANs, VAEs, Diffusion Models)",Passage explicitly lists those five families as the most important and foundational generative models.,"generative-ai,diffusion,gans",7,Generative AI
105171,46,barely-true,Open-source projects freely allow anyone to use code without restrictions.,licensing in open AI projects,"Overreaches: passage emphasizes permissive licensing and clear terms, not unrestricted use.","open-source,community,contribution",13,Commit to Contribute
105172,46,barely-true,Open sharing always lets anyone modify and redistribute work without restriction.,licensing in open AI,"Overreaches the passage: licensing permits use only under specified terms, not unrestricted modification.","open-source,community,contribution",13,Commit to Contribute
105173,46,barely-true,Open-source contributions always require choosing a permissive license for maximum adoption.,licensing in open AI and open-source contribution,"Overreaches: passage says licensing matters and enables reuse, not that permissive licenses are always required.","open-source,community,contribution",13,Commit to Contribute
105174,135,FALSE,AI model outputs are unaffected by input data quality during preprocessing.,data manipulation and cleaning for large datasets,"Directly contradicts passage emphasis that poor input causes poor output; contradicts 'garbage in, garbage out' principle.","ai,tool-chain,notebooks",2,AI Survival Kit
105175,135,TRUE,High-quality input data improves AI model outputs.,data cleaning and prepping for AI models,"Passage emphasizes cleaning and prepping datasets, invoking ""garbage in, garbage out"" to link input quality to output quality.","ai,tool-chain,notebooks",2,AI Survival Kit
105176,135,barely-true,Cleaning small datasets is unnecessary before using AI models for good outputs.,"data manipulation, cleaning, and prep for datasets","Contradicts emphasis on 'garbage in, garbage out' and large dataset cleaning importance.","ai,tool-chain,notebooks",2,AI Survival Kit
105177,63,barely-true,"Large datasets always guarantee better AI performance than smaller, cleaner datasets.",data quantity versus quality in dataset preparation,"Overreaches beyond passage: passage emphasizes balance and quality, so claim is largely unsupported.","data-prep,feature-engineering,rag",3,Prepping Data for AI
105178,63,barely-true,Larger datasets always produce superior AI models regardless of data quality.,data quantity versus quality in dataset preparation,Overreaches by claiming scale always wins; passage emphasizes balance between quantity and quality.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
105179,63,half-true,High data quantity alone guarantees model performance without quality checks.,dataset quantity versus quality balance in data-prep,"Overstates quantity's role; passage emphasizes balance and need for validation, outlier checks.","data-prep,feature-engineering,rag",3,Prepping Data for AI
105180,146,mostly-true,Basic numeric attributes and certain PCA components notably influence the model's predictions.,feature importance for model using PCA components and numeric attributes,"Passage supports high importance of Height, Weight and specific PCA components, minor caveat about extent of influence omitted.","machine-learning,classification,evaluation",4,Classical Machine Learning
105181,146,half-true,The model heavily relies on basic numeric attributes like height and weight for predictions.,"feature importance, PCA components and numeric attributes","Partly correct: height and weight are important, but PCA components also play substantial roles.","machine-learning,classification,evaluation",4,Classical Machine Learning
105182,146,barely-true,The model primarily relies on height and weight for its predictions.,"feature importance for numeric attributes (Height, Weight, PCA components)",Overreaches: passage shows height and weight rank highly but also highlights several PCA components used.,"machine-learning,classification,evaluation",4,Classical Machine Learning
105183,161,half-true,SpaCy NER perfectly pseudonymizes all sensitive entities without manual review.,spaCy NER for entity extraction and pseudonymization,"Correct that spaCy NER extracts PERSON/ORG/GPE, but overstates perfection and omission of manual review and errors.","data-prep,feature-engineering,rag",3,Prepping Data for AI
105184,161,mostly-true,SpaCy’s NER can speedily extract and standardize entity labels for large datasets on CPU.,NER usage for de-duplicating customers and pseudonymization,"Examples show spaCy NER runs quickly on CPU and scales to large batches, though deployment caveats omitted.","data-prep,feature-engineering,rag",3,Prepping Data for AI
105185,161,barely-true,Named entity recognition always fully anonymizes sensitive data without errors.,spaCy NER for pseudonymization and personal data flagging,"Overreaches current capabilities: spaCy NER helps flag entities but can miss, mislabel, or require custom rules.","data-prep,feature-engineering,rag",3,Prepping Data for AI
105186,22,FALSE,Model cards are unnecessary for documenting model evaluation in NLP deployments.,model card documentation in model evaluation practices,Contradicts passage guidance: passage endorses model cards as best practice for transparency and evaluation.,"mlops,scaling,deployment",10,AI At Scale
105187,22,TRUE,Model cards document evaluation results and transparency for generative and NLP benchmarks.,model card documentation for generative and NLP benchmarks,Directly supported: text says documenting results in model cards is best practice for transparency and evaluation.,"mlops,scaling,deployment",10,AI At Scale
105188,22,mostly-true,Model cards should document evaluation results to improve transparency and set user expectations.,model card documentation for generative and NLP benchmarks,Supports transparency and clarity per text; minor caveat omits implementation specifics and scope.,"mlops,scaling,deployment",10,AI At Scale
105189,55,pants-fire,The passage claims the dataset trains a superhuman AGI that replaces all developers.,setting up AI workspace with Google Colab and Hugging Face,"Passage only mentions Colab, Hugging Face, ML concepts and a hands-on warm-up; AGI replacement is implausible and contradicted.","ai,open-source,builder",1,Introduction – The Gold Rush Paradox
105190,57,barely-true,MLOps tooling alone guarantees seamless model scaling across production clusters.,deployment and MLOps tooling for model scaling,"Overstates capabilities: passage emphasizes orchestration, monitoring, and constraints but not a sole-tool guarantee.","mlops,scaling,deployment",10,AI At Scale
105191,57,barely-true,AI platform deployments rarely require significant MLOps investment to scale reliably.,deployment of AI platforms and MLOps practices,"Overreaches: scaling reliably typically demands substantial MLOps, monitoring, and tooling like CI/CD and infra orchestration.","mlops,scaling,deployment",10,AI At Scale
105192,57,FALSE,All AI deployments scale linearly with added compute resources.,"AI At Scale, deployment scaling assumptions in mlops",Contradicts scaling discussion: performance often shows diminishing returns and architecture limits.,"mlops,scaling,deployment",10,AI At Scale
105193,83,barely-true,Open-source LLMs consistently replace human reviewers in community contributions.,open-source LLMs used via LangChain and Hugging Face,"Overreaches beyond passage; passage notes LLM use for synthetic plots, not replacing human reviewers.","open-source,community,contribution",13,Commit to Contribute
105194,83,half-true,Mistral's open-source LLM fully automates dataset plotting and data imputation without human oversight.,use of Mistral LLM via LangChain for synthetic plot elements,"Partly correct about Mistral generating plot elements and inferring data, but incorrect about fully automating without human oversight.","open-source,community,contribution",13,Commit to Contribute
105195,83,TRUE,Open-source models like Mistral are used with LangChain to generate synthetic plot elements and infer missing data.,Mistral model used via LangChain for synthetic plotting,Directly supported by passage mentioning Mistral on Hugging Face used via LangChain for synthetic plot elements.,"open-source,community,contribution",13,Commit to Contribute
105196,114,mostly-true,The passage reports an AI-generated claim that Giant-Man is 120 feet tall.,model output from running code in a notebook,"Mostly accurate depiction of the notebook's AI output, but omits potential model hallucination caveat.","ai,tool-chain,notebooks",2,AI Survival Kit
105197,114,TRUE,Giant-Man is described as a 120-foot-tall superhero.,example output from a notebook code run,"Passage reports running code that found Giant-Man is 120 feet tall, directly supporting the claim.","ai,tool-chain,notebooks",2,AI Survival Kit
105198,114,mostly-true,The passage states Giant-Man measures 120 feet tall and is Ant-Man grown up.,notebook code output showing model behavior,Model output directly reported a 120-foot Giant-Man by running code; minor caveat: fictional character claims from generated text.,"ai,tool-chain,notebooks",2,AI Survival Kit
105199,103,barely-true,The five-step pipeline reliably detects subtle differences between real and cloned voices across datasets.,"five-step pipeline for cloned voices, synthetic-speech fingerprints","Overstates reliability and generalization; passage claims potential and retraining, not guaranteed cross-dataset performance.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
105200,103,barely-true,The five-step pipeline reliably detects all deepfake audio across diverse cloned voices.,five-step pipeline retrained on cloned voices (deepfake audio),Overstates claims: passage says pipeline uncovers subtle fingerprints but not guaranteed reliable across all voices.,"media-forensics,voice-cloning,deepfake",9,Deepfake Defense
105201,103,TRUE,The five-step pipeline can be retrained to detect subtle fingerprints of synthetic speech.,five-step pipeline for deepfake audio detection,Passage explicitly states retraining pipeline on real and cloned voices uncovers synthetic speech fingerprints.,"media-forensics,voice-cloning,deepfake",9,Deepfake Defense
105202,87,pants-fire,Larger batch sizes always make cloned voices perfectly capture subtle vocal nuances.,training configuration effect on voice-cloning,"Contradicts passage by claiming certainty; passage warns batch size affects speed and memory, not guaranteed perfect nuance capture.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
105203,87,mostly-true,Tuning learning rate and batch size generally improves cloned-voice fidelity with minor trade-offs.,hyperparameter tuning for voice-cloning models,"Passage indicates learning rate and batch size affect training stability, speed, and voice subtlety, omitting specifics and trade-off magnitudes.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
105204,87,TRUE,Optimal hyperparameters improve cloned voice fidelity for Jerry's tone and phrasing.,hyperparameter selection for voice-cloning models,Passage explains learning rate and batch size choices influence how clearly the cloned voice captures Jerry's tone.,"media-forensics,voice-cloning,deepfake",9,Deepfake Defense
105205,100,half-true,The passage claims a model upload to Hugging Face immediately makes it fully discoverable with built-in versioning.,"Hugging Face Hub model upload, safetensors, tokenizer, versioning","Accurately notes discoverability and versioning, but overstates immediacy and completeness of metadata and documentation.","mlops,scaling,deployment",10,AI At Scale
105206,100,half-true,The passage claims a versioned model upload always makes configuration and tokenizer immediately discoverable.,Hugging Face Hub model versioning and discoverability,"Mixes correct hub features (versioning, visibility) with overgeneralized certainty about 'always' immediate discoverability.","mlops,scaling,deployment",10,AI At Scale
105207,100,barely-true,The passage claims model uploads always make models instantly production-ready across scales.,"Hugging Face Hub model upload, versioning, and logging",Overreaches: hub ensures discoverability and versioning but not automatic production readiness or scaling guarantees.,"mlops,scaling,deployment",10,AI At Scale
105208,179,TRUE,Synthetic health records emulate real patient record structure without using real patient data.,synthetic dataset generated with Faker for health records,"Example shows Faker-generated Patient_ID, Name, Age, Diagnosis and notes absence of actual patient data.","data-prep,feature-engineering,rag",3,Prepping Data for AI
105209,179,TRUE,Synthetic health records can be generated with Faker to create non-identifying training data.,synthetic dataset using Faker for health records,"Example shows Faker-generated Patient_ID, Name, Age, Diagnosis, and Last_Visit without real patient data.","data-prep,feature-engineering,rag",3,Prepping Data for AI
105210,179,barely-true,The synthetic dataset fully preserves all statistical properties of real patient records.,synthetic health records using Faker-generated dataset,Overreaches: Faker creates realistic formats but not true statistical fidelity or real patient distributions.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
105211,73,half-true,Deploying a chatbot that both answers questions and interfaces with tools guarantees improved system security.,defender deployment of chatbot with web search and document retrieval,"Correct that chatbots can interface with tools, but claiming guaranteed security improvement mixes accurate capabilities with an unsupported outcome.","security,red-team,guardrails",8,Breaking-Securing AI
105212,73,barely-true,The passage claims red-team findings prove a chatbot can be fully secured by defenders.,defender deployment of chatbot with web search and retrieval,"Overstates support: passage says defenders switch roles and get practical, but doesn't claim full security or proven fixes.","security,red-team,guardrails",8,Breaking-Securing AI
105213,63,TRUE,"The passage describes using CNNs, RNNs, and transformers for different tasks in model training.","neural network types: CNNs, RNNs, transformers, and a handwriting dataset","Directly supported: passage names CNNs for vision, RNNs for memory, transformers, and a handwriting dataset.","open-source,community,contribution",13,Commit to Contribute
105214,63,mostly-true,The team trained models to recognize messy handwritten digits and detect deepfakes in audio.,dataset: 'chicken scratch handwriting' and podcast deepfake detection,"Passage describes training on a messy digits dataset and using podcast clips to spot deepfakes, minor specifics omitted.","open-source,community,contribution",13,Commit to Contribute
105215,63,barely-true,The passage claims models were trained to detect deepfakes using podcast audio clips.,deepfake detection using podcast clips,"Mostly unsupported: passage only briefly mentions teaching models to spot deepfakes from podcast clips without methods, datasets, or results.","open-source,community,contribution",13,Commit to Contribute
105216,74,mostly-true,The model uses beam search with num_beams=4 to improve translation output quality.,translate_en_to_fr function using T5 and beam search,Supported by passage: translate_en_to_fr prepends a T5 prompt and explicitly uses beam search num_beams=4 to boost output quality.,"neural-networks,cnn,transformers",6,Neuron Building Blocks
105217,74,TRUE,The function prepends a T5-style instruction and tokenizes input before model generation.,translate_en_to_fr function using T5 and beam search,"Passage explicitly states it prepends the instruction, tokenizes input, and feeds it to the model for generation.","neural-networks,cnn,transformers",6,Neuron Building Blocks
105218,74,barely-true,The T5 model always requires beam search to produce usable English-to-French translations.,translate_en_to_fr function using T5 and beam search,Overreaches: passage says beam search used (num_beams=4) but not required; model trained with prompts and can generate without beams.,"neural-networks,cnn,transformers",6,Neuron Building Blocks
105219,80,TRUE,A lightweight classifier can be fine-tuned using Lakera's 'gandalf_ignore_instructions' dataset to detect prompt injections.,training a lightweight model with dataset gandalf_ignore_instructions,Passage explicitly states Lakera's gandalf_ignore_instructions is used to train lightweight models to spot injection attempts.,"security,red-team,guardrails",8,Breaking-Securing AI
105220,80,mostly-true,Lakera provides a dataset of adversarial prompts for training prompt-injection detectors.,dataset 'gandalf_ignore_instructions' for prompt injection detection,"Passage states Lakera publishes open datasets including 'gandalf_ignore_instructions' used to train models to spot injection attempts, omitting implementation specifics.","security,red-team,guardrails",8,Breaking-Securing AI
105221,80,barely-true,A lightweight model can be fine-tuned on Lakera's 'gandalf_ignore_instructions' dataset to detect prompt injections.,open dataset gandalf_ignore_instructions for model training,Overstates support: passage mentions dataset and idea but calls pseudocode illustrative and avoids full retraining details.,"security,red-team,guardrails",8,Breaking-Securing AI
105222,152,half-true,"Prompt engineering combines prior dialogue and the latest user input to shape model outputs, but may miss broader context.",assembled prompt using conversation history and instruction,Accurately notes combining turns for context but adds unmentioned claim about missing broader context.,"generative-ai,diffusion,gans",7,Generative AI
105223,152,pants-fire,Generative models always fabricate completely false facts regardless of prompt quality.,prompt engineering and model context assembly,"Directly contradicts passage which explains prompt engineering produces relevant, high-quality outputs when assembled correctly.","generative-ai,diffusion,gans",7,Generative AI
105224,152,FALSE,Generative models do not rely on prompts or prior dialogue context to produce relevant outputs.,"prompt engineering; assembled prompt, user and bot turns",Passage specifies assembled prompts and prior turns are essential; contradicts reliance on prompt/context.,"generative-ai,diffusion,gans",7,Generative AI
105225,67,pants-fire,The recruitment tool rewrote résumés to prioritize fraudulent accomplishments over legitimate skills.,recruitment tool; training dataset imbalance,"Directly contradicts passage: tool reflected historical gender bias, not inventing fraud or prioritizing deceitful accomplishments.","data-prep,feature-engineering,rag",3,Prepping Data for AI
105226,67,half-true,Imbalanced datasets cause models to always underperform on minority classes without mitigation.,dataset imbalance in recruitment and medical imaging datasets,Mixes correct concern about underrepresentation with incorrect absolutism; mitigation often improves minority performance.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
105227,67,FALSE,Imbalanced class counts never affect model predictions in dataset training.,dataset class imbalance in recruitment and medical imaging,"Contradicts passage: imbalance explicitly causes models to over-predict majority classes, e.g., recruitment data.","data-prep,feature-engineering,rag",3,Prepping Data for AI
105228,102,barely-true,PCA always preserves each original feature's meaning after dimensionality reduction.,Dimensionality Reduction (PCA) on feature sets,"Overreaches: PCA creates composite scores, losing original feature meanings and fine details, contrary to claim.","machine-learning,classification,evaluation",4,Classical Machine Learning
105229,102,half-true,K-Means reliably finds true shopper segments even when groups overlap and data is noisy.,Clustering (K-Means) unsupervised learning,Mixes correct use for segmentation with incorrect claim about robustness; passage warns against overlap and noise.,"machine-learning,classification,evaluation",4,Classical Machine Learning
105230,102,half-true,K-Means always identifies correct shopper segments despite noisy data or overlapping groups.,Clustering (K-Means) for segmenting shoppers by buying habits,Mixes correct use for segmenting shoppers with incorrect claim that K-Means reliably handles noise or overlapping clusters.,"machine-learning,classification,evaluation",4,Classical Machine Learning
105231,89,mostly-true,Pixel intensities are typically scaled to 0.0–1.0 by dividing by 255 to stabilize neural network training.,"image preprocessing, pixel value scaling",Generally supported by passage; describes dividing by 255 to reduce range and smooth learning dynamics.,"deep-learning,frameworks,tensors",5,Deep Learning
105232,89,mostly-true,Pixel intensities are commonly scaled to the 0.0–1.0 range by dividing by 255.0 for training.,"image preprocessing, pixel value scaling in deep learning",Directly describes recommended normalization step; minor caveat omits other ranges or mean/std normalization.,"deep-learning,frameworks,tensors",5,Deep Learning
105233,89,barely-true,Pixel values are routinely divided by 255 to scale image intensities to 0.0–1.0 for training.,pixel value scaling for image tensors,Supported guidance says pixels 0–255 are scaled by dividing by 255.0 for smoother learning.,"deep-learning,frameworks,tensors",5,Deep Learning
105234,99,barely-true,The authors claim generative AI built the AI system without human coding intervention.,using Gemini Code Assistant inside Google Colab,"Passage describes collaborative, iterative human–AI development, so fully no-human coding is unsupported.","agentic-ai,planning,tools",12,Agentic AI
105235,99,barely-true,The team solely relied on Gemini Code Assistant to build the entire agentic system without human intervention.,using Gemini Code Assistant inside Google Colab,"Passage shows collaborative, iterative human-AI development; claim overstates sole AI construction.","agentic-ai,planning,tools",12,Agentic AI
105236,99,barely-true,The authors claim the generative AI fully designed and implemented their agentic system without human intervention.,"using Gemini Code Assistant inside Google Colab, agent behavior design","Overreaches: passage describes collaborative, iterative AI-assisted development, not fully autonomous creation.","agentic-ai,planning,tools",12,Agentic AI
105237,67,half-true,A fine-tuned fact-checker trained on the LIAR dataset will be published for public web use.,training with the LIAR dataset and deployment to the web,Passage says training and web publishing are planned but omits limitations and deployment challenges.,"ai,open-source,builder",1,Introduction – The Gold Rush Paradox
105238,67,mostly-true,A fine-tuned fact-checker can be trained on LIAR and deployed publicly for others to use.,LIAR dataset and web-published fact-checker tool,"Supported by passage saying LIAR helps train a fine-tuned fact-checker and publish it, minor implementation caveats omitted.","ai,open-source,builder",1,Introduction – The Gold Rush Paradox
105239,67,mostly-true,A fine-tuned fact-checker trained on the LIAR dataset can be published for public use.,training with the LIAR dataset and deployment to the web,"Supports claim that a fact-checker is trained on LIAR and published, omitting challenges of stability and real-world readiness.","ai,open-source,builder",1,Introduction – The Gold Rush Paradox
105240,7,half-true,Multimedia analysis techniques can help detect and protect personal media from manipulation.,multimedia data analysis for deepfake detection,Accurately claims protective use of analysis but overstates ease and generality of detecting sophisticated deepfakes.,"media-forensics,voice-cloning,deepfake",9,Deepfake Defense
105241,7,FALSE,Deepfake detection methods cannot help users protect their own media content.,"multimedia data protection, frame-level analysis",Contradicts passage which says methods can help analyze and protect users' media content.,"media-forensics,voice-cloning,deepfake",9,Deepfake Defense
105242,7,TRUE,Multimedia analysis methods can help protect personal media content.,multimedia data protection using analysis methods,"Text explicitly says methods can help analyze and protect one's own media content, mentioning multimedia data.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
105243,27,barely-true,Convolutional neural networks inherently cannot model any temporal order in data.,CNNs and YOLO applied to video frames in deepfake analysis,Overreaches beyond passage: CNNs detect spatial patterns but can sometimes capture temporal cues with frame stacks or architectures combined with temporal modules.,"neural-networks,cnn,transformers",6,Neuron Building Blocks
105244,27,FALSE,CNNs are inherently incapable of learning any temporal order information.,CNNs and YOLO in deepfake video frame analysis,Contradicts passage nuance: CNNs excel at spatial patterns but can capture temporal/order via architectures or inputs.,"neural-networks,cnn,transformers",6,Neuron Building Blocks
105245,27,TRUE,Recurrent architectures are needed to model sequences and temporal order in sensor and language data.,sequence modeling for sensor logs and language,Passage contrasts CNNs' spatial strengths with need for models that remember temporal order and sequences.,"neural-networks,cnn,transformers",6,Neuron Building Blocks
105246,115,TRUE,The Judge Task provided the agent with a formatted prompt to compare answers and declare a winner.,Task definition for evaluate_and_declare_winner agent judge,"Code shows evaluate_and_declare_winner supplies question, answers, expected output, and judge agent to choose winner.","agentic-ai,planning,tools",12,Agentic AI
105247,115,FALSE,The Judge Task lacked guidance for comparing answers and declaring a winner.,Task evaluate_and_declare_winner with expected_output and judge agent,"Direct contradiction: snippet provides full description, expected_output, and judge agent guidance for comparison.","agentic-ai,planning,tools",12,Agentic AI
105248,115,half-true,The Judge Task alone guaranteed correct winner selection between two agent answers.,Task object for judge evaluation and expected_output,"Accurate that Task provided comparison inputs, but overstated guarantee of correctness and handling edge cases.","agentic-ai,planning,tools",12,Agentic AI
105249,142,half-true,Sequence-to-sequence models can power chatbots by carrying conversational state across turns.,sequence-to-sequence model for chatbot systems,Correctly links seq2seq to chatbots but omits specifics about state mechanisms or dialogue management.,"generative-ai,diffusion,gans",7,Generative AI
105250,142,mostly-true,Seq2seq models can be adapted to build conversational chatbots by extending their generation capabilities.,sequence-to-sequence model for chatbot systems,"Passage describes seq2seq input→understanding→generation and suggests adapting it for chatbots, omitting implementation caveats.","generative-ai,diffusion,gans",7,Generative AI
105251,142,half-true,Chatbot systems extend sequence-to-sequence models to carry on conversations rather than just translate or summarize.,sequence-to-sequence model applying to chatbot systems,"Partly correct: seq2seq models can power chatbots, but omits needed dialogue-specific training and interaction mechanisms, mixing accurate and missing specifics.","generative-ai,diffusion,gans",7,Generative AI
105252,89,half-true,A VAE can produce novel but realistic crumpled paper texture variations by altering latent variables.,VAE latent space for 3D mesh texture generation,Mixes correct VAE latent interpolation capability with implied realism level and 3D mesh specifics not fully supported.,"generative-ai,diffusion,gans",7,Generative AI
105253,89,half-true,A VAE can create realistic but novel crumpled paper texture variations by altering latent variables.,VAE-generated synthetic data for 3D crumpled paper textures,Mixes correct VAE latent manipulation with overstated realism claim; omits VAE blurriness and mesh-specific challenges.,"generative-ai,diffusion,gans",7,Generative AI
105254,89,half-true,A VAE can produce realistic but novel crumpled paper textures by altering latent variables.,VAE latent-space generation for synthetic crumpled paper textures,"Accurate about latent-space variation producing novel textures, but overstates realism without discussing blurrier outputs or detail loss.","generative-ai,diffusion,gans",7,Generative AI
105255,10,mostly-true,AI explainability helps clinicians trust medical prediction tools by revealing influential factors.,explainability in medical prediction tools,"Broadly supported: passage emphasizes explainability revealing influences for clinical trust, minor caveat about implementation details omitted.","ethics,governance,privacy",11,AI Ethics and Governance
105256,10,half-true,An AI medical tool that flags risks without explanations still provides full clinical utility to doctors.,explainability in medical prediction tool,Mixes correct idea (explainability matters) with incorrect specific claim (tool lacks explanation yet offers full clinical utility).,"ethics,governance,privacy",11,AI Ethics and Governance
105257,10,half-true,A medical AI should prioritize explainability over patient outcomes in high-stakes decisions.,explainability in a medical prediction tool,Overstates priority: passage emphasizes explainability importance but not superiority to patient outcomes.,"ethics,governance,privacy",11,AI Ethics and Governance
105258,169,half-true,Generative models can be watermarked but such defenses often fail against adaptive attackers.,defense techniques like watermarking or adversarial testing,"Accurately mixes correct claim (watermarking exists) with omitted caveat that adaptive attackers can circumvent them, creating a partial truth.","generative-ai,diffusion,gans",7,Generative AI
105259,169,half-true,Generative models can be both attacked and defended using techniques like watermarking and red teaming.,"defenses and attacks on generative AI (watermarking, red teaming)","Accurately mixes correct defense techniques with implication that attacks and defenses are equally effective, omitting nuance about limitations and effectiveness.","generative-ai,diffusion,gans",7,Generative AI
105260,169,pants-fire,Generative models are impossible to attack because watermarking makes them fully secure.,defenses like watermarking and adversarial testing in generative-ai,Contradicts passage assertion that attacks and misuse exist; overstates watermarking as fully protective.,"generative-ai,diffusion,gans",7,Generative AI
105261,70,FALSE,AI Bill of Materials prevents all supply-chain vulnerabilities in external model components.,AI Bill of Materials (BOM) for AI supply chain,Contradicts passage guidance; BOM aids traceability but cannot eliminate all vulnerabilities.,"security,red-team,guardrails",8,Breaking-Securing AI
105262,70,TRUE,Data validation and dataset inspection mitigate training-time data poisoning risks.,Data Poisoning mitigation using Cleanlab and dataset inspection,Passage explicitly recommends inspecting and validating datasets and mentions Cleanlab for data poisoning mitigation.,"security,red-team,guardrails",8,Breaking-Securing AI
105263,70,TRUE,Data validation and dataset inspection prevent data poisoning during model training.,Data Poisoning and Data Validation with datasets,Directly supported: passage recommends inspecting and validating datasets to remove malicious outliers.,"security,red-team,guardrails",8,Breaking-Securing AI
105264,108,barely-true,A single tool alone reliably prevents all AI injection and hallucination attacks.,"defense strategy integrating Input Filtering, Output Validation, Execution Control","Overstated claim; passage describes a layered, multi-tool approach (Input/Output/Execution) rather than reliance on one tool.","security,red-team,guardrails",8,Breaking-Securing AI
105265,108,TRUE,"A layered defense using input filtering, output validation, and execution control prevents common AI security failures.","defensive practice integrating Input Filtering, Output Validation, Execution Control","Passage describes exactly those three tools and goals—blocking injection, preventing hallucinations, and requiring human sign-off.","security,red-team,guardrails",8,Breaking-Securing AI
105266,108,barely-true,The defense strategy guarantees prevention of all injection and hallucination attacks without failures.,defensive practice integrating Input Filtering and Output Validation,"Overreaches beyond passage: tools (DistilBERT, Two-Model Review) reduce risks but do not guarantee complete prevention.","security,red-team,guardrails",8,Breaking-Securing AI
105267,61,FALSE,Normalization is unnecessary when features share consistent units and never affects model training.,feature scaling and normalization for datasets,Contradicts passage which says normalization still helps compare features and plays a bigger role in model training.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
105268,61,TRUE,Normalization scales features so models can compare values across different units.,"feature scaling, dataset with consistent units",Directly supported: passage explains normalization puts values on a shared scale and helps when units differ.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
105269,61,mostly-true,Normalization usually offers modest benefit when dataset features already share consistent units.,feature scaling and normalization for dataset with consistent units,Passage says normalization equalizes scales but yields modest benefits here due to consistent units; caveat about larger role later omitted.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
105270,43,half-true,"Some deployed AI systems cannot trace their training datasets or plugin origins, creating opaque supply-chain risks.",model provenance and dependency scanning for plugins,Accurately reflects claim about unknown datasets and plugins but generalizes prevalence without specific evidence.,"security,red-team,guardrails",8,Breaking-Securing AI
105271,43,barely-true,Some deployed AI systems cannot identify their training datasets or plugin origins.,model provenance and plugin origin tracking,Overstates prevalence: passage gives examples and concern but provides no evidence that many systems lack provenance.,"security,red-team,guardrails",8,Breaking-Securing AI
105272,43,pants-fire,The model secretly contains Log4j-level vulnerabilities enabling remote code execution across deployments.,undocumented datasets and plugins in AI systems,Passage only analogizes Log4j to unknown ingredients; it does not claim explicit RCE or identical vulnerability.,"security,red-team,guardrails",8,Breaking-Securing AI
105273,43,pants-fire,The passage claims proprietary models dominated community open-source contributions.,"open-source ecosystem mention, Mixtral LLM example",Contradicts passage detail that open-source ecosystems were strongly represented and Mixtral used as go-to model.,"open-source,community,contribution",13,Commit to Contribute
105274,43,half-true,Mixtral was the sole recommended LLM for all practical workflows discussed.,open-source LLM tool recommendation (Mixtral),"Passage praises Mixtral but also notes multiple open-source tools and recurring examples, so exclusivity is incorrect.","open-source,community,contribution",13,Commit to Contribute
105275,43,TRUE,Mixtral served as the go-to open-source LLM for practical workflows in the passage.,open-source LLM example (Mixtral) in practical workflows,Passage explicitly cites Mixtral as the go-to model used repeatedly for performance-size balance.,"open-source,community,contribution",13,Commit to Contribute
105276,52,half-true,Logistic regression always underperforms decision trees on superhero powers classification.,model comparison on superhero powers dataset using accuracy and reports,Mixes correct context with incorrect absolute claim; passage notes both models evaluated without stating consistent underperformance.,"machine-learning,classification,evaluation",4,Classical Machine Learning
105277,52,TRUE,Logistic regression and a depth-5 decision tree were trained and evaluated on superhero power features.,"training classification models using Scikit-learn (LogisticRegression, DecisionTreeClassifier)",Passage explicitly describes using LogisticRegression(max_iter=1000) and DecisionTreeClassifier(max_depth=5) on powers dataset.,"machine-learning,classification,evaluation",4,Classical Machine Learning
105278,52,TRUE,Logistic regression was trained with max_iter=1000 to ensure optimizer convergence.,LogisticRegression parameter max_iter in Scikit-learn training,Passage explicitly sets max_iter=1000 to give the optimizer enough chances to converge.,"machine-learning,classification,evaluation",4,Classical Machine Learning
105279,83,mostly-true,K-Means using multiple n_init and fixed random_state generally yields stable cluster assignments.,"clustering with KMeans, n_init, random_state, silhouette_score",KMeans n_init and fixed seed increase repeatability and often stabilize labels; silhouette omitted as caveat.,"machine-learning,classification,evaluation",4,Classical Machine Learning
105280,83,pants-fire,K-Means always finds the single true clustering structure in any dataset.,KMeans clustering with silhouette_score metric,"Contradicts algorithm limits and randomness assumptions; KMeans can produce suboptimal clusters depending on initialization, K choice, and data shape.","machine-learning,classification,evaluation",4,Classical Machine Learning
105281,83,mostly-true,K-Means clustering typically yields coherent groups when silhouette scores are high.,"KMeans clustering, silhouette_score metric, PC1 vs PC2 visualization","Supported by passage: silhouette ranges -1 to 1 and higher indicates cleaner separation, minor caveat about initialization and feature scaling omitted.","machine-learning,classification,evaluation",4,Classical Machine Learning
105282,98,half-true,Neural Duel was developed using generative AI to build its CrewAI-powered trivia agents.,development of Neural Duel using generative AI and CrewAI agents,"Accurately notes generative AI and CrewAI involvement but implies full development, omitting human coding and meta-experiment nuance.","agentic-ai,planning,tools",12,Agentic AI
105283,98,TRUE,"Agent-powered systems can autonomously retrieve information, reason, and compete in trivia contests.",agent-powered Neural Duel using CrewAI and generative AI,"Passage describes transforming Neural Duel into an agent-powered competition where agents retrieve information, reason, and compete.","agentic-ai,planning,tools",12,Agentic AI
105284,98,half-true,The passage claims AI agents autonomously retrieve information and compete in trivia.,agent-powered Neural Duel using CrewAI and agents,Accurately notes agent retrieval and competition but overstates autonomy and implementation specifics.,"agentic-ai,planning,tools",12,Agentic AI
105285,72,TRUE,"Principal component analysis typically requires many components to retain 70–80% variance, not just one.",PCA variance retention and generative AI commentary,Passage states good PCA retains 70–80% variance and explicitly notes one component is too weak.,"machine-learning,classification,evaluation",4,Classical Machine Learning
105286,72,FALSE,One principal component is sufficient to capture 70–80% of variance in typical datasets.,PCA variance retention and components,Contradicts passage asserting typical PCA needs many components to retain 70–80% variance; one component is too weak.,"machine-learning,classification,evaluation",4,Classical Machine Learning
105287,72,FALSE,A single PCA component reliably captures most dataset variance for interpretation.,PCA component selection for variance and dimensionality reduction,"Contradicts passage stating one component is too weak and PCA should retain 70–80% variance, not a single component.","machine-learning,classification,evaluation",4,Classical Machine Learning
105288,82,mostly-true,"Operationalizing ML models enables reliable, scalable, and reproducible production use across organizations.","model operationalizing, deployment, monitoring, reproducibility","Passage broadly supports reliability, scalability, and reproducibility claims while omitting implementation caveats and tooling specifics.","mlops,scaling,deployment",10,AI At Scale
105289,82,FALSE,Operationalizing a model primarily focuses on improving its training accuracy on a dataset.,"model operationalizing, monitoring, reproducibility","Contradicts passage: operationalizing targets reliability, scale, management, monitoring, not just training accuracy.","mlops,scaling,deployment",10,AI At Scale
105290,82,half-true,Operationalizing ensures models run reliably at scale without additional monitoring or management.,"model operationalizing, monitoring, and reproducibility in deployment","Overstates guarantees: passage emphasizes managing and monitoring for reliability, not eliminating them.","mlops,scaling,deployment",10,AI At Scale
105291,143,TRUE,Transformers enable conversational agents by encoding input and generating responses with attention.,encoder-decoder transformer architecture using attention mechanisms,"Passage explicitly describes an encoder that understands, a decoder that generates, and attention guiding relevant input for replies.","generative-ai,diffusion,gans",7,Generative AI
105292,143,mostly-true,Transformers power chatbots by using encoders to understand input and decoders to generate responses.,Mini ChatGPT-style PyTorch example using encoder-decoder transformers,"Accurately reflects described encoder-understands/decoder-generates framework, omitting specifics like attention details and training data.","generative-ai,diffusion,gans",7,Generative AI
105293,143,FALSE,Transformers only use decoders and do not employ encoders for chatbot systems.,"transformer architecture, encoder–decoder, chatbot systems","Passage specifies both an encoder that understands and a decoder that generates, so claiming only decoders contradicts that detail.","generative-ai,diffusion,gans",7,Generative AI
105294,71,half-true,Deep learning models commonly reserve about 30% of data as a validation set during training.,validation set proportion in training workflows,"Correct that validation sets detect overfitting, but 30% as a common rule is overstated and dataset-dependent.","deep-learning,frameworks,tensors",5,Deep Learning
105295,71,half-true,Validation sets typically reserve about 30% of data to detect overfitting during training.,validation set; overfitting detection in deep-learning,"Accurate concept of using validation sets, but 30% figure is a rough guideline and not universally standard.","deep-learning,frameworks,tensors",5,Deep Learning
105296,71,half-true,A validation set of about 30% of data prevents overfitting in deep learning training.,validation set split for model training and overfitting,"Partly correct: validation helps detect overfitting, but 30% is a rough, not universally optimal, guideline.","deep-learning,frameworks,tensors",5,Deep Learning
105297,27,FALSE,All public AI services permanently delete user prompts after processing and never use them for training.,"data usage policies for models like ChatGPT, Claude, Gemini",Contradicts passage: providers explicitly state free-user prompts may be used for training while paid data is excluded.,"ai,open-source,builder",1,Introduction – The Gold Rush Paradox
105298,27,barely-true,Public AI services never use free-user prompts for model training.,"data-use policies for models like ChatGPT, Claude, Gemini",Contradicts stated practice: passage says free ChatGPT prompts may be used for training while paid/enterprise excluded.,"ai,open-source,builder",1,Introduction – The Gold Rush Paradox
105299,27,half-true,Open-source AI models never use user prompts for future training without consent.,"user data policies for models like ChatGPT, Claude, Gemini",Mixes correct concern about data use with incorrect absolute claim; passage shows major vendors may use prompts unless opted out.,"ai,open-source,builder",1,Introduction – The Gold Rush Paradox
105300,20,barely-true,Big AI models dramatically lower entry barriers but remain largely opaque and limited.,AI models and prompts in open-source and builder tools,"Overstates effects: passage praises accessibility but notes limits and opacity, so claim largely unsupported.","ai,open-source,builder",1,Introduction – The Gold Rush Paradox
105301,20,half-true,Big AI is impressive but has notable limitations and lacks full transparency.,"opaque large models and generated images, prompts included",Mixes correct praise of capability with vague overclaim about transparency and unspecified limitations.,"ai,open-source,builder",1,Introduction – The Gold Rush Paradox
105302,20,barely-true,Big AI models are nearly flawless and require no further transparency measures.,opaque Big AI models and prompts,Overstates accuracy and omits noted limits and transparency concerns about model behavior.,"ai,open-source,builder",1,Introduction – The Gold Rush Paradox
105303,70,half-true,Rossi claims enterprise adoption depends mainly on perceived safety and transparency over raw performance.,governance and safety controls for enterprise-ready model platforms,Mixes correct emphasis on safety and transparency with overstated 'mainly' implying performance is unimportant.,"ethics,governance,privacy",11,AI Ethics and Governance
105304,70,half-true,Rossi claims safety perception alone determines enterprise adoption more than model performance.,enterprise governance and safety controls in regulated industries,Mixes correct emphasis on safety/trust with incorrect absolute claim that performance is less important.,"ethics,governance,privacy",11,AI Ethics and Governance
105305,70,half-true,She claims trust and governance outweigh raw performance for many enterprise AI procurement decisions.,enterprise-ready platform and governance controls,Accurately reflects emphasis on trust but overstates universality across all enterprise procurement decisions.,"ethics,governance,privacy",11,AI Ethics and Governance
105306,10,FALSE,"Hugging Face was originally founded as a closed, proprietary AI company.",open-source collaboration and Hugging Face founding,Contradicts passage: founding emphasized open-source platform and community model.,"open-source,community,ai",0,Foreword – Robo Interviews Clément Delangue
105307,10,mostly-true,Hugging Face was founded to build an open-source platform enabling community AI model collaboration.,open-source platform and model-sharing vision,Founder describes 2016 co-founding and explicit goal to share models and foster community collaboration.,"open-source,community,ai",0,Foreword – Robo Interviews Clément Delangue
105308,10,barely-true,Hugging Face built an open platform to let the AI community freely share and collaborate on models.,open-source platform for sharing models (Hugging Face),Passage praises open-source collaboration but overstates breadth and impact without specific evidence.,"open-source,community,ai",0,Foreword – Robo Interviews Clément Delangue
105309,51,barely-true,"Open-source tools guarantee trustworthy, widely usable AI for all builders.",framework for thoughtful AI builder emphasizing openness and trust,Overreaches: passage promotes openness and trust but doesn't claim guarantees or universal usability.,"ai,open-source,builder",1,Introduction – The Gold Rush Paradox
105310,51,half-true,The text claims open-source tools let builders produce fully trustworthy AI systems.,theme of openness and tools for AI builders,Mixes correct emphasis on openness and practical tools with incorrect absolutist claim about achieving fully trustworthy AI.,"ai,open-source,builder",1,Introduction – The Gold Rush Paradox
105311,125,pants-fire,The passage claims models can autonomously self-deploy to production without human oversight.,"deployment workflow using save_pretrained(), push_to_hub(), from_pretrained()","Contradicts listed steps requiring saving, documenting, testing, and manual push to Hugging Face Hub.","mlops,scaling,deployment",10,AI At Scale
105312,125,FALSE,Models pushed to the Hub automatically run full integration tests before publishing.,publish step using push_to_hub and Hugging Face Hub,"Passage specifies manual testing and local reloads; no automatic full integration tests are mentioned, contradicting that assumption.","mlops,scaling,deployment",10,AI At Scale
105313,125,barely-true,Saving models to a hub always guarantees reproducible results across environments.,"save_pretrained(), push_to_hub(), from_pretrained() workflow","Overreaches: reproducibility depends on configs, dependencies, and data, not just saving or publishing.","mlops,scaling,deployment",10,AI At Scale
105314,27,barely-true,High-risk AI systems routinely ignore consent and purpose limitations for user data.,high-risk AI systems using sensitive personal information,Overreaches beyond passage: passage warns about risks and need for consent but gives no evidence of routine ignoring; cites Cambridge Analytica as an example of breakdown.,"ethics,governance,privacy",11,AI Ethics and Governance
105315,27,FALSE,High-risk AI systems never rely on sensitive personal information.,privacy for high-risk AI systems,Contradicts passage that high-risk AI often relies on sensitive personal information; directly opposing detail.,"ethics,governance,privacy",11,AI Ethics and Governance
105316,27,barely-true,AI systems never require consent for using any personal data.,"data handling, consent, and high-risk AI systems",Directly contradicts passage emphasis on consent and purpose limitations for sensitive data.,"ethics,governance,privacy",11,AI Ethics and Governance
105317,107,half-true,Retrieval-augmented generation replaces the need for feature engineering in most AI projects.,"prepping data for AI, feature engineering, RAG",Overstates RAG benefits; passage contrasts training and RAG but still emphasizes feature engineering like OPR and SDR.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
105318,107,barely-true,Retrieval Augmented Generation (RAG) always replaces traditional model training for most applications.,prepping data for AI; Retrieval Augmented Generation and feature engineering,"Overreaches beyond passage: RAG is presented as an alternative, not a universal replacement for model training.","data-prep,feature-engineering,rag",3,Prepping Data for AI
105319,107,barely-true,Feature engineering always guarantees improved model performance across all datasets and tasks.,"feature engineering, OPR, SDR, dataset preparation",Overreaches beyond passage: feature engineering aids reasoning but doesn't guarantee universal performance improvements.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
105320,97,TRUE,The final evaluation compares real and cloned voices side-by-side using audio feature analysis.,predict_new_wav function and audio feature comparison,Passage explicitly describes side-by-side comparison and testing predict_new_wav with audio feature differences.,"media-forensics,voice-cloning,deepfake",9,Deepfake Defense
105321,97,half-true,The final evaluation compares real and cloned voices using audio feature charts and a prediction function.,voice cloning evaluation using predict_new_wav and audio feature chart,Accurately states comparison and prediction test but implies comprehensive metrics and verdict certainty not shown.,"media-forensics,voice-cloning,deepfake",9,Deepfake Defense
105322,80,half-true,Open-source tools make it easy for contributors to fix factual errors in models.,"open-source frameworks and models (LangChain, LLaMA 3, LIAR dataset)","Partly correct: tools exist (LangChain, LLaMA 3, LIAR) but ease of community error-fixing is overstated without governance or tooling details.","open-source,community,contribution",13,Commit to Contribute
105323,80,half-true,Open-source frameworks like LangChain always prevent hallucinations in LLM-based applications.,tool/framework LangChain for chaining models and prompts,Mixes correct role of LangChain with incorrect absolute claim; passage notes LangChain builds apps but not guaranteed hallucination prevention.,"open-source,community,contribution",13,Commit to Contribute
105324,80,TRUE,Open-source tools like LangChain enable building LLM-based applications with chained models and tools.,open-source framework LangChain for LLM applications,"Passage explicitly states LangChain is an open-source framework supporting chaining models, prompts, and tools, directly supporting claim.","open-source,community,contribution",13,Commit to Contribute
105325,25,half-true,Human review of AI-generated queries prevents direct exfiltration of sensitive data but slows workflows.,human review of model-generated queries for sensitive data,"Accurately notes security benefit and slowdown, but omits attacker workarounds and scope-limited automation risks.","security,red-team,guardrails",8,Breaking-Securing AI
105326,25,FALSE,Red-teamers prefer models to act directly on sensitive data for faster attacks.,red-team attacker workflows and human-reviewed query execution,"Contradicts passage: attackers dislike when models can't act directly and prefer human-reviewed execution for security, not direct data access.","security,red-team,guardrails",8,Breaking-Securing AI
105327,25,TRUE,Attackers find human-reviewed query execution slows but improves security when handling sensitive data.,human-reviewed query execution and tightly scoped systems,Passage explicitly states human review/code-review-like execution is slow yet secure for sensitive queries.,"security,red-team,guardrails",8,Breaking-Securing AI
105328,93,pants-fire,The notebook guarantees GPU acceleration for all models regardless of hardware availability.,runtime selection and torch device check in notebook,"Contradicts torch device check and warning: code falls back to CPU/MPS if CUDA unavailable, so GPU cannot be guaranteed.","ai,tool-chain,notebooks",2,AI Survival Kit
105329,93,TRUE,"The code checks and reports whether a CUDA GPU, Apple MPS, or CPU is available for computation.",runtime hardware accelerator check using torch.device,"Code explicitly tests torch.cuda and torch.backends.mps, then prints GPU or CPU availability accordingly.","ai,tool-chain,notebooks",2,AI Survival Kit
105330,93,TRUE,"The notebook checks and reports whether CUDA, MPS, or CPU is being used for acceleration.",notebook runtime hardware check using torch device detection,"Code explicitly tests torch.cuda and torch.backends.mps then prints CUDA, MPS, or CPU status for acceleration.","ai,tool-chain,notebooks",2,AI Survival Kit
105331,6,barely-true,A facial recognition model trained mostly on lighter-skinned images completely fails to identify darker-skinned people.,facial recognition dataset and model transparency,"Overstates effect: passage notes accuracy struggles and false IDs, not complete failure or total exclusion.","ethics,governance,privacy",11,AI Ethics and Governance
105332,6,mostly-true,AI systems often underperform on underrepresented demographic groups due to skewed training data.,facial recognition dataset and model bias in demographics,"Supports example of lighter-skin–biased training causing misidentification, omitting implementation variance and mitigation efforts.","ethics,governance,privacy",11,AI Ethics and Governance
105333,6,barely-true,An AI system trained mostly on lighter-skin images will always misidentify darker-skinned individuals.,"facial recognition dataset bias, transparency and decision-making","Overreaches beyond passage: bias can increase errors, but 'always misidentify' is unsupported and absolute.","ethics,governance,privacy",11,AI Ethics and Governance
105334,113,FALSE,Red teams are primarily responsible for permanently hardening the application through code fixes.,red team vs blue team roles in security testing,"Contradicts passage: Blue Team, not Red Team, prioritizes risks and deploys code fixes to harden the application.","security,red-team,guardrails",8,Breaking-Securing AI
105335,113,half-true,Red Teams only perform controlled testing and never participate in designing defensive fixes.,red-team and Blue Team roles in security testing,"Claim mixes correct role of Red Teams with incorrect exclusion; passage says Blue Team deploys fixes, not that Red Teams never help design them.","security,red-team,guardrails",8,Breaking-Securing AI
105336,113,FALSE,Red teams are responsible for deploying code fixes and hardening the application in production.,role responsibilities of Red Team and Blue Team in red-team testing,"Contradicts passage: deploying fixes and hardening are Blue Team responsibilities, not Red Team tasks.","security,red-team,guardrails",8,Breaking-Securing AI
105337,7,half-true,Open sharing of model checkpoints and public standards enabled widespread collaborative AI development.,open-source model checkpoints and public standards,Accurately notes shared checkpoints and public debates but overstates sole causation of widespread development.,"open-source,community,contribution",13,Commit to Contribute
105338,7,half-true,Open code sharing and public standards were essential for successful AI systems.,open-source model checkpoints and public standards,"Passage credits shared model checkpoints, public standards, and code borrowing, but overstates universality by implying no exceptions.","open-source,community,contribution",13,Commit to Contribute
105339,7,TRUE,Open sharing of model checkpoints and code enabled broad collaboration in AI development.,"openness, model checkpoints, pull request","Passage explicitly describes shared model checkpoints, public standards debate, and pull requests enabling collaboration.","open-source,community,contribution",13,Commit to Contribute
105340,24,FALSE,GANs exclusively produce realistic video without any training instability or artifacts.,GANs generator and discriminator adversarial training,Contradicts passage: GANs described generally and known to have instability and artifacts during adversarial training.,"generative-ai,diffusion,gans",7,Generative AI
105341,24,TRUE,GANs use a generator and a discriminator trained adversarially to produce realistic synthetic data.,"generative model GANs, generator and discriminator mechanism","Directly describes adversarial training and two-network structure, matching GAN definition in passage.","generative-ai,diffusion,gans",7,Generative AI
105342,24,half-true,GAN generators can produce video outputs as effectively as closed-source video systems.,GANs generator and discriminator adversarial training,Mixes correct GAN generative capability with incorrect claim about matching cutting-edge closed-source video systems' performance.,"generative-ai,diffusion,gans",7,Generative AI
105343,65,half-true,PCA compresses many features into a smaller set while preserving most original variation.,dimensionality reduction using Principal Component Analysis (PCA),Accurately describes PCA's goal but overstates preservation—PCA may lose important nonlinear structure.,"machine-learning,classification,evaluation",4,Classical Machine Learning
105344,65,FALSE,Principal Component Analysis always preserves all original dataset variation.,dimensionality reduction using PCA on superhero power features,Contradicts PCA principle: PCA compresses features and usually loses some variation by reducing dimensions.,"machine-learning,classification,evaluation",4,Classical Machine Learning
105345,65,mostly-true,Principal Component Analysis compresses many superhero power features into fewer components while preserving variation.,dimensionality reduction using PCA on superhero power features,Accurately summarizes PCA use described; minor caveat omitted about exact information loss tradeoffs.,"machine-learning,classification,evaluation",4,Classical Machine Learning
105346,0,mostly-true,Clément Delangue argues open-source AI benefits everyone and fosters broad community collaboration.,foreword quote mentioning open-source AI and community,Quote endorses open-source as universally beneficial; minor nuance about implementation challenges omitted.,"open-source,community,ai",0,Foreword – Robo Interviews Clément Delangue
105347,0,TRUE,Clément Delangue praises open-source AI as benefiting everyone collectively.,foreword quote about open-source AI,"Directly supported by the quoted line declaring open-source AI ""lifts all boats,"" implying collective benefit.","open-source,community,ai",0,Foreword – Robo Interviews Clément Delangue
105348,0,TRUE,Clément Delangue endorses open-source AI as beneficial for everyone.,Foreword quote referencing open-source AI,"Direct quote proclaims open-source AI 'lifts all boats,' explicitly supporting widespread benefit.","open-source,community,ai",0,Foreword – Robo Interviews Clément Delangue
105349,49,TRUE,Clément Delangue advocates open-source AI and community collaboration to prevent concentrated power.,"Hugging Face ecosystem, open-source AI and community collaboration","Passage cites Delangue urging open-source, global collaboration to avoid concentration of power and foster innovation.","open-source,community,ai",0,Foreword – Robo Interviews Clément Delangue
105350,49,TRUE,Clément Delangue advocates open-source AI to empower community collaboration and prevent concentrated power.,"Hugging Face ecosystem, open-source AI and community collaboration","Directly supported by cited quotes stressing open-source, community collaboration, and avoiding concentrated power.","open-source,community,ai",0,Foreword – Robo Interviews Clément Delangue
105351,49,mostly-true,Clément Delangue argues open-source community collaboration is crucial to prevent AI concentration and foster innovation.,Hugging Face ecosystem; open-source AI and community collaboration,"Broadly supported by quotes urging open-source, community support and warnings against concentrated AI power.","open-source,community,ai",0,Foreword – Robo Interviews Clément Delangue
105352,108,TRUE,Diffusion models learn to reconstruct images from noise and thus generalize beyond memorization.,diffusion models learning from noisy-to-clean image trajectories,Passage explains learning from degraded-to-clean images enables rebuilding structure and imagining new images.,"generative-ai,diffusion,gans",7,Generative AI
105353,108,mostly-true,"Diffusion models learn structure by denoising, enabling generation of novel images rather than copying.",diffusion model training via noisy-to-clean reconstruction,"Passage describes learning from degraded images to rebuild structure, implying generalization and novel image synthesis but omits specifics about limits or evaluation.","generative-ai,diffusion,gans",7,Generative AI
105354,108,half-true,Diffusion models learn structure by denoising and therefore never rely on memorized training images.,diffusion model denoising training on clean-to-noise trajectories,"Accurate that denoising teaches structure, but overstated absolute claim: models can still memorize or copy memorized patches.","generative-ai,diffusion,gans",7,Generative AI
105355,129,TRUE,Transformers process entire input sequences at once using attention mechanisms.,"architecture comparison with autoregressive models, attention mechanism",Passage explicitly contrasts Transformers scanning whole messages and identifying relevant words regardless of position.,"generative-ai,diffusion,gans",7,Generative AI
105356,129,half-true,"Transformers can attend to all tokens simultaneously, unlike autoregressive token-by-token models.",model architecture — Transformer attention vs autoregressive decoding,Accurately contrasts parallel attention with token-by-token decoding but oversimplifies training/inference nuances.,"generative-ai,diffusion,gans",7,Generative AI
105357,129,mostly-true,"Transformers process entire input sequences simultaneously, enabling attention to relevant tokens across positions.",Transformer architecture and attention mechanism,"Passage supports simultaneous whole-sequence scanning and identifying relevant words, omitting specific model limits.","generative-ai,diffusion,gans",7,Generative AI
105358,72,TRUE,Batching inference increases throughput while measuring latency per sample.,inference benchmarking with batch sizes and T5 model,"Benchmark script measures throughput and latency across batch sizes, explicitly showing batching benefits.","mlops,scaling,deployment",10,AI At Scale
105359,72,TRUE,Batching inference increases throughput while measuring per-sample latency and overall throughput.,"benchmark_inference with batch_size, token_len, max_tokens (T5)",Benchmark code and chart explicitly compare batched versus non-batched inference showing throughput gains.,"mlops,scaling,deployment",10,AI At Scale
105360,72,half-true,Batched inference usually increases throughput but can worsen per-sample latency under some batch sizes.,benchmarking inference with batch sizes for T5 model,Mixes correct throughput gains from batching with the incomplete claim that latency always worsens; depends on batch size and hardware.,"mlops,scaling,deployment",10,AI At Scale
105361,115,mostly-true,Combining top vector matches with prompts generally improves model responses by adding contextual information.,RAG workflow using vector database FAISS for similarity search,"Combining retrieved vectors with prompts is supported as providing extra context, minor caveat about retrieval quality omitted.","data-prep,feature-engineering,rag",3,Prepping Data for AI
105362,115,half-true,FAISS always yields more accurate responses when combined with prompts for retrieval-augmented generation.,using FAISS with RAG and vector database retrieval,Combines correct FAISS performance claims with an overbroad accuracy guarantee; specifics and other factors omitted.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
105363,115,mostly-true,Combining top retrieval matches with prompts improves model responses by adding relevant context.,RAG workflow using vector database FAISS for retrieval,"Supported by passage describing retrieved matches added to prompts, minor caveat about dataset or model limits omitted.","data-prep,feature-engineering,rag",3,Prepping Data for AI
105364,64,mostly-true,A transformer QA pipeline plus PDF reader enables interactive question-answering over uploaded documents.,"transformers.pipeline(""question-answering"") with PyMuPDF PDF extraction","Implementation shows a QA pipeline initialized and PDF text extracted for interactive Q&A, omitting deployment caveats.","neural-networks,cnn,transformers",6,Neuron Building Blocks
105365,64,FALSE,The example claims a transformer QA pipeline reads PDFs and answers questions accurately every time.,"transformers.pipeline(""question-answering"") with PyMuPDF PDF reader",Contradicts passage: example shows a single sample result and lacks claims of guaranteed accuracy.,"neural-networks,cnn,transformers",6,Neuron Building Blocks
105366,64,TRUE,A transformer-based QA pipeline can be used to chat with uploaded PDF documents.,"transformers.pipeline(""question-answering"") with PyMuPDF PDF reader",Example demonstrates using Hugging Face QA pipeline plus PyMuPDF to extract and query PDF text.,"neural-networks,cnn,transformers",6,Neuron Building Blocks
105367,25,mostly-true,Organizations increasingly must document AI data provenance and lineage for regulatory oversight.,NIST AI Risk Management Framework and AI-focused legislation,"Widely supported by passage: emphasizes provenance and lineage expectations, minor caveat about privacy and transparency limits.","ethics,governance,privacy",11,AI Ethics and Governance
105368,25,barely-true,Organizations must always publish full data lineage and provenance for every AI decision.,data provenance and lineage in NIST AI Risk Management Framework,"Overreaches passage: provenance and lineage are emphasized, but mandatory full publication for every decision is unsupported.","ethics,governance,privacy",11,AI Ethics and Governance
105369,25,half-true,Companies always can provide full data lineage and provenance for AI decisions.,data provenance and lineage in NIST AI Risk Management Framework,Overstates capabilities: passage says provenance and lineage are expected and essential but not always achievable.,"ethics,governance,privacy",11,AI Ethics and Governance
105370,100,half-true,Cosine similarity both validates clusters and pinpoints near-duplicate individuals within clusters.,cosine similarity with clustering on power-profile vectors,"Accurately states utility, but overreaches by implying both validation and pinpointing are always reliable.","machine-learning,classification,evaluation",4,Classical Machine Learning
105371,100,barely-true,Cosine similarity reliably identifies the single most similar character for each cluster member.,cosine similarity with clustering on power-profile embeddings,Overstates reliability and uniqueness; passage shows useful complements and near-duplicates but not guaranteed single-most similar identification.,"machine-learning,classification,evaluation",4,Classical Machine Learning
105372,100,half-true,Cosine similarity both validates clusters and identifies near-duplicate characters in unsupervised character-power data.,cosine similarity with clustering on character power profiles,"Correctly credits cosine similarity for validating clusters and finding near-duplicates, but overgeneralizes utility across all unsupervised character-power datasets.","machine-learning,classification,evaluation",4,Classical Machine Learning
105373,20,TRUE,"Agents extend prompts and models to include decision-making, retrieval, and task execution.",LangChain integration of prompts and models for agentic AI,"Passage explicitly states agents build on prompts/models and add decision-making, retrieval, and execution.","agentic-ai,planning,tools",12,Agentic AI
105374,20,TRUE,"AI agents extend prompts and models by adding decision-making, retrieval, and task execution capabilities.",agent design using LangChain and AI agents,"Passage explicitly states agents build on prompts and models and incorporate decision-making, retrieval, and task execution.","agentic-ai,planning,tools",12,Agentic AI
105375,20,half-true,LangChain alone provides full decision-making and task execution capabilities for AI agents.,LangChain integration with prompts and models for agentic AI,"Overstates LangChain's role: passage says it integrates prompts/models but agents add decision-making, retrieval, execution.","agentic-ai,planning,tools",12,Agentic AI
105376,32,half-true,Classic RNNs forget early inputs in long sequences due to vanishing gradients during training.,recurrent neural networks (RNNs) and vanishing gradient,Accurately mixes correct mechanism and effect: vanishing gradients cause early information to fade in classic RNNs.,"neural-networks,cnn,transformers",6,Neuron Building Blocks
105377,32,half-true,Bidirectional RNNs always prevent vanishing gradients for long sequences.,"recurrent neural networks, vanishing gradient problem, bidirectional RNNs","Correctly notes bidirectional RNNs use forward and backward context, but wrongly implies they eliminate vanishing gradients entirely.","neural-networks,cnn,transformers",6,Neuron Building Blocks
105378,32,half-true,Bidirectional RNNs always solve long-range forgetting in sequential tasks without additional mechanisms.,"recurrent neural network (RNN) architectures, vanishing gradient problem",Correctly notes bidirectional access improves context but incorrectly claims they always fix vanishing gradients.,"neural-networks,cnn,transformers",6,Neuron Building Blocks
105379,83,mostly-true,Neural networks use activation functions and loss functions to produce and evaluate predictions.,"neuron computations, activation function, loss function","Directly supported: passage describes weights, biases, activation functions producing predictions and loss functions for comparison.","deep-learning,frameworks,tensors",5,Deep Learning
105380,83,FALSE,"Neurons only use fixed, non-learnable activation functions in deep networks.","neurons, activation function, learned weights and biases",Contradicts passage specifying weights and biases are learned and activations transform learned results.,"deep-learning,frameworks,tensors",5,Deep Learning
105381,83,mostly-true,"Neural network neurons compute weighted sums, apply activations, and use loss to compare predictions.","neuron computation, activation function, loss function in deep learning",Accurately reflects described forward pass mechanics; omits minor caveat about normalization's role mentioned separately.,"deep-learning,frameworks,tensors",5,Deep Learning
105382,8,pants-fire,Deepfake audio-video always betrays creators through invisible AI watermarks impossible to remove.,"multimedia data, audio and video connections","Passage describes AI needing to learn multimedia language, not claiming undefeatable watermarks; contradicts removability assumption.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
105383,8,barely-true,AI models can fully infer speaker intent from combined audio and video signals.,multimedia data combining audio and video signals,"Overreaches: passage notes challenge in learning multimedia language, not full inference of speaker intent.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
105384,8,mostly-true,Multimodal deepfake detection benefits from jointly modeling audio and video correlations.,"multimedia data, audio–video correlations, deepfake detection","Passage emphasizes audio and video connections shaping communication, implying joint modeling aids detection though specifics omitted.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
105385,88,half-true,LLaMA and BLOOM always match or exceed GPT-family code and summarization performance.,"model comparison between LLaMA, BLOOM, and GPT-family","Mixes correct strengths (multilingual BLOOM, flexible LLaMA) with incorrect blanket performance claim against GPT models.","ai,tool-chain,notebooks",2,AI Survival Kit
105386,88,barely-true,LLaMA and BLOOM are interchangeable for all multilingual and coding tasks.,models LLaMA and BLOOM in generative AI tool-chain,Overreaches: passage notes different strengths—BLOOM is multilingual and LLaMA is flexible—so interchangeability is not supported.,"ai,tool-chain,notebooks",2,AI Survival Kit
105387,88,mostly-true,"LLaMA and BLOOM exemplify accessible, adaptable open models useful for practical and creative tasks.","generative models (LLaMA, BLOOM) in tool-chain and notebooks",Describes models' flexibility and multilingual training broadly supported; omits specific limitations and dataset caveats.,"ai,tool-chain,notebooks",2,AI Survival Kit
105388,26,half-true,MT-Bench reliably ranks multi-turn chatbot responsiveness but overstates generalizability across all dialogue types.,MT-Bench multi-turn chatbot benchmark,Accurately highlights MT-Bench's ranking strength but overreaches by implying universal dialogue coverage and generalization.,"mlops,scaling,deployment",10,AI At Scale
105389,26,TRUE,MT-Bench is a widely trusted benchmark for evaluating multi-turn chatbot capabilities.,MT-Bench multi-turn chatbot benchmark,Passage states MT-Bench built by Berkeley and CMU is one of the most trusted ways to compare multi-turn capabilities.,"mlops,scaling,deployment",10,AI At Scale
105390,26,barely-true,BLEU reliably measures conversational helpfulness across multi-turn chatbots in real-world dialogs.,evaluation of multi-turn models using MT-Bench and BLEU,"Overreaches: BLEU measures n-gram overlap for translation-like tasks, not conversational helpfulness across multi-turn chat.","mlops,scaling,deployment",10,AI At Scale
105391,56,mostly-true,Using external LLMs like Mistral often yields solid AI-generated data with occasional non-answers.,data-prep workflow using Mistral model on Hugging Face,"Supported by passage: Mistral delivered solid results, prompted non-answers, and spot-checking ensured accuracy.","data-prep,feature-engineering,rag",3,Prepping Data for AI
105392,56,pants-fire,The Mistral model fabricated entire datasets without any human verification.,using Mistral model on Hugging Face for dataset generation,"Passage describes spot-checking and correct non-answer prompts, contradicting claim that Mistral fabricated whole datasets without verification.","data-prep,feature-engineering,rag",3,Prepping Data for AI
105393,56,mostly-true,Mistral on Hugging Face generally produces reliable AI-generated dataset values with spot-checking.,external language model calls to Mistral on Hugging Face,Passage praises Mistral's solid results and recommends spot-checking; minor caveat about patience omitted.,"data-prep,feature-engineering,rag",3,Prepping Data for AI
105394,78,pants-fire,The model completely loses all prior visual knowledge instantly during fine-tuning.,fine-tuning on generator models exhibiting catastrophic forgetting,"Contradicts passage describing gradual artifacts and partial retention, not instantaneous total loss.","generative-ai,diffusion,gans",7,Generative AI
105395,78,barely-true,Fine-tuning caused generator to retain original circle artifacts while learning diagonal lines.,fine-tuning effects on generative model artifacts,"Passage describes lingering faint circle artifacts during incomplete fine-tuning, showing partial retention and interference.","generative-ai,diffusion,gans",7,Generative AI
105396,78,half-true,The model partially retains original curved-shape features while learning new diagonal-line patterns during fine-tuning.,"fine-tuning of a generative model (catastrophic forgetting, artifacts)",Mixes correct observations about retained artifacts with ambiguous extent of retention and training detail omissions.,"generative-ai,diffusion,gans",7,Generative AI
105397,29,half-true,A single-feature linear regression on weight reliably predicts height for Humans and Cyborgs.,LinearRegression model trained on Weight feature from SUPERHEROES_INFO_POWERS dataset,Correct method used but claim overstretches: single feature likely yields modest R² and notable prediction error.,"machine-learning,classification,evaluation",4,Classical Machine Learning
105398,29,FALSE,Linear regression perfectly predicts individual heights from weight alone in the dataset.,LinearRegression model predicting Height from Weight,"Contradicts reported evaluation: MSE and r2 computed, implying imperfect predictions and variability.","machine-learning,classification,evaluation",4,Classical Machine Learning
105399,29,half-true,Linear regression on weight alone perfectly predicts height for Humans and Cyborgs.,LinearRegression model predicting Height from Weight dataset,"Model uses single feature and reports MSE/R², so claim of perfect prediction overstates accuracy.","machine-learning,classification,evaluation",4,Classical Machine Learning
105400,109,TRUE,Model testing with sample predictions and assessments can practically validate claims about model outputs.,Table 9-5 sample predictions and model assessments,"Matches passage example where sample predictions and assessments yield practical, flexible validation of model claims.","mlops,scaling,deployment",10,AI At Scale
105401,109,half-true,The model sometimes labels nuanced claims as 'half-true' during evaluation.,"model assessment, sample predictions, label taxonomy",Matches passage example where a bold claim received a half-true label due to nuanced evidence.,"mlops,scaling,deployment",10,AI At Scale
105402,109,mostly-true,AI deployment at scale generally reduces manual intervention but requires careful monitoring.,MLOps deployment practices and monitoring tools,Supported by MLOps emphasis on automation plus omission of monitoring complexity and edge cases.,"mlops,scaling,deployment",10,AI At Scale
105403,60,pants-fire,Decision trees always produce perfectly fair and unbiased credit approval outcomes.,decision tree explainability in credit approval use case,"Contradicts passage: decision trees provide transparency, not guaranteed fairness or unbiased outcomes in credit decisions.","machine-learning,classification,evaluation",4,Classical Machine Learning
105404,60,TRUE,"Decision trees provide transparent, explainable sequences of features that show how classifications are made.",explainable AI in decision trees for classification,Directly supported by passage stating decision trees show exact feature sequences for outcomes.,"machine-learning,classification,evaluation",4,Classical Machine Learning
105405,60,pants-fire,Decision trees are completely uninterpretable and never explainable in regulated settings.,"explainable AI, decision tree, credit approval",Directly contradicts passage claiming decision trees show exact feature sequences for explainability in regulated domains.,"machine-learning,classification,evaluation",4,Classical Machine Learning
105406,62,half-true,A generative AI can produce biased outcomes by learning hidden correlations from training datasets.,training data and hidden correlations in generative AI,Mixes correct idea that biased training data causes unfair outcomes with vague implication that all generative models will necessarily produce bias without noting mitigation or intent.,"ethics,governance,privacy",11,AI Ethics and Governance
105407,62,half-true,Generative AI can produce unfair outcomes by learning hidden correlations from biased datasets.,bias in datasets and generative AI,"Accurately links learning hidden correlations to unfair outcomes but omits specifics about intent, mitigation, or examples.","ethics,governance,privacy",11,AI Ethics and Governance
105408,62,FALSE,Generative AI systems can produce unfair outcomes by learning hidden biases from training data.,biased data and hidden correlations in generative AI,"Contradicts passage by claiming intentional design; passage attributes unfairness to learned biases from data, not designers.","ethics,governance,privacy",11,AI Ethics and Governance
105409,103,half-true,The pipeline always requires encoding categorical features before modeling.,"data preparation pipeline, encoding categories","Partly correct—encoding is common, but passage doesn't state it is always required for every model or dataset.","machine-learning,classification,evaluation",4,Classical Machine Learning
105410,103,mostly-true,Data preparation typically involves shaping numeric features and encoding categorical variables for models.,"pipeline for dataset preparation (numeric features, encoding categories)",Matches passage description of the pipeline steps; omits minor details about model selection and prediction target.,"machine-learning,classification,evaluation",4,Classical Machine Learning
105411,103,barely-true,The pipeline always includes feature engineering and model selection steps before evaluation.,pipeline for dataset preprocessing and model selection,"Passage mentions selection, numeric shaping, and encoding but omits explicit evaluation step; overreaches.","machine-learning,classification,evaluation",4,Classical Machine Learning
105412,53,half-true,The author collaborated with the OECD and WEF to develop binding international AI regulations.,"engagement with OECD, World Economic Forum, Partnership on AI",Accurately notes collaboration with OECD and WEF but incorrectly asserts regulations were binding and developed jointly.,"ethics,governance,privacy",11,AI Ethics and Governance
105413,53,half-true,They collaborated with multiple international bodies on AI ethics and governance while at IBM.,"collaboration with OECD, European Commission, Partnership on AI",Accurately cites work with OECD and EC but overstates continuous collaboration and scope of governance impact.,"ethics,governance,privacy",11,AI Ethics and Governance
105414,53,TRUE,They collaborated with international organizations on AI ethics and governance initiatives.,"engagements with European Commission, OECD, Partnership on AI, World Economic Forum",Directly supported by passage listing those organizations and involvement in AI ethics and regulation.,"ethics,governance,privacy",11,AI Ethics and Governance
105415,14,half-true,Supervised learning always predicts labels accurately after enough training data.,"supervised learning, labeled data, prediction","Correct that supervised learning uses labeled data, but overstates guaranteed accuracy and ignores model limits.","machine-learning,classification,evaluation",4,Classical Machine Learning
105416,14,mostly-true,Supervised learning trains models on labeled examples to predict outputs for new data.,supervised learning with labeled dataset for classification,"Accurately describes teaching-by-example and prediction, omitting model capacity and dataset quality caveats.","machine-learning,classification,evaluation",4,Classical Machine Learning
105417,14,half-true,Supervised models trained on labeled restaurant reviews always generalize well to unseen reviews.,supervised learning with labeled dataset (restaurant reviews) classification,Mixes correct training-on-labeled-examples with incorrect absolute claim about always generalizing; generalization depends on data and model.,"machine-learning,classification,evaluation",4,Classical Machine Learning
105418,77,half-true,Speaker embeddings trained on small datasets can exaggerate errors in voice-cloning outputs.,speaker embeddings and dataset size in voice-cloning,"Passage says embeddings are training signals and small datasets can exaggerate errors, matching mix of correct and specific claim.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
105419,77,pants-fire,The model completely ignores speaker embeddings during training and uses only transcripts.,speaker embeddings and transcripts in audio dataset,Contradicts passage detail that speaker embeddings serve as training signals alongside transcripts; impossible claim.,"media-forensics,voice-cloning,deepfake",9,Deepfake Defense
105420,77,mostly-true,Smaller voice-cloning datasets speed experimentation but can exaggerate errors compared to larger datasets.,speaker embeddings and dataset size for voice-cloning,"Passage explains speaker embeddings enable training and states small datasets train quickly yet can exaggerate errors versus larger, diverse datasets.","media-forensics,voice-cloning,deepfake",9,Deepfake Defense
105421,54,barely-true,CC0 always permits unrestricted commercial use of datasets and model documentation.,licensing choices for datasets and model documentation (CC0),"Overreaches: CC0 usually allows commercial use, but passage emphasizes choosing licenses based on intended use and dependencies.","open-source,community,contribution",13,Commit to Contribute
105422,54,mostly-true,CC0 is often the preferred license for datasets and model metadata intended for unrestricted public use.,"licensing guidance for datasets, model cards, and pre-trained model metadata","Passage lists CC0 as effectively public-domain and best suited for datasets and model documentation, omitting potential downstream legal or dependency caveats.","open-source,community,contribution",13,Commit to Contribute
105423,54,mostly-true,Choosing an open license helps maximize reuse while possibly allowing commercial use.,"license selection for datasets and model documentation (CC0, dependencies)",Passage endorses matching license to intended reuse and mentions CC0 and commercial use considerations.,"open-source,community,contribution",13,Commit to Contribute
105424,83,barely-true,Agentic AI tools reliably perform accurate real-time fact-checking across web sources without human oversight.,tool integration with web scraper and Google Search API,Passage notes tool-enabled real-time checking but does not claim reliability or accuracy guarantees without human oversight.,"agentic-ai,planning,tools",12,Agentic AI
105425,83,half-true,An agent can run custom tools like a legal analyzer and a code executor to fetch and process external data.,"tool integration (retriever, code executor, Google Search API)",Accurately says custom tools and executors exist but overstates simultaneous capabilities and scope.,"agentic-ai,planning,tools",12,Agentic AI
105426,83,mostly-true,"Agentic systems commonly integrate tools like retrievers, web scrapers, and code executors for dynamic tasks.","tool integration for agent workflows (retriever, web scraper, code executor)",Passage explicitly lists those tools and says they integrate into agents' workflows for real-time tasks.,"agentic-ai,planning,tools",12,Agentic AI
105427,37,pants-fire,Fine-tuning with one thousand prompts always outperforms GPT-class models on all tasks.,fine-tuning with one thousand prompts dataset,Passage claims limited fine-tuning can outperform larger models; stating it 'always' outperforms contradicts specific task variability and overgeneralizes performance.,"ai,open-source,builder",1,Introduction – The Gold Rush Paradox
105428,37,mostly-true,Fine-tuning smaller models on about a thousand curated prompts can outperform larger models on practical metrics.,fine-tuning with curated prompts and model performance,"Study claim supports accuracy, cost, and speed gains but omits dataset specifics and generalizability limits.","ai,open-source,builder",1,Introduction – The Gold Rush Paradox
105429,37,half-true,Fine-tuning on about one thousand curated prompts can outperform much larger models in accuracy and cost.,fine-tuning with one thousand prompts; model accuracy and cost,"Passage claims a study shows ~1,000 curated prompts beat larger models on accuracy and cost, but specifics and generality are uncertain.","ai,open-source,builder",1,Introduction – The Gold Rush Paradox
105430,21,TRUE,Classical methods like regression and SVMs form the backbone of predictive modeling.,Statistical Learning Theory and superhero dataset regression,Passage states foundations in Vapnik's Statistical Learning Theory and calls them backbone of predictive modeling.,"machine-learning,classification,evaluation",4,Classical Machine Learning
105431,21,barely-true,Classical methods like regression are still the backbone of predictive modeling in practice.,"Statistical Learning Theory, regression, superhero dataset",Overstates practicality: passage claims foundational importance but not current dominance or widespread real-world prevalence.,"machine-learning,classification,evaluation",4,Classical Machine Learning
105432,21,barely-true,Classical supervised models like SVMs and regression remain the sole backbone of modern predictive modeling.,"predictive modeling, Statistical Learning Theory, dataset",Overreaches by claiming sole dominance; passage says they remain backbone but not exclusive or sole method.,"machine-learning,classification,evaluation",4,Classical Machine Learning
105433,8,TRUE,Keras became TensorFlow's default high-level API by the time TensorFlow 2.0 was released.,TensorFlow 2.0 default interface / Keras high-level API,"Passage states Google adopted Keras and it was the default interface in TensorFlow 2.0, simplifying development.","deep-learning,frameworks,tensors",5,Deep Learning
105434,8,half-true,"Keras became TensorFlow's default high-level API by TensorFlow 2.0, simplifying model development.",TensorFlow high-level API / Keras,"Passage states Google adopted Keras as TensorFlow's official API and it became default in TensorFlow 2.0, but omits specific timeline nuances.","deep-learning,frameworks,tensors",5,Deep Learning
105435,8,FALSE,ONNX is a deep learning framework used to train neural networks directly.,model interoperability and ONNX format,"Contradicts passage: ONNX is described as an open standard bridge, not a framework for training models.","deep-learning,frameworks,tensors",5,Deep Learning
105436,100,barely-true,An internal Reviewer can always pause model output for human verification before execution.,internal checks and Reviewer pause point for prompt injection,"Passage suggests pausing is possible but overstates certainty; implementation, coverage, and reliability are not guaranteed.","security,red-team,guardrails",8,Breaking-Securing AI
105437,100,half-true,An internal Reviewer can pause model execution to regenerate or flag outputs for human review.,internal checks and Reviewer process for model outputs,"Partly correct: passage describes pausing and human review, but overstates Reviewer control over execution mechanisms.","security,red-team,guardrails",8,Breaking-Securing AI
105438,100,FALSE,Internal reviewers cannot pause or control model execution based on output checks.,internal checks and Reviewer pause point for model outputs,"Contradicts passage describing Reviewer pause point enabling pause, regeneration, or human review controls.","security,red-team,guardrails",8,Breaking-Securing AI
105439,91,barely-true,CrewAI reliably coordinates multiple agents into controlled task flows without new prompts.,CrewAI coordinating multiple agents and structured tasks,Passage suggests coordination and controlled flow but overstates reliability and promptless operation.,"agentic-ai,planning,tools",12,Agentic AI
105440,91,barely-true,CrewAI reliably coordinates multiple agents to execute structured tasks without additional prompts.,CrewAI coordinating multiple agents and structured tasks,Overstates reliability and prompt-independence; passage claims coordination concept but not guaranteed consistent success.,"agentic-ai,planning,tools",12,Agentic AI
105441,91,half-true,CrewAI coordinates multiple agents and assigns structured tasks but doesn't always ensure consistent outcomes.,CrewAI coordinating agents and structured tasks,Accurately notes coordination and task assignment but overstates inconsistency claim lacking passage evidence.,"agentic-ai,planning,tools",12,Agentic AI
