{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Chapter 1 - Core AI Concepts and Tools\n",
        "This notebook sets up your Python environment and explores core AI concepts such as machine learning, deep learning, and generative models. It demonstrates how to integrate AI into applications while maintaining ethical standards using popular frameworks like Scikit-learn, Hugging Face, and Stable Diffusion."
      ],
      "metadata": {
        "id": "S7MCZqg-engg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Listing 1-1: Example of a Listing\n",
        "This is a simple example of a listing in Google Colab (This is the markdown cell)\n",
        "\n",
        "The code cell follows below..."
      ],
      "metadata": {
        "id": "zsfMp3nWp_kO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "TENSOR = torch.rand(2, 3)\n",
        "print(TENSOR)"
      ],
      "metadata": {
        "id": "5JbmLjYlqLp-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Listing 1-2: Installing the Python Starter Set\n",
        "Let's kick things off by installing your 'survival kit' of Python libraries using **pip**, so you're fully equipped with the tools you'll need for development."
      ],
      "metadata": {
        "id": "ZwV8U_hffGnr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install fundamental Python libraries for data manipulation, visualization,\n",
        "# and AI models\n",
        "\n",
        "%pip install numpy pandas matplotlib scikit-learn"
      ],
      "metadata": {
        "id": "WLzXuunCfTYK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Listing 1-3: Importing Core Libraries\n",
        "In this block, we import core libraries like **NumPy, Pandas, and Matplotlib**, verifying that our setup is configured correctly for the notebook."
      ],
      "metadata": {
        "id": "ejg1G5rLftA_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import sklearn\n",
        "\n",
        "# Confirm that libraries are set up correctly\n",
        "print('Libraries installed, imported, and ready to go!')"
      ],
      "metadata": {
        "id": "06wCLK-Pf5pk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Listing 1-4: Cleansing a Dataset\n",
        "We’ll cleanse a dataset of superhero attributes, handling missing values and dropping incomplete rows, ensuring it’s ready for analysis or modeling using **Pandas' Dataframe**."
      ],
      "metadata": {
        "id": "MsEJSvLhgCZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample dataset of fictional superheroes\n",
        "data = {'Name': ['Captain Valor', 'Mighty Max', 'Lady Storm', None],\n",
        "        'Age': [35, 29, 28, None],\n",
        "        'Power_Level': [95, 89, 93, 88]}\n",
        "\n",
        "# Load the dataset into a Pandas DataFrame\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Display the original DataFrame\n",
        "print('Original DataFrame:', df, sep='\\n')\n",
        "\n",
        "# Fill missing values in the 'Age' column with the mean age\n",
        "df = df.assign(Age=df['Age'].fillna(df['Age'].mean()))\n",
        "\n",
        "# Remove rows where the 'Name' field is missing\n",
        "df = df.dropna(subset=['Name'])\n",
        "\n",
        "# Display the cleaned DataFrame\n",
        "print('\\nCleaned DataFrame:', df, sep='\\n')\n"
      ],
      "metadata": {
        "id": "pbuOR5mUgNvc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Listing 1-5: Comparing Data with Element-Wise Operations\n",
        "We'll use **NumPy** for element-wise operations, comparing superhero abilities and challenges to determine suitability based on strength and speed features."
      ],
      "metadata": {
        "id": "qQCPCsiMgUnr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Superhero power matrix (rows: heroes, columns: strength, speed)\n",
        "# Hero A (Speedster), Hero B (Strongman)\n",
        "heroes = np.array([[90, 75],  # High speed, moderate strength\n",
        "                   [60, 95]]) # Low speed, high strength\n",
        "\n",
        "# Object challenge matrix (rows: strength, speed requirements)\n",
        "# Object 1: Train, Object 2: Speeding Bullet\n",
        "objects = np.array([[80, 50],  # High strength, moderate speed required\n",
        "                    [40, 100]])# Low strength, very high speed required\n",
        "\n",
        "# Element-wise division to compare powers to challenges\n",
        "result = heroes / objects\n",
        "\n",
        "# Print the power matrices and the result\n",
        "print(\"Hero Power Levels:\\n\", heroes)\n",
        "print(\"\\nObject Challenges:\\n\", objects)\n",
        "print(\"\\nHero-to-Object Power Ratio (Division):\\n\", result)"
      ],
      "metadata": {
        "id": "Ps5BY3QliNZV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Listing 1-6: Calculating dot product and Cosine Similarity\n",
        "We use the **NumPy** dot product to calculate the similarity between two superheroes' attributes (strength, speed, intelligence). We then compute the cosine similarity to interpret how closely aligned their power profiles are.\n"
      ],
      "metadata": {
        "id": "UgYVlLifiT9i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create two superhero power vectors (strength, speed, intelligence)\n",
        "hero_1 = np.array([85, 90, 75])  # Hero A: strong, fast, smart\n",
        "hero_2 = np.array([80, 85, 70])  # Hero B: slightly less in all areas\n",
        "\n",
        "# Calculate the dot product to compare their power profiles\n",
        "dot_product = np.dot(hero_1, hero_2)\n",
        "\n",
        "# Calculate the magnitude (norm) of each vector\n",
        "magnitude_hero_1 = np.linalg.norm(hero_1)\n",
        "magnitude_hero_2 = np.linalg.norm(hero_2)\n",
        "\n",
        "# Calculate the cosine similarity\n",
        "cosine_similarity = dot_product / (magnitude_hero_1 * magnitude_hero_2)\n",
        "\n",
        "# Print the power profiles, dot product, and cosine similarity\n",
        "print(\"Hero A Power Profile:\", hero_1)\n",
        "print(\"Hero B Power Profile:\", hero_2)\n",
        "print(\"\\nDot Product (Similarity):\", dot_product)\n",
        "print(\"\\nCosine Similarity (Range: -1 to 1):\", cosine_similarity)\n",
        "\n",
        "# Interpret the cosine similarity\n",
        "if cosine_similarity > 0.9:\n",
        "    similarity_text = \"The heroes have very similar power profiles.\"\n",
        "elif cosine_similarity > 0.7:\n",
        "    similarity_text = \"The heroes have somewhat similar power profiles.\"\n",
        "else:\n",
        "    similarity_text = \"The heroes have quite different power profiles.\"\n",
        "\n",
        "print(\"\\nInterpretation:\", similarity_text)"
      ],
      "metadata": {
        "id": "MGLUzH_didLT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting the Profiles of Hero 1 and Hero 2\n",
        "\n",
        "attributes = ['Strength', 'Speed', 'Intelligence']\n",
        "\n",
        "# Plotting side-by-side bar chart\n",
        "x = np.arange(len(attributes))  # Label locations\n",
        "width = 0.35  # Bar width\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(8, 6))\n",
        "bars1 = ax.bar(x - width/2, hero_1, width, label=\"Hero A\", color=\"blue\")\n",
        "bars2 = ax.bar(x + width/2, hero_2, width, label=\"Hero B\", color=\"red\")\n",
        "\n",
        "# Adding labels, title, and legend\n",
        "ax.set_xlabel('Attributes')\n",
        "ax.set_ylabel('Values')\n",
        "ax.set_title('Comparison of Hero Power Profiles')\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels(attributes)\n",
        "ax.legend()\n",
        "\n",
        "# Annotating the bars\n",
        "for bars in [bars1, bars2]:\n",
        "    for bar in bars:\n",
        "        height = bar.get_height()\n",
        "        ax.text(bar.get_x() + bar.get_width()/2, height + 2, f\"{height:.0f}\",\n",
        "                ha='center', va='bottom')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "ykXWs1882lrT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Listing 1-7: Optimizing Attributes with Gradients\n",
        "We use **NumPy** to calculate the gradient between current and target attributes, showing the amount and direction of improvement needed for superheroes."
      ],
      "metadata": {
        "id": "7PFMHCM5ih5F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Current and target attribute levels (e.g., strength, speed)\n",
        "current_values = np.array([60, 80])\n",
        "target_values = np.array([90, 100])\n",
        "\n",
        "# Calculate the gradient showing required improvement to meet targets\n",
        "gradient = target_values - current_values\n",
        "\n",
        "# Display current levels, targets, and gradient values\n",
        "print('Current Attributes (strength, speed):', current_values)\n",
        "print('Target Attributes (strength, speed):', target_values)\n",
        "print('\\nGradient (Improvement Needed):', gradient)\n",
        "\n",
        "# Explanation of output\n",
        "if np.all(gradient >= 0):\n",
        "    explanation = (\n",
        "        \"The gradient values show how much improvement is needed to meet \"\n",
        "        \"the target levels.\"\n",
        "    )\n",
        "else:\n",
        "    explanation = (\n",
        "        \"Some attributes exceed targets, so not all require adjustments.\"\n",
        "    )\n",
        "\n",
        "print(\"\\nExplanation:\", explanation)"
      ],
      "metadata": {
        "id": "-MJDvaiQisgD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Listing 1-8: Estimating Success Probability\n",
        "We use **NumPy** to compare superhero attributes against thresholds, calculating the probability of success through element-wise operations.\n"
      ],
      "metadata": {
        "id": "Tam31MdOixTy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the actual values (e.g., strength and speed)\n",
        "actual_values = np.array([80, 90])\n",
        "\n",
        "# Define the threshold required for success\n",
        "required_thresholds = np.array([70, 85])\n",
        "\n",
        "# Calculate success probability (actual values divided by required thresholds)\n",
        "probability_of_success = actual_values / required_thresholds\n",
        "\n",
        "# Print the actual values, thresholds, and calculated probabilities\n",
        "print('Actual Values (strength, speed):', actual_values)\n",
        "print('Required Thresholds (strength, speed required):', required_thresholds)\n",
        "print('\\nProbability of Success:', probability_of_success)\n",
        "\n",
        "# Explanation of output\n",
        "if np.all(probability_of_success >= 1):\n",
        "    explanation = \"Values exceed thresholds, showing high success probability.\"\n",
        "else:\n",
        "    explanation = \"Values are below the thresholds, indicating a lower probability of success.\"\n",
        "\n",
        "print(\"\\nExplanation:\", explanation)"
      ],
      "metadata": {
        "id": "hnlWHsBMi7yB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Listing 1-9: Predicting Revenue Using Linear Regression\n",
        "This block uses machine learning **Scikit-learn** to predict superhero movie box office revenue based on production budgets, demonstrating **linear regression** for simple financial forecasting. We’ll also predict the box office revenue if the budget is $400 million.\n"
      ],
      "metadata": {
        "id": "yP9EeRnRjFIP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Linear Regression package from Scikit-learn\n",
        "from sklearn.linear_model import LinearRegression\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Example data: production budgets (input) and box office revenue (output)\n",
        "budgets = np.array([100, 150, 200, 250, 300]).reshape(-1, 1)  # in millions\n",
        "box_office = np.array([300, 400, 600, 750, 900])  # in millions\n",
        "\n",
        "# Create and train the linear regression model\n",
        "model = LinearRegression()\n",
        "model.fit(budgets, box_office)\n",
        "\n",
        "# Predict box office revenue based on production budgets\n",
        "predicted_revenue = model.predict(budgets)\n",
        "\n",
        "# Predict box office revenue for a $400 million budget\n",
        "new_budget = np.array([[400]])  # in millions\n",
        "predicted_new_revenue = model.predict(new_budget)\n",
        "\n",
        "# Print the slope (m), intercept (b), and prediction for $400 million budget\n",
        "print(f\"Slope (m): {model.coef_[0]}\")\n",
        "print(f\"Intercept (b): {model.intercept_}\")\n",
        "print(f\"Predicted Revenue for $400M budget: {predicted_new_revenue[0]:.2f}M\")"
      ],
      "metadata": {
        "id": "izlIleHyjOg5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the data points and regression line\n",
        "\n",
        "plt.scatter(budgets, box_office, color='blue', label='Actual Revenue')\n",
        "plt.plot(budgets, predicted_revenue, color='red', label='Predicted Revenue')\n",
        "plt.scatter(new_budget, predicted_new_revenue, color='green', marker='x',\n",
        "            s=100, label='Prediction for $400M')\n",
        "plt.xlabel('Production Budget (in millions)')\n",
        "plt.ylabel('Box Office Revenue (in millions)')\n",
        "plt.title('Linear Regression: Revenue vs Budget')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "SbvajwIPTCah"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Listing 1-10: Classifying Emails Using Naive Bayes\n",
        "Trains a model using Scikit-learn's **Naive Bayes** classifier to determine if superhero-themed emails are **spam or not spam**, demonstrating **text classification** and natural language processing."
      ],
      "metadata": {
        "id": "X4HkIlTCjUI1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "# Sample dataset: 5 spam and 5 non-spam emails\n",
        "emails = [\n",
        "    'Unlock Unlimited Superpowers Today!',\n",
        "    'Claim Your Free Kryptonite—Limited Offer!',\n",
        "    'Win a Year’s Supply of Superhero Gear!',\n",
        "    'Congratulations! You’ve Been Selected as the Next Avenger!',\n",
        "    'Free Batmobile Test Drive!',\n",
        "    'Quarterly sales report is due next Monday',\n",
        "    'Please review the attached budget proposal for next quarter',\n",
        "    'Reminder: Team meeting on Thursday at 9 AM',\n",
        "    'Your invoice for services rendered is attached',\n",
        "    'Client feedback report from last week’s presentation'\n",
        "]\n",
        "\n",
        "# Labels for spam (1) and non-spam (0)\n",
        "labels = [1, 1, 1, 1, 1, 0, 0, 0, 0, 0]\n",
        "\n",
        "# Convert emails to a bag-of-words representation using bi-grams\n",
        "vectorizer = CountVectorizer(ngram_range=(1, 2), stop_words='english')\n",
        "X = vectorizer.fit_transform(emails)\n",
        "\n",
        "# Create and train the Naive Bayes classifier\n",
        "model = MultinomialNB()\n",
        "model.fit(X, labels)\n",
        "\n",
        "# Test the model with new emails\n",
        "new_emails = [\n",
        "    'Congratulations, You’ve Been Chosen as the Next Avenger!',\n",
        "    'Final review of training schedule',\n",
        "    'Free ticket to the Superhero Conference—Register now!',\n",
        "    'Please review the attached project plan for the upcoming quarter'\n",
        "]\n",
        "X_new = vectorizer.transform(new_emails)\n",
        "predictions = model.predict(X_new)\n",
        "\n",
        "# Display predictions for each email\n",
        "for email, prediction in zip(new_emails, predictions):\n",
        "    print(f\"Email: '{email}' is {'spam' if prediction == 1 else 'not spam'}\")"
      ],
      "metadata": {
        "id": "tMOixXuujdXl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Listing 1-11: Image Classification with a Pre-Trained Model\n",
        "We'll use a pre-trained model from **Hugging Face** to classify an image, demonstrating **deep learning** for image classification, in this case a superhero comic book image."
      ],
      "metadata": {
        "id": "-Li1FR4Njjrk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "from transformers import pipeline\n",
        "from PIL import Image\n",
        "import requests\n",
        "\n",
        "# Load an image for classification from a URL\n",
        "BASE_URL = 'https://opensourceai-book.github.io/code/media/'\n",
        "url = BASE_URL + 'C01-ComicBook.jpeg'\n",
        "image = Image.open(requests.get(url, stream=True).raw)\n",
        "\n",
        "# Load a pre-trained image classification model from Hugging Face\n",
        "classifier = pipeline('image-classification')\n",
        "\n",
        "# Classify the image and retrieve predictions\n",
        "predictions = classifier(image)\n",
        "\n",
        "# Print the top prediction with its confidence score\n",
        "top_prediction = predictions[0]\n",
        "print(f\"Top Prediction: {top_prediction['label']} \"\n",
        "      f\"with a score of {top_prediction['score']:.2f}\")"
      ],
      "metadata": {
        "id": "AWcTRE3QkA7E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Listing 1-12: Check Runtime Selection and Install Libraries for Image Generation\n",
        "\n",
        "\n",
        "Before running, Try to enable GPU in Colab by selecting \"Change runtime type\" from the Runtime menu and choosing GPU under the Hardware Accelerator dropdown for faster computations.\n",
        "\n",
        "To generate images with **Stable Diffusion**, we install the essential libraries: diffusers, transformers, and torch. These tools enable model loading, operation, and **GPU** compatibility for image generation."
      ],
      "metadata": {
        "id": "x2VnseplkOQO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required libraries for Stable Diffusion\n",
        "# Ensure you have diffusers, transformers, and torch installed\n",
        "%pip install -q diffusers transformers torch\n",
        "\n",
        "import torch\n",
        "\n",
        "# Determine the available device: CUDA (GPU) or CPU\n",
        "device = (\"cuda\" if torch.cuda.is_available()\n",
        "          else \"mps\" if torch.backends.mps.is_available()\n",
        "          else \"cpu\")\n",
        "\n",
        "# Warn the user if GPU is not available\n",
        "if device == \"cpu\":\n",
        "    print(\"WARNING: No GPU detected. Tasks may take significantly longer.\")\n",
        "else:\n",
        "    print(f\"Using {device} device for acceleration.\")"
      ],
      "metadata": {
        "id": "auYaHf8PkTAd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Listing 1-13: Generating Images Using Stable Diffusion\n",
        "We will generate a comic-style image using a pre-trained Stable Diffusion model. This exercise involves using **GPU** acceleration for faster image generation."
      ],
      "metadata": {
        "id": "RN38p5RwkWu5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries for image generation\n",
        "from diffusers import StableDiffusionPipeline\n",
        "import torch\n",
        "from PIL import Image\n",
        "from IPython.display import display\n",
        "\n",
        "# Check if GPU is available and set precision accordingly\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "torch_dtype = (torch.float16 if torch.cuda.is_available() else torch.float32)\n",
        "\n",
        "# Load the Stable Diffusion model with the appropriate settings\n",
        "pipe = StableDiffusionPipeline.from_pretrained(\n",
        "    'runwayml/stable-diffusion-v1-5',\n",
        "    torch_dtype=torch_dtype\n",
        ").to(device)\n",
        "\n",
        "# Define a text prompt for generating an image\n",
        "prompt = ('a family-friendly comic-style supervillain using colors; primary red, '\n",
        "          'bright blue, sunny yellow, black and white')\n",
        "\n",
        "# Generate the image using the pipeline with fewer inference steps for speed\n",
        "image = pipe(prompt, num_inference_steps=20).images[0]\n",
        "\n",
        "# Display the generated image\n",
        "display(image)"
      ],
      "metadata": {
        "id": "RxVQLuuZkhIV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Listing 1-14: Setting Up Hugging Face Access Token\n",
        "### 🔐 Accessing Hugging Face Models\n",
        "\n",
        "To use Hugging Face models in this notebook:\n",
        "\n",
        "1. Go to [huggingface.co/settings/tokens](https://huggingface.co/settings/tokens)\n",
        "2. Click **+ Create New Token**, copy the value (e.g. `hf_abc123...`)\n",
        "3. In Colab, click the 🔑 icon in the sidebar to open *Secrets*\n",
        "4. Click **+ Add new secret**  \n",
        "   - Name: `HF_TOKEN`  \n",
        "   - Value: your token  \n",
        "5. Ensure notebook access is enabled (blue checkmark)\n",
        "\n",
        "Then run the code cell below to set your API keys for use in Hugging Face-powered tools and frameworks throughout the notebook."
      ],
      "metadata": {
        "id": "CShNvcHaknYY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Constants and API Key Configuration\n",
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "# === Load API keys securely from Google Colab Secrets ===\n",
        "def load_api_keys():\n",
        "    keys = {\n",
        "        \"HF_TOKEN\": userdata.get(\"HF_TOKEN\"),\n",
        "        \"SERPAPI_API_KEY\": userdata.get(\"SERPAPI_API_KEY\"),\n",
        "        \"OPENAI_API_KEY\": userdata.get(\"OPENAI_API_KEY\"),\n",
        "    }\n",
        "    for key, value in keys.items():\n",
        "        if not value:\n",
        "            raise ValueError(f\"❌ Missing {key}. Please set this API key in Colab secrets.\")\n",
        "        os.environ[key] = value\n",
        "    print(\"✅ All API keys loaded and configured successfully.\")\n",
        "\n",
        "# Execute API key loading upon running this cell\n",
        "load_api_keys()"
      ],
      "metadata": {
        "id": "mBUoYzBMk2GF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Listing 1-15: Installing Required Packages for Hugging Face and LangChain\n",
        "First, we install the necessary packages for using Hugging Face Hub and LangChain, which include community modules and tools for building language model applications.\n",
        "\n",
        "Next, we will set up a basic Q&A chatbot using LangChain and a small language model from Hugging Face. This demonstrates chaining models and using templates.\n",
        "\n",
        "⚠️ Note: Hugging Face contributors frequently update, deprecate, or change the availability of hosted models. The model we use below may eventually be retired or replaced. If the model no longer responds or fails to load, you may need to swap it with another from the list of currently supported models available at:\n",
        "https://huggingface.co/docs/text-generation-inference/en/supported_models"
      ],
      "metadata": {
        "id": "_HoDuNiRk7AN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required packages for Hugging Face and LangChain usage\n",
        "%pip install --quiet huggingface_hub langchain langchain-community langchain_openai google-search-results\n",
        "\n",
        "print(\"All required packaged installed and ready!\")"
      ],
      "metadata": {
        "id": "tAmSCj7TlEOA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Define the default LLM (Text Generation Model) to use from Hugging Face\n",
        "Run the code cell below to define the DEFAULT_MODEL constant\n",
        "> ⚠️ If you get an error running LangChain code due to a missing model, welcome to open-source AI development. Models are updated or replaced often. Check Hugging Face’s list of supported text generation models here:  \n",
        "> https://huggingface.co/docs/api-inference/en/supported-models"
      ],
      "metadata": {
        "id": "LQBMuFTNaRD5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the model to use\n",
        "MODEL = \"mistralai/Mistral-Nemo-Instruct-2407\""
      ],
      "metadata": {
        "id": "KA4bJNupaVux"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import InferenceClient\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "# Create the inference client\n",
        "client = InferenceClient(model=MODEL)\n",
        "\n",
        "# Define a chat-style prompt template\n",
        "chat_prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"Please respond in {language} in 20 words or less.\"),\n",
        "    (\"human\", \"{input}\")\n",
        "])\n",
        "\n",
        "# Format the prompt with variables\n",
        "formatted_prompt = chat_prompt.format(\n",
        "    input=\"Who is the tallest superhero?\",\n",
        "    language=\"English\"\n",
        ")\n",
        "\n",
        "# Send the formatted message to the model\n",
        "response = client.chat.completions.create(\n",
        "    model=MODEL,\n",
        "    messages=[{\"role\": \"user\", \"content\": formatted_prompt}],\n",
        "    max_tokens=100,\n",
        "    temperature=0.1\n",
        ")\n",
        "\n",
        "# Display the model’s response\n",
        "print(response.choices[0].message.content)"
      ],
      "metadata": {
        "id": "SqRhAU5ulYHv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Listing 1-16: Dynamic Agent Task Handling with LangChain\n",
        "Create a LangChain agent that dynamically interacts with tools for tasks like web searching and performing calculations. This showcases the flexibility of **LangChain’s agent framework**."
      ],
      "metadata": {
        "id": "F4u55E1glarq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries for LangChain agent setup\n",
        "from langchain.agents import AgentType, initialize_agent, load_tools\n",
        "from langchain_openai import OpenAI\n",
        "\n",
        "# Initialize the OpenAI agent with a temperature setting for output randomness\n",
        "llm = OpenAI(temperature=0.1)\n",
        "\n",
        "# Load tools for the agent, including SERPAPI for searches and\n",
        "# llm-math for calculations\n",
        "tools = load_tools(['serpapi', 'llm-math'], llm=llm)\n",
        "\n",
        "# Initialize the LangChain agent with the loaded tools and\n",
        "# configure response handling\n",
        "agent = initialize_agent(\n",
        "    tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True\n",
        ")\n",
        "\n",
        "# Query the agent to retrieve and calculate data\n",
        "query = 'Add average rating of Spider-Man and Iron-Man movies'\n",
        "agent.invoke(query)"
      ],
      "metadata": {
        "id": "s_e2j9Xvlkce"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Listing 1-17: Detecting and Mitigating Bias Using Fairlearn\n",
        "To evaluate and mitigate bias in machine learning models, we install the **Fairlearn** library, which offers tools for assessing fairness in predictions.\n",
        "\n",
        "Once installed, we use a simulated dataset and logistic regression to evaluate model bias using Fairlearn, highlighting techniques for ensuring ethical AI practices."
      ],
      "metadata": {
        "id": "G0Vpp7DdlqcY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install Fairlearn library for evaluating model fairness\n",
        "%pip install fairlearn"
      ],
      "metadata": {
        "id": "HD9tUuyTl2RB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from fairlearn.metrics import MetricFrame, selection_rate\n",
        "\n",
        "# Set a random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "# Generate simulated data (100 samples with attributes like age,\n",
        "# income, and gender)\n",
        "n_samples = 100\n",
        "ages = np.random.randint(18, 66, size=n_samples)\n",
        "incomes = np.random.randint(20000, 120001, size=n_samples)\n",
        "genders = np.random.randint(0, 2, size=n_samples)  # 0 for Male, 1 for Female\n",
        "\n",
        "# Simulate loan approval status based on income and age\n",
        "loan_approval = (incomes > 50000) & (ages < 50)\n",
        "loan_approval = loan_approval.astype(int)  # Convert boolean to integer\n",
        "\n",
        "# Create a DataFrame for the dataset\n",
        "data = pd.DataFrame({\n",
        "    'age': ages,\n",
        "    'income': incomes,\n",
        "    'gender': genders,\n",
        "    'loan_approval': loan_approval\n",
        "})\n",
        "\n",
        "# Split the data into features and target variable\n",
        "X = data[['age', 'income', 'gender']]\n",
        "y = data['loan_approval']\n",
        "\n",
        "# Train-test split with 20% data for testing\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train a logistic regression model\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate the model's fairness using Fairlearn\n",
        "predictions = model.predict(X_test)\n",
        "metric_frame = MetricFrame(\n",
        "    metrics=selection_rate,\n",
        "    y_true=y_test,\n",
        "    y_pred=predictions,\n",
        "    sensitive_features=X_test['gender']\n",
        ")\n",
        "\n",
        "# Display bias evaluation results\n",
        "print('\\nSelection rates across gender groups:')\n",
        "print(metric_frame.by_group)"
      ],
      "metadata": {
        "id": "Xd5h41a7mHk0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}