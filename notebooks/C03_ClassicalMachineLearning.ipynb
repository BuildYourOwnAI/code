{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Chapter 3 - Exploring Classical Machine Learning\n",
        "This chapter covers regression and classification techniques using Scikit-learn, demonstrating how classical models like linear regression and decision trees are built, interpreted, and evaluated."
      ],
      "metadata": {
        "id": "c3n10wusCNR6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note:** Run the following cell to define constants related to datasets"
      ],
      "metadata": {
        "id": "RxgGdMvRCQg2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cHihzm4BJZfF"
      },
      "outputs": [],
      "source": [
        "# Base GitHub repository URL\n",
        "BASE_URL = \"https://opensourceai-book.github.io/code/datasets/\"\n",
        "\n",
        "# Dataset file names\n",
        "POWERS_FILE = \"superheroes_powers.csv\"\n",
        "INFO_POWERS_FILE  = \"superheroes_info_powers.csv\"\n",
        "INFO_POWERS2_FILE = \"superheroes_info_powers2.csv\"\n",
        "PLOTS_FILE = \"superheroes_story_plots.csv\"\n",
        "\n",
        "# Construct full dataset URLs\n",
        "SUPERHEROES_POWERS_URL = f\"{BASE_URL}{POWERS_FILE}\"\n",
        "SUPERHEROES_INFO_POWERS_URL = f\"{BASE_URL}{INFO_POWERS_FILE}\"\n",
        "SUPERHEROES_INFO_POWERS2_URL = f\"{BASE_URL}{INFO_POWERS2_FILE}\"\n",
        "SUPERHEROES_INFO_PLOTS_URL = f\"{BASE_URL}{PLOTS_FILE}\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Listing 3-1: Linear Regression of Superhero Height and Weight\n",
        "Performs linear regression to predict height from weight, using filtered superhero data and evaluating with the coefficient, intercept, and mean squared error. Then Plots the actual versus predicted heights, visualizing the linear regression modelâ€™s performance and highlighting how well the model fits the superhero data."
      ],
      "metadata": {
        "id": "9jN9bxgnEbJl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv(SUPERHEROES_INFO_POWERS_URL)\n",
        "\n",
        "# Step 1: Data Preprocessing\n",
        "# Filter for \"Human\" and \"Cyborg\" races\n",
        "df = df[df['Race'].isin(['Human', 'Cyborg'])]\n",
        "\n",
        "# Remove blank (NaN) values for 'Height' and 'Weight'\n",
        "df = df.dropna(subset=['Height', 'Weight'])\n",
        "\n",
        "# Simple outlier removal: Remove extreme values for 'Height' and 'Weight'\n",
        "df = df[(df['Weight'] >= 30) & (df['Weight'] <= 400)]\n",
        "df = df[(df['Height'] >= 100) & (df['Height'] <= 350)]\n",
        "\n",
        "# Select columns for regression\n",
        "X = df[['Weight']].values  # Independent variable (Weight)\n",
        "y = df['Height'].values    # Dependent variable (Height)\n",
        "\n",
        "# Split into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Step 2: Build and Train the Model\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Step 3: Make Predictions and Evaluate\n",
        "y_pred = model.predict(X_test)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "print(f\"Coefficient: {model.coef_[0]}\")\n",
        "print(f\"Intercept: {model.intercept_}\")\n",
        "print(f\"Mean Squared Error: {mse:.2f}\")"
      ],
      "metadata": {
        "id": "qvSmxWWdJ3P-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run the following code cell to plot the results"
      ],
      "metadata": {
        "id": "WasCVJFSCELX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Plot the Results\n",
        "plt.scatter(X_test, y_test, color='blue', label='Actual Heights')\n",
        "plt.plot(X_test, y_pred, color='red', label='Predicted Heights')\n",
        "plt.xlabel(\"Weight\")\n",
        "plt.ylabel(\"Height\")\n",
        "plt.title(\"Linear Regression: Height vs. Weight (Human & Cyborg)\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "GaEkhJGVB223"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Listing 3-2: Training Classification Models for Superhero Races\n",
        "Trains logistic regression and decision tree models to classify superheroes into races (Human, Mutant, Cyborg) using powers data, then outputs accuracy and performance metrics. Then Visualizes the decision tree using a simplified, color-coded representation to help understand how the model makes predictions based on superhero attributes."
      ],
      "metadata": {
        "id": "KzzgENH-FZCN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Load the superhero powers dataset\n",
        "df_powers = pd.read_csv(SUPERHEROES_POWERS_URL)\n",
        "\n",
        "# Load the additional superhero info for race data\n",
        "info_df = pd.read_csv(SUPERHEROES_INFO_POWERS_URL)\n",
        "\n",
        "# Merge powers data with race information\n",
        "df = df_powers.merge(info_df[['name', 'Race']],\n",
        "                     left_on='hero_names', right_on='name')\n",
        "\n",
        "# Filter to only the most common races: Human, Mutant, Cyborg\n",
        "df = df[df['Race'].isin(['Human', 'Mutant', 'Cyborg'])]\n",
        "df = df.dropna()  # Drop any rows with missing data\n",
        "\n",
        "# Convert Race to numerical values\n",
        "df['Race'] = df['Race'].map({'Human': 0, 'Mutant': 1, 'Cyborg': 2})\n",
        "\n",
        "# Select all powers as features\n",
        "X = df.drop(columns=['hero_names', 'name', 'Race']).astype(int).values\n",
        "y = df['Race'].values  # Labels: Human (0), Mutant (1), Cyborg (2)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Logistic Regression Model\n",
        "log_model = LogisticRegression(max_iter=1000)\n",
        "log_model.fit(X_train, y_train)\n",
        "log_predictions = log_model.predict(X_test)\n",
        "log_accuracy = accuracy_score(y_test, log_predictions)\n",
        "log_report = classification_report(y_test, log_predictions)\n",
        "\n",
        "# Decision Tree Model\n",
        "tree_model = DecisionTreeClassifier()\n",
        "tree_model.fit(X_train, y_train)\n",
        "tree_predictions = tree_model.predict(X_test)\n",
        "tree_accuracy = accuracy_score(y_test, tree_predictions)\n",
        "tree_report = classification_report(y_test, tree_predictions)\n",
        "\n",
        "# Output results\n",
        "print(\"Logistic Regression Accuracy:\", log_accuracy)\n",
        "print(\"Logistic Regression Report:\\n\", log_report)\n",
        "print(\"Decision Tree Accuracy:\", tree_accuracy)\n",
        "print(\"Decision Tree Report:\\n\", tree_report)"
      ],
      "metadata": {
        "id": "G_EiS-uBuCVN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run the following code cell to plot the decision tree"
      ],
      "metadata": {
        "id": "bXGx7M4YFsTR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as mpatches\n",
        "\n",
        "# Colors for the races: Blue for Human, Red for Mutant, Yellow for Cyborg\n",
        "colors = ['blue', 'red', 'yellow']\n",
        "\n",
        "# Plot the decision tree using colors only\n",
        "plt.figure(figsize=(12, 8))\n",
        "ax = plt.gca()\n",
        "\n",
        "# Recursive function to plot nodes\n",
        "def plot_node(node, depth, x, width):\n",
        "    if tree_model.tree_.children_left[node] != tree_model.tree_.children_right[node]:\n",
        "        # Calculate positions of child nodes\n",
        "        left_x = x - width / 2\n",
        "        right_x = x + width / 2\n",
        "        next_width = width / 2\n",
        "\n",
        "        # Plot lines to child nodes\n",
        "        ax.plot([x, left_x], [depth, depth + 1], 'k-')\n",
        "        ax.plot([x, right_x], [depth, depth + 1], 'k-')\n",
        "\n",
        "        # Recursively plot child nodes\n",
        "        plot_node(tree_model.tree_.children_left[node], depth + 1,\n",
        "                  left_x, next_width)\n",
        "        plot_node(tree_model.tree_.children_right[node], depth + 1,\n",
        "                  right_x, next_width)\n",
        "    else:\n",
        "        # Plot a colored square for leaf nodes\n",
        "        predicted_class = tree_model.tree_.value[node].argmax()\n",
        "        ax.add_patch(plt.Rectangle((x - 0.1, depth - 0.1), 0.2, 0.2,\n",
        "                                   color=colors[predicted_class]))\n",
        "\n",
        "# Start plotting from the root node\n",
        "plot_node(1, 2, 0.5, 1.0)\n",
        "\n",
        "# Remove axes and add legend\n",
        "ax.axis('off')\n",
        "legend_patches = [mpatches.Patch(color=color, label=label) for color, label in\n",
        "                  zip(colors, ['Human', 'Mutant', 'Cyborg'])]\n",
        "plt.legend(handles=legend_patches, loc='upper right')\n",
        "plt.title(\"Simplified Decision Tree Visualization\")\n",
        "plt.gca().invert_yaxis()  # Invert the y-axis so the root is at the top\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "yqziqTleEN10"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Listing 3-3: Dimensionality Reduction with PCA Power Score\n",
        "This code uses PCA for dimensionality reduction, enhancing the superheroes_info_powers dataset with a more nuanced Power Score, offering a comprehensive measure of superheroes' abilities."
      ],
      "metadata": {
        "id": "FhQO7QQsx3gh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Load the datasets\n",
        "df_info_powers = pd.read_csv(SUPERHEROES_INFO_POWERS_URL)\n",
        "df_powers = pd.read_csv(SUPERHEROES_POWERS_URL)\n",
        "\n",
        "# Merge datasets on hero names\n",
        "df = df_info_powers.merge(df_powers, left_on='name', right_on='hero_names')\n",
        "\n",
        "# Drop columns that are not power-related\n",
        "non_power_cols = ['name', 'Gender', 'Race', 'Height', 'Publisher',\n",
        "                  'Alignment', 'Weight', 'OPR', 'SDR', 'hero_names']\n",
        "X = df.drop(columns=non_power_cols).astype(int)\n",
        "\n",
        "# Standardize the data\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Apply PCA to reduce to one principal component\n",
        "pca = PCA(n_components=1)\n",
        "pca_power_score = pca.fit_transform(X_scaled)\n",
        "\n",
        "# Round PCA power scores to one decimal point\n",
        "pca_power_score = np.round(pca_power_score, 1)\n",
        "\n",
        "# Add the PCA Power Score to the merged dataset\n",
        "df['PCA_Power_Score'] = pca_power_score\n",
        "\n",
        "# Match back only relevant columns to original info_powers dataset\n",
        "df_info_powers = df_info_powers.merge(df[['name', 'PCA_Power_Score']],\n",
        "                                      on='name', how='left')\n",
        "\n",
        "# Save updated dataset to a new CSV file\n",
        "# df_info_powers.to_csv(INFO_POWERS2_FILE, index=False)\n",
        "\n",
        "# Preview the new dataset's features\n",
        "print(df_info_powers)"
      ],
      "metadata": {
        "id": "uAgr3Prkx6-7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Listing 3-4: K-Means Clustering of Superheroes by PCA Power Score and Alignment\n",
        "Applies K-Means Clustering on PCA Power Score and encoded Alignment to group superheroes, adding variation for clearer visualization of clusters using Matplotlib."
      ],
      "metadata": {
        "id": "QKH7qAaDI-jk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.cluster import KMeans\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load the updated dataset with PCA Power Score\n",
        "df_info_powers = pd.read_csv(SUPERHEROES_INFO_POWERS2_URL)\n",
        "\n",
        "# Encode the 'Alignment' feature (0 for bad, 1 for good, 0.5 for neutral)\n",
        "alignment_map = {'bad': 0, 'good': 1, 'neutral': 0.5}\n",
        "df_info_powers['Alignment_Encoded'] = df_info_powers['Alignment'].map(\n",
        "    alignment_map\n",
        ")\n",
        "\n",
        "# Select PCA Power Score and Alignment (encoded)\n",
        "df_cluster = df_info_powers[['PCA_Power_Score', 'Alignment_Encoded']].dropna()\n",
        "\n",
        "# Apply K-Means Clustering with 3 clusters\n",
        "kmeans = KMeans(n_clusters=3, random_state=42)\n",
        "df_cluster['Cluster'] = kmeans.fit_predict(df_cluster)\n",
        "\n",
        "# Add small random variation to 'Alignment_Encoded' values\n",
        "variation = np.random.uniform(-0.1, 0.1, size=df_cluster.shape[0])\n",
        "df_cluster['Alignment_Variation'] = df_cluster['Alignment_Encoded'] + variation\n",
        "\n",
        "# Plot the clusters with adjusted scale and custom colors\n",
        "plt.figure(figsize=(8, 6))\n",
        "scatter = plt.scatter(\n",
        "    df_cluster['PCA_Power_Score'], df_cluster['Alignment_Variation'],\n",
        "    c=df_cluster['Cluster'], cmap='coolwarm', alpha=0.6\n",
        ")\n",
        "plt.xlabel('PCA Power Score')\n",
        "plt.ylabel('Alignment')\n",
        "plt.title('Clustering Using PCA Power Score with Alignment')\n",
        "plt.colorbar(scatter, label='Cluster', ticks=[0, 0.5, 1])\n",
        "plt.yticks([0, 0.5, 1], ['Bad', 'Neutral', 'Good'])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "0rOYkZnqeb7S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Listing 3-5: Cosine Similarity Calculation for Superheroes Relationships\n",
        "Calculates the cosine similarity between superheroes, identifying the most and least similar pairs based on their powers. The results highlight relationships between characters."
      ],
      "metadata": {
        "id": "FjqcOuvvWXQx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Load the info_powers2 dataset\n",
        "df_info_powers = pd.read_csv(SUPERHEROES_INFO_POWERS2_URL)\n",
        "\n",
        "# Select relevant features for cosine similarity calculation\n",
        "features = ['PCA_Power_Score', 'OPR', 'SDR']\n",
        "df_filtered = df_info_powers.dropna(subset=features)\n",
        "\n",
        "# Extract features and corresponding hero names\n",
        "X = df_filtered[features].values\n",
        "hero_names = df_filtered['name'].values\n",
        "\n",
        "# Calculate the cosine similarity matrix\n",
        "cosine_sim_matrix = cosine_similarity(X)\n",
        "\n",
        "# Create a DataFrame for the similarity matrix\n",
        "similarities = pd.DataFrame(cosine_sim_matrix, index=hero_names,\n",
        "                            columns=hero_names)\n",
        "\n",
        "# Flatten the matrix and remove self-comparisons\n",
        "flattened = similarities.reset_index().melt(id_vars='index')\n",
        "flattened = flattened[flattened['index'] != flattened['variable']]\n",
        "\n",
        "# Find the most and least similar pairs\n",
        "most_similar = flattened.loc[flattened['value'].idxmax()]\n",
        "least_similar = flattened.loc[flattened['value'].idxmin()]\n",
        "\n",
        "# Most and Least Similar Heroes\n",
        "print(\"Most Similar Heroes:\")\n",
        "print(f\"Hero 1: {most_similar['index']}\")\n",
        "print(f\"Hero 2: {most_similar['variable']}\")\n",
        "print(f\"Similarity Score: {most_similar['value']}\\n\")\n",
        "\n",
        "print(\"Least Similar Heroes:\")\n",
        "print(f\"Hero 1: {least_similar['index']}\")\n",
        "print(f\"Hero 2: {least_similar['variable']}\")\n",
        "print(f\"Similarity Score: {least_similar['value']}\")"
      ],
      "metadata": {
        "id": "-EDCOneqTekE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Listing 3-6: Training Step 1: Loading and Encoding\n",
        "Combines multiple traits into a single textual representation, summarizing each superhero's profile and encodes gender from text to numerical values, prepping for comprehensive analysis of superhero profiles during training."
      ],
      "metadata": {
        "id": "ERcXuY8iiEeR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the required libraries\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv(SUPERHEROES_INFO_POWERS2_URL)\n",
        "\n",
        "# Drop rows with missing Gender and prepare textual features\n",
        "df = df.dropna(subset=['Gender'])\n",
        "df['Description'] = (\n",
        "    \"Name: \" + df['name'].fillna(\"Unknown\") + \", \" +\n",
        "    \"Race: \" + df['Race'].fillna(\"Unknown\") + \", \" +\n",
        "    \"Height: \" + df['Height'].fillna(0).astype(str) + \", \" +\n",
        "    \"Weight: \" + df['Weight'].fillna(0).astype(str) + \", \" +\n",
        "    \"Offense Boost: \" + df['OPR'].fillna(0).astype(str) + \", \" +\n",
        "    \"Defense Boost: \" + df['SDR'].fillna(0).astype(str) + \", \" +\n",
        "    \"PCA Power Score: \" + df['PCA_Power_Score'].fillna(0).astype(str) + \", \" +\n",
        "    \"Alignment: \" + df['Alignment'].fillna(\"Unknown\")\n",
        ")\n",
        "\n",
        "# Encode Gender into numerical format\n",
        "le_gender = LabelEncoder()\n",
        "df['GenderEncoded'] = le_gender.fit_transform(df['Gender'])\n",
        "\n",
        "# Display the first few rows of the dataset\n",
        "df[['Description', 'Gender', 'GenderEncoded']].head(10)"
      ],
      "metadata": {
        "id": "ippt3PPCiRPR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Listing 3-7: Training Step 2 - Testing the Baseline Accuracy\n",
        "Calculates baseline accuracy by predicting the most frequent class in the training data, providing a benchmark for evaluating model performance."
      ],
      "metadata": {
        "id": "qOMMz9WnWF4Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Transform textual features into numerical vectors using TF-IDF\n",
        "tfidf_vectorizer = TfidfVectorizer()\n",
        "X = tfidf_vectorizer.fit_transform(df['Description'])\n",
        "\n",
        "# Encode the Gender field into numerical format (e.g., Male -> 0, Female -> 1)\n",
        "le_gender = LabelEncoder()\n",
        "y = le_gender.fit_transform(df['Gender'])\n",
        "\n",
        "# Split the dataset into 70% training and 30% testing subsets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42\n",
        ")\n",
        "\n",
        "# Create a baseline prediction using the most frequent class from training data\n",
        "baseline_pred = [y_train[0]] * len(y_test)\n",
        "\n",
        "# Calculate the baseline accuracy by comparing predictions to actual test labels\n",
        "baseline_accuracy = accuracy_score(y_test, baseline_pred)\n",
        "print(f\"Baseline Accuracy (Before Training): {baseline_accuracy:.2f}\")"
      ],
      "metadata": {
        "id": "POAWrvBOWE8E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Listing 3-8: Step 3 - Training a Naive Bayes Model\n",
        "Trains a Naive Bayes classifier using TF-IDF features, evaluates predictions on test data, and reports the model's accuracy. It ensures effective text classification."
      ],
      "metadata": {
        "id": "uWsBZ8Naf7t3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score, classification_report, precision_score\n",
        "from sklearn.metrics import recall_score, f1_score\n",
        "\n",
        "# Train model with baseline TF-IDF\n",
        "nb_model = MultinomialNB()\n",
        "nb_model.fit(X_train, y_train)\n",
        "\n",
        "# Test the model\n",
        "train_pred = nb_model.predict(X_test)\n",
        "\n",
        "# Calculate Accuracy\n",
        "train_accuracy = accuracy_score(y_test, train_pred)\n",
        "\n",
        "# Calculate Precision, Recall, and F1-Score\n",
        "precision = precision_score(y_test, train_pred, average='weighted')\n",
        "recall = recall_score(y_test, train_pred, average='weighted')\n",
        "f1 = f1_score(y_test, train_pred, average='weighted')\n",
        "\n",
        "# Print Metrics\n",
        "print(f\"Accuracy After Training: {train_accuracy:.2f}\")\n",
        "print(f\"Precision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"F1-Score: {f1:.2f}\")\n",
        "\n",
        "# Print Classification Report\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, train_pred, target_names=le_gender.classes_))"
      ],
      "metadata": {
        "id": "LG2onn8MgBEn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Listing 3-9: Step 4 - Fine Tuning\n",
        "Refines TF-IDF parameters, preprocesses descriptions, and retrains the Naive Bayes model for improved performance."
      ],
      "metadata": {
        "id": "-IMUG9aO4WGO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Preprocess Description to remove structural terms\n",
        "df['Processed_Description'] = df['Description'].replace(\n",
        "    r\"(Name:|Race:|Height:|Weight:|Offense Boost:|Defense Boost:|\"\n",
        "    r\"PCA Power Score:|Alignment:)\", \"\", regex=True\n",
        ").str.strip()\n",
        "\n",
        "# Fine-Tune TF-IDF to improve feature extraction\n",
        "tfidf_vectorizer_tuned = TfidfVectorizer(\n",
        "    ngram_range=(1, 1),  # Focus only on unigrams for structured data\n",
        "    min_df=1,            # Capture rare but potentially meaningful terms\n",
        "    max_df=0.8,          # Exclude overly common terms\n",
        "    stop_words=None,     # Do not remove any terms explicitly\n",
        "    max_features=200     # Limit to the top 1000 most informative features\n",
        ")\n",
        "\n",
        "# Transform the cleaned descriptions\n",
        "X_tuned = tfidf_vectorizer_tuned.fit_transform(df['Processed_Description'])\n",
        "\n",
        "# Split data into training and testing sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train_tuned, X_test_tuned, y_train, y_test = train_test_split(\n",
        "    X_tuned, y, test_size=0.3, random_state=42\n",
        ")\n",
        "\n",
        "# Train a Naive Bayes model on the fine-tuned TF-IDF features\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "nb_model = MultinomialNB()\n",
        "nb_model.fit(X_train_tuned, y_train)\n",
        "\n",
        "# Predict using the fine-tuned model\n",
        "fine_tuned_pred = nb_model.predict(X_test_tuned)\n",
        "\n",
        "# Calculate and print key metrics\n",
        "fine_tuned_accuracy = accuracy_score(y_test, fine_tuned_pred)\n",
        "print(f\"Accuracy After Fine-Tuning: {fine_tuned_accuracy:.2f}\")\n",
        "\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, fine_tuned_pred, target_names=le_gender.classes_))\n"
      ],
      "metadata": {
        "id": "O0cOPX0L4erY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Listing 3-10: Step 5 - Visualizing a Confusion Matrix for Model Evaluation\n",
        "Generates and visualizes the confusion matrix, showing the breakdown of correct and incorrect predictions for each class in the dataset."
      ],
      "metadata": {
        "id": "8AizO7lS1yDz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate and display confusion matrix\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "cm_tuned = confusion_matrix(y_test, fine_tuned_pred)\n",
        "ConfusionMatrixDisplay(\n",
        "    confusion_matrix=cm_tuned,\n",
        "    display_labels=le_gender.classes_\n",
        ").plot(cmap=\"Blues\")\n",
        "\n",
        "# Show the plot\n",
        "import matplotlib.pyplot as plt\n",
        "plt.title(\"Confusion Matrix: Fine-Tuned TF-IDF Model\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "VJKRjoMZ13Qq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Listing 3-11: SHAP Explanation for Random Forest\n",
        "SHAP explains predictions of superhero gender from a random forest classifier trained on structured features."
      ],
      "metadata": {
        "id": "7Ta7krYS-d5z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import required libraries\n",
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "import shap\n",
        "\n",
        "# Load dataset and clean missing values\n",
        "df = pd.read_csv(SUPERHEROES_INFO_POWERS2_URL)\n",
        "df = df.dropna(subset=['Gender', 'Height', 'Weight', 'PCA_Power_Score', 'OPR',\n",
        "                       'SDR'])\n",
        "\n",
        "# Select features and encode target variable\n",
        "X = df[['Height', 'Weight', 'PCA_Power_Score', 'OPR', 'SDR']]\n",
        "y = df['Gender'].map({'Male': 1, 'Female': 0})\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3,\n",
        "                                                    random_state=42)\n",
        "\n",
        "# Train Random Forest classifier\n",
        "model = RandomForestClassifier(random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Model Accuracy: {accuracy:.2f}\")\n",
        "\n",
        "# Use SHAP to explain predictions\n",
        "explainer = shap.TreeExplainer(model)\n",
        "shap_values = explainer.shap_values(X_test)\n",
        "\n",
        "# Visualize SHAP summary plot for the Male class\n",
        "shap.summary_plot(shap_values[1], X_test, feature_names=X.columns)\n",
        "\n",
        "# Display sample SHAP contributions with feature values\n",
        "features_df = pd.DataFrame(X_test, columns=X.columns)\n",
        "shap_values_mean = shap_values[1].mean(axis=1)  # Aggregate SHAP values per row\n",
        "shap_values_df = pd.DataFrame(shap_values[1], columns=X.columns)\n",
        "summary_df = pd.concat([features_df, shap_values_df.add_prefix('SHAP_')], axis=1)\n",
        "\n",
        "# Print the first 10 rows for inspection\n",
        "print(\"\\nSample Data with SHAP Contributions:\\n\")\n",
        "print(summary_df.head(10))"
      ],
      "metadata": {
        "id": "Av8CbZ3M-koF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}