{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V5E1"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Chapter 4: Deep Learning\n",
        "\n",
        "**Welcome to Chapter 4**. This notebook contains the listings for Chapter 4, which explains the fundamentals of deep learning."
      ],
      "metadata": {
        "id": "w7DzfChwAQNW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Listing 4-1 A Simply PyTorch Model\n",
        "This listing implements a subset of the general skeleton for the end-to-end lifecycle of a PyTorch project, which includes loading and preparing data, defining or loading a model, specifying the loss function and optimizer, training with validation, evaluating performance, and saving the model for later use. This code demonstrates the essential stages of a working PyTorch program without including optional steps such as inference pipelines or model deployment."
      ],
      "metadata": {
        "id": "Wcad3HisQ7DA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from pathlib import Path\n",
        "\n",
        "# 1. Load and prepare data\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.1307,), (0.3081,))\n",
        "])\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST('.', train=True, download=True, transform=transform),\n",
        "    batch_size=64,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST('.', train=False, transform=transform),\n",
        "    batch_size=1000,\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "# 2. Define or load model\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(28 * 28, 128)\n",
        "        self.fc2 = nn.Linear(128, 64)\n",
        "        self.fc3 = nn.Linear(64, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 28 * 28)   # flatten 28x28 → 784\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        return self.fc3(x)\n",
        "\n",
        "model = Net()\n",
        "\n",
        "# 3. Specify loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# 4. Train model\n",
        "for epoch in range(12):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "\n",
        "    for data, target in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = criterion(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    avg_train_loss = running_loss / len(train_loader)\n",
        "\n",
        "    # 5. Validate model during training\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            output = model(data)\n",
        "            loss = criterion(output, target)\n",
        "            val_loss += loss.item()\n",
        "            preds = output.argmax(dim=1)\n",
        "            correct += (preds == target).sum().item()\n",
        "            total += target.size(0)\n",
        "\n",
        "    avg_val_loss = val_loss / len(test_loader)\n",
        "    val_accuracy = correct / total * 100\n",
        "\n",
        "    print(\n",
        "        f\"Epoch {epoch + 1}: \"\n",
        "        f\"train loss={avg_train_loss:.4f}, \"\n",
        "        f\"val loss={avg_val_loss:.4f}, \"\n",
        "        f\"val acc={val_accuracy:.2f}%\"\n",
        "    )\n",
        "\n",
        "# 6. Evaluate and test (final pass)\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for data, target in test_loader:\n",
        "        output = model(data)\n",
        "        preds = output.argmax(dim=1)\n",
        "        correct += (preds == target).sum().item()\n",
        "        total += target.size(0)\n",
        "\n",
        "test_accuracy = correct / total * 100\n",
        "print(f\"Final Test Accuracy: {test_accuracy:.2f}%\")\n",
        "\n",
        "# 7. Save model\n",
        "save_path = Path(\"mnist_model.pt\").resolve()\n",
        "torch.save(model.state_dict(), save_path)\n",
        "print(\"Model saved to \" + str(save_path))\n"
      ],
      "metadata": {
        "id": "y2s0d4iqP5g1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "mgmlOltCVUoS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Listing 4.2 - Training Accuracy on 1,000 MNIST Samples\n",
        "This example shows how a model can plateau early, leading to diminishing returns."
      ],
      "metadata": {
        "id": "pkbNwjDjz_Gj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "82XoxB7p7w15",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Define the CNN\n",
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.fc = nn.Linear(32 * 7 * 7, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(torch.relu(self.conv1(x)))\n",
        "        x = self.pool(torch.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 32 * 7 * 7)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "# Set up device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Load only 1,000 MNIST training samples\n",
        "transform = transforms.ToTensor()\n",
        "mnist_train = datasets.MNIST(root=\"./data\", train=True, download=True, transform=transform)\n",
        "subset = Subset(mnist_train, list(range(1000)))\n",
        "train_loader = DataLoader(subset, batch_size=32, shuffle=True)\n",
        "\n",
        "# Model, loss, optimizer\n",
        "model = SimpleCNN().to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Train for 30 epochs\n",
        "epochs = 30\n",
        "accuracies = []\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    correct, total = 0, 0\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        correct += (preds == labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "\n",
        "    acc = 100 * correct / total\n",
        "    accuracies.append(acc)\n",
        "    print(f\"Epoch {epoch+1}: Accuracy = {acc:.2f}%\")\n",
        "\n",
        "# Plot the accuracy over epochs\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(range(1, epochs+1), accuracies, marker='o', label='Training Accuracy')\n",
        "plt.xticks(np.arange(1, epochs+1, step=5))\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy (%)')\n",
        "plt.title('Training Accuracy on 1,000 MNIST Samples')\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Listing 4.3 - Using the Trained Model to Predict Custom Digits\n",
        "This code reloads the saved model and uses it to classify new images. Because the model is already trained, the process is straightforward: load the stored weights, prepare the input images using the same preprocessing steps as during training, and then make predictions on the new images.\n"
      ],
      "metadata": {
        "id": "8oeHA0stBZoY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Minimal MNIST inference in Colab\n",
        "\n",
        "import io\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from PIL import Image\n",
        "from google.colab import files\n",
        "import torchvision.transforms as T\n",
        "\n",
        "# 1) Model (same architecture as training)\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(28*28, 128)\n",
        "        self.fc2 = nn.Linear(128, 64)\n",
        "        self.fc3 = nn.Linear(64, 10)\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 28*28)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        return self.fc3(x)\n",
        "\n",
        "# 2) Load trained weights\n",
        "model = Net()\n",
        "model.load_state_dict(torch.load(\"/content/mnist_model.pt\", map_location=\"cpu\"))\n",
        "model.eval()\n",
        "\n",
        "# 3) Preprocessing (match MNIST: 1×28×28 + same normalization)\n",
        "preprocess = T.Compose([\n",
        "    T.Grayscale(),          # ensure 1 channel, since MNIST is grayscale\n",
        "    T.Resize((28, 28)),\n",
        "    T.ToTensor(),\n",
        "    T.Normalize((0.1307,), (0.3081,))\n",
        "])\n",
        "\n",
        "# 4) Upload image(s) and predict\n",
        "@torch.no_grad()\n",
        "def predict(name, content):\n",
        "    img = Image.open(io.BytesIO(content))\n",
        "    x = preprocess(img).unsqueeze(0)      # [1,1,28,28]\n",
        "    pred = model(x).argmax(dim=1).item()\n",
        "    print(f\"The predicted digit for {name} is: {pred}\")\n",
        "\n",
        "print(\"Upload MNIST-like digit image(s):\")\n",
        "for fname, content in files.upload().items():\n",
        "    predict(fname, content)\n"
      ],
      "metadata": {
        "id": "X5uCSo-cBgAw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}