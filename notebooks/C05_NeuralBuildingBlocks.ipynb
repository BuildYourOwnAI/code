{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Chapter 5 Neural Bulding Blocks\n",
        "Before a neural network can recognize a digit, detect objects, understand a sentence, translate text, or complete your email, it needs to *see*, *remember*, *interpret*, and *compress* information. There are four foundational deep learning architectures that make this possible: Autoencoders. CNNs, RNNs, and Transformers. Chapter 5 explains these architectures through examples and visual explanations.\n"
      ],
      "metadata": {
        "id": "3wlxmughMhwS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Listing 5-1 Reconstructing Images from the MNIST Dataset Using an Autoencoder\n",
        "This listing builds a small autoencoder that learns to compress and reconstruct handwritten digits from the MNIST dataset."
      ],
      "metadata": {
        "id": "OWo3R0ru3UP3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------------------------------------------\n",
        "# Step 1: Imports and Setup\n",
        "# ------------------------------------------------------\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# ------------------------------------------------------\n",
        "# Step 2: Load MNIST\n",
        "# ------------------------------------------------------\n",
        "transform = transforms.ToTensor()\n",
        "train_data = datasets.MNIST(\n",
        "    root=\"data\", train=True, transform=transform, download=True\n",
        ")\n",
        "train_loader = DataLoader(train_data, batch_size=256, shuffle=True)\n",
        "\n",
        "# ------------------------------------------------------\n",
        "# Step 3: Define a simple fully connected autoencoder\n",
        "# ------------------------------------------------------\n",
        "class Autoencoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # Encoder: 784 -> 64 -> 16 (bottleneck)\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(28 * 28, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 16),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "        # Decoder: 16 -> 64 -> 784\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(16, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 28 * 28),\n",
        "            nn.Sigmoid(),  # output pixels in [0, 1]\n",
        "        )\n",
        "\n",
        "        # ---------------------------------------------------\n",
        "        # Improving the Output - To get sharper images,\n",
        "        # comment out the original encoder and decoder above,\n",
        "        # and uncomment this wider encoder and decoder:\n",
        "        # ---------------------------------------------------\n",
        "        # self.encoder = nn.Sequential(\n",
        "        #     nn.Flatten(),\n",
        "        #     nn.Linear(28 * 28, 128),\n",
        "        #     nn.ReLU(),\n",
        "        #     nn.Linear(128, 64),\n",
        "        #     nn.ReLU()         # 64-dimensional bottleneck\n",
        "        # )\n",
        "        # self.decoder = nn.Sequential(\n",
        "        #     nn.Linear(64, 128),\n",
        "        #     nn.ReLU(),\n",
        "        #     nn.Linear(128, 28 * 28),\n",
        "        #     nn.Sigmoid()\n",
        "        # )\n",
        "\n",
        "    def forward(self, x):\n",
        "        z = self.encoder(x)\n",
        "        out = self.decoder(z)\n",
        "        return out.view(-1, 1, 28, 28)\n",
        "\n",
        "model = Autoencoder().to(device)\n",
        "criterion = nn.MSELoss() # MSE works well for grayscale\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "# ------------------------------------------------------\n",
        "# Step 4: Train the autoencoder to reconstruct its input\n",
        "# ------------------------------------------------------\n",
        "num_epochs = 3\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    running_loss = 0.0\n",
        "    for imgs, _ in train_loader:\n",
        "        imgs = imgs.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(imgs)\n",
        "        loss = criterion(outputs, imgs)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item() * imgs.size(0)\n",
        "\n",
        "    epoch_loss = running_loss / len(train_loader.dataset)\n",
        "    print(f\"Epoch {epoch + 1}: loss {epoch_loss:.4f}\")\n",
        "\n",
        "# ------------------------------------------------------\n",
        "# Step 5: Visualize original and reconstructed digits\n",
        "# ------------------------------------------------------\n",
        "model.eval()\n",
        "imgs, _ = next(iter(train_loader))\n",
        "imgs = imgs[:8].to(device)\n",
        "\n",
        "with torch.no_grad():\n",
        "    decoded = model(imgs).cpu()\n",
        "\n",
        "imgs = imgs.cpu()\n",
        "\n",
        "plt.figure(figsize=(12, 3))\n",
        "for i in range(8):\n",
        "    # Original\n",
        "    ax = plt.subplot(2, 8, i + 1)\n",
        "    plt.imshow(imgs[i].squeeze(), cmap=\"gray\")\n",
        "    ax.axis(\"off\")\n",
        "\n",
        "    # Reconstructed\n",
        "    ax = plt.subplot(2, 8, i + 9)\n",
        "    plt.imshow(decoded[i].squeeze(), cmap=\"gray\")\n",
        "    ax.axis(\"off\")\n",
        "\n",
        "plt.suptitle(\"Original digits (top) vs reconstructed digits (bottom)\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "ksArdCGP3TGk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Listing 5-2 Using reconstruction error from an autoencoder to detect anomalies\n",
        "This program reuses the MNIST setup and teaches the network what “normal” looks like by training it only on digits 0 through 7. Later, we evaluate it on the full test set, including digits 8 and 9, and see how the reconstruction error changes."
      ],
      "metadata": {
        "id": "CgStv97fCc5H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------------------------------------------\n",
        "# Step 1: Imports and Setup\n",
        "# ------------------------------------------------------\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from torchvision import datasets, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "# ------------------------------------------------------------------\n",
        "# Step 2: Define a simple fully connected autoencoder\n",
        "# ------------------------------------------------------------------\n",
        "class Autoencoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # Encoder: 784 -> 64 -> 16 (bottleneck)\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(28 * 28, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 16),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "        # Decoder: 16 -> 64 -> 784\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(16, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 28 * 28),\n",
        "            nn.Sigmoid(),  # output pixels in [0, 1]\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        z = self.encoder(x)\n",
        "        out = self.decoder(z)\n",
        "        return out.view(-1, 1, 28, 28)\n",
        "\n",
        "# ------------------------------------------------------------------\n",
        "# Step 3: Load MNIST train and test sets\n",
        "# ------------------------------------------------------------------\n",
        "transform = transforms.ToTensor()\n",
        "\n",
        "train_data = datasets.MNIST(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    transform=transform,\n",
        "    download=True,\n",
        ")\n",
        "\n",
        "test_data = datasets.MNIST(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    transform=transform,\n",
        "    download=True,\n",
        ")\n",
        "\n",
        "# ------------------------------------------------------------------\n",
        "# Step 4: Keep only digits 0–7 for training (normal data)\n",
        "# ------------------------------------------------------------------\n",
        "train_mask = train_data.targets < 8\n",
        "x_train_normal = train_data.data[train_mask].float() / 255.0   # [N, 28, 28]\n",
        "x_train_normal = x_train_normal.unsqueeze(1)                   # [N, 1, 28, 28]\n",
        "\n",
        "normal_loader = DataLoader(x_train_normal, batch_size=256, shuffle=True)\n",
        "\n",
        "# ------------------------------------------------------------------\n",
        "# Step 5: Create and train a new autoencoder on normal digits only\n",
        "# ------------------------------------------------------------------\n",
        "model = Autoencoder().to(device)\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "num_epochs = 5\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "\n",
        "    for imgs in normal_loader:\n",
        "        imgs = imgs.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        recon = model(imgs)\n",
        "        loss = criterion(recon, imgs)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item() * imgs.size(0)\n",
        "\n",
        "    epoch_loss = running_loss / len(normal_loader.dataset)\n",
        "    print(f\"Epoch {epoch + 1}: loss {epoch_loss:.4f}\")\n",
        "\n",
        "# ------------------------------------------------------------------\n",
        "# Step 6: Score the entire test set by reconstruction error\n",
        "# ------------------------------------------------------------------\n",
        "x_test = test_data.data.float() / 255.0   # [N, 28, 28]\n",
        "x_test = x_test.unsqueeze(1)              # [N, 1, 28, 28]\n",
        "y_test = test_data.targets                # digit labels\n",
        "\n",
        "test_ds = TensorDataset(x_test, y_test)\n",
        "test_loader = DataLoader(test_ds, batch_size=256, shuffle=False)\n",
        "\n",
        "model.eval()\n",
        "all_errors = []\n",
        "all_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for imgs, labels in test_loader:\n",
        "        imgs = imgs.to(device)\n",
        "        recon = model(imgs)\n",
        "\n",
        "        # Mean squared error per image, averaged over all pixels\n",
        "        err = ((imgs - recon) ** 2).mean(dim=[1, 2, 3]).cpu()\n",
        "\n",
        "        all_errors.append(err)\n",
        "        all_labels.append(labels)\n",
        "\n",
        "errors = torch.cat(all_errors).numpy()\n",
        "labels = torch.cat(all_labels).numpy()\n",
        "\n",
        "# ------------------------------------------------------------------\n",
        "# Step 7: Compare reconstruction error for normal digits (0-7)\n",
        "#         and unusual digits (8-9)\n",
        "# ------------------------------------------------------------------\n",
        "normal_mask = labels < 8\n",
        "anom_mask = labels >= 8\n",
        "\n",
        "# Use a threshold based on NORMAL data only (typical anomaly-detection practice)\n",
        "threshold = np.percentile(errors[normal_mask], 95)\n",
        "\n",
        "# Use shared bin edges so the histograms are directly comparable\n",
        "bins = np.linspace(errors.min(), errors.max(), 41)\n",
        "\n",
        "plt.figure(figsize=(8, 4))\n",
        "\n",
        "# Option A: counts with a clearer y-label\n",
        "plt.hist(\n",
        "    errors[normal_mask],\n",
        "    bins=bins,\n",
        "    histtype=\"step\",\n",
        "    label=\"Digits 0–7 (test set)\",\n",
        ")\n",
        "plt.hist(\n",
        "    errors[anom_mask],\n",
        "    bins=bins,\n",
        "    histtype=\"step\",\n",
        "    linestyle=\"--\",\n",
        "    label=\"Digits 8–9 (test set)\",\n",
        ")\n",
        "\n",
        "# If you prefer Option B, uncomment density=True in both hist calls\n",
        "# and change ylabel.\n",
        "# plt.hist(..., density=True, ...)\n",
        "# plt.ylabel(\"Probability density\")\n",
        "\n",
        "plt.axvline(threshold, color=\"black\", linestyle=\":\", label=\"Threshold (95th pct of digits 0–7)\")\n",
        "\n",
        "plt.xlabel(\"Reconstruction error (MSE per image)\")\n",
        "plt.ylabel(\"Number of test images (per bin)\")\n",
        "plt.title(\"Autoencoder anomaly detection on MNIST\")\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# ------------------------------------------------------------------\n",
        "# Step 8: Confirm what contributes to the right tail\n",
        "# ------------------------------------------------------------------\n",
        "tail_mask = errors >= threshold\n",
        "\n",
        "# (A) Tail composition by digit label\n",
        "unique, counts = np.unique(labels[tail_mask], return_counts=True)\n",
        "tail_counts = dict(zip(unique.tolist(), counts.tolist()))\n",
        "total_tail = int(tail_mask.sum())\n",
        "\n",
        "print(f\"Images in the tail (error ≥ threshold): {total_tail}\")\n",
        "print(\"Tail breakdown by digit label:\")\n",
        "for d in range(10):\n",
        "    c = tail_counts.get(d, 0)\n",
        "    if c > 0:\n",
        "        print(f\"  Digit {d}: {c} ({c / total_tail:.1%})\")\n",
        "\n",
        "# (B) Show a few highest-error examples and their labels\n",
        "k = 12\n",
        "idx_sorted = np.argsort(errors)[::-1]\n",
        "top_idx = idx_sorted[:k]\n",
        "\n",
        "print(\"\\nTop error examples (label, error):\")\n",
        "for i in top_idx:\n",
        "    print(f\"  {int(labels[i])}, {errors[i]:.4f}\")\n",
        "\n",
        "# Visualize those top-k images\n",
        "fig, axs = plt.subplots(1, k, figsize=(1.2 * k, 2))\n",
        "for ax, i in zip(axs, top_idx):\n",
        "    ax.imshow(x_test[i].squeeze().numpy(), cmap=\"gray\")\n",
        "    ax.set_title(str(int(labels[i])))\n",
        "    ax.axis(\"off\")\n",
        "plt.suptitle(\"Highest reconstruction errors (titles are true labels)\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "DLd4c6xJESb3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Listing 5-3 Using a pretrained YOLOv5 model to detect objects in an image\n",
        "This example lets you upload an image and count the objects in it using a pre-trained YOLOv5 object-detection model."
      ],
      "metadata": {
        "id": "G-k9fmTh-1B4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y8mfKr5VMgpX"
      },
      "outputs": [],
      "source": [
        "# ------------------------------------------------------------------\n",
        "# Step 1: Set up YOLOv5 and install dependencies\n",
        "# ------------------------------------------------------------------\n",
        "!git clone https://github.com/ultralytics/yolov5  # clone\n",
        "%cd yolov5\n",
        "%pip install -r requirements.txt\n",
        "\n",
        "# ------------------------------------------------------------------\n",
        "# Step 2: Imports\n",
        "# ------------------------------------------------------------------\n",
        "import torch\n",
        "import cv2\n",
        "from collections import Counter\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "from google.colab import files\n",
        "import io\n",
        "\n",
        "# ------------------------------------------------------------------\n",
        "# Step 3: Upload an image\n",
        "# ------------------------------------------------------------------\n",
        "uploaded = files.upload()\n",
        "image_path = next(iter(uploaded))  # take the first uploaded file\n",
        "\n",
        "# ------------------------------------------------------------------\n",
        "# Step 4: Load pretrained model\n",
        "#         This example uses the medium-sized YOLOv5m variant.\n",
        "# ------------------------------------------------------------------\n",
        "model = torch.hub.load('.', 'yolov5m', source='local')\n",
        "\n",
        "# ------------------------------------------------------------------\n",
        "# Step 5: Run inference\n",
        "# ------------------------------------------------------------------\n",
        "results = model(image_path)\n",
        "\n",
        "# ------------------------------------------------------------------\n",
        "# Step 6: Count detected classes\n",
        "# ------------------------------------------------------------------\n",
        "detections = results.pandas().xyxy[0]\n",
        "class_names = detections['name'].tolist()\n",
        "counts = Counter(class_names)\n",
        "\n",
        "print(\"\\nDetected Objects:\")\n",
        "for label, count in counts.items():\n",
        "    print(f\"- {label}: {count}\")\n",
        "\n",
        "# ------------------------------------------------------------------\n",
        "# Step 7: Display image with bounding boxes\n",
        "# ------------------------------------------------------------------\n",
        "results.render()\n",
        "img = Image.fromarray(results.ims[0])\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.imshow(img)\n",
        "plt.axis('off')\n",
        "plt.title(\"Detected Objects\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Listing 5-4 YOLOv5 video object detection implemented as repeated image detection using YOLOv5\n",
        "This code runs YOLOv5 on an uploaded video inside a Colab notebook and prints a compact per-second table. With a few additional steps, the same pattern can support traffic monitoring, wildlife observation, or automated inspection on a conveyor belt."
      ],
      "metadata": {
        "id": "suZ2k7S9XDnl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------------------------------------------------------------\n",
        "# Step 1: Suppress nonessential warnings (including AMP FutureWarnings)\n",
        "# ----------------------------------------------------------------------\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "\n",
        "# ----------------------------------------------------------------------\n",
        "# Step 2: Setup and imports\n",
        "# ----------------------------------------------------------------------\n",
        "!git clone https://github.com/ultralytics/yolov5\n",
        "%cd yolov5\n",
        "%pip install -r requirements.txt\n",
        "\n",
        "import torch\n",
        "import cv2\n",
        "from collections import Counter, defaultdict\n",
        "from google.colab import files\n",
        "import math\n",
        "\n",
        "# ----------------------------------------------------------------------\n",
        "# Step 3: Load pretrained model\n",
        "# ----------------------------------------------------------------------\n",
        "model = torch.hub.load('.', 'yolov5m', source='local')\n",
        "model.conf = 0.25  # confidence threshold (optional)\n",
        "\n",
        "# ----------------------------------------------------------------------\n",
        "# Step 4: Upload video\n",
        "# ----------------------------------------------------------------------\n",
        "print(\"Please upload a video file (e.g., .mp4)\")\n",
        "uploaded = files.upload()\n",
        "video_source = next(iter(uploaded.keys()))\n",
        "\n",
        "cap = cv2.VideoCapture(video_source)\n",
        "if not cap.isOpened():\n",
        "    raise RuntimeError(f\"Could not open video source: {video_source}\")\n",
        "\n",
        "# ----------------------------------------------------------------------\n",
        "# Step 5: Determine FPS (fallback if missing)\n",
        "# ----------------------------------------------------------------------\n",
        "fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "if not fps or math.isnan(fps) or fps < 1:\n",
        "    fps = 30.0\n",
        "\n",
        "# ----------------------------------------------------------------------\n",
        "# Step 6: Limit runtime for notebook safety\n",
        "# ----------------------------------------------------------------------\n",
        "MAX_SECONDS = 15\n",
        "max_frames = int(MAX_SECONDS * fps)\n",
        "\n",
        "# ----------------------------------------------------------------------\n",
        "# Step 7: Store per-second MAX counts (non-accumulating)\n",
        "# ----------------------------------------------------------------------\n",
        "per_second_max = defaultdict(Counter)\n",
        "\n",
        "frame_idx = 0  # 0-based\n",
        "while True:\n",
        "    ret, frame_bgr = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    if frame_idx >= max_frames:\n",
        "        break\n",
        "\n",
        "    second = int(frame_idx / fps)\n",
        "    frame_idx += 1\n",
        "\n",
        "    # OpenCV uses BGR; YOLO expects RGB\n",
        "    frame_rgb = cv2.cvtColor(frame_bgr, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # Run inference\n",
        "    results = model(frame_rgb)\n",
        "    detections = results.pandas().xyxy[0]\n",
        "    frame_counts = Counter(detections[\"name\"].tolist())\n",
        "\n",
        "    # Keep the maximum count seen in any frame during this second\n",
        "    for label, count in frame_counts.items():\n",
        "        if count > per_second_max[second][label]:\n",
        "            per_second_max[second][label] = count\n",
        "\n",
        "cap.release()\n",
        "\n",
        "# ----------------------------------------------------------------------\n",
        "# Step 8: Final per-second table\n",
        "# ----------------------------------------------------------------------\n",
        "print(\"\\nPer-second detection summary (max per-frame counts):\\n\")\n",
        "\n",
        "for second in sorted(per_second_max.keys()):\n",
        "    counts = per_second_max[second]\n",
        "    summary = \", \".join(f\"{k}={v}\" for k, v in counts.most_common()) if counts else \"(none)\"\n",
        "    print(f\"t={second:2d}s | {summary}\")\n"
      ],
      "metadata": {
        "id": "P8y1yYyrXbU9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Listing 5-5 Removing backgrounds with a segmentation CNN\n",
        "This example uses a pretrained DeepLabV3 network, which preserves the spatial structure of the image and assigns a class label to each pixel. The result is a detailed map that shows which parts of the scene belong to the subject and which parts are background. The code uses this map to remove the background of the image."
      ],
      "metadata": {
        "id": "LsrabvTwQpX2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CNN example: Remove the background with DeepLabV3 segmentation\n",
        "# Upload one image (a child, a person, etc.) and the CNN will\n",
        "# output a transparent PNG.\n",
        "\n",
        "# ----------------------------------------------------------------------\n",
        "# Step 1: Imports and Setup\n",
        "# ----------------------------------------------------------------------\n",
        "import io\n",
        "import numpy as np\n",
        "import torch\n",
        "from torchvision import models\n",
        "from PIL import Image\n",
        "from google.colab import files\n",
        "from IPython.display import display\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "# ----------------------------------------------------------------------\n",
        "# Step 2: Load pretrained DeepLabV3 model and its transforms\n",
        "# ----------------------------------------------------------------------\n",
        "weights = models.segmentation.DeepLabV3_ResNet50_Weights.DEFAULT\n",
        "model = models.segmentation.deeplabv3_resnet50(weights=weights).to(device).eval()\n",
        "preprocess = weights.transforms()\n",
        "\n",
        "# ----------------------------------------------------------------------\n",
        "# Step 3: Upload an image\n",
        "# ----------------------------------------------------------------------\n",
        "print(\"Please upload a photo\")\n",
        "uploaded = files.upload()\n",
        "filename = next(iter(uploaded.keys()))\n",
        "\n",
        "img = Image.open(io.BytesIO(uploaded[filename])).convert(\"RGB\")\n",
        "\n",
        "# ----------------------------------------------------------------------\n",
        "# Step 4: Run the image through the CNN\n",
        "# ----------------------------------------------------------------------\n",
        "input_tensor = preprocess(img).unsqueeze(0).to(device)\n",
        "\n",
        "with torch.no_grad():\n",
        "    output = model(input_tensor)[\"out\"][0]  # [num_classes, H, W]\n",
        "\n",
        "labels = output.argmax(0).cpu().numpy()\n",
        "\n",
        "# ----------------------------------------------------------------------\n",
        "# Step 5: Build a foreground mask: anything not background (class 0)\n",
        "# ----------------------------------------------------------------------\n",
        "foreground_mask = labels != 0\n",
        "\n",
        "# ----------------------------------------------------------------------\n",
        "# Step 6: Make the background transparent (RGBA + alpha channel)\n",
        "# ----------------------------------------------------------------------\n",
        "img_resized = img.resize((labels.shape[1], labels.shape[0])).convert(\"RGBA\")\n",
        "img_np = np.array(img_resized).copy()\n",
        "\n",
        "alpha = np.where(foreground_mask, 255, 0).astype(np.uint8)\n",
        "img_np[..., 3] = alpha\n",
        "\n",
        "# ----------------------------------------------------------------------\n",
        "# Step 7: Display the result\n",
        "# ----------------------------------------------------------------------\n",
        "result_pil = Image.fromarray(img_np)\n",
        "print(\"Showing result…\")\n",
        "display(result_pil)\n",
        "\n",
        "# ----------------------------------------------------------------------\n",
        "# Step 8: Optional: save a PNG with transparency\n",
        "# ----------------------------------------------------------------------\n",
        "out_name = \"background_removed.png\"\n",
        "result_pil.save(out_name)\n",
        "print(\"Saved:\", out_name)"
      ],
      "metadata": {
        "id": "LJslSAjobZhY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Listing 5-6 A simple LSTM model that trains on historical NVDA prices and plots the network’s forecast against the actual market data\n",
        "This code trains on historical data and evaluates the LSTM on the last part of that same history. It is not forecasting future dates beyond the dataset. It is learning to map a window of recent prices to the next price inside the same historical period. This setup is useful for learning and for checking whether the network has captured basic trends.  "
      ],
      "metadata": {
        "id": "OHRstEzwTe4J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------------------------------------------------------------\n",
        "# Step 1: Setup and Imports\n",
        "# ----------------------------------------------------------------------\n",
        "!pip install yfinance matplotlib scikit-learn torch --quiet\n",
        "import yfinance as yf\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ----------------------------------------------------------------------\n",
        "# Step 2: Download and scale the time-series data\n",
        "# ----------------------------------------------------------------------\n",
        "def get_timeseries(ticker, start, end, seq_len=20):\n",
        "    data = yf.download(ticker, start=start, end=end)\n",
        "    prices = data[['Close']].values.astype('float32')\n",
        "    scaler = MinMaxScaler()\n",
        "\n",
        "    # ----------------------------------------------------------------------\n",
        "    # Step 2a: In strict forecasting pipelines, scalers are fit\n",
        "    #          on training data only\n",
        "    # ----------------------------------------------------------------------\n",
        "    scaled = scaler.fit_transform(prices)\n",
        "\n",
        "    X, y = [], []\n",
        "    for i in range(len(scaled) - seq_len):\n",
        "        X.append(scaled[i:i+seq_len])\n",
        "        y.append(scaled[i+seq_len])\n",
        "    return torch.tensor(X), torch.tensor(y), scaler, data.index[seq_len:]\n",
        "\n",
        "# ----------------------------------------------------------------------\n",
        "# Step 3: Define the LSTM model\n",
        "# ----------------------------------------------------------------------\n",
        "class PriceLSTM(nn.Module):\n",
        "    def __init__(self, hidden_size=50):\n",
        "        super().__init__()\n",
        "        # input_size=1 (one feature: closing price)\n",
        "        # hidden_size controls the dimensionality of the internal state\n",
        "        # batch_first=True means input shape is (batch, sequence_length, features)\n",
        "        self.lstm = nn.LSTM(1, hidden_size, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, 1)\n",
        "    def forward(self, x):\n",
        "        out, _ = self.lstm(x)\n",
        "        # out has shape (batch_size, sequence_length, hidden_size)\n",
        "        # out[:, -1, :] selects the final time step for each sequence\n",
        "        return self.fc(out[:, -1, :])\n",
        "\n",
        "# ----------------------------------------------------------------------\n",
        "# Step 4: Train the model\n",
        "# ----------------------------------------------------------------------\n",
        "def train_model(ticker='NVDA', start='2024-01-01', end='2027-12-31', epochs=200):\n",
        "    X, y, scaler, dates = get_timeseries(ticker, start, end)\n",
        "    split = int(0.8 * len(X))\n",
        "    X_train, X_test = X[:split], X[split:]\n",
        "    y_train, y_test = y[:split], y[split:]\n",
        "\n",
        "    model = PriceLSTM()\n",
        "    criterion = nn.MSELoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "    model.train()\n",
        "\n",
        "    for _ in range(epochs):\n",
        "        optimizer.zero_grad()\n",
        "        loss = criterion(model(X_train), y_train)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    return model, X_test, y_test, scaler, dates[split:]\n",
        "\n",
        "# ----------------------------------------------------------------------\n",
        "# Step 5: Evaluate and visualize predictions\n",
        "# ----------------------------------------------------------------------\n",
        "def evaluate_model(model, X_test, y_test, scaler, dates, ticker):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        preds = model(X_test)\n",
        "    actual = scaler.inverse_transform(y_test)\n",
        "    predicted = scaler.inverse_transform(preds.numpy())\n",
        "\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    plt.plot(dates, actual, label=\"Actual\", color=\"black\")\n",
        "    plt.plot(dates, predicted, label=\"Predicted\", linestyle=\"--\", color=\"gray\")\n",
        "    plt.title(f\"{ticker} Price Forecast\")\n",
        "    plt.xlabel(\"Date\"); plt.ylabel(\"Price\")\n",
        "    plt.legend(); plt.grid(True); plt.tight_layout(); plt.show()\n",
        "\n",
        "# ----------------------------------------------------------------------\n",
        "# Step 6: Run the experiment\n",
        "# ----------------------------------------------------------------------\n",
        "model, X_test, y_test, scaler, dates = train_model(\n",
        "    ticker=\"NVDA\",\n",
        "    start=\"2018-01-01\",\n",
        "    end=\"2023-12-31\",\n",
        "    epochs=50,\n",
        ")\n",
        "evaluate_model(model, X_test, y_test, scaler, dates, \"NVDA\")"
      ],
      "metadata": {
        "id": "_JkMkYcPTLN0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Listing 5-7: Sequence Modeling Demo: RNN vs. LSTM vs. GRU\n",
        "Listing 5-7 in the Google Colab notebook presents a compact, end-to-end sequence modeling demonstration comparing three recurrent architectures: a basic RNN, an LSTM, and a GRU. The code is intentionally small and self-contained so that each transformation is visible.\n",
        "\n",
        "The goal is conceptual clarity, not state-of-the-art language modeling. You will see how text becomes numbers, how sequences become supervised training examples, and how recurrent architectures transform short context into a probability distribution over the next word.\n"
      ],
      "metadata": {
        "id": "RqObfBPvPEPx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------------------------\n",
        "# Step 1. Import Required Libraries\n",
        "# ---------------------------------------------\n",
        "# PyTorch: Deep learning framework for building neural networks\n",
        "# torch.nn: Neural network modules (layers, loss functions)\n",
        "# torch.optim: Optimization algorithms (Adam, SGD, etc.)\n",
        "# numpy: Numerical computing library\n",
        "# re: Regular expressions for text preprocessing\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "import re\n",
        "\n",
        "# ---------------------------------------------\n",
        "# Step 2. Set Random Seeds for Reproducibility\n",
        "# ---------------------------------------------\n",
        "# Setting seeds ensures that random operations produce the same results\n",
        "# every time the program runs, making experiments reproducible\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "# ---------------------------------------------\n",
        "# Step 3. Define Training Corpus\n",
        "# ---------------------------------------------\n",
        "# This is our training data - a small collection of simple sentences\n",
        "# The models will learn patterns from these sentences to predict next words\n",
        "CORPUS = \"\"\"\n",
        "Mary had a little lamb\n",
        "the cat sat on the mat\n",
        "the dog sat on the log\n",
        "the bird flew over the tree\n",
        "The quick brown fox jumps over the lazy dog\n",
        "the fish swam in the sea\n",
        "Mary had a dog and they played together\n",
        "the cat and the dog played together\n",
        "the bird sang in the tree\n",
        "the fish jumped out of the sea\n",
        "the dog ran to the park\n",
        "Mary had a bird that flew away\n",
        "the cat climbed up the tree\n",
        "the bird built a nest in the tree\n",
        "\"\"\"\n",
        "\n",
        "# ---------------------------------------------\n",
        "# Step 4. Define RNN Model Architecture\n",
        "# ---------------------------------------------\n",
        "# RNN (Recurrent Neural Network) is the simplest sequential model\n",
        "# It processes sequences one element at a time, maintaining a hidden state\n",
        "# Problem: Struggles with long-term dependencies due to vanishing gradients\n",
        "class RNNModel(nn.Module):\n",
        "    \"\"\"Simple RNN model for sequence prediction\"\"\"\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim):\n",
        "        super(RNNModel, self).__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "\n",
        "        # Embedding layer: Converts word indices to dense vectors\n",
        "        # vocab_size: Number of unique words in vocabulary\n",
        "        # embedding_dim: Size of the embedding vector for each word\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "\n",
        "        # RNN layer: Processes sequences and maintains hidden state\n",
        "        # batch_first=True means input shape is (batch, sequence, features)\n",
        "        self.rnn = nn.RNN(embedding_dim, hidden_dim, batch_first=True)\n",
        "\n",
        "        # Fully connected layer: Maps hidden state to vocabulary predictions\n",
        "        self.fc = nn.Linear(hidden_dim, vocab_size)\n",
        "\n",
        "    def forward(self, x, hidden=None):\n",
        "        # Convert word indices to embeddings\n",
        "        embedded = self.embedding(x)\n",
        "\n",
        "        # Process sequence through RNN\n",
        "        # output: all hidden states, hidden: final hidden state\n",
        "        output, hidden = self.rnn(embedded, hidden)\n",
        "\n",
        "        # Take only the last time step's output for prediction\n",
        "        output = self.fc(output[:, -1, :])\n",
        "        return output, hidden\n",
        "\n",
        "# ---------------------------------------------\n",
        "# Step 5. Define LSTM Model Architecture\n",
        "# ---------------------------------------------\n",
        "# LSTM (Long Short-Term Memory) improves upon RNN with memory cells\n",
        "# It uses gates (input, forget, output) to control information flow\n",
        "# Advantage: Better at capturing long-term dependencies in sequences\n",
        "class LSTMModel(nn.Module):\n",
        "    \"\"\"LSTM model for sequence prediction\"\"\"\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim):\n",
        "        super(LSTMModel, self).__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "\n",
        "        # Embedding layer: Same as RNN, converts words to vectors\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "\n",
        "        # LSTM layer: Uses gates to selectively remember/forget information\n",
        "        # Has both hidden state (h) and cell state (c)\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
        "\n",
        "        # Output layer: Maps LSTM output to vocabulary predictions\n",
        "        self.fc = nn.Linear(hidden_dim, vocab_size)\n",
        "\n",
        "    def forward(self, x, hidden=None):\n",
        "        # Convert word indices to embeddings\n",
        "        embedded = self.embedding(x)\n",
        "\n",
        "        # Process through LSTM\n",
        "        # hidden contains both h (hidden state) and c (cell state)\n",
        "        output, hidden = self.lstm(embedded, hidden)\n",
        "\n",
        "        # Use last time step for prediction\n",
        "        output = self.fc(output[:, -1, :])\n",
        "        return output, hidden\n",
        "\n",
        "# ---------------------------------------------\n",
        "# Step 6. Define GRU Model Architecture\n",
        "# ---------------------------------------------\n",
        "# GRU (Gated Recurrent Unit) is a simplified version of LSTM\n",
        "# Uses only 2 gates (reset and update) instead of 3\n",
        "# Advantage: Fewer parameters than LSTM, often trains faster with similar performance\n",
        "class GRUModel(nn.Module):\n",
        "    \"\"\"GRU model for sequence prediction\"\"\"\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim):\n",
        "        super(GRUModel, self).__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "\n",
        "        # Embedding layer: Converts word indices to dense vectors\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "\n",
        "        # GRU layer: Simpler than LSTM but still handles long-term dependencies\n",
        "        # Uses reset gate and update gate to control information flow\n",
        "        self.gru = nn.GRU(embedding_dim, hidden_dim, batch_first=True)\n",
        "\n",
        "        # Output layer: Projects GRU output to vocabulary size\n",
        "        self.fc = nn.Linear(hidden_dim, vocab_size)\n",
        "\n",
        "    def forward(self, x, hidden=None):\n",
        "        # Convert word indices to embeddings\n",
        "        embedded = self.embedding(x)\n",
        "\n",
        "        # Process through GRU\n",
        "        # GRU only has hidden state (no separate cell state like LSTM)\n",
        "        output, hidden = self.gru(embedded, hidden)\n",
        "\n",
        "        # Use last time step's output for prediction\n",
        "        output = self.fc(output[:, -1, :])\n",
        "        return output, hidden\n",
        "\n",
        "# ---------------------------------------------\n",
        "# Step 7. Define SequencePredictor Class\n",
        "# ---------------------------------------------\n",
        "# This class orchestrates the entire workflow:\n",
        "# - Data preprocessing and vocabulary building\n",
        "# - Creating training sequences\n",
        "# - Training models\n",
        "# - Making predictions\n",
        "class SequencePredictor:\n",
        "    \"\"\"Handles data preprocessing, training, and prediction\"\"\"\n",
        "    def __init__(self, corpus, embedding_dim=32, hidden_dim=64, seq_length=3):\n",
        "        # seq_length: How many words to use as context for prediction\n",
        "        # embedding_dim: Size of word embedding vectors\n",
        "        # hidden_dim: Size of RNN/LSTM/GRU hidden state\n",
        "        self.seq_length = seq_length\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "\n",
        "        # Preprocess the corpus into a list of words\n",
        "        self.words = self._preprocess(corpus)\n",
        "\n",
        "        # Build vocabulary: unique words sorted alphabetically\n",
        "        self.vocab = sorted(set(self.words))\n",
        "        self.vocab_size = len(self.vocab)\n",
        "\n",
        "        # Create bidirectional mappings between words and indices\n",
        "        # word2idx: Convert words to numbers for neural network input\n",
        "        # idx2word: Convert predictions back to words\n",
        "        self.word2idx = {word: idx for idx, word in enumerate(self.vocab)}\n",
        "        self.idx2word = {idx: word for word, idx in self.word2idx.items()}\n",
        "\n",
        "        # Create training data: sequences of words and their next word\n",
        "        self.X_train, self.y_train = self._create_sequences()\n",
        "\n",
        "        # Initialize all three model architectures for comparison\n",
        "        self.rnn_model = RNNModel(self.vocab_size, embedding_dim, hidden_dim)\n",
        "        self.lstm_model = LSTMModel(self.vocab_size, embedding_dim, hidden_dim)\n",
        "        self.gru_model = GRUModel(self.vocab_size, embedding_dim, hidden_dim)\n",
        "\n",
        "    # ---------------------------------------------\n",
        "    # Step 8. Text Preprocessing Method\n",
        "    # ---------------------------------------------\n",
        "    def _preprocess(self, text):\n",
        "        \"\"\"Tokenize and clean text\"\"\"\n",
        "        # Convert all text to lowercase for consistency\n",
        "        text = text.lower()\n",
        "\n",
        "        # Remove all non-alphabetic characters (keep only letters and spaces)\n",
        "        # This removes punctuation, numbers, etc.\n",
        "        text = re.sub(r'[^a-z\\s]', '', text)\n",
        "\n",
        "        # Split text into individual words\n",
        "        words = text.split()\n",
        "        return words\n",
        "\n",
        "    # ---------------------------------------------\n",
        "    # Step 9. Create Training Sequences\n",
        "    # ---------------------------------------------\n",
        "    def _create_sequences(self):\n",
        "        \"\"\"Create input-output sequences for training\"\"\"\n",
        "        # X: Input sequences (context words)\n",
        "        # y: Target words (what comes next)\n",
        "        X, y = [], []\n",
        "\n",
        "        # Slide a window through the text\n",
        "        # For each position, take seq_length words as input\n",
        "        # and the next word as the target to predict\n",
        "        for i in range(len(self.words) - self.seq_length):\n",
        "            # Extract sequence of words as context\n",
        "            sequence = self.words[i:i + self.seq_length]\n",
        "\n",
        "            # The word immediately after the sequence is the target\n",
        "            target = self.words[i + self.seq_length]\n",
        "\n",
        "            # Convert words to indices (neural networks need numbers)\n",
        "            X.append([self.word2idx[word] for word in sequence])\n",
        "            y.append(self.word2idx[target])\n",
        "\n",
        "        # Convert to PyTorch tensors for training\n",
        "        return torch.tensor(X), torch.tensor(y)\n",
        "\n",
        "    # ---------------------------------------------\n",
        "    # Step 10. Model Training Method\n",
        "    # ---------------------------------------------\n",
        "    def train_model(self, model, epochs=100, lr=0.01):\n",
        "        \"\"\"Train a given model\"\"\"\n",
        "        # CrossEntropyLoss: Standard loss for classification tasks\n",
        "        # Combines softmax and negative log likelihood\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "        # Adam optimizer: Adaptive learning rate optimization algorithm\n",
        "        # Generally works well without much tuning\n",
        "        optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "        # Set model to training mode (enables dropout, batch norm, etc.)\n",
        "        model.train()\n",
        "\n",
        "        # Training loop: Iterate through the dataset multiple times\n",
        "        for epoch in range(epochs):\n",
        "            # Zero out gradients from previous iteration\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Forward pass: Get model predictions\n",
        "            output, _ = model(self.X_train)\n",
        "\n",
        "            # Calculate loss: How wrong are the predictions?\n",
        "            loss = criterion(output, self.y_train)\n",
        "\n",
        "            # Backward pass: Calculate gradients\n",
        "            loss.backward()\n",
        "\n",
        "            # Update model parameters based on gradients\n",
        "            optimizer.step()\n",
        "\n",
        "            # Print progress every 20 epochs\n",
        "            if (epoch + 1) % 20 == 0:\n",
        "                print(f\"  Epoch {epoch + 1}/{epochs}, Loss: {loss.item():.4f}\")\n",
        "\n",
        "    # ---------------------------------------------\n",
        "    # Step 11. Prediction Method\n",
        "    # ---------------------------------------------\n",
        "    def predict_next_word(self, model, input_phrase):\n",
        "        \"\"\"Predict the next word given an input phrase\"\"\"\n",
        "        # Set model to evaluation mode (disables dropout, etc.)\n",
        "        model.eval()\n",
        "\n",
        "        # Clean and tokenize the input phrase\n",
        "        words = self._preprocess(input_phrase)\n",
        "\n",
        "        # Handle phrases shorter than required sequence length\n",
        "        # Pad with 'the' (a common word) to reach seq_length\n",
        "        if len(words) < self.seq_length:\n",
        "            print(f\"  Warning: Input phrase has {len(words)} words, padding to {self.seq_length} words\")\n",
        "            words = ['the'] * (self.seq_length - len(words)) + words\n",
        "\n",
        "        # If phrase is longer, take only the last seq_length words\n",
        "        words = words[-self.seq_length:]\n",
        "\n",
        "        # Convert words to indices, handling unknown words gracefully\n",
        "        indices = []\n",
        "        for word in words:\n",
        "            if word in self.word2idx:\n",
        "                indices.append(self.word2idx[word])\n",
        "            else:\n",
        "                # Unknown words are replaced with 'the'\n",
        "                print(f\"  Warning: Unknown word '{word}', using 'the' instead\")\n",
        "                indices.append(self.word2idx['the'])\n",
        "\n",
        "        # Create input tensor with batch dimension\n",
        "        input_tensor = torch.tensor([indices])\n",
        "\n",
        "        # Make prediction without computing gradients (saves memory)\n",
        "        with torch.no_grad():\n",
        "            # Get model output (logits)\n",
        "            output, _ = model(input_tensor)\n",
        "\n",
        "            # Convert logits to probabilities using softmax\n",
        "            probabilities = torch.softmax(output, dim=1)\n",
        "\n",
        "            # Get the word with highest probability\n",
        "            predicted_idx = torch.argmax(probabilities, dim=1).item()\n",
        "\n",
        "            # Get confidence score for the prediction\n",
        "            confidence = probabilities[0][predicted_idx].item()\n",
        "\n",
        "        # Convert index back to word\n",
        "        predicted_word = self.idx2word[predicted_idx]\n",
        "        return predicted_word, confidence\n",
        "\n",
        "# ---------------------------------------------\n",
        "# Step 12. Main Function - Program Entry Point\n",
        "# ---------------------------------------------\n",
        "def main():\n",
        "    print(\"=\" * 70)\n",
        "    print(\"PyTorch Sequence Modeling Demo: RNN vs LSTM vs GRU\")\n",
        "    print(\"=\" * 70)\n",
        "    print(\"\\nInitializing models and preparing data...\")\n",
        "\n",
        "    # ---------------------------------------------\n",
        "    # Step 12a. Initialize the Predictor\n",
        "    # ---------------------------------------------\n",
        "    # Create predictor with:\n",
        "    # - embedding_dim=32: Each word represented as 32-dimensional vector\n",
        "    # - hidden_dim=64: RNN/LSTM/GRU hidden state size\n",
        "    # - seq_length=3: Use 3 words of context to predict the next word\n",
        "    predictor = SequencePredictor(CORPUS, embedding_dim=32, hidden_dim=64, seq_length=3)\n",
        "\n",
        "    # Display dataset statistics\n",
        "    print(f\"\\nVocabulary size: {predictor.vocab_size}\")\n",
        "    print(f\"Training sequences: {len(predictor.X_train)}\")\n",
        "    print(f\"Vocabulary: {predictor.vocab[:15]}...\")\n",
        "\n",
        "    # ---------------------------------------------\n",
        "    # Step 12b. Train All Three Models\n",
        "    # ---------------------------------------------\n",
        "    # Train each model for 100 epochs to learn word patterns\n",
        "\n",
        "    print(\"\\n\" + \"-\" * 70)\n",
        "    print(\"Training RNN Model...\")\n",
        "    print(\"-\" * 70)\n",
        "    predictor.train_model(predictor.rnn_model, epochs=100)\n",
        "\n",
        "    print(\"\\n\" + \"-\" * 70)\n",
        "    print(\"Training LSTM Model...\")\n",
        "    print(\"-\" * 70)\n",
        "    predictor.train_model(predictor.lstm_model, epochs=100)\n",
        "\n",
        "    print(\"\\n\" + \"-\" * 70)\n",
        "    print(\"Training GRU Model...\")\n",
        "    print(\"-\" * 70)\n",
        "    predictor.train_model(predictor.gru_model, epochs=100)\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 70)\n",
        "    print(\"Training Complete! Now you can test the models.\")\n",
        "    print(\"=\" * 70)\n",
        "\n",
        "    # ---------------------------------------------\n",
        "    # Step 12c. Interactive Prediction Loop\n",
        "    # ---------------------------------------------\n",
        "    # Allow user to test the models with custom input phrases\n",
        "    while True:\n",
        "        print(\"\\n\" + \"-\" * 70)\n",
        "        user_input = input(\"\\nEnter a phrase (or 'quit' to exit): \").strip()\n",
        "\n",
        "        # Check for exit commands\n",
        "        if user_input.lower() in ['quit', 'exit', 'q']:\n",
        "            print(\"\\nThank you for using the Sequence Modeling Demo!\")\n",
        "            break\n",
        "\n",
        "        # Validate input\n",
        "        if not user_input:\n",
        "            print(\"Please enter a valid phrase.\")\n",
        "            continue\n",
        "\n",
        "        print(f\"\\nInput phrase: '{user_input}'\")\n",
        "        print(\"\\nPredictions:\")\n",
        "\n",
        "        # Get predictions from all three models\n",
        "        # Each model predicts the next word and provides confidence score\n",
        "\n",
        "        # RNN prediction\n",
        "        rnn_word, rnn_conf = predictor.predict_next_word(predictor.rnn_model, user_input)\n",
        "        print(f\"  RNN:  '{rnn_word}' (confidence: {rnn_conf:.2%})\")\n",
        "\n",
        "        # LSTM prediction\n",
        "        lstm_word, lstm_conf = predictor.predict_next_word(predictor.lstm_model, user_input)\n",
        "        print(f\"  LSTM: '{lstm_word}' (confidence: {lstm_conf:.2%})\")\n",
        "\n",
        "        # GRU prediction\n",
        "        gru_word, gru_conf = predictor.predict_next_word(predictor.gru_model, user_input)\n",
        "        print(f\"  GRU:  '{gru_word}' (confidence: {gru_conf:.2%})\")\n",
        "\n",
        "        # Show complete predicted sentences\n",
        "        print(\"\\nComplete predictions:\")\n",
        "        print(f\"  RNN:  '{user_input} {rnn_word}'\")\n",
        "        print(f\"  LSTM: '{user_input} {lstm_word}'\")\n",
        "        print(f\"  GRU:  '{user_input} {gru_word}'\")\n",
        "\n",
        "# ---------------------------------------------\n",
        "# Step 13. Program Entry Point\n",
        "# ---------------------------------------------\n",
        "# This ensures main() only runs when script is executed directly\n",
        "# (not when imported as a module)\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "ZPutDw80O7Ek"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Listing 5-8 A simple interactive example of sentiment analysis\n",
        "This example uses Hugging Face Transformers to classify the sentiment of a sentence with DistilBERT, a lightweight version of BERT."
      ],
      "metadata": {
        "id": "InaJ-WQExp27"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------------------------\n",
        "# Step 1. Setup and Imports\n",
        "# ---------------------------------------------\n",
        "!pip install transformers --quiet\n",
        "\n",
        "from transformers import pipeline\n",
        "\n",
        "# ---------------------------------------------\n",
        "# Step 2. Load a sentiment-analysis pipeline\n",
        "#         (DistilBERT by default)\n",
        "# ---------------------------------------------\n",
        "classifier = pipeline(\"sentiment-analysis\")\n",
        "\n",
        "# ---------------------------------------------\n",
        "# Step 3. Print User Instructions\n",
        "# ---------------------------------------------\n",
        "print(\"Enter a message to analyze its sentiment.\")\n",
        "print(\"Type 'quit' to exit.\\n\")\n",
        "\n",
        "# ---------------------------------------------\n",
        "# Step 4. Interactive Input Loop\n",
        "# ---------------------------------------------\n",
        "while True:\n",
        "\n",
        "    # ---------------------------------------------\n",
        "    # Step 4a. Read and normalize user input\n",
        "    # ---------------------------------------------\n",
        "    s = input(\"Your message: \").strip()\n",
        "\n",
        "    # ---------------------------------------------\n",
        "    # Step 4b. Exit condition\n",
        "    # ---------------------------------------------\n",
        "    if s.lower() in {\"quit\", \"exit\"}:\n",
        "        break\n",
        "\n",
        "    # ---------------------------------------------\n",
        "    # Step 4c. Basic validation: reject empty input\n",
        "    # ---------------------------------------------\n",
        "    if not s:\n",
        "        print(\"Please type a non-empty message.\\n\")\n",
        "        continue\n",
        "\n",
        "    # ---------------------------------------------\n",
        "    # Step 5. Run Transformer Inference\n",
        "    # ---------------------------------------------\n",
        "    result = classifier(s)[0]\n",
        "\n",
        "    # ---------------------------------------------\n",
        "    # Step 6. Extract and Present the Result\n",
        "    # ---------------------------------------------\n",
        "    label = result[\"label\"]\n",
        "    score = result[\"score\"] * 100\n",
        "    print(f\"→ {label} ({score:.1f}%)\\n\")\n"
      ],
      "metadata": {
        "id": "cdFudQLNxFJE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Listing 5-9 A small question-answering example\n",
        "This simple example lets you type context and then ask a question about it."
      ],
      "metadata": {
        "id": "JyXPzHTvzL9D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------------------------\n",
        "# Step 1. Import the pipeline helper\n",
        "# ---------------------------------------------\n",
        "from transformers import pipeline\n",
        "\n",
        "# ---------------------------------------------\n",
        "# Step 2. Load a question-answering pipeline\n",
        "#         (default pretrained model)\n",
        "# ---------------------------------------------\n",
        "qa = pipeline(\"question-answering\")\n",
        "\n",
        "# ---------------------------------------------\n",
        "# Step 3. Collect user input\n",
        "# ---------------------------------------------\n",
        "context = input(\"Enter context: \")\n",
        "question = input(\"Now enter your question: \")\n",
        "\n",
        "# ---------------------------------------------\n",
        "# Step 4. Run Transformer inference\n",
        "# ---------------------------------------------\n",
        "result = qa(question=question, context=context)\n",
        "\n",
        "# ---------------------------------------------\n",
        "# Step 5. Extract and display the answer\n",
        "# ---------------------------------------------\n",
        "print(f\"Answer: {result['answer']} (score: {result['score']:.2f})\")"
      ],
      "metadata": {
        "id": "QQ8cThwZzuJ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Listing 5-10 A compact implementation of the chat-with-my-data pattern\n",
        "The following code asks the user to upload a PDF file through the browser. Once the file is uploaded, the script extracts the text from each page and stores it as a single context string. The user can then enter questions about the document. Each question, together with the document text, is passed to a pretrained question-answering model. The model uses attention to locate the most relevant span and returns an answer with a confidence score."
      ],
      "metadata": {
        "id": "84ZAJt3B0YQo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------------------------\n",
        "# Step 1. Install required libraries (Colab)\n",
        "# ---------------------------------------------\n",
        "# transformers: pretrained Transformer models + pipelines\n",
        "# PyMuPDF (fitz): PDF parsing and text extraction\n",
        "!pip install transformers --quiet\n",
        "!pip install PyMuPDF --quiet\n",
        "\n",
        "# ---------------------------------------------\n",
        "# Step 2. Import dependencies\n",
        "# ---------------------------------------------\n",
        "from transformers import pipeline\n",
        "import fitz  # PyMuPDF\n",
        "from google.colab import files\n",
        "\n",
        "# ---------------------------------------------\n",
        "# Step 3. Upload a PDF from your local machine\n",
        "# ---------------------------------------------\n",
        "# Colab returns a dict: {filename: bytes}\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Take the first uploaded file\n",
        "file_name = next(iter(uploaded))\n",
        "pdf_data = uploaded[file_name]\n",
        "\n",
        "# ---------------------------------------------\n",
        "# Step 4. Extract text from the uploaded PDF\n",
        "# ---------------------------------------------\n",
        "def extract_text_from_pdf_bytes(pdf_bytes):\n",
        "    \"\"\"Extract all page text from a PDF stored as raw bytes.\"\"\"\n",
        "    doc = fitz.open(stream=pdf_bytes, filetype=\"pdf\")\n",
        "    text = \"\"\n",
        "    for page in doc:\n",
        "        text += page.get_text()\n",
        "    doc.close()\n",
        "    return text\n",
        "\n",
        "context = extract_text_from_pdf_bytes(pdf_data)\n",
        "\n",
        "# ---------------------------------------------\n",
        "# Step 5. Initialize a question-answering pipeline\n",
        "# ---------------------------------------------\n",
        "qa = pipeline(\"question-answering\")\n",
        "\n",
        "# ---------------------------------------------\n",
        "# Step 6. Interactive Q&A loop over the PDF text\n",
        "# ---------------------------------------------\n",
        "print(\"\\nPDF loaded. Ask me anything about its contents. Type 'quit' to exit.\")\n",
        "\n",
        "while True:\n",
        "    # -----------------------------------------\n",
        "    # Step 6a. Read and validate the question\n",
        "    # -----------------------------------------\n",
        "    question = input(\"\\nYour question: \").strip()\n",
        "\n",
        "    if question.lower() == \"quit\":\n",
        "        print(\"Exiting Q&A.\")\n",
        "        break\n",
        "\n",
        "    if len(question) == 0:\n",
        "        print(\"Please enter a valid question.\")\n",
        "        continue\n",
        "\n",
        "    # -----------------------------------------\n",
        "    # Step 6b. Run extractive QA inference\n",
        "    # -----------------------------------------\n",
        "    try:\n",
        "        result = qa(question=question, context=context)\n",
        "\n",
        "        # -------------------------------------\n",
        "        # Step 6c. Present the answer span\n",
        "        # -------------------------------------\n",
        "        print(f\"Answer: {result['answer']} (score: {result['score']:.2f})\")\n",
        "\n",
        "    except Exception as e:\n",
        "        # -------------------------------------\n",
        "        # Step 6d. Basic error handling\n",
        "        # -------------------------------------\n",
        "        print(f\"Could not answer the question. Reason: {e}\")"
      ],
      "metadata": {
        "id": "sFXKzDmR06Sp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}