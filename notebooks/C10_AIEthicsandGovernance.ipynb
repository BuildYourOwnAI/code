{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Chapter 10 Ethics and Governance in AI\n",
        "Chapter 10 introduces the foundations of ethics in AI and the principles of AI governance. We look at the roles of global standards and governing bodies, outline prac-tical ways to govern AI systems across their lifecycle, and review techniques for identifying and mitigating bias. The chapter concludes with an interview with Dr. Francesca Rossi, IBM Fellow and Global Leader for AI Ethics, who connects these ideas to real practice in industry and policy."
      ],
      "metadata": {
        "id": "3wlxmughMhwS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Listing 10-1 Using Great Expectations for Data Quality Checks\n",
        "This minimal example, which can be expanded into full pipelines, shows how data validation can become an automated, repeatable governance practice."
      ],
      "metadata": {
        "id": "G-k9fmTh-1B4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y8mfKr5VMgpX"
      },
      "outputs": [],
      "source": [
        "!pip install great_expectations pandas scikit-learn\n",
        "\n",
        "import pandas as pd\n",
        "import great_expectations as gx\n",
        "from great_expectations.expectations import (\n",
        "    ExpectColumnValuesToNotBeNull,\n",
        "    ExpectColumnValuesToBeBetween,\n",
        "    ExpectTableRowCountToBeBetween,\n",
        ")\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "\n",
        "# Load a tabular dataset into a DataFrame\n",
        "data = load_breast_cancer()\n",
        "df = pd.DataFrame(data.data, columns=data.feature_names)\n",
        "\n",
        "# Create a GX Data Context (in-memory)\n",
        "context = gx.get_context()\n",
        "\n",
        "# 1. Add a pandas Data Source\n",
        "data_source = context.data_sources.add_pandas(\"breast_cancer_source\")\n",
        "\n",
        "# 2. Add a Data Asset for this DataFrame\n",
        "data_asset = data_source.add_dataframe_asset(name=\"breast_cancer_asset\")\n",
        "\n",
        "# 3. Add a Batch Definition that uses the whole DataFrame\n",
        "batch_def = data_asset.add_batch_definition_whole_dataframe(\"whole_dataframe\")\n",
        "\n",
        "# 4. Pass the in-memory DataFrame as batch parameters\n",
        "batch = batch_def.get_batch(batch_parameters={\"dataframe\": df})\n",
        "\n",
        "# Define expectations\n",
        "exp1 = ExpectColumnValuesToNotBeNull(column=\"mean radius\")\n",
        "exp2 = ExpectColumnValuesToBeBetween(\n",
        "    column=\"mean texture\",\n",
        "    min_value=0,\n",
        "    max_value=100,\n",
        ")\n",
        "exp3 = ExpectTableRowCountToBeBetween(\n",
        "    min_value=100,\n",
        "    max_value=10000,\n",
        ")\n",
        "\n",
        "# Validate expectations against the Batch\n",
        "res1 = batch.validate(exp1)\n",
        "res2 = batch.validate(exp2)\n",
        "res3 = batch.validate(exp3)\n",
        "\n",
        "print(\"Null check on 'mean radius':\", res1.success)\n",
        "print(\"Range check on 'mean texture':\", res2.success)\n",
        "print(\"Row count check:\", res3.success)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Listing 10-2 Opacus Differential Privacy Example\n",
        "This example illustrates how differential privacy can be incorporated directly into model training workflows."
      ],
      "metadata": {
        "id": "NCrf_hJiD1Td"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install opacus\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from opacus import PrivacyEngine\n",
        "\n",
        "# Load a small tabular dataset\n",
        "data = load_breast_cancer()\n",
        "X = torch.tensor(data.data, dtype=torch.float32)\n",
        "y = torch.tensor(data.target, dtype=torch.long)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "train_ds = TensorDataset(X_train, y_train)\n",
        "train_loader = DataLoader(train_ds, batch_size=64, shuffle=True)\n",
        "\n",
        "# Simple classifier\n",
        "model = nn.Sequential(\n",
        "    nn.Linear(X_train.shape[1], 32),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(32, 2)\n",
        ")\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Attach differential privacy using Opacus\n",
        "privacy_engine = PrivacyEngine()\n",
        "\n",
        "model, optimizer, train_loader = privacy_engine.make_private_with_epsilon(\n",
        "    module=model,\n",
        "    optimizer=optimizer,\n",
        "    data_loader=train_loader,\n",
        "    epochs=3,\n",
        "    target_epsilon=5.0,\n",
        "    target_delta=1e-5,\n",
        "    max_grad_norm=1.0,\n",
        ")\n",
        "\n",
        "# Training loop (very small, for illustration)\n",
        "model.train()\n",
        "for epoch in range(3):\n",
        "    for xb, yb in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        logits = model(xb)\n",
        "        loss = criterion(logits, yb)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "epsilon = privacy_engine.get_epsilon(delta=1e-5)\n",
        "print(f\"Training finished with ε = {epsilon:.2f}, δ = 1e-5\")\n"
      ],
      "metadata": {
        "id": "kGtUmzXFEF40"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Listing 10-3 Measuring Group-wise Fairness with Fairlearn\n",
        "This program trains a simple classifier, then uses Fairlearn to compute accuracy and selection rate for each group. It shows how a model that looks acceptable overall can still behave differently across groups, which is central to fairness analysis and governance."
      ],
      "metadata": {
        "id": "jSG80_y0F6oL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fairlearn scikit-learn\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score          # <-- from sklearn.metrics\n",
        "from fairlearn.metrics import MetricFrame, selection_rate  # <-- only these from fairlearn\n",
        "\n",
        "# Synthetic dataset with a binary label\n",
        "X, y = make_classification(\n",
        "    n_samples=2000,\n",
        "    n_features=10,\n",
        "    n_informative=5,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Synthetic \"group\" attribute (for example, two demographic groups)\n",
        "rng = np.random.default_rng(42)\n",
        "group_attr = rng.integers(0, 2, size=y.shape[0])  # values 0 or 1\n",
        "\n",
        "X_train, X_test, y_train, y_test, g_train, g_test = train_test_split(\n",
        "    X, y, group_attr, test_size=0.3, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# Train a simple classifier\n",
        "clf = LogisticRegression(max_iter=1000)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Predictions\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Use Fairlearn to compute metrics by group\n",
        "metric_frame = MetricFrame(\n",
        "    metrics={\n",
        "        \"accuracy\": accuracy_score,\n",
        "        \"selection_rate\": selection_rate,\n",
        "    },\n",
        "    y_true=y_test,\n",
        "    y_pred=y_pred,\n",
        "    sensitive_features=g_test,\n",
        ")\n",
        "\n",
        "print(\"Overall accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"\\nAccuracy by group:\")\n",
        "print(metric_frame.by_group[\"accuracy\"])\n",
        "\n",
        "print(\"\\nSelection rate by group:\")\n",
        "print(metric_frame.by_group[\"selection_rate\"])\n"
      ],
      "metadata": {
        "id": "_oMKLX9fGJe2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Listing 10-4 Using SHAP to Identify Influential Features\n",
        "This listing trains a random forest on a tabular dataset and uses SHAP to rank the most influential features. By computing the mean absolute SHAP value for each fea-ture, the example highlights which inputs contribute most strongly to the model’s outputs. This approach provides a practical, interpretable summary of model behavior and helps identify cases where a model might be relying on inappropriate signals or proxies for sensitive attributes. In real deployments, domain-specific feature names often make these explanations even more informative."
      ],
      "metadata": {
        "id": "ddZeJfIZJfSR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install shap scikit-learn pandas matplotlib\n",
        "\n",
        "import shap\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load a tabular dataset with multiple informative features\n",
        "data = load_breast_cancer()\n",
        "X = pd.DataFrame(data.data, columns=data.feature_names)\n",
        "y = data.target\n",
        "\n",
        "# Train/test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# Train a tree-based classifier\n",
        "model = RandomForestClassifier(\n",
        "    n_estimators=200,\n",
        "    max_depth=None,\n",
        "    random_state=42,\n",
        ")\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Create SHAP explainer and compute values on the test set\n",
        "explainer = shap.TreeExplainer(model)\n",
        "X_sample = X_test\n",
        "\n",
        "shap_values = explainer.shap_values(X_sample)\n",
        "\n",
        "# For a binary classifier, shap_values is a list (one array per class)\n",
        "if isinstance(shap_values, list):\n",
        "    shap_values_class_1 = shap_values[1]   # SHAP values for positive class\n",
        "else:\n",
        "    shap_values_class_1 = shap_values\n",
        "\n",
        "# Ensure we have (n_samples, n_features) by collapsing any extra dims\n",
        "shap_values_class_1 = np.array(shap_values_class_1)\n",
        "if shap_values_class_1.ndim > 2:\n",
        "    # e.g., (n_samples, n_features, 1) -> average over last axis\n",
        "    shap_values_class_1 = shap_values_class_1.mean(axis=-1)\n",
        "\n",
        "# Compute mean absolute SHAP value per feature -> shape (n_features,)\n",
        "mean_abs_shap = np.mean(np.abs(shap_values_class_1), axis=0)\n",
        "mean_abs_shap = np.asarray(mean_abs_shap, dtype=float).ravel()\n",
        "\n",
        "feature_names = np.array(X_sample.columns)\n",
        "\n",
        "# Sort features by importance (descending) and select top 10\n",
        "order = np.argsort(mean_abs_shap)[::-1]\n",
        "top_k = min(10, len(mean_abs_shap))\n",
        "top_idx = order[:top_k]\n",
        "\n",
        "top_features = feature_names[top_idx]\n",
        "top_importances = mean_abs_shap[top_idx]   # 1-D float array of length top_k\n",
        "\n",
        "print(\"Top features by mean absolute SHAP value:\")\n",
        "for name, val in zip(top_features, top_importances):\n",
        "    print(f\"{name}: {val:.4f}\")\n",
        "\n",
        "# Plot as a horizontal bar chart\n",
        "plt.figure(figsize=(8, 5))\n",
        "positions = np.arange(len(top_features))\n",
        "plt.barh(positions, top_importances)\n",
        "plt.yticks(positions, top_features)\n",
        "plt.gca().invert_yaxis()  # highest importance at the top\n",
        "plt.xlabel(\"mean(|SHAP value|) (average impact on model output)\")\n",
        "plt.title(\"Top features by mean absolute SHAP value\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Ir6AZ-0TJqkO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Listing 10-5 Tracking Model Training and Metrics with MLflow\n",
        "This example shows how to log a model training run with MLflow. The code demonstrates how systematic experiment tracking can strengthen governance by making it easier to reproduce results, audit model behavior, and understand how a model was built."
      ],
      "metadata": {
        "id": "eb4p9h3voIld"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mlflow\n",
        "\n",
        "import mlflow\n",
        "import mlflow.sklearn\n",
        "\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "# Load a small dataset\n",
        "data = load_breast_cancer()\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    data.data, data.target,\n",
        "    test_size=0.3,\n",
        "    random_state=42,\n",
        "    stratify=data.target\n",
        ")\n",
        "\n",
        "# Start an MLflow run\n",
        "with mlflow.start_run(run_name=\"rf_governance_example\"):\n",
        "    n_estimators = 100\n",
        "    max_depth = 5\n",
        "\n",
        "    # Log parameters\n",
        "    mlflow.log_param(\"n_estimators\", n_estimators)\n",
        "    mlflow.log_param(\"max_depth\", max_depth)\n",
        "\n",
        "    # Train model\n",
        "    model = RandomForestClassifier(\n",
        "        n_estimators=n_estimators,\n",
        "        max_depth=max_depth,\n",
        "        random_state=42\n",
        "    )\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Evaluate and log metrics\n",
        "    y_prob = model.predict_proba(X_test)[:, 1]\n",
        "    auc = roc_auc_score(y_test, y_prob)\n",
        "    mlflow.log_metric(\"roc_auc\", auc)\n",
        "\n",
        "    # Log the model artifact with an input example\n",
        "    mlflow.sklearn.log_model(\n",
        "        sk_model=model,\n",
        "        artifact_path=\"model\",\n",
        "        input_example=X_train[:5]\n",
        "    )\n",
        "\n",
        "    print(\"Logged run with ROC AUC:\", auc)\n"
      ],
      "metadata": {
        "id": "Pn3IWRwooSG2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}