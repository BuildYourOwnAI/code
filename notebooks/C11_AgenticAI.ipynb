{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## **Chapter 11 - Agentic AI**\n",
        "This notebook explores Agentic AI through structured examples, showcasing how AI agents plan, retrieve data, and execute tasks autonomously. Using `LangChain` and `CrewAI`, the notebook demonstrates key abstractions, including datasets, prompts, model selection, agent-based reasoning, and task execution. Examples range from structured data retrieval using Hugging Face datasets to interactive AI agents that process information and act independently. By the end, you'll see how these frameworks power AI-driven decision-making and automation, making AI applications more adaptive and autonomous."
      ],
      "metadata": {
        "id": "hqQCTuyowKk-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Setting Up API Keys** for Hugging Face, Google, and OpenAI\n",
        "Before running the code examples in this chapter, API keys must be configured for Hugging Face Hub, Google APIs (Serper and Gemini), and OpenAI. This script retrieves stored credentials in Google Colab Secrets and sets them as environment variables for seamless integration with AI services.\n",
        "\n",
        "***Note:*** See Google Colab Secrets for instructions on how to store and manage API keys securely."
      ],
      "metadata": {
        "id": "ko1MK3DGxu-P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# API Key Setup for Hugging Face Hub, Google API, and OpenAI in Google Colab\n",
        "from google.colab import userdata\n",
        "import os\n",
        "\n",
        "# Retrieve Hugging Face API key (using the correct key name)\n",
        "hf_api_key = userdata.get(\"HUGGINGFACEHUB_ACCESS_TOKEN\")\n",
        "if hf_api_key:\n",
        "    os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = hf_api_key  # Standard expected variable name for Hugging Face\n",
        "    print(\"‚úÖ Hugging Face API key loaded successfully.\")\n",
        "else:\n",
        "    raise ValueError(\"‚ùå Error: HUGGINGFACEHUB_ACCESS_TOKEN not found in Google Colab secrets. Please set it before running.\")\n",
        "\n",
        "# Retrieve Google Serper API key\n",
        "serper_api_key = userdata.get(\"SERPAPI_API_KEY\")\n",
        "if serper_api_key:\n",
        "    os.environ[\"SERPAPI_API_KEY\"] = serper_api_key\n",
        "    print(\"‚úÖ Serper API key loaded successfully.\")\n",
        "else:\n",
        "    raise ValueError(\"‚ùå Error: SERPAPI_API_KEY not found in Google Colab secrets. Please set it before running.\")\n",
        "\n",
        "# Retrieve Google Gemini API key\n",
        "google_api_key = userdata.get(\"GEMINI_API_KEY\")\n",
        "if google_api_key:\n",
        "    os.environ[\"GEMINI_API_KEY\"] = google_api_key\n",
        "    print(\"‚úÖ Google Gemini API key loaded successfully.\")\n",
        "else:\n",
        "    raise ValueError(\"‚ùå Error: GEMINI_API_KEY not found in Google Colab secrets. Please set it before running.\")\n",
        "\n",
        "\n",
        "# Retrieve OpenAI API key\n",
        "openai_api_key = userdata.get(\"OPENAI_API_KEY\")\n",
        "if openai_api_key:\n",
        "    os.environ[\"OPENAI_API_KEY\"] = openai_api_key\n",
        "    print(\"‚úÖ OpenAI API key loaded successfully.\")\n",
        "else:\n",
        "    raise ValueError(\"‚ùå Error: OPENAI_API_KEY not found in Google Colab secrets. Please set it before running.\")\n"
      ],
      "metadata": {
        "id": "J-Mhzj9bZVQR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Listing 9-1: Loading and Analyzing Game Data\n",
        "This code retrieves and processes the **Steam Games** dataset from Hugging Face. It selects the top five highest-rated games, sorting them by positive reviews. The dataset provides structured information on game titles, genres, and player feedback, forming the foundation for AI-driven analysis and decision-making.\n",
        "\n",
        "***Note:*** Before running this code, ensure you have the necessary dependencies installed by running:"
      ],
      "metadata": {
        "id": "8CAELECSSpLS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install --quiet datasets"
      ],
      "metadata": {
        "id": "6d8rGi-ATMCp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "import pandas as pd\n",
        "\n",
        "# Load the Steam Games dataset from Hugging Face\n",
        "dataset = load_dataset(\"FronkonGames/steam-games-dataset\",\n",
        "                       split=\"train\")\n",
        "\n",
        "# Convert to Pandas DataFrame\n",
        "df = dataset.to_pandas()\n",
        "\n",
        "# Select relevant columns\n",
        "df = df[[\"Name\", \"Genres\", \"Positive\"]].sort_values(\n",
        "     by=\"Positive\", ascending=False).head(5)\n",
        "\n",
        "# Rename columns for clarity\n",
        "df.columns = [\"Game\", \"Genres\", \"Positive_Reviews\"]\n",
        "\n",
        "# Display structured dataset output\n",
        "print(\"\\nTop 5 Highest Rated Games on Steam:\")\n",
        "print(df.to_string(index=False))"
      ],
      "metadata": {
        "id": "TucMXj5rSuHD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Listing 9-2: Implementing AI-Driven Prompt Templates and Querying Models\n",
        "This code demonstrates how AI agents interact using structured prompt templates and model queries. Using LangChain's prompt abstractions, it defines different types of interactions‚Äîranging from basic prompts and few-shot learning to dynamic data integration from external sources like Hugging Face datasets. The script then queries LLMs like Mistral and OpenAI models, generating structured responses for trivia, NPC interactions, and game strategy design.\n",
        "\n",
        "***Note:*** Ensure dependencies are installed before running:"
      ],
      "metadata": {
        "id": "gZjYGxexj7zu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required packages for Hugging Face and LangChain usage\n",
        "\n",
        "print(\"Installing packages... this can take a minute or two.\")\n",
        "\n",
        "%pip install --upgrade --quiet huggingface_hub\n",
        "\n",
        "%pip install -q langchain langchain-community langchain-huggingface langchain-openai google-search-results\n",
        "\n",
        "print(\"All required packaged installed and ready!\")"
      ],
      "metadata": {
        "id": "_TYGjsKtkSuh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import InferenceClient\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from datasets import load_dataset\n",
        "import pandas as pd\n",
        "\n",
        "# Initialize API client and define default model\n",
        "DEFAULT_MODEL = \"mistralai/Mistral-Nemo-Instruct-2407\"\n",
        "client = InferenceClient()\n",
        "\n",
        "def query_model(messages, model=DEFAULT_MODEL, max_tokens=500,\n",
        "                temperature=0.7):\n",
        "    \"\"\"\n",
        "    Sends a list of messages to the AI model and returns the response.\n",
        "\n",
        "    Parameters:\n",
        "        messages (list): A list of message dictionaries (role, content).\n",
        "        model (str): The AI model to use (default is Mistral-Nemo).\n",
        "        max_tokens (int): Maximum number of tokens for the response.\n",
        "        temperature (float): Controls randomness (higher = more creative).\n",
        "\n",
        "    Returns:\n",
        "        str: The AI-generated response.\n",
        "    \"\"\"\n",
        "    response = client.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=messages,\n",
        "        max_tokens=max_tokens,\n",
        "        temperature=temperature\n",
        "    )\n",
        "\n",
        "    return response.choices[0].message.content\n",
        "\n",
        "# --- Test Template #1: Wise Old Wizard ---\n",
        "wizard_prompt = ChatPromptTemplate.from_messages([\n",
        "    ('system', \"You are a wise old wizard guiding players on their journey.\"),\n",
        "    ('human', \"Player Question: {player_question}\"),\n",
        "])\n",
        "\n",
        "wizard_prompt = ChatPromptTemplate.from_messages([\n",
        "    ('system', \"You are a wise old wizard guiding players on their journey.\"),\n",
        "    ('human', \"Player Question: How do I master fire magic?\"),\n",
        "    ('ai', \"To master fire magic, study ancient scrolls in the Ember Library and \"\n",
        "           \"practice channeling heat energy through controlled breathing.\"),\n",
        "    ('human', \"Player Question: What is the best weapon for a sorcerer?\"),\n",
        "    ('ai', \"A sorcerer benefits most from a staff infused with elemental power, \"\n",
        "           \"such as the Arcane Emberstaff.\"),\n",
        "    ('human', \"Player Question: {player_question}, answer in 100 words or less.\")\n",
        "])\n",
        "\n",
        "# Format the wizard prompt example\n",
        "wizard_message = wizard_prompt.format(\n",
        "    player_question=\"How do I master fire magic?\"\n",
        ")\n",
        "\n",
        "# Test the Wise Old Wizard prompt\n",
        "wizard_response = query_model([{\"role\": \"user\", \"content\": wizard_message}])\n",
        "print(\"\\nüîÆ Wise Old Wizard Says:\\n\", wizard_response)\n",
        "\n",
        "# --- Test Template #2: NPC Dialogue ---\n",
        "npc_prompt = ChatPromptTemplate.from_messages([\n",
        "    ('system', \"You are an NPC in a fantasy RPG. Guide the player \"\n",
        "               \"without giving spoilers.\"),\n",
        "    ('human', \"Player Info:\\n- Class: {player_class}\\n- Location: \"\n",
        "              \"{current_location}\"),\n",
        "    ('human', \"Quest Progress: {quest_progress}\"),\n",
        "    ('human', \"Question: {player_question}, answer in 100 words or less.\")\n",
        "])\n",
        "\n",
        "# Format the NPC dialogue example\n",
        "npc_message = npc_prompt.format(\n",
        "    player_class=\"Mage\",\n",
        "    current_location=\"Darkwood Forest\",\n",
        "    quest_progress=\"Searching for the lost artifact\",\n",
        "    player_question=\"Where should I look next?\"\n",
        ")\n",
        "\n",
        "# Test NPC prompt template with the model\n",
        "npc_response = query_model([{\"role\": \"user\", \"content\": npc_message}])\n",
        "print(\"\\nüßô NPC Response:\\n\", npc_response)\n",
        "\n",
        "# --- Test Template #3: Game Analysis ---\n",
        "# Load and prepare the dataset\n",
        "dataset = load_dataset(\"FronkonGames/steam-games-dataset\", split=\"train\")\n",
        "df = dataset.to_pandas()\n",
        "\n",
        "# Extract the top-rated games\n",
        "df = df[[\"Name\", \"Genres\", \"Positive\"]].sort_values(\n",
        "     by=\"Positive\", ascending=False).head(5)\n",
        "\n",
        "# Format game data into structured input for AI\n",
        "game_list = \"\\n\".join(f\"{row['Name']} (Genre: {row['Genres']}, \"\n",
        "                       f\"Reviews: {row['Positive']})\"\n",
        "                       for _, row in df.iterrows())\n",
        "\n",
        "# Define the prompt template for game analysis\n",
        "game_prompt = ChatPromptTemplate.from_messages([\n",
        "    ('system', \"Based on the most popular games below, create a simple interactive \"\n",
        "               \"game scenario where multiple AI agents play distinct roles.\"),\n",
        "    ('human', \"Here are the top-rated games:\\n{game_list}\\n\\n\"\n",
        "              \"Design a small-scale game scenario suitable for AI agents to play, \"\n",
        "              \"including:\\n\"\n",
        "              \"- Title\\n- Setting & Theme\\n- Three AI agent roles with unique skills\\n\"\n",
        "              \"- How these agents interact to complete a shared objective\")\n",
        "])\n",
        "\n",
        "\n",
        "# Format the game analysis example\n",
        "game_message = game_prompt.format(game_list=game_list)\n",
        "\n",
        "# Test game analysis prompt template with the model\n",
        "game_response = query_model([{\"role\": \"user\", \"content\": game_message}])\n",
        "print(\"\\nüéÆ Game Concept Suggestion:\\n\", game_response)"
      ],
      "metadata": {
        "id": "OYFxfL6Bj_KH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Same as above, instead using OpenAI"
      ],
      "metadata": {
        "id": "5lKs6Q8Kyh4k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from datasets import load_dataset\n",
        "import pandas as pd\n",
        "\n",
        "# Initialize the OpenAI model client\n",
        "llm = ChatOpenAI(model_name=\"gpt-4-turbo\", temperature=0.7)\n",
        "\n",
        "def query_model(messages, model=llm, max_tokens=500):\n",
        "    \"\"\"\n",
        "    Sends a list of messages to the AI model and returns the response.\n",
        "\n",
        "    Parameters:\n",
        "        messages (list): A list of message dictionaries (role, content).\n",
        "        model (ChatOpenAI): The OpenAI model instance.\n",
        "        max_tokens (int): Maximum number of tokens for the response.\n",
        "\n",
        "    Returns:\n",
        "        str: The AI-generated response.\n",
        "    \"\"\"\n",
        "    response = model.invoke(messages)\n",
        "    return response.content\n",
        "\n",
        "# --- Test Prompt 1: Basic Prompt Structure ---\n",
        "basic_prompt = ChatPromptTemplate.from_messages([\n",
        "    ('system', \"You are a trivia expert who provides clear and informative answers.\"),\n",
        "    ('human', \"Who invented the lightbulb?\"),\n",
        "    ('ai', \"The lightbulb was invented by Thomas Edison in 1879.\")\n",
        "])\n",
        "\n",
        "# Format the basic prompt example\n",
        "basic_message = basic_prompt.format()\n",
        "\n",
        "# Test the Basic Prompt Structure\n",
        "basic_response = query_model([{\"role\": \"user\", \"content\": basic_message}])\n",
        "print(\"\\nüí° Trivia Expert Says:\\n\", basic_response)\n",
        "\n",
        "# --- Test Prompt 2: Few-Shot Prompting ---\n",
        "few_shot_prompt = ChatPromptTemplate.from_messages([\n",
        "    ('system', \"You are a trivia expert providing clear, well-researched answers.\"),\n",
        "    ('human', \"Who discovered gravity?\"),\n",
        "    ('ai', \"Gravity was discovered by Sir Isaac Newton in the late 17th century.\"),\n",
        "    ('human', \"What is the speed of light?\"),\n",
        "    ('ai', \"The speed of light is approximately 299,792 kilometers per second.\"),\n",
        "    ('human', \"Who developed the theory of relativity?\"),\n",
        "    ('ai', \"Albert Einstein developed the theory of relativity in the early 20th \"\n",
        "           \"century.\"),\n",
        "    ('human', \"Question: {trivia_question}, answer in 100 words or less.\")\n",
        "])\n",
        "\n",
        "# Format the few-shot prompt example\n",
        "few_shot_message = few_shot_prompt.format(\n",
        "    trivia_question=\"Who discovered penicillin?\"\n",
        ")\n",
        "\n",
        "# Test the Few-Shot Prompt\n",
        "few_shot_response = query_model([{\"role\": \"user\", \"content\": few_shot_message}])\n",
        "print(\"\\nüß™ Few-Shot Trivia Expert Says:\\n\", few_shot_response)\n",
        "\n",
        "# --- Test Prompt 3: Prompt with Variables ---\n",
        "variable_prompt = ChatPromptTemplate.from_messages([\n",
        "    ('system', \"You are a trivia expert providing players with challenging questions.\"),\n",
        "    ('human', \"Category: {trivia_category}\"),\n",
        "    ('human', \"Question: {trivia_question}, answer in 100 words or less.\")\n",
        "])\n",
        "\n",
        "# Format the prompt with variables\n",
        "variable_message = variable_prompt.format(\n",
        "    trivia_category=\"Science\",\n",
        "    trivia_question=\"What is the speed of light?\"\n",
        ")\n",
        "\n",
        "# Test the Prompt with Variables\n",
        "variable_response = query_model([{\"role\": \"user\", \"content\": variable_message}])\n",
        "print(\"\\n‚ö° Trivia Expert Says:\\n\", variable_response)\n",
        "\n",
        "# --- Test Prompt 4: Dynamic Data Integration ---\n",
        "# Load and prepare the dataset\n",
        "dataset = load_dataset(\"FronkonGames/steam-games-dataset\", split=\"train\")\n",
        "df = dataset.to_pandas()\n",
        "\n",
        "# Extract the top-rated games\n",
        "df = df[[\"Name\", \"Genres\", \"Positive\"]].sort_values(\n",
        "     by=\"Positive\", ascending=False).head(5)\n",
        "\n",
        "# Format game data into structured input for AI\n",
        "game_list = \"\\n\".join(f\"{row['Name']} (Genre: {row['Genres']}, \"\n",
        "                       f\"Reviews: {row['Positive']})\"\n",
        "                       for _, row in df.iterrows())\n",
        "\n",
        "# Define the prompt template for structured AI gameplay\n",
        "game_prompt = ChatPromptTemplate.from_messages([\n",
        "    ('system', \"Based on the most popular games below, define a simple game \"\n",
        "               \"structure designed for three AI agents.\"),\n",
        "    ('human', \"Here are the top-rated games:\\n{game_list}\\n\\n\"\n",
        "              \"Using this list as inspiration, generate:\\n\"\n",
        "              \"- A recommended game genre\\n\"\n",
        "              \"- A title for the game\\n\"\n",
        "              \"- A simple strategy or turn-based game mechanic\\n\"\n",
        "              \"- Three AI agent roles: two players and one Game Master (GM)\\n\"\n",
        "              \"- A brief explanation of how the game is played\")\n",
        "])\n",
        "\n",
        "# Format the game analysis example\n",
        "game_message = game_prompt.format(game_list=game_list)\n",
        "\n",
        "# Test the Prompt with Dynamic Data\n",
        "game_response = query_model([{\"role\": \"user\", \"content\": game_message}])\n",
        "print(\"\\nüéÆ Game Concept Suggestion:\\n\", game_response)\n"
      ],
      "metadata": {
        "id": "V0GmGou6NKV8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Listing 9-3: Implementing AI Agents and Automating a Trivia Contest\n",
        "This code sets up Neural Duel, a structured AI-driven trivia game using CrewAI. It defines four agents‚Äîa Game Master, two contestants, and a Judge‚Äîeach assigned specific tasks. The Game Master generates real-time trivia questions, the contestants respond independently, and the Judge evaluates and declares the winner. The flow function ensures data moves correctly between agents, orchestrating a fair and competitive game.\n",
        "\n",
        "Note: Before running this code, install dependencies below:"
      ],
      "metadata": {
        "id": "qwRTeLuxzGmQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture --no-stderr\n",
        "%pip install -U --quiet 'crewai[tools]' aisuite"
      ],
      "metadata": {
        "id": "1jlOZoIMZWA_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from crewai import Agent, Task, Crew, Process\n",
        "from langchain_openai import ChatOpenAI\n",
        "from crewai_tools import WebsiteSearchTool\n",
        "\n",
        "# --- Initialize Web Search Tool ---\n",
        "search_tool = WebsiteSearchTool()\n",
        "\n",
        "# --- Define LLMs ---\n",
        "system_llm = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0.7,\n",
        "                        max_tokens=250)\n",
        "player1_llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0.8,\n",
        "                         max_tokens=50)\n",
        "player2_llm = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0.9,\n",
        "                         max_tokens=50)\n",
        "\n",
        "# --- Define Agents ---\n",
        "\n",
        "game_master = Agent(\n",
        "    role=\"Game Master\",\n",
        "    goal=\"Generate trivia questions on non-political current events today.\",\n",
        "    backstory=\"An impartial host creating fair and engaging trivia games.\",\n",
        "    tools=[search_tool],\n",
        "    llm=system_llm\n",
        ")\n",
        "\n",
        "player_1 = Agent(\n",
        "    role=\"Contestant 1\",\n",
        "    goal=\"Answer trivia questions quickly using only internal knowledge.\",\n",
        "    backstory=\"A fast-thinking trivia player relying on existing knowledge.\",\n",
        "    llm=player1_llm\n",
        ")\n",
        "\n",
        "player_2 = Agent(\n",
        "    role=\"Contestant 2\",\n",
        "    goal=\"Answer trivia questions strategically, focusing on reasoning.\",\n",
        "    backstory=\"A methodical contestant carefully formulating responses.\",\n",
        "    llm=player2_llm\n",
        ")\n",
        "\n",
        "judge = Agent(\n",
        "    role=\"Judge\",\n",
        "    goal=\"Evaluate trivia answers and declare a winner with justification.\",\n",
        "    backstory=\"An impartial adjudicator ensuring fairness in competition.\",\n",
        "    llm=system_llm\n",
        ")\n",
        "\n",
        "# --- Define Tasks ---\n",
        "\n",
        "generate_question_and_answer = Task(\n",
        "    description=\"Create a trivia question on a non-political event today. \"\n",
        "                \"Ensure the event is recent and unlikely in LLM training data. \"\n",
        "                \"Format the response as:\\n\\n\"\n",
        "                \"Question: <trivia question>\\n\"\n",
        "                \"Answer: <correct answer>\",\n",
        "    expected_output=\"A clearly formatted trivia question and correct answer.\",\n",
        "    agent=game_master\n",
        ")\n",
        "\n",
        "player1_answer = Task(\n",
        "    description=\"Given the question:\\n{question}\\n\\n\"\n",
        "                \"Provide your best answer using only internal knowledge.\",\n",
        "    expected_output=\"A concise and accurate response to the trivia question.\",\n",
        "    agent=player_1\n",
        ")\n",
        "\n",
        "player2_answer = Task(\n",
        "    description=\"Given the question:\\n{question}\\n\\n\"\n",
        "                \"Provide your best answer with logical reasoning.\",\n",
        "    expected_output=\"A thoughtful and well-reasoned response to the trivia \"\n",
        "                    \"question.\",\n",
        "    agent=player_2\n",
        ")\n",
        "\n",
        "evaluate_and_declare_winner = Task(\n",
        "    description=\"Given the question:\\n{question}\\n\\n\"\n",
        "                \"Correct answer:\\n{right_answer}\\n\\n\"\n",
        "                \"Player 1's answer:\\n{player1_answer}\\n\\n\"\n",
        "                \"Player 2's answer:\\n{player2_answer}\\n\\n\"\n",
        "                \"Determine the most accurate response and declare the winner.\\n\\n\"\n",
        "                \"Format as:\\n\\n\"\n",
        "                \"Winner: Contestant X\\n\"\n",
        "                \"Justification: <brief explanation>\",\n",
        "    expected_output=\"A clear winner declaration and reasoning.\",\n",
        "    agent=judge\n",
        ")\n",
        "\n",
        "# --- Define Crews ---\n",
        "\n",
        "game_master_crew = Crew(\n",
        "    agents=[game_master],\n",
        "    tasks=[generate_question_and_answer],\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "player1_crew = Crew(\n",
        "    agents=[player_1],\n",
        "    tasks=[player1_answer],\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "player2_crew = Crew(\n",
        "    agents=[player_2],\n",
        "    tasks=[player2_answer],\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "judge_crew = Crew(\n",
        "    agents=[judge],\n",
        "    tasks=[evaluate_and_declare_winner],\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "# --- Define Flow Function to Orchestrate Contest ---\n",
        "\n",
        "def extract_question_answer(response_text):\n",
        "    \"\"\"Extracts question and answer from structured text using regex.\"\"\"\n",
        "    match = re.search(r\"Question:\\s*(.*?)\\s*Answer:\\s*(.*)\",\n",
        "                      response_text, re.IGNORECASE)\n",
        "    if match:\n",
        "        return match.group(1).strip(), match.group(2).strip()\n",
        "    return \"No question generated.\", \"No correct answer provided.\"\n",
        "\n",
        "def run_neural_duel():\n",
        "    \"\"\"Orchestrates the trivia contest flow between AI agents.\"\"\"\n",
        "    print(\"üé≤ Starting Neural Duel!\\n\")\n",
        "\n",
        "    # Step 1: Game Master generates trivia question and correct answer\n",
        "    gm_results = game_master_crew.kickoff()\n",
        "    print(\"\\nüîç Raw Game Master Results:\\n\", gm_results)\n",
        "\n",
        "    # Extract question and correct answer\n",
        "    question, correct_answer = extract_question_answer(str(gm_results))\n",
        "\n",
        "    print(f\"\\nüìù Trivia Question: {question}\")\n",
        "    print(f\"ü§´ (Secret) Correct Answer: {correct_answer}\")\n",
        "\n",
        "    # Step 2: Players answer the question\n",
        "    player1_results = player1_crew.kickoff(inputs={\"question\": question})\n",
        "    player2_results = player2_crew.kickoff(inputs={\"question\": question})\n",
        "\n",
        "    print(f\"\\nüèÖ Contestant 1's Answer: {str(player1_results)}\")\n",
        "    print(f\"üèÖ Contestant 2's Answer: {str(player2_results)}\")\n",
        "\n",
        "    # Step 3: Judge evaluates responses and declares the winner\n",
        "    judge_results = judge_crew.kickoff(inputs={\n",
        "        \"question\": question,\n",
        "        \"right_answer\": correct_answer,\n",
        "        \"player1_answer\": str(player1_results),\n",
        "        \"player2_answer\": str(player2_results)\n",
        "    })\n",
        "\n",
        "    print(\"\\nüèÜ Neural Duel Results:\\n\", str(judge_results))\n",
        "\n",
        "# --- Run the Game ---\n",
        "run_neural_duel()\n",
        "\n"
      ],
      "metadata": {
        "id": "V6k6HfzMHo92"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}