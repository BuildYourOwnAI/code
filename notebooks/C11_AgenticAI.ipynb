{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## **Chapter 11 - Agentic AI**\n",
        "This notebook explores Agentic AI through structured examples, showcasing how AI agents plan, retrieve data, and execute tasks autonomously. Using `LangChain` and `CrewAI`, the notebook demonstrates key abstractions, including datasets, prompts, model selection, agent-based reasoning, and task execution. Examples range from structured data retrieval using Hugging Face datasets to interactive AI agents that process information and act independently. By the end, you'll see how these frameworks power AI-driven decision-making and automation, making AI applications more adaptive and autonomous."
      ],
      "metadata": {
        "id": "hqQCTuyowKk-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Setting Up API Keys** for Hugging Face, Google, and OpenAI\n",
        "Before running the code examples in this chapter, API keys must be configured for Hugging Face Hub, Google APIs (Serper and Gemini), and OpenAI. This script retrieves stored credentials in Google Colab Secrets and sets them as environment variables for seamless integration with AI services.\n",
        "\n",
        "***Note:*** See Google Colab Secrets for instructions on how to store and manage API keys securely."
      ],
      "metadata": {
        "id": "ko1MK3DGxu-P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# API Key Setup for Hugging Face Hub, Google API, and OpenAI in Google Colab\n",
        "# Constants and API Key Configuration\n",
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "# === Load API keys securely from Google Colab Secrets ===\n",
        "def load_api_keys():\n",
        "    keys = {\n",
        "        \"HF_TOKEN\": userdata.get(\"HF_TOKEN\"),\n",
        "        \"OPENAI_API_KEY\": userdata.get(\"OPENAI_API_KEY\"),\n",
        "        \"SERPAPI_API_KEY\": userdata.get(\"SERPAPI_API_KEY\"),\n",
        "        \"SERPER_API_KEY\": userdata.get(\"SERPER_API_KEY\")\n",
        "    }\n",
        "    for key, value in keys.items():\n",
        "        if not value:\n",
        "            raise ValueError(f\"‚ùå Missing {key}. Please set this API key in Colab secrets.\")\n",
        "        os.environ[key] = value\n",
        "    print(\"‚úÖ All API keys loaded and configured successfully.\")\n",
        "\n",
        "# Execute API key loading upon running this cell\n",
        "load_api_keys()\n"
      ],
      "metadata": {
        "id": "J-Mhzj9bZVQR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Listing 9-1: Loading and Analyzing Game Data\n",
        "This code retrieves and processes the **Steam Games** dataset from Hugging Face. It selects the top five highest-rated games, sorting them by positive reviews. The dataset provides structured information on game titles, genres, and player feedback, forming the foundation for AI-driven analysis and decision-making.\n",
        "\n",
        "***Note:*** Before running this code, ensure you have the necessary dependencies installed by running:"
      ],
      "metadata": {
        "id": "8CAELECSSpLS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install --quiet datasets"
      ],
      "metadata": {
        "id": "6d8rGi-ATMCp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "import pandas as pd\n",
        "\n",
        "# Load the Steam Games dataset from Hugging Face\n",
        "dataset = load_dataset(\"FronkonGames/steam-games-dataset\",\n",
        "                       split=\"train\")\n",
        "\n",
        "# Convert to Pandas DataFrame\n",
        "df = dataset.to_pandas()\n",
        "\n",
        "# Select relevant columns\n",
        "df = df[[\"Name\", \"Genres\", \"Positive\"]].sort_values(\n",
        "     by=\"Positive\", ascending=False).head(5)\n",
        "\n",
        "# Rename columns for clarity\n",
        "df.columns = [\"Game\", \"Genres\", \"Positive_Reviews\"]\n",
        "\n",
        "# Display structured dataset output\n",
        "print(\"\\nTop 5 Highest Rated Games on Steam:\")\n",
        "print(df.to_string(index=False))"
      ],
      "metadata": {
        "id": "TucMXj5rSuHD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Listing 11-2: Building Prompt Templates and Querying AI Models with LangChain\n",
        "\n",
        "This listing walks through a progression of prompt-engineering techniques using\n",
        "LangChain and Hugging Face models. It begins by installing the required packages\n",
        "and setting up a Hugging Face text-generation endpoint. The first cells introduce\n",
        "basic prompt templates, then extend them with one-shot and few-shot examples.\n",
        "Next, the code demonstrates variable substitution to create flexible, category-\n",
        "driven trivia prompts. The listing then integrates structured data from the Steam\n",
        "Games Dataset, showing how real-world information can be fed into AI-driven game\n",
        "concept generation. Finally, the listing runs all templates end-to-end, producing\n",
        "structured responses from several prompt formats.\n",
        "\n",
        "***Note:*** Install the required dependencies before running the listing. The pip installation step may produce a few warnings or version-conflict messages in Colab, but in our experience the code cells still run correctly once the packages are in place."
      ],
      "metadata": {
        "id": "gZjYGxexj7zu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required packages for Hugging Face and LangChain usage\n",
        "\n",
        "print(\"Installing packages... this can take a minute or two.\")\n",
        "\n",
        "%pip install -q langchain langchain-community langchain-huggingface langchain-openai google-search-results\n",
        "\n",
        "print(\"All required packaged installed and ready!\")"
      ],
      "metadata": {
        "id": "_TYGjsKtkSuh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === Hugging Face trivia chatbot with LangChain ===\n",
        "\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_huggingface import ChatHuggingFace, HuggingFaceEndpoint\n",
        "\n",
        "# Models that work with the Hugging Face Inference API for text generation\n",
        "DEFAULT_MODELS = [\n",
        "    \"mistralai/Mistral-7B-Instruct-v0.2\",\n",
        "    \"meta-llama/Meta-Llama-3-8B-Instruct\",\n",
        "    \"openai/gpt-oss-128k\",\n",
        "]\n",
        "\n",
        "DEFAULT_MODEL = DEFAULT_MODELS[0]          # Pick one model from the list\n",
        "TEMP = 0.2                                 # Lower = more focused answers\n",
        "\n",
        "base_llm = HuggingFaceEndpoint(\n",
        "    repo_id=DEFAULT_MODEL,                 # Hugging Face model id\n",
        "    task=\"text-generation\",                # Use text-generation endpoint\n",
        "    temperature=TEMP,                      # Sampling temperature\n",
        "    max_new_tokens=128,                    # Max tokens in each reply\n",
        "    return_full_text=False,                # Only return new text\n",
        "    # huggingfacehub_api_token=\"YOUR_TOKEN\",  # Or set env var instead\n",
        ")\n",
        "\n",
        "chat_llm = ChatHuggingFace(llm=base_llm)   # Wrap endpoint as a chat model\n",
        "parser = StrOutputParser()                 # Parse output into a plain string"
      ],
      "metadata": {
        "id": "PmRGgSld6ci4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === Basic Trivia Prompt Example ===\n",
        "\n",
        "basic_prompt = ChatPromptTemplate.from_messages([\n",
        "    (   \"system\",\n",
        "        \"You are a trivia expert who provides informative answers.\",\n",
        "    ),\n",
        "    (   \"human\",\n",
        "        \"Who invented the lightbulb?\",\n",
        "    ),\n",
        "    (   \"ai\",\n",
        "        \"The lightbulb was invented by Thomas Edison in 1879.\",\n",
        "    ),\n",
        "    (   \"human\",\n",
        "        \"{question}\",\n",
        "    ),\n",
        "])\n",
        "\n",
        "basic_chain = basic_prompt | chat_llm | parser  # Prompt ‚Üí LLM ‚Üí text\n",
        "\n",
        "response = basic_chain.invoke(\n",
        "    {\n",
        "        \"question\": \"What is the tallest mountain on Earth?\",\n",
        "    }\n",
        ")\n",
        "print(\"üìò Trivia Response:\\n\", response)"
      ],
      "metadata": {
        "id": "9Y0kcHat5W71"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === Few-shot trivia example with Hugging Face ===\n",
        "\n",
        "few_shot_prompt = ChatPromptTemplate.from_messages([\n",
        "    # System Prompt\n",
        "    ('system', \"You are a trivia expert providing clear answers.\"),\n",
        "    # First Example\n",
        "    ('human', \"Who discovered gravity?\"),\n",
        "    ('ai', \"Gravity was discovered by Sir Isaac Newton in the 17th century.\"),\n",
        "    # Second Example\n",
        "    ('human', \"What is the speed of light?\"),\n",
        "    ('ai', \"The speed of light is approximately 299,792 kilometers per second.\"),\n",
        "    # Third Example\n",
        "    ('human', \"Who developed the theory of relativity?\"),\n",
        "    ('ai', \"Albert Einstein developed the theory of relativity.\"),\n",
        "    # The Question posed to AI model\n",
        "    ('human', \"Who are the authors of ‚ÄòBuild Your Own AI?‚Äô.\")\n",
        "])\n",
        "\n",
        "few_shot_chain = few_shot_prompt | chat_llm | parser\n",
        "\n",
        "response = few_shot_chain.invoke({})\n",
        "print(\"üìó Few-shot Response:\\n\", response)"
      ],
      "metadata": {
        "id": "GO6PiHrc7pdD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === Variable trivia prompt with Hugging Face ===\n",
        "\n",
        "variable_prompt = ChatPromptTemplate.from_messages([\n",
        "    (   \"system\",\n",
        "        \"You are a trivia expert providing players with challenging questions.\",\n",
        "    ),\n",
        "    (   \"human\",\n",
        "        \"Category: {trivia_category}\",\n",
        "    ),\n",
        "    (   \"human\",\n",
        "        \"Question: {trivia_question}, answer in 50 words or less.\",\n",
        "    ),\n",
        "])\n",
        "\n",
        "variable_chain = variable_prompt | chat_llm | parser\n",
        "\n",
        "response = variable_chain.invoke(\n",
        "    {\n",
        "        \"trivia_category\": \"Astronomy\",\n",
        "        \"trivia_question\": \"What causes a solar eclipse?\",\n",
        "    }\n",
        ")\n",
        "\n",
        "print(\"üéØ Trivia Response:\\n\", response)"
      ],
      "metadata": {
        "id": "ysrX0Ou_8P00"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === Game analysis with Hugging Face ===\n",
        "\n",
        "from datasets import load_dataset\n",
        "import pandas as pd\n",
        "\n",
        "# Load the Steam dataset\n",
        "dataset = load_dataset(\n",
        "    \"FronkonGames/steam-games-dataset\", split=\"train\"\n",
        ")\n",
        "df = dataset.to_pandas()\n",
        "\n",
        "# Extract the top five highest-rated games\n",
        "df = df[[\"Name\", \"Genres\", \"Positive\"]].sort_values(\n",
        "    by=\"Positive\", ascending=False\n",
        ").head(5)\n",
        "\n",
        "# Format the games into a compact list for the prompt\n",
        "game_list = \"\\n\".join(\n",
        "    f\"{row['Name']} (Genre: {row['Genres']}, Reviews: {row['Positive']})\"\n",
        "    for _, row in df.iterrows()\n",
        ")\n",
        "\n",
        "# Create the game-analysis prompt\n",
        "game_prompt = ChatPromptTemplate.from_messages([\n",
        "    (\n",
        "        \"system\",\n",
        "        \"Using the top games below, design a simple three-agent game.\",\n",
        "    ),\n",
        "    (\n",
        "        \"human\",\n",
        "        \"Top-rated games:\\n{game_list}\\n\\n\"\n",
        "        \"Provide:\\n\"\n",
        "        \"- A recommended genre\\n\"\n",
        "        \"- A game title\\n\"\n",
        "        \"- A basic mechanic\\n\"\n",
        "        \"- Three agent roles (2 players, 1 GM)\\n\"\n",
        "        \"- A short play explanation\",\n",
        "    ),\n",
        "])\n",
        "\n",
        "# Build the chain (prompt ‚Üí LLM ‚Üí text)\n",
        "game_chain = game_prompt | chat_llm | parser\n",
        "\n",
        "# Invoke with the formatted game list\n",
        "response = game_chain.invoke({\"game_list\": game_list})\n",
        "\n",
        "print(\"üéÆ Game Concept:\\n\", response)"
      ],
      "metadata": {
        "id": "l0xyFo499Bmy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === Running all trivia prompt templates ===\n",
        "\n",
        "# Basic trivia prompt\n",
        "basic_chain = basic_prompt | chat_llm | parser\n",
        "basic_out = basic_chain.invoke(\n",
        "    {\"question\": \"Who invented the telephone?\"}\n",
        ")\n",
        "\n",
        "# Few-shot trivia prompt\n",
        "few_shot_chain = few_shot_prompt | chat_llm | parser\n",
        "few_shot_out = few_shot_chain.invoke({})\n",
        "\n",
        "# Variable trivia prompt\n",
        "variable_chain = variable_prompt | chat_llm | parser\n",
        "variable_out = variable_chain.invoke(\n",
        "    {\n",
        "        \"trivia_category\": \"Physics\",\n",
        "        \"trivia_question\": \"What is quantum tunneling?\",\n",
        "    }\n",
        ")\n",
        "\n",
        "print(\"Basic:\", basic_out)\n",
        "print(\"Few-shot:\", few_shot_out)\n",
        "print(\"Variable:\", variable_out)"
      ],
      "metadata": {
        "id": "FbcCfES4DGxR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Listing 11-3: Implementing AI Agents and Automating a Trivia Contest\n",
        "This code sets up Neural Duel, a structured AI-driven trivia game using CrewAI. It defines four agents‚Äîa Game Master, two contestants, and a Judge‚Äîeach assigned specific tasks. The Game Master generates real-time trivia questions with a web search tool, the contestants respond independently, and the Judge evaluates and declares the winner. The flow function ensures data moves correctly between agents, orchestrating a fair and competitive game.\n",
        "\n",
        "**Note:** Before running this code, install the required dependencies  \n",
        "(for example, `pip install \"crewai[tools]\" langchain-openai openai`).  \n",
        "Because open-source packages evolve quickly, Colab may show occasional\n",
        "version warnings or dependency conflicts during installation. These seldom\n",
        "prevent the code from running, but if something does break, try restarting\n",
        "the runtime, reinstalling packages, or switching to an alternate search tool\n",
        "from `crewai_tools`. If the agents appear to loop or stall, increasing\n",
        "`max_iter` to 3 and enabling `verbose=True` usually helps stabilize behavior\n",
        "and makes debugging easier."
      ],
      "metadata": {
        "id": "qwRTeLuxzGmQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture --no-stderr\n",
        "%pip install crewai crewai-tools langchain-openai openai qdrant-client\n",
        "\n",
        "print(\"----- CrewAI Installed! -----\")"
      ],
      "metadata": {
        "id": "1jlOZoIMZWA_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from crewai import Agent, Task, Crew, Process\n",
        "from langchain_openai import ChatOpenAI\n",
        "from crewai_tools import SerperDevTool\n",
        "\n",
        "# --- Initialize Web Search Tool ---\n",
        "search_tool = SerperDevTool()\n",
        "\n",
        "# --- Define LLMs ---\n",
        "system_llm = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0.7,\n",
        "                        max_tokens=250)\n",
        "player1_llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0.8,\n",
        "                         max_tokens=50)\n",
        "player2_llm = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0.9,\n",
        "                         max_tokens=50)\n",
        "\n",
        "# --- Define Agents ---\n",
        "\n",
        "game_master = Agent(\n",
        "    role=\"Game Master\",\n",
        "    goal=\"Generate trivia questions on non-political current events today.\",\n",
        "    backstory=\"An impartial host creating fair and engaging trivia games.\",\n",
        "    tools=[search_tool],\n",
        "    max_iter = 3,\n",
        "    llm=system_llm\n",
        ")\n",
        "\n",
        "player_1 = Agent(\n",
        "    role=\"Contestant 1\",\n",
        "    goal=\"Answer trivia questions quickly using only internal knowledge.\",\n",
        "    backstory=\"A fast-thinking trivia player relying on existing knowledge.\",\n",
        "    max_iter = 3,\n",
        "    llm=player1_llm\n",
        ")\n",
        "\n",
        "player_2 = Agent(\n",
        "    role=\"Contestant 2\",\n",
        "    goal=\"Answer trivia questions strategically, focusing on reasoning.\",\n",
        "    backstory=\"A methodical contestant carefully formulating responses.\",\n",
        "    max_iter = 3,\n",
        "    llm=player2_llm\n",
        ")\n",
        "\n",
        "judge = Agent(\n",
        "    role=\"Judge\",\n",
        "    goal=\"Evaluate trivia answers and declare a winner with justification.\",\n",
        "    backstory=\"An impartial adjudicator ensuring fairness in competition.\",\n",
        "    max_iter = 3,\n",
        "    llm=system_llm\n",
        ")\n",
        "\n",
        "# --- Define Tasks ---\n",
        "\n",
        "generate_question_and_answer = Task(\n",
        "    description=\"Create a trivia question on a non-political event today. \"\n",
        "                \"Ensure the event is recent and unlikely in LLM training data. \"\n",
        "                \"Format the response as:\\n\\n\"\n",
        "                \"Question: <trivia question>\\n\"\n",
        "                \"Answer: <correct answer>\",\n",
        "    expected_output=\"A clearly formatted trivia question and correct answer.\",\n",
        "    agent=game_master\n",
        ")\n",
        "\n",
        "player1_answer = Task(\n",
        "    description=\"Given the question:\\n{question}\\n\\n\"\n",
        "                \"Provide your best answer using only internal knowledge.\",\n",
        "    expected_output=\"A concise and accurate response to the trivia question.\",\n",
        "    agent=player_1\n",
        ")\n",
        "\n",
        "player2_answer = Task(\n",
        "    description=\"Given the question:\\n{question}\\n\\n\"\n",
        "                \"Provide your best answer with logical reasoning.\",\n",
        "    expected_output=\"A thoughtful and well-reasoned response to the trivia \"\n",
        "                    \"question.\",\n",
        "    agent=player_2\n",
        ")\n",
        "\n",
        "evaluate_and_declare_winner = Task(\n",
        "    description=\"Given the question:\\n{question}\\n\\n\"\n",
        "                \"Correct answer:\\n{right_answer}\\n\\n\"\n",
        "                \"Player 1's answer:\\n{player1_answer}\\n\\n\"\n",
        "                \"Player 2's answer:\\n{player2_answer}\\n\\n\"\n",
        "                \"Determine the most accurate response and declare the winner.\\n\\n\"\n",
        "                \"Format as:\\n\\n\"\n",
        "                \"Winner: Contestant X\\n\"\n",
        "                \"Justification: <brief explanation>\",\n",
        "    expected_output=\"A clear winner declaration and reasoning.\",\n",
        "    agent=judge\n",
        ")\n",
        "\n",
        "# --- Define Crews ---\n",
        "\n",
        "game_master_crew = Crew(\n",
        "    agents=[game_master],\n",
        "    tasks=[generate_question_and_answer],\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "player1_crew = Crew(\n",
        "    agents=[player_1],\n",
        "    tasks=[player1_answer],\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "player2_crew = Crew(\n",
        "    agents=[player_2],\n",
        "    tasks=[player2_answer],\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "judge_crew = Crew(\n",
        "    agents=[judge],\n",
        "    tasks=[evaluate_and_declare_winner],\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "# --- Define Flow Function to Orchestrate Contest ---\n",
        "\n",
        "def extract_question_answer(response_text):\n",
        "    \"\"\"Extracts question and answer from structured text using regex.\"\"\"\n",
        "    match = re.search(r\"Question:\\s*(.*?)\\s*Answer:\\s*(.*)\",\n",
        "                      response_text, re.IGNORECASE)\n",
        "    if match:\n",
        "        return match.group(1).strip(), match.group(2).strip()\n",
        "    return \"No question generated.\", \"No correct answer provided.\"\n",
        "\n",
        "def run_neural_duel():\n",
        "    \"\"\"Orchestrates the trivia contest flow between AI agents.\"\"\"\n",
        "    print(\"üé≤ Starting Neural Duel!\\n\")\n",
        "\n",
        "    # Step 1: Game Master generates trivia question and correct answer\n",
        "    gm_results = game_master_crew.kickoff()\n",
        "    print(\"\\nüîç Raw Game Master Results:\\n\", gm_results)\n",
        "\n",
        "    # Extract question and correct answer\n",
        "    question, correct_answer = extract_question_answer(str(gm_results))\n",
        "\n",
        "    print(f\"\\nüìù Trivia Question: {question}\")\n",
        "    print(f\"ü§´ (Secret) Correct Answer: {correct_answer}\")\n",
        "\n",
        "    # Step 2: Players answer the question\n",
        "    player1_results = player1_crew.kickoff(inputs={\"question\": question})\n",
        "    player2_results = player2_crew.kickoff(inputs={\"question\": question})\n",
        "\n",
        "    print(f\"\\nüèÖ Contestant 1's Answer: {str(player1_results)}\")\n",
        "    print(f\"üèÖ Contestant 2's Answer: {str(player2_results)}\")\n",
        "\n",
        "    # Step 3: Judge evaluates responses and declares the winner\n",
        "    judge_results = judge_crew.kickoff(inputs={\n",
        "        \"question\": question,\n",
        "        \"right_answer\": correct_answer,\n",
        "        \"player1_answer\": str(player1_results),\n",
        "        \"player2_answer\": str(player2_results)\n",
        "    })\n",
        "\n",
        "    print(\"\\nüèÜ Neural Duel Results:\\n\", str(judge_results))\n",
        "\n",
        "# --- Run the Game ---\n",
        "run_neural_duel()\n",
        "\n"
      ],
      "metadata": {
        "id": "V6k6HfzMHo92"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Listing 11-4: Generating Chapter Artwork with the Illustrator Agent\n",
        "This code defines the Chapter Illustrator agent, a lightweight AI designed to create a single image for the chapter. The agent uses DALL¬∑E as its sole tool and receives a short visual prompt describing the desired scene. When run, the agent produces a landscape-oriented, comic-style illustration of two AI robots playing chess, demonstrating how an agent can carry out a focused creative task within a larger workflow."
      ],
      "metadata": {
        "id": "fbHkEYojhDhG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture --no-stderr\n",
        "%pip install crewai crewai-tools langchain-openai openai qdrant-client"
      ],
      "metadata": {
        "id": "EXcdVuxlhJH0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from crewai import Agent, Task, Crew, Process\n",
        "from crewai_tools import DallETool\n",
        "\n",
        "# Ensure API key is set\n",
        "if \"OPENAI_API_KEY\" not in os.environ:\n",
        "    raise SystemExit(\"Please set the OPENAI_API_KEY env var before running.\")\n",
        "\n",
        "# Landscape DALL¬∑E tool\n",
        "image_tool = DallETool(\n",
        "    model=\"dall-e-3\",\n",
        "    size=\"1792x1024\",   # landscape orientation\n",
        "    quality=\"standard\",\n",
        "    n=1,\n",
        ")\n",
        "\n",
        "# Minimal and clear agent\n",
        "illustrator_agent = Agent(\n",
        "    role=\"Illustrator\",\n",
        "    goal=\"Generate exactly one DALL-E image when requested.\",\n",
        "    backstory=\"You convert short prompts into visual concepts.\",\n",
        "    tools=[image_tool],\n",
        "    llm=\"gpt-4o-mini\",\n",
        "    verbose=True,\n",
        ")\n",
        "\n",
        "# Task: explicitly tell agent how to call the tool\n",
        "chapter_image_task = Task(\n",
        "    description=(\n",
        "        \"Use ONLY the Dall-E Tool.\\n\\n\"\n",
        "        \"Your Action Input MUST be JSON of this form:\\n\"\n",
        "        \"{\\\"image_description\\\": \\\"<prompt>\\\"}\\n\\n\"\n",
        "        \"Use this image description:\\n\"\n",
        "        \"Create a clean, comic-style image on a white background with a \"\n",
        "        \"color palette of Primary Red, Bright Blue, Sunny Yellow, Deep Black, \"\n",
        "        \"White, and Muted Grey. Depict two playful AI bots playing chess against \"\n",
        "        \"each other. Landscape composition.\"\n",
        "    ),\n",
        "    expected_output=\"A DALL-E image URL.\",\n",
        "    agent=illustrator_agent,\n",
        ")\n",
        "\n",
        "chapter_image_crew = Crew(\n",
        "    agents=[illustrator_agent],\n",
        "    tasks=[chapter_image_task],\n",
        "    process=Process.sequential,\n",
        "    verbose=True,\n",
        ")\n",
        "\n",
        "def generate_chapter_image():\n",
        "    result = chapter_image_crew.kickoff()\n",
        "    print(\"\\n=== Chapter Image Result ===\\n\")\n",
        "    print(result)\n",
        "    print(\"\\n============================\\n\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    generate_chapter_image()"
      ],
      "metadata": {
        "id": "w8oALYbLqS9s"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}