{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# InterviewAgent - From Foreword of Open Source AI\n",
        "This notebook uses **CrewAI** agents to simulate an interview with a public figure—drawing exclusively from real quotes across public podcasts, articles, and transcripts. It includes modular programs for discovering sources, assembling quote-based responses, and compiling everything into a polished markdown interview suitable for publication. The design supports scalable, trustworthy dialogue generation for book chapters, blogs, or media projects involving open-source AI.\n",
        "\n",
        "Before running any of the main program listings, be sure to first run the setup cells:\n",
        "- `pip install` to bring in required libraries (`crewai[tools])\n",
        "- Google Colab Secrets loading cell to securely access your API keys (used by tools like `Serper` and `OpenAI`)\n",
        "- Global constants defining the default model, output paths, ** interviewee name, and questions**\n",
        "\n"
      ],
      "metadata": {
        "id": "UQ4whvzFFZlY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pgkc-_qSWJJl"
      },
      "outputs": [],
      "source": [
        "%%capture --no-stderr\n",
        "%pip install -U --quiet 'crewai[tools]' aisuite databricks-sdk boto3"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Constants and API Key Configuration\n",
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "# === Load API keys securely from Google Colab Secrets ===\n",
        "def load_api_keys():\n",
        "    keys = {\n",
        "        \"HF_TOKEN\": userdata.get(\"HF_TOKEN\"),\n",
        "        \"SERPER_API_KEY\": userdata.get(\"SERPER_API_KEY\"),\n",
        "        \"OPENAI_API_KEY\": userdata.get(\"OPENAI_API_KEY\"),\n",
        "        \"GEMINI_API_KEY\": userdata.get(\"GEMINI_API_KEY\"),\n",
        "    }\n",
        "    for key, value in keys.items():\n",
        "        if not value:\n",
        "            raise ValueError(f\"❌ Missing {key}. Please set this API key in Colab secrets.\")\n",
        "        os.environ[key] = value\n",
        "    print(\"✅ All API keys loaded and configured successfully.\")\n",
        "\n",
        "# Execute API key loading upon running this cell\n",
        "load_api_keys()"
      ],
      "metadata": {
        "id": "WSLl_1mUWOz0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === Config ===\n",
        "DEFAULT_MODEL = \"gpt-4o-mini\"\n",
        "#DEFAULT_MODEL = \"huggingface/meta-llama/Meta-Llama-3.1-8B-Instruct\"\n",
        "\n",
        "# === Directory and File Configuration ===\n",
        "DIRECTORY = \"interview_outputs\"\n",
        "RAW_OUTPUT = \"compiled_interview_raw.txt\"\n",
        "FINAL_OUTPUT = \"interview_final.md\"\n"
      ],
      "metadata": {
        "id": "aoBxsH9ViDPV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === Interviewee Name (edit this for future interviews) ===\n",
        "INTERVIEWEE = \"Clement Delangue\"\n",
        "\n",
        "# === Interview Questions ===\n",
        "INTERVIEW_QUESTIONS = [\n",
        "    \"Can you tell us about your background, education, and the events leading up to the founding of Hugging Face?\",\n",
        "    \"How did the name Hugging Face come about?\",\n",
        "    \"What is Hugging Face's mission?\",\n",
        "    \"What does open source AI mean to you?\",\n",
        "    \"Tell us about Hugging Face Partnerships\"\n",
        "    \"What is the future of AI?\"\n",
        "]"
      ],
      "metadata": {
        "id": "7_Wr_WxgiJN-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Listing F-1A: Media Source Discovery Agent\n",
        "This listing shows a focused script that uses a single `CrewAI` agent to discover up to 12 verified public sources featuring the interviewee. The agent is equipped with search and website tools and is instructed to find interviews, blog posts, podcasts, company articles, and LinkedIn posts where the subject has shared meaningful commentary. Each source is saved with a short description and URL, creating a reusable foundation for future interview tasks. The results are stored in a single output file.\n"
      ],
      "metadata": {
        "id": "vzVkq34VFSHc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from crewai import Agent, Task, Crew\n",
        "from crewai_tools import SerperDevTool, WebsiteSearchTool\n",
        "\n",
        "# === Tools ===\n",
        "search_tool = SerperDevTool()\n",
        "web_rag_tool = WebsiteSearchTool()\n",
        "\n",
        "# === Configuration ===\n",
        "SOURCE_OUTPUT_FILE = os.path.join(DIRECTORY, \"verified_sources.txt\")\n",
        "os.makedirs(DIRECTORY, exist_ok=True)\n",
        "\n",
        "# === Create Discovery Agent ===\n",
        "def create_discovery_agent():\n",
        "    return Agent(\n",
        "        role=\"Interview Source Discovery Agent\",\n",
        "        goal=f\"Identify up to 12 verified public sources featuring interviews or direct quotes by {INTERVIEWEE}.\",\n",
        "        backstory=(\n",
        "            f\"You are a research assistant trained to discover interview content and direct public statements made by {INTERVIEWEE}. \"\n",
        "            \"Your job is to find blog posts, company blogs, podcasts, video transcripts, media articles, and public LinkedIn posts where \"\n",
        "            f\"{INTERVIEWEE} shares relevant commentary, especially on topics like AI, openness, innovation, and Hugging Face.\"\n",
        "        ),\n",
        "        tools=[search_tool, web_rag_tool],\n",
        "        llm=DEFAULT_MODEL,\n",
        "        verbose=True,\n",
        "    )\n",
        "\n",
        "# === Create Discovery Task ===\n",
        "def create_discovery_task(agent):\n",
        "    return Task(\n",
        "        description=(\n",
        "            f\"Find up to 12 verified public sources (blogs, podcasts, company sites, media interviews, LinkedIn posts) \"\n",
        "            f\"that feature direct quotes, interview segments, or substantial remarks made by {INTERVIEWEE}.\\n\\n\"\n",
        "            f\"Requirements:\\n\"\n",
        "            \"- Do not include duplicate domains or sources.\\n\"\n",
        "            \"- Ensure each source includes a valid URL.\\n\"\n",
        "            \"- Briefly describe what kind of source it is and why it's relevant.\\n\"\n",
        "            \"- Use bullet format for output (up to 12 items max).\\n\\n\"\n",
        "            \"If fewer than 12 strong matches are found, return what you can.\"\n",
        "        ),\n",
        "        expected_output=(\n",
        "            \"A bullet-point list of up to 12 verified sources, each with a short description and plain-text URL. Example:\\n\"\n",
        "            \"- Forbes Africa article about Clément’s early business ventures and education. https://www.forbesafrica.com/... \\n\"\n",
        "            \"- Hugging Face blog post about open-source partnerships. https://huggingface.co/blog/...\"\n",
        "        ),\n",
        "        agent=agent,\n",
        "        output_file=SOURCE_OUTPUT_FILE\n",
        "    )\n",
        "\n",
        "# === Run Discovery Crew ===\n",
        "def run_discovery_crew():\n",
        "    agent = create_discovery_agent()\n",
        "    task = create_discovery_task(agent)\n",
        "\n",
        "    crew = Crew(\n",
        "        agents=[agent],\n",
        "        tasks=[task],\n",
        "        verbose=True\n",
        "    )\n",
        "    crew.kickoff()\n",
        "\n",
        "    print(f\"✅ Discovery complete. Verified sources saved to: {SOURCE_OUTPUT_FILE}\")\n",
        "\n",
        "# === Entry Point ===\n",
        "if __name__ == \"__main__\":\n",
        "    run_discovery_crew()\n"
      ],
      "metadata": {
        "id": "GbRNvrEOFWL1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Listing F-1: Agent-Guided Quote-Based Interview Builder\n",
        "This script uses `CrewAI` to simulate interview responses using publicly available quotes from a specified interviewee. It creates one agent per question, each tasked with locating quotes that plausibly address that question using tools like `Serper` and `WebsiteSearchTool`. The output consists of literal, cited responses stored in individual files. This method supports scalable, citation-respecting interview assembly using publicly sourced material without paraphrasing or generative content."
      ],
      "metadata": {
        "id": "zFGFWHwz3pdq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from crewai import Agent, Task, Crew\n",
        "from crewai_tools import SerperDevTool, WebsiteSearchTool\n",
        "\n",
        "# === Tools ===\n",
        "search_tool = SerperDevTool()\n",
        "web_rag_tool = WebsiteSearchTool()\n",
        "\n",
        "# === Create Output Directory ===\n",
        "OUTPUT_DIR = \"interview_outputs\"\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "# === Create Agents ===\n",
        "def create_question_agent(question, index):\n",
        "    return Agent(\n",
        "        role=f\"Interview Question Agent {index + 1}\",\n",
        "        goal=f\"Find a public source of text dialog where {INTERVIEWEE} answers a question similar to: '{question}'.\",\n",
        "        backstory=(\n",
        "            \"You are an AI researcher simulating interviews from quoted material from public sources. \"\n",
        "            \"Your job is to find quotes from public interviewee that come close to addressing the question.\"\n",
        "        ),\n",
        "        tools=[search_tool, web_rag_tool],\n",
        "        llm=DEFAULT_MODEL,\n",
        "        verbose=True,\n",
        "    )\n",
        "\n",
        "# === Create Tasks ===\n",
        "def create_question_task(question, index, agent):\n",
        "    file_path = os.path.join(OUTPUT_DIR, f\"Q{index + 1}-response.txt\")\n",
        "    return Task(\n",
        "        description=(\n",
        "            f\"Your task is to simulate a response to the following interview question for {INTERVIEWEE}.\\n\\n\"\n",
        "            f\"Question {index + 1}: {question}\\n\\n\"\n",
        "            f\"- Search for quotes from {INTERVIEWEE} that plausably answer this question or a closely related one.\\n\"\n",
        "            \"- Use only quotes from sourced interview — do not paraphrase or summarize.\\n\"\n",
        "            \"- Keep the answer between 50–200 words of quoted material if possible.\\n\"\n",
        "            \"- End the answer with source URL(s).\\n\"\n",
        "            \"- If no close quote exists, output 'No matching quote found.'\"\n",
        "        ),\n",
        "        expected_output=(\n",
        "            f\"The response must include:\\n\"\n",
        "            f\"1. **Question {index + 1}: {question}**\\n\"\n",
        "            f\"2. **Quoted Response from {INTERVIEWEE}** (only sourced quotes, no paraphrasing)\\n\"\n",
        "            f\"3. **Source URL(s)** (plain URLs only)\"\n",
        "        ),\n",
        "        agent=agent,\n",
        "        output_file=file_path\n",
        "    )\n",
        "\n",
        "# === Run Crew ===\n",
        "def run_interview_crew():\n",
        "    agents = [create_question_agent(q, i) for i, q in enumerate(INTERVIEW_QUESTIONS)]\n",
        "    tasks = [create_question_task(q, i, agent) for i, (q, agent) in enumerate(zip(INTERVIEW_QUESTIONS, agents))]\n",
        "\n",
        "    interview_crew = Crew(\n",
        "        agents=agents,\n",
        "        tasks=tasks,\n",
        "        verbose=True\n",
        "    )\n",
        "\n",
        "    interview_crew.kickoff()\n",
        "\n",
        "# === Entry Point ===\n",
        "if __name__ == \"__main__\":\n",
        "    run_interview_crew()\n"
      ],
      "metadata": {
        "id": "j-C723agWgIL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Listing F-1B: Shared-Agent Interview with Context-Aware Tasks\n",
        "This version **(still under development)** uses a single agent to generate quote-based responses to multiple interview questions. The process starts with a discovery phase that locates public interviews or transcripts featuring the interviewee. Each follow-up task is given that shared context to locate relevant quotes. The result is a modular, efficient way to simulate an interview entirely from public content, one file per question."
      ],
      "metadata": {
        "id": "PEjIw2q9JTB8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from crewai import Agent, Task, Crew\n",
        "from crewai_tools import SerperDevTool, WebsiteSearchTool, FileReadTool\n",
        "\n",
        "# === Config ===\n",
        "SOURCE_FILE = os.path.join(DIRECTORY, \"interview_sources.txt\")\n",
        "os.makedirs(DIRECTORY, exist_ok=True)\n",
        "\n",
        "# === Tools ===\n",
        "search_tool = SerperDevTool()\n",
        "web_rag_tool = WebsiteSearchTool()\n",
        "\n",
        "# === Discovery Agent ===\n",
        "def create_discovery_agent():\n",
        "    return Agent(\n",
        "        role=\"Interview Discovery Agent\",\n",
        "        goal=f\"Find public, text-based interview sources where {INTERVIEWEE} is quoted or interviewed directly.\",\n",
        "        backstory=\"You specialize in sourcing interview transcripts, podcasts, conference talks, or Q&A blogs featuring the subject.\",\n",
        "        tools=[search_tool],\n",
        "        llm=DEFAULT_MODEL,\n",
        "        verbose=True\n",
        "    )\n",
        "\n",
        "def create_discovery_task(agent):\n",
        "    return Task(\n",
        "        description=(\n",
        "            f\"Find up to 10 credible public sources that feature {INTERVIEWEE} being interviewed or quoted at length. \"\n",
        "            \"Prioritize interviews, podcasts, blog posts, YouTube transcripts, or conference talks. Do not include pages that simply mention them without direct speech.\"\n",
        "        ),\n",
        "        expected_output=(\n",
        "            f\"A list of up to 10 plain-text URLs, one per line, where {INTERVIEWEE} is quoted directly or being interviewed.\"\n",
        "        ),\n",
        "        agent=agent,\n",
        "        output_file=SOURCE_FILE\n",
        "    )\n",
        "\n",
        "# === Interview Agent ===\n",
        "def create_interview_agent():\n",
        "    return Agent(\n",
        "        role=\"Quote-Based Interview Agent\",\n",
        "        goal=f\"Answer each question using literal quotes from public sources featuring {INTERVIEWEE}.\",\n",
        "        backstory=\"You are conducting a structured interview using only verifiable quotes from prior interviews and public appearances.\",\n",
        "        tools=[FileReadTool(file_path=SOURCE_FILE)],\n",
        "        llm=DEFAULT_MODEL,\n",
        "        verbose=True\n",
        "    )\n",
        "\n",
        "def create_question_task(question, index, agent, context_tasks=None):\n",
        "    file_path = os.path.join(DIRECTORY, f\"Q{index + 1}-response.txt\")\n",
        "    return Task(\n",
        "        description=(\n",
        "            f\"Using only the provided public sources, generate a response to this interview question:\\n\\n\"\n",
        "            f\"**Question {index + 1}: {question}**\\n\\n\"\n",
        "            \"Use direct quotes that reasonably relate to the question (not necessarily exact matches). \"\n",
        "            \"Do not summarize or paraphrase. Keep the answer between 50–200 words of quoted material if available. \"\n",
        "            \"End with the URLs of the sources used. If no material fits, output 'No matching quote found.'\"\n",
        "        ),\n",
        "        expected_output=(\n",
        "            f\"**Question {index + 1}: {question}**\\n\\n\"\n",
        "            f\"**Quoted Response from {INTERVIEWEE}:**\\n\"\n",
        "            \"- One or more sourced quotes\\n\\n\"\n",
        "            \"**Source URL(s):**\\n\"\n",
        "            \"- One per line\"\n",
        "        ),\n",
        "        agent=agent,\n",
        "        output_file=file_path,\n",
        "        context=context_tasks if context_tasks else []\n",
        "    )\n",
        "\n",
        "# === Run Crew ===\n",
        "def run_interview_crew():\n",
        "    # Step 1: Discovery\n",
        "    discovery_agent = create_discovery_agent()\n",
        "    discovery_task = create_discovery_task(discovery_agent)\n",
        "    Crew(agents=[discovery_agent], tasks=[discovery_task], verbose=True).kickoff()\n",
        "\n",
        "    # Step 2: Interview responses with shared source context\n",
        "    interview_agent = create_interview_agent()\n",
        "    tasks = [\n",
        "        create_question_task(q, i, interview_agent, context_tasks=[discovery_task])\n",
        "        for i, q in enumerate(INTERVIEW_QUESTIONS)\n",
        "    ]\n",
        "\n",
        "    Crew(agents=[interview_agent], tasks=tasks, verbose=True).kickoff()\n",
        "\n",
        "# === Entry Point ===\n",
        "if __name__ == \"__main__\":\n",
        "    run_interview_crew()\n"
      ],
      "metadata": {
        "id": "ceiAniNuJRcY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Listing F-3: Markdown Interview Polisher from Q&A Files\n",
        "This post-processing pipeline converts a set of structured interview responses into a clean, flowing markdown transcript. It first concatenates individual question files, then uses a single CrewAI agent to reformat the content as a readable, conversational interview. Questions are rephrased for natural flow, and literal quotes are preserved in the answers. Source links are retained to ensure transparency. This is the final step for publishing polished, AI-assisted interviews."
      ],
      "metadata": {
        "id": "_UWPjXnje-fE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from crewai import Agent, Task, Crew\n",
        "from crewai_tools import FileReadTool\n",
        "\n",
        "# === Step 1: Concatenate Interview Files ===\n",
        "def concatenate_interview_files(input_dir, output_file):\n",
        "    files = sorted([\n",
        "        f for f in os.listdir(input_dir)\n",
        "        if f.startswith(\"Q\") and f.endswith(\"-response.txt\")\n",
        "    ])\n",
        "\n",
        "    with open(output_file, \"w\") as outfile:\n",
        "        for filename in files:\n",
        "            path = os.path.join(input_dir, filename)\n",
        "            with open(path, \"r\") as infile:\n",
        "                content = infile.read().strip()\n",
        "                outfile.write(content + \"\\n\\n\")\n",
        "\n",
        "    print(f\"✅ Concatenated {len(files)} files into {output_file}\")\n",
        "\n",
        "# === Step 2: Create Agent to Polish Interview ===\n",
        "def create_polishing_agent(input_file_path, interviewee_name):\n",
        "    return Agent(\n",
        "        role=\"Interview Editor Agent\",\n",
        "        goal=f\"Transform raw literal responses into a polished markdown interview with {interviewee_name}.\",\n",
        "        backstory=(\n",
        "            f\"You are an experienced editor and conversational designer. Your job is to turn structured question-and-answer content \"\n",
        "            f\"into a smooth, professional markdown interview. The subject of this interview is {interviewee_name}.\"\n",
        "        ),\n",
        "        tools=[FileReadTool(file_path=input_file_path)],\n",
        "        llm=DEFAULT_MODEL,\n",
        "        verbose=True,\n",
        "    )\n",
        "\n",
        "# === Step 3: Create Task ===\n",
        "def create_polishing_task(agent, interviewee_name):\n",
        "    return Task(\n",
        "        description=(\n",
        "            f\"You are editing an interview featuring {interviewee_name} from structured Q&A content.\\n\\n\"\n",
        "            \"Your job is to produce a smooth markdown-formatted interview transcript.\\n\\n\"\n",
        "            \"Instructions:\\n\"\n",
        "            \"- Rewrite the questions in a natural voice, as if interviewer were asking them live.\\n\"\n",
        "            \"- Do not paraphrase the answers. Use literal quotes from the source, placed in double quotes.\\n\"\n",
        "            \"- Each answer must include one or more source links from the original response file.\\n\"\n",
        "            f\"- Format as markdown with clear **Robo:** and **{interviewee_name}:** prefixes.\\n\"\n",
        "            \"- Maintain a flowing, intelligent, and conversational tone.\\n\"\n",
        "            \"- Include the following at the top of the file:\\n\"\n",
        "            f\"  - Markdown title (e.g., '# Interview with {interviewee_name}')\\n\"\n",
        "            \"  - Interviewee name\\n\"\n",
        "            \"  - Placeholder for date\\n\"\n",
        "            \"-  Ensure that all interview questions (Q1 to QN) are represented.\\n\"\n",
        "            \"-  Each answer must end with clearly marked source URL(s).\"\n",
        "        ),\n",
        "        expected_output=(\n",
        "            \"A complete markdown-formatted interview saved to the output file. It must include:\\n\"\n",
        "            \"- Title, interviewee name, date placeholder\\n\"\n",
        "            \"- Robo/Interviewer and interviewee dialogue\\n\"\n",
        "            \"- Literal quotes (not paraphrased) from the subject\\n\"\n",
        "            \"- One or more source URLs following each response\"\n",
        "        ),\n",
        "        agent=agent,\n",
        "        output_file=FINAL_OUTPUT\n",
        "    )\n",
        "\n",
        "# === Step 4: Assemble and Run Crew ===\n",
        "def run_interview_polishing_pipeline():\n",
        "    # Step 1: Concatenate source Q&A files\n",
        "    concatenate_interview_files(DIRECTORY, RAW_OUTPUT)\n",
        "\n",
        "    # Step 2: Create the polishing agent\n",
        "    agent = create_polishing_agent(RAW_OUTPUT, INTERVIEWEE)\n",
        "\n",
        "    # Step 3: Define the polishing task\n",
        "    task = create_polishing_task(agent, INTERVIEWEE)\n",
        "\n",
        "    # Step 4: Create and run the crew\n",
        "    crew = Crew(\n",
        "        agents=[agent],\n",
        "        tasks=[task],\n",
        "        verbose=True\n",
        "    )\n",
        "    crew.kickoff()\n",
        "\n",
        "    print(f\"✅ Final interview output saved to '{FINAL_OUTPUT}'\")\n",
        "\n",
        "# === Entry Point ===\n",
        "if __name__ == \"__main__\":\n",
        "    run_interview_polishing_pipeline()\n",
        "\n"
      ],
      "metadata": {
        "id": "lKzgavuwfFCb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}